.. currentmodule:: sklearn

.. _glossary:

=========================================
مسرد المصطلحات الشائعة وعناصر واجهة برمجة التطبيقات
=========================================

يأمل هذا المسرد في تمثيل الاصطلاحات الضمنية والصريحة
المطبقة في Scikit-learn وواجهة برمجة التطبيقات الخاصة به بشكل نهائي، مع توفير مرجع
للمستخدمين والمساهمين. يهدف إلى وصف المفاهيم وإما تفصيل
واجهة برمجة التطبيقات المقابلة لها أو ربطها بأجزاء أخرى ذات صلة من الوثائق
التي تقوم بذلك. من خلال ربط إدخالات المسرد من مرجع واجهة برمجة التطبيقات ودليل
المستخدم، قد نقلل من التكرار وعدم التناسق.

نبدأ بإدراج المفاهيم العامة (وأي مفاهيم لم تكن مناسبة في أي مكان آخر)، ولكن
يتم سرد مجموعات أكثر تحديدًا من المصطلحات ذات الصلة أدناه:
:ref:`glossary_estimator_types`، :ref:`glossary_target_types`،
:ref:`glossary_methods`، :ref:`glossary_parameters`،
:ref:`glossary_attributes`، :ref:`glossary_sample_props`.


مفاهيم عامة
================

.. glossary::

    1d
    مصفوفة أحادية البعد
        مصفوفة أحادية البعد. مصفوفة NumPy التي يبلغ طول ``.shape`` الخاص بها 1.
        متجه.

    2d
    مصفوفة ثنائية الأبعاد
        مصفوفة ثنائية الأبعاد. مصفوفة NumPy التي يبلغ طول ``.shape`` الخاص بها 2.
        غالبًا ما تُمثل مصفوفة.

    واجهة برمجة التطبيقات
        تشير إلى كل من الواجهات *المحددة* للمقدرات المُنفذة في
        Scikit-learn والاصطلاحات *المعممة* عبر أنواع
        المقدرات كما هو موضح في هذا المسرد و :ref:`نظرة عامة في وثائق
        المساهم <api_overview>`.

        تم توثيق الواجهات المحددة التي تُشكل واجهة برمجة التطبيقات العامة لـ Scikit-learn
        إلى حد كبير في :ref:`api_ref`. ومع ذلك، فإننا نعتبر أي شيء أقل رسمية
        كواجهة برمجة تطبيقات عامة إذا لم يبدأ أي من المُعرِّفات المطلوبة للوصول إليه
        بـ ``_``. نحاول عمومًا الحفاظ على :term:`التوافق مع الإصدارات السابقة` لجميع
        الكائنات في واجهة برمجة التطبيقات العامة.

        واجهة برمجة التطبيقات الخاصة، بما في ذلك الدوال والوحدات النمطية والأساليب التي تبدأ
        بـ ``_`` غير مضمونة لتكون مستقرة.


    يشبه المصفوفة
        تنسيق البيانات الأكثر شيوعًا *لإدخال* مقدرات ودوال Scikit-learn،
        يشبه المصفوفة هو أي كائن من نوع تنتج :func:`numpy.asarray` له
        مصفوفة ذات شكل مناسب (عادةً ما تكون أحادية أو ثنائية الأبعاد) من نوع بيانات
        مناسب (عادةً ما يكون رقميًا).

        يتضمن هذا:

        * مصفوفة numpy
        * قائمة من الأرقام
        * قائمة من قوائم الأرقام بطول k لطول ثابت k
        * :class:`pandas.DataFrame` مع جميع الأعمدة الرقمية
        * :class:`pandas.Series` رقمية

        يستبعد:

        * :term:`مصفوفة متفرقة`
        * مصفوفة متفرقة
        * مُكرِّر
        * مُولِّد

        لاحظ أن *ناتج* مقدرات ودوال scikit-learn (على سبيل المثال،
        التنبؤات) يجب أن يكون عمومًا مصفوفات أو مصفوفات متفرقة، أو قوائم
        منها (كما هو الحال في :term:`متعدد المخرجات` :class:`tree.DecisionTreeClassifier`
        ``predict_proba``). المقدر الذي يُعيد ``predict()`` الخاص به قائمة أو
        `pandas.Series` غير صالح.

    سمة
    السمات
        نستخدم السمة في الغالب للإشارة إلى كيفية تخزين معلومات النموذج في
        مقدر أثناء التوفيق. أي سمة عامة مخزنة في نموذج
        مقدر مطلوب أن تبدأ بحرف أبجدي وتنتهي بشرطة سفلية واحدة إذا تم تعيينها في
        :term:`fit` أو :term:`partial_fit`. هذه هي ما يتم توثيقه ضمن
        وثائق *السمات* الخاصة بالمقدر. المعلومات المخزنة في السمات
        عادةً ما تكون إما: إحصائيات كافية تُستخدم للتنبؤ أو
        التحويل؛ نواتج :term:`استنتاجية` مثل :term:`labels_` أو
        :term:`embedding_`؛ أو بيانات تشخيصية، مثل
        :term:`feature_importances_`.
        السمات الشائعة مُدرجة :ref:`أدناه <glossary_attributes>`.

        قد يكون للسمة العامة نفس اسم مُنشئ
        :term:`parameter`، مع إلحاق ``_``. يُستخدم هذا لتخزين
        إصدار تم التحقق من صحته أو تقديره من إدخال المستخدم. على سبيل المثال،
        يتم إنشاء :class:`decomposition.PCA` باستخدام معلمة ``n_components``.
        من هذا، جنبًا إلى جنب مع المعلمات الأخرى والبيانات،
        يُقدِّر PCA السمة ``n_components_``.

        قد يتم أيضًا تعيين سمات خاصة أخرى تُستخدم في التنبؤ/التحويل/إلخ.
        عند التوفيق. تبدأ هذه بشرطة سفلية واحدة ولا يُضمن
        أن تكون مستقرة للوصول العام.

        يجب أن تكون السمة العامة في نموذج مقدر لا ينتهي بشرطة سفلية
        هي القيمة المخزنة وغير المعدلة لـ ``__init__``
        :term:`parameter` التي تحمل نفس الاسم. نظرًا لهذا التكافؤ، يتم
        توثيق هذه ضمن وثائق *المعلمات* الخاصة بالمقدر.

    التوافق مع الإصدارات السابقة
        نحاول عمومًا الحفاظ على التوافق مع الإصدارات السابقة (أي يمكن تمديد
        الواجهات والسلوكيات ولكن لا يمكن تغييرها أو إزالتها) من إصدار
        إلى إصدار، لكن هذا يأتي مع بعض الاستثناءات:

        واجهة برمجة التطبيقات العامة فقط
            قد يتغير سلوك الكائنات التي يتم الوصول إليها من خلال المُعرِّفات الخاصة
            (تلك التي تبدأ بـ ``_``) بشكل تعسفي بين
            الإصدارات.
        كما هو موثق
            سنفترض عمومًا أن المستخدمين قد التزموا بأنواع
            المعلمات الموثقة ونطاقاتها. إذا طلبت الوثائق
            قائمة وأعطى المستخدم tuple، فإننا لا نضمن سلوكًا
            متسقًا من إصدار إلى إصدار.
        الإهمال
            قد تتغير السلوكيات بعد فترة :term:`إهمال`
            (عادة ما تكون إصدارين). يتم إصدار التحذيرات باستخدام وحدة
            :mod:`warnings` الخاصة بـ Python.
        وسيطات الكلمات الرئيسية
            قد نفترض أحيانًا أنه يتم تمرير جميع المعلمات الاختيارية (بخلاف X
            و y إلى :term:`fit` والأساليب المماثلة) كوسيطات ذات
            كلمات رئيسية فقط وقد يتم إعادة ترتيبها موضعيًا.
        إصلاحات الأخطاء والتحسينات
            قد تُغيِّر إصلاحات الأخطاء - وفي كثير من الأحيان - التحسينات سلوك
            المقدرات، بما في ذلك تنبؤات المقدر المُدرَّب على
            نفس البيانات و :term:`random_state`. عندما يحدث هذا،
            نحاول ملاحظته بوضوح في سجل التغيير.
        التسلسل
            لا نقدم أي ضمانات بأن تخليل المقدر في إصدار واحد
            سيسمح بإلغاء تخليله إلى نموذج مكافئ في
            الإصدار اللاحق. (بالنسبة للمقدرات في حزمة sklearn،
            نُصدر تحذيرًا عند محاولة إلغاء التخليل هذا، حتى لو
            حدث أنه يعمل.) انظر :ref:`persistence_limitations`.
        :func:`utils.estimator_checks.check_estimator`
            نحن نقدم ضمانات توافق محدودة مع الإصدارات السابقة لفحوصات
            المقدر: قد نضيف متطلبات إضافية على المقدرات
            التي تم اختبارها باستخدام هذه الدالة، عادةً عندما كان يتم افتراضها بشكل غير رسمي
            ولكن لم يتم اختبارها رسميًا.


        على الرغم من هذا العقد غير الرسمي مع مستخدمينا، يتم توفير البرنامج
        كما هو، كما هو مذكور في الترخيص. عندما يُسبب إصدار عن غير قصد
        تغييرات غير متوافقة مع الإصدارات السابقة، تُعرف هذه
        باسم انحدارات البرامج.

    قابل للاستدعاء
        دالة أو فئة أو كائن ينفذ أسلوب ``__call__``؛ أي شيء يُعيد True عندما تكون وسيطة `callable()
        <https://docs.python.org/3/library/functions.html#callable>`_.

    ميزة فئوية
        الميزة الفئوية أو الاسمية هي الميزة التي تحتوي على
        مجموعة محدودة من القيم المنفصلة عبر مجموعة البيانات.
        يتم تمثيلها عادةً كأعمدة من الأعداد الصحيحة أو
        السلاسل. سيتم رفض السلاسل من قبل معظم مقدرات scikit-learn،
        وسيتم التعامل مع الأعداد الصحيحة على أنها ترتيبية أو
        قائمة على العد. للاستخدام مع معظم المقدرات،
        يجب تشفير المتغيرات الفئوية بشكل أحادي الاتجاه. تشمل الاستثناءات البارزة
        النماذج المستندة إلى الشجرة مثل الغابات العشوائية ونماذج التعزيز المتدرج
        التي غالبًا ما تعمل بشكل أفضل وأسرع مع المتغيرات الفئوية المُرمَّزة بالأعداد الصحيحة.
        :class:`~sklearn.preprocessing.OrdinalEncoder` يساعد في تشفير
        الميزات الفئوية ذات القيمة السلسلة كأعداد صحيحة ترتيبية، و
        :class:`~sklearn.preprocessing.OneHotEncoder` يمكن استخدامه لـ
        تشفير الميزات الفئوية بشكل أحادي الاتجاه.
        انظر أيضًا :ref:`preprocessing_categorical_features` وحزمة
        `categorical-encoding
        <https://github.com/scikit-learn-contrib/category_encoders>`_
        للحصول على أدوات تتعلق بتشفير الميزات الفئوية.


    استنساخ
    مستنسخ
        لنسخ :term:`نموذج مقدر` وإنشاء نموذج جديد باستخدام
        :term:`معلمات` متطابقة، ولكن بدون أي :term:`سمات` مناسبة،
        باستخدام :func:`~sklearn.base.clone`.

        عندما يتم استدعاء ``fit``، عادةً ما يقوم :term:`مقدر التعريف التلوي` باستنساخ
        نموذج مقدر مُغلَّف قبل ملاءمة النموذج المستنسخ.
        (تشمل الاستثناءات، لأسباب تتعلق بالإصدارات القديمة،
        :class:`~pipeline.Pipeline` و
        :class:`~pipeline.FeatureUnion`.)

        إذا كانت معلمة `random_state` الخاصة بالمقدر عددًا صحيحًا (أو إذا
        لم يكن لدى المقدر معلمة `random_state`)، فسيتم إرجاع
        *استنساخ دقيق*: سيعطي الاستنساخ والمقدر الأصلي نفس
        النتائج تمامًا. خلاف ذلك، يتم إرجاع *استنساخ إحصائي*: قد ينتج الاستنساخ
        نتائج مختلفة عن المقدر الأصلي. يمكن العثور على مزيد من
        التفاصيل في :ref:`randomness`.

    اختبارات شائعة
        يشير هذا إلى الاختبارات التي يتم إجراؤها على كل فئة مقدر تقريبًا في
        Scikit-learn للتحقق من امتثالها لاتفاقيات واجهة برمجة التطبيقات الأساسية. إنها
        متاحة للاستخدام الخارجي من خلال
        :func:`utils.estimator_checks.check_estimator`، مع وجود معظم
        التنفيذ في ``sklearn/utils/estimator_checks.py``.


        ملاحظة: بعض الاستثناءات لنظام الاختبار الشائع مُرمَّزة حاليًا
        في المكتبة، لكننا نأمل في استبدال هذا عن طريق وضع علامة على
        السلوكيات الاستثنائية على المقدر باستخدام :term:`علامات المقدر` الدلالية.


    التوفيق المتبادل
        طريقة إعادة أخذ عينات تقسم البيانات بشكل متكرر إلى مجموعات فرعية متنافية بشكل متبادل
        لملاءمة مرحلتين. خلال المرحلة الأولى، تُمكِّن المجموعات الفرعية
        المتنافية بشكل متبادل من حساب التنبؤات أو التحويلات على البيانات التي لم
        يتم رؤيتها أثناء التدريب. ثم يتم استخدام البيانات المحسوبة
        في المرحلة الثانية. الهدف هو تجنب وجود أي
        تكيف زائد في المرحلة الأولى يُسبب تحيزًا في توزيع بيانات الإدخال
        للمرحلة الثانية.
        للحصول على أمثلة على استخدامه، انظر: :class:`~preprocessing.TargetEncoder`،
        :class:`~ensemble.StackingClassifier`،
        :class:`~ensemble.StackingRegressor` و
        :class:`~calibration.CalibratedClassifierCV`.


    التحقق المتبادل
        طريقة إعادة أخذ عينات تقسم البيانات بشكل متكرر إلى مجموعات فرعية "تدريب" و "اختبار"
        متنافية بشكل متبادل بحيث يمكن تقييم أداء النموذج على البيانات غير المرئية. يحافظ هذا على البيانات
        ويتجنب الحاجة إلى استبعاد مجموعة بيانات "التحقق من الصحة" ويُراعي التباين حيث يتم
        إجراء جولات متعددة من التحقق المتبادل بشكل عام.
        انظر :ref:`دليل المستخدم <cross_validation>` لمزيد من التفاصيل.


    الإهمال
        نستخدم الإهمال لانتهاك ضمانات :term:`التوافق مع الإصدارات السابقة` الخاصة بنا ببطء،
        عادةً لـ:

        * تغيير القيمة الافتراضية لمعلمة؛ أو
        * إزالة معلمة أو سمة أو أسلوب أو فئة، إلخ.


        سنُصدر عادةً تحذيرًا عند استخدام عنصر مُهمَل،
        على الرغم من أنه قد تكون هناك قيود على هذا. على سبيل المثال، سنطرح
        تحذيرًا عندما يُعيِّن شخص ما معلمة تم إهمالها، ولكن
        قد لا نفعل ذلك عند الوصول إلى سمة هذه المعلمة في نموذج
        المقدر.

        انظر :ref:`دليل المساهمين <contributing_deprecation>`.


    الأبعاد
        قد يُستخدم للإشارة إلى عدد :term:`الميزات` (أي
        :term:`n_features`)، أو الأعمدة في مصفوفة ميزات ثنائية الأبعاد.
        ومع ذلك، تُستخدم الأبعاد أيضًا للإشارة إلى طول شكل مصفوفة NumPy،
        مما يميز المصفوفة أحادية الأبعاد عن المصفوفة ثنائية الأبعاد.


    سلسلة وثائق
        الوثائق المُضمنة لوحدة نمطية أو فئة أو دالة، إلخ، عادةً
        في التعليمات البرمجية كسلسلة في بداية تعريف الكائن، و
        يمكن الوصول إليها كسمة ``__doc__`` للكائن.

        نحاول الالتزام بـ `PEP257
        <https://www.python.org/dev/peps/pep-0257/>`_، ونتبع اتفاقيات `NumpyDoc
        <https://numpydoc.readthedocs.io/en/latest/format.html>`_.


    شرطة سفلية مزدوجة
    ترميز الشرطة السفلية المزدوجة
        عند تحديد أسماء المعلمات للمقدرات المتداخلة، قد يتم
        استخدام ``__`` للفصل بين الأصل والفرع في بعض السياقات. الاستخدام الأكثر
        شيوعًا هو عند تعيين المعلمات من خلال مقدر تعريف تلوي باستخدام
        :term:`set_params` وبالتالي في تحديد شبكة بحث في
        :ref:`بحث المعلمة <grid_search>`. انظر :term:`parameter`.
        يُستخدم أيضًا في :meth:`pipeline.Pipeline.fit` لتمرير
        :term:`خصائص العينة` إلى أساليب ``fit`` الخاصة بالمقدرات في
        خط الأنابيب.


    نوع البيانات
    نوع البيانات
        تفترض مصفوفات NumPy نوع بيانات متجانس في كل مكان، متاح في
        سمة ``.dtype`` لمصفوفة (أو مصفوفة متفرقة). نفترض عمومًا أنواع بيانات
        بسيطة لبيانات scikit-learn: عدد عشري أو عدد صحيح.
        قد ندعم أنواع بيانات الكائن أو السلسلة للمصفوفات قبل التشفير
        أو التحويل إلى متجه. لا تعمل المقدرات الخاصة بنا مع مصفوفات الهياكل، على
        سبيل المثال.

        يمكن أن تقدم وثائقنا أحيانًا معلومات حول دقة نوع البيانات،
        على سبيل المثال `np.int32`، `np.int64`، إلخ. عندما يتم توفير الدقة،
        فإنها تشير إلى نوع بيانات NumPy. إذا تم استخدام دقة عشوائية،
        فستشير الوثائق إلى نوع البيانات `integer` أو `floating`.
        لاحظ أنه في هذه الحالة، يمكن أن تكون الدقة معتمدة على النظام الأساسي.
        يشير نوع البيانات `numeric` إلى قبول كل من `integer` و `floating`.


        عندما يتعلق الأمر بالاختيار بين نوع البيانات 64 بت (أي `np.float64` و
        `np.int64`) ونوع البيانات 32 بت (أي `np.float32` و `np.int32`)،
        فإن الأمر يتعلق بالمفاضلة بين الكفاءة والدقة. تُقدم أنواع 64 بت
        نتائج أكثر دقة نظرًا لخطأ النقطة العائمة الأقل، لكنها تتطلب المزيد من موارد
        الحوسبة، مما يؤدي إلى عمليات أبطأ وزيادة استخدام الذاكرة. على النقيض من ذلك،
        تعد أنواع 32 بت بتحسين سرعة التشغيل وتقليل استهلاك الذاكرة، ولكن
        تُسبب خطأ أكبر في النقطة العائمة. يعتمد تحسين الكفاءة على
        تحسين المستوى الأدنى مثل التحويل إلى متجه،
        إرسال تعليمات متعددة واحدة (SIMD)، أو تحسين ذاكرة التخزين المؤقت ولكن
        بشكل حاسم على توافق الخوارزمية المستخدمة.


        على وجه التحديد، يجب أن يُراعي اختيار الدقة ما إذا كانت
        الخوارزمية المستخدمة يمكنها الاستفادة بفعالية من `np.float32`. بعض
        الخوارزميات، وخاصة أساليب التصغير، مُرمَّزة حصريًا
        لـ `np.float64`، مما يعني أنه حتى لو تم تمرير `np.float32`،
        فإنها تُشغِّل تحويلًا تلقائيًا مرة أخرى إلى `np.float64`. هذا لا
        يلغي فقط وفورات الحساب المقصودة ولكنه يُسبب أيضًا
        نفقات عامة إضافية، مما يجعل العمليات مع `np.float32` أبطأ بشكل غير متوقع
        وأكثر كثافة في استخدام الذاكرة بسبب خطوة التحويل الإضافية هذه.


    كتابة البطة
        نحاول تطبيق `كتابة البطة
        <https://en.wikipedia.org/wiki/Duck_typing>`_ لتحديد كيفية
        التعامل مع بعض قيم الإدخال (على سبيل المثال، التحقق مما إذا كان مقدر معين
        هو مصنف). أي أننا نتجنب استخدام ``isinstance`` حيثما أمكن ذلك،
        ونعتمد على وجود أو غياب السمات لتحديد سلوك
        الكائن. هناك حاجة إلى بعض الفروق الدقيقة عند اتباع هذا
        النهج:

        * بالنسبة لبعض المقدرات، قد لا تتوفر سمة إلا بمجرد
          :term:`ملاءمتها`. على سبيل المثال، لا يمكننا تحديد ما إذا كان
          :term:`predict_proba` متاحًا مسبقًا في بحث شبكي حيث تتضمن الشبكة
          التناوب بين متنبئ احتمالي وغير احتمالي في الخطوة الأخيرة من خط
          الأنابيب. في ما يلي، لا يمكننا تحديد ما إذا كان ``clf`` احتماليًا إلا بعد
          ملاءمته على بعض البيانات::

              >>> from sklearn.model_selection import GridSearchCV
              >>> from sklearn.linear_model import SGDClassifier
              >>> clf = GridSearchCV(SGDClassifier(),
              ...                    param_grid={'loss': ['log_loss', 'hinge']})

          هذا يعني أنه لا يمكننا التحقق من السمات المكتوبة بالبط إلا بعد
          الملاءمة، وأنه يجب أن نكون حريصين على جعل :term:`مقدرات التعريف التلوي`
          تقدم فقط سمات وفقًا لحالة المقدر الأساسي بعد الملاءمة.

        * التحقق مما إذا كانت سمة موجودة (باستخدام ``hasattr``) بشكل عام
          مكلف مثل الحصول على السمة (``getattr`` أو ترميز
          النقطة). في بعض الحالات، قد يكون الحصول على السمة مكلفًا بالفعل (على سبيل المثال،
          بالنسبة لبعض تطبيقات
          :term:`feature_importances_`، مما قد يشير إلى أن هذا عيب في تصميم واجهة برمجة التطبيقات).
          لذا، يجب تجنب الشفرة التي تقوم بـ ``hasattr`` متبوعًا بـ ``getattr``؛ يُفضل
          ``getattr`` داخل كتلة try-except.

        * لتحديد بعض جوانب توقعات المقدر أو
          دعمه لميزة ما، نستخدم :term:`علامات المقدر` بدلاً من
          كتابة البطة.

    الإيقاف المبكر
        يتمثل هذا في إيقاف أسلوب التحسين التكراري قبل
        تقارب فقدان التدريب، لتجنب التكيف الزائد. يتم ذلك
        عمومًا عن طريق مراقبة درجة التعميم على مجموعة التحقق من الصحة. عند
        توفرها، يتم تنشيطها من خلال المعلمة
        ``early_stopping`` أو عن طريق تعيين :term:`n_iter_no_change` موجب.


    نموذج مقدر
        نستخدم هذا المصطلح أحيانًا للتمييز بين فئة :term:`مقدر`
        ونموذج تم إنشاؤه. على سبيل المثال، في ما يلي،
        ``cls`` هي فئة مقدر، بينما ``est1`` و ``est2`` هما
        نماذج::

            cls = RandomForestClassifier
            est1 = cls()
            est2 = RandomForestClassifier()

    أمثلة
        نحاول تقديم أمثلة على الاستخدام الأساسي لمعظم الدوال و
        الفئات في واجهة برمجة التطبيقات:

        * كاختبارات وثائق في سلاسل الوثائق الخاصة بها (أي داخل شفرة مكتبة ``sklearn/``
          نفسها).
        * كأمثلة في :ref:`معرض الأمثلة <general_examples>`
          المعروضة (باستخدام `sphinx-gallery
          <https://sphinx-gallery.readthedocs.io/>`_) من البرامج النصية في
          دليل ``examples/``، مع توضيح الميزات أو المعلمات الرئيسية
          للمقدر/الدالة. يجب أيضًا الرجوع إلى هذه من
          دليل المستخدم.
        * أحيانًا في :ref:`دليل المستخدم <user_guide>` (مبني من ``doc/``)
          جنبًا إلى جنب مع وصف فني للمقدر.


    تجريبي
        أداة تجريبية قابلة للاستخدام بالفعل، لكن واجهة برمجة التطبيقات العامة الخاصة بها، مثل
        قيم المعلمات الافتراضية أو السمات الملائمة، لا تزال عرضة
        للتغيير في الإصدارات المستقبلية بدون سياسة تحذير :term:`الإهمال` المعتادة.

    مقياس التقييم
    مقاييس التقييم
        تقدم مقاييس التقييم مقياسًا لمدى جودة أداء النموذج. قد
        نستخدم هذا المصطلح على وجه التحديد للإشارة إلى الدوال في :mod:`~sklearn.metrics`
        (مع تجاهل :mod:`~sklearn.metrics.pairwise`)، على عكس
        أسلوب :term:`score` وواجهة برمجة تطبيقات :term:`scoring` المستخدمة في التحقق المتبادل.
        انظر :ref:`model_evaluation`.

        عادةً ما تقبل هذه الدوال حقيقة أساسية (أو البيانات الأولية
        حيث يُقيِّم المقياس التجميع بدون حقيقة أساسية) وتنبؤًا، سواء كان
        ناتج :term:`predict` (``y_pred``)،
        أو :term:`predict_proba` (``y_proba``)، أو دالة تسجيل عشوائية
        بما في ذلك :term:`decision_function` (``y_score``).
        عادةً ما يتم تسمية الدوال بحيث تنتهي بـ ``_score`` إذا كانت الدرجة الأكبر
        تشير إلى نموذج أفضل، و ``_loss`` إذا كانت الدرجة الأقل
        تشير إلى نموذج أفضل. هذا التنوع في الواجهة يُحفز
        واجهة برمجة تطبيقات التسجيل.

        لاحظ أن بعض المقدرات يمكنها حساب مقاييس غير مدرجة
        في :mod:`~sklearn.metrics` وهي خاصة بالمقدر، ولا سيما احتمالات
        النموذج.


    علامات المقدر
        ميزة مقترحة (على سبيل المثال :issue:`8022`) يتم من خلالها وصف إمكانيات المقدر
        من خلال مجموعة من العلامات الدلالية. سيُمكِّن هذا بعض السلوكيات في وقت التشغيل
        بناءً على فحص المقدر، ولكنه
        يسمح أيضًا باختبار كل مقدر من أجل الثوابت المناسبة
        مع استثنائه من :term:`الاختبارات الشائعة` الأخرى.

        يتم تحديد بعض جوانب علامات المقدر حاليًا من خلال
        :term:`كتابة البطة` للأساليب مثل ``predict_proba`` ومن خلال
        بعض السمات الخاصة على كائنات المقدر:

        .. glossary::

            ``_estimator_type``
                تُحدد هذه السمة ذات القيمة السلسلة المقدر على أنه
                مصنف أو مقدر انحدار، إلخ. يتم تعيينها بواسطة mixins مثل
                :class:`base.ClassifierMixin`، ولكنها تحتاج إلى اعتماد أكثر وضوحًا
                على :term:`مقدر التعريف التلوي`. يجب عادةً فحص قيمتها
                عن طريق مساعد مثل :func:`base.is_classifier`.

        لمزيد من المعلومات التفصيلية، انظر :ref:`estimator_tags`.

    ميزة
    الميزات
    متجه الميزات
        بشكل تجريدي، الميزة هي دالة (بمعناها الرياضي)
        تربط كائنًا تم أخذ عينة منه بكمية رقمية أو فئوية.
        يُستخدم "الميزة" أيضًا بشكل شائع للإشارة إلى هذه الكميات، كونها العناصر
        الفردية لمتجه يُمثل عينة. في مصفوفة البيانات، يتم تمثيل الميزات
        كأعمدة: يحتوي كل عمود على نتيجة تطبيق دالة الميزة على مجموعة من
        العينات.


        في أماكن أخرى، تُعرف الميزات باسم السمات أو المتنبئات أو المُتغيرات
        المستقلة.

        تفترض جميع المقدرات تقريبًا في scikit-learn أن الميزات رقمية و
        محدودة وغير مفقودة، حتى عندما يكون لها مجالات وتوزيعات دلالية
        متميزة (فئوية، ترتيبية، قائمة على العد،
        ذات قيمة حقيقية، فاصل). انظر أيضًا :term:`ميزة فئوية` و
        :term:`قيم مفقودة`.

        يشير ``n_features`` إلى عدد الميزات في مجموعة البيانات.


    الملاءمة
        استدعاء :term:`fit` (أو :term:`fit_transform`، :term:`fit_predict`،
        إلخ) على مقدر.

    ملائم
        حالة المقدر بعد :term:`الملاءمة`.

        لا يوجد إجراء تقليدي للتحقق مما إذا كان المقدر
        ملائمًا. ومع ذلك، فإن المقدر غير الملائم:

        * يجب أن يطرح :class:`exceptions.NotFittedError` عند استدعاء أسلوب التنبؤ
          (:term:`predict`، :term:`transform`، إلخ).
          (يُستخدم :func:`utils.validation.check_is_fitted` داخليًا
          لهذا الغرض.)
        * يجب ألا يحتوي على أي :term:`سمات` تبدأ بحرف أبجدي
          وتنتهي بشرطة سفلية. (لاحظ أن واصف
          السمة قد لا يزال موجودًا في الفئة، ولكن يجب أن
          يُعيد hasattr القيمة False)

    دالة
        نحن نقدم واجهات دوال مخصصة للعديد من الخوارزميات، بينما
        تقدم فئات :term:`المقدر` واجهة أكثر اتساقًا.

        على وجه الخصوص، قد يقدم Scikit-learn واجهة دالة تُلائم
        نموذجًا لبعض البيانات وتُعيد معلمات النموذج التي تم تعلمها، كما هو الحال في
        :func:`linear_model.enet_path`. بالنسبة للنماذج الاستنتاجية، يُعيد هذا أيضًا
        تضمين أو تسميات الكتلة، كما هو الحال في
        :func:`manifold.spectral_embedding` أو :func:`cluster.dbscan`. تقدم العديد
        من محولات المعالجة المسبقة أيضًا واجهة دالة، تُشبه
        استدعاء :term:`fit_transform`، كما هو الحال في
        :func:`preprocessing.maxabs_scale`. يجب أن يكون المستخدمون حريصين على تجنب
        :term:`تسرب البيانات` عند استخدام هذه
        الدوال المكافئة لـ ``fit_transform``.

        ليس لدينا سياسة صارمة بشأن متى نقدم أو متى لا نقدم
        أشكال دوال للمقدرات، ولكن يجب على المسؤولين عن الصيانة مراعاة
        الاتساق مع الواجهات الحالية، وما إذا كان توفير دالة
        سيؤدي إلى تضليل المستخدمين عن أفضل الممارسات (فيما يتعلق بتسرب البيانات،
        إلخ.)

    معرض
        انظر :term:`أمثلة`.

    معلمة فائقة
        انظر :term:`معلمة`.


    الإسناد
        تتطلب معظم خوارزميات التعلم الآلي ألا تحتوي مدخلاتها على
        :term:`قيم مفقودة`، ولن تعمل إذا تم انتهاك هذا الشرط.
        يُشار إلى الخوارزميات التي تحاول ملء (أو إسناد) القيم المفقودة
        باسم خوارزميات الإسناد.

    قابل للفهرسة
        :term:`يشبه المصفوفة`، :term:`مصفوفة متفرقة`، pandas DataFrame أو
        متسلسلة (عادةً ما تكون قائمة).


    الاستقراء
    استنتاجي
        التعلم الآلي الاستنتاجي (على النقيض من :term:`الاستنتاجي`) يبني نموذجًا لبعض البيانات
        التي يمكن تطبيقها بعد ذلك على نماذج جديدة.
        معظم المقدرات في Scikit-learn استنتاجية، ولديها أساليب :term:`predict`
        و/أو :term:`transform`.


    joblib
        مكتبة Python (https://joblib.readthedocs.io) تُستخدم في Scikit-learn لـ
        تسهيل التوازي البسيط والتخزين المؤقت. يركز Joblib على
        العمل بكفاءة مع مصفوفات numpy، مثل من خلال استخدام
        :term:`تخطيط الذاكرة`. انظر :ref:`parallelism` لمزيد من
        المعلومات.

    مصفوفة مؤشر التسمية
    مصفوفات مؤشر متعددة التسميات
        التنسيق المستخدم لتمثيل بيانات متعددة التسميات، حيث يتوافق كل صف من مصفوفة ثنائية الأبعاد
        أو مصفوفة متفرقة مع عينة، يتوافق كل عمود
        مع فئة، وكل عنصر هو 1 إذا تم تسمية العينة
        بالفئة و 0 إن لم يكن.

    تسرب
    تسرب البيانات
        مشكلة في التحقق المتبادل حيث يمكن
        المبالغة في تقدير أداء التعميم حيث تم تضمين معرفة بيانات الاختبار عن غير قصد
        في تدريب نموذج. هذا خطر، على سبيل المثال، عند
        تطبيق :term:`محول` على مجموعة بيانات بأكملها بدلاً من
        كل جزء تدريب في تقسيم التحقق المتبادل.


        نهدف إلى توفير واجهات (مثل :mod:`~sklearn.pipeline` و
        :mod:`~sklearn.model_selection`) تحمي المستخدم من تسرب البيانات.


    تخطيط الذاكرة
        استراتيجية كفاءة الذاكرة التي تحتفظ بالبيانات على القرص بدلاً من
        نسخها في الذاكرة الرئيسية. يمكن إنشاء خرائط الذاكرة للمصفوفات
        التي يمكن قراءتها أو كتابتها أو كليهما، باستخدام :obj:`numpy.memmap`. عند
        استخدام :term:`joblib` لموازاة العمليات في Scikit-learn، قد
        يقوم تلقائيًا بتخطيط المصفوفات الكبيرة لتقليل النفقات العامة لازدواجية
        الذاكرة في المعالجة المتعددة.


    قيم مفقودة
        لا تعمل معظم مقدرات Scikit-learn مع القيم المفقودة. عندما تعمل
        (على سبيل المثال، في :class:`impute.SimpleImputer`)، فإن NaN هو التمثيل
        المفضل للقيم المفقودة في المصفوفات العشرية. إذا كانت المصفوفة
        ذات نوع بيانات عدد صحيح، فلا يمكن تمثيل NaN. لهذا السبب، ندعم
        تحديد قيمة ``missing_values`` أخرى عند :term:`الإسناد` أو
        يمكن إجراء التعلم في مساحة عدد صحيح.
        :term:`البيانات غير المُعلَّمة <unlabeled data>` هي حالة خاصة للقيم المفقودة
        في :term:`الهدف`.

    ``n_features``
        عدد :term:`الميزات`.


    ``n_outputs``
        عدد :term:`المخرجات` في :term:`الهدف`.


    ``n_samples``
        عدد :term:`العينات`.


    ``n_targets``
        مرادف لـ:term:`n_outputs`.

    وثائق سردية
        اسم مستعار لـ :ref:`دليل المستخدم <user_guide>`، أي الوثائق المكتوبة
        في ``doc/modules/``. على عكس :ref:`مرجع واجهة برمجة التطبيقات <api_ref>` المقدم
        من خلال سلاسل الوثائق، يهدف دليل المستخدم إلى:

        * تجميع الأدوات التي يوفرها Scikit-learn معًا بشكل موضوعي أو من حيث
          الاستخدام؛
        * تحفيز سبب استخدام شخص ما لأداة معينة، غالبًا من خلال
          المقارنة؛
        * تقديم أوصاف بديهية وفنية للأدوات؛
        * تقديم أو ربط :term:`أمثلة` لاستخدام الميزات الرئيسية للأداة.

    np
        اختصار لـ Numpy نظرًا لعبارة الاستيراد التقليدية::

            import numpy as np

    التعلم عبر الإنترنت
        حيث يتم تحديث النموذج بشكل متكرر عن طريق تلقي كل دفعة من :term:`الأهداف`
        الحقيقية الأساسية بعد وقت قصير من إجراء تنبؤات على الدفعة المقابلة
        من البيانات. بطبيعة الحال، يجب أن يكون النموذج قابلاً للاستخدام للتنبؤ
        بعد كل دفعة. انظر :term:`partial_fit`.

    خارج النواة
        استراتيجية كفاءة حيث لا يتم تخزين جميع البيانات في الذاكرة الرئيسية
        مرة واحدة، عادةً عن طريق إجراء التعلم على دفعات من البيانات. انظر
        :term:`partial_fit`.


    المخرجات
        متغيرات قياسية/فئوية فردية لكل عينة في
        :term:`الهدف`. على سبيل المثال، في التصنيف متعدد التسميات، يتوافق كل
        تسمية ممكنة مع ناتج ثنائي. وتسمى أيضًا *الاستجابات* أو
        *المهام* أو *الأهداف*.
        انظر :term:`multiclass multioutput` و :term:`continuous multioutput`.

    زوج
        tuple بطول اثنين.

    معلمة
    المعلمات
        نستخدم *المعلمة* في الغالب للإشارة إلى جوانب المقدر التي
        يمكن تحديدها في بنائه. على سبيل المثال، ``max_depth`` و
        ``random_state`` هما معلمات :class:`~ensemble.RandomForestClassifier`.
        يتم تخزين المعلمات الخاصة بمُنشئ المقدر دون تعديل كـ
        سمات على نموذج المقدر، وتبدأ تقليديًا بحرف
        أبجدي وتنتهي بحرف أبجدي رقمي. يتم وصف معلمات مُنشئ
        كل مقدر في سلسلة وثائق المقدر.

        لا نستخدم المعلمات بالمعنى الإحصائي، حيث تكون المعلمات
        هي القيم التي تُحدد نموذجًا ويمكن تقديرها من البيانات. ما
        نسميه معلمات قد يكون ما يسميه الإحصائيون المعلمات الفائقة للنموذج:
        جوانب لتكوين بنية النموذج التي غالبًا لا يتم
        تعلمها مباشرةً من البيانات. ومع ذلك، تُستخدم المعلمات الخاصة بنا أيضًا لـ
        وصف عمليات النمذجة التي لا تؤثر على النموذج الذي تم تعلمه، مثل
        :term:`n_jobs` للتحكم في التوازي.

        عند الحديث عن معلمات :term:`مقدر التعريف التلوي`، قد
        نقوم أيضًا بتضمين معلمات المقدرات التي يغلِّفها
        مقدر التعريف التلوي. عادةً، يتم الإشارة إلى هذه المعلمات المتداخلة
        باستخدام :term:`شرطة سفلية مزدوجة` (``__``) للفصل بين
        المقدر كمعلمة ومعلمته. وبالتالي، ``clf =
        BaggingClassifier(estimator=DecisionTreeClassifier(max_depth=3))``
        لديه معلمة عميقة ``estimator__max_depth`` بقيمة ``3``،
        والتي يمكن الوصول إليها باستخدام ``clf.estimator.max_depth`` أو
        ``clf.get_params()['estimator__max_depth']``.


        يمكن استرداد قائمة المعلمات وقيمها الحالية من
        :term:`نموذج مقدر` باستخدام أسلوب :term:`get_params` الخاص به.

        بين الإنشاء والملاءمة، يمكن تعديل المعلمات باستخدام
        :term:`set_params`. لتمكين هذا، لا يتم عادةً
        التحقق من صحة المعلمات أو تغييرها عند إنشاء المقدر، أو عند تعيين كل
        معلمة. يتم إجراء التحقق من صحة المعلمة عند استدعاء :term:`fit`.

        المعلمات الشائعة مُدرجة :ref:`أدناه <glossary_parameters>`.

    مقياس زوجي
    مقاييس زوجية
        بمعناه الواسع، يُحدد المقياس الزوجي دالة لقياس
        التشابه أو الاختلاف بين عينتين (مع تمثيل كل منهما عادةً
        كـ :term:`متجه ميزة`). نحن نقدم بشكل خاص
        تطبيقات لمقاييس المسافة (بالإضافة إلى المقاييس غير الصحيحة مثل
        مسافة جيب التمام) من خلال :func:`metrics.pairwise_distances`، و
        دوال النواة (فئة مقيدة من دوال التشابه) في
        :func:`metrics.pairwise.pairwise_kernels`. يمكن لهذه حساب مصفوفات المسافة الزوجية
        المتماثلة وبالتالي تخزين البيانات بشكل زائد عن الحاجة.

        انظر أيضًا :term:`محسوب مسبقًا` و :term:`مقياس`.


        لاحظ أنه بالنسبة لمعظم مقاييس المسافة، نعتمد على التطبيقات من
        :mod:`scipy.spatial.distance`، ولكن قد نعيد التنفيذ من أجل الكفاءة في
        سياقنا. تُستخدم واجهة :class:`metrics.DistanceMetric` لتنفيذ
        مقاييس المسافة للتكامل مع بحث الجيران الفعال.


    pd
        اختصار لـ `Pandas <https://pandas.pydata.org>`_ نظرًا لعبارة
        الاستيراد التقليدية::

            import pandas as pd

    محسوب مسبقًا
        حيث تعتمد الخوارزميات على :term:`المقاييس الزوجية`، ويمكن حسابها
        من المقاييس الزوجية وحدها، غالبًا ما نسمح للمستخدم بتحديد
        أن :term:`X` المقدم موجود بالفعل في مساحة (عدم) التشابه الزوجية،
        بدلاً من مساحة الميزات. أي أنه عند تمريره إلى
        :term:`fit`، فهو مصفوفة مربعة متماثلة، مع كل متجه
        يشير إلى (عدم) التشابه مع كل عينة، وعندما يتم تمريره إلى
        أساليب التنبؤ/التحويل، يتوافق كل صف مع عينة اختبار
        وكل عمود مع عينة تدريب.


        عادةً ما تتم الإشارة إلى استخدام X المحسوب مسبقًا عن طريق تعيين معلمة ``metric``
        أو ``affinity`` أو ``kernel`` إلى السلسلة "precomputed". إذا
        كان هذا هو الحال، فيجب على المقدر تعيين علامة المقدر `pairwise`
        على أنها True.


    مستطيلي
        تسمى البيانات التي يمكن تمثيلها كمصفوفة بـ :term:`عينات` على
        المحور الأول ومجموعة ثابتة ومحدودة من :term:`الميزات` على المحور الثاني
        بالمستطيلة.


        يستبعد هذا المصطلح العينات ذات الهياكل غير المتجهة، مثل النص،
        وصورة ذات حجم عشوائي، وسلسلة زمنية ذات طول عشوائي، ومجموعة من
        المتجهات، إلخ. الغرض من :term:`المحول المتجه` هو إنتاج
        أشكال مستطيلة لمثل هذه البيانات.


    عينة
    عينات
        عادةً ما نستخدم هذا المصطلح كاسم للإشارة إلى متجه ميزة واحد.
        في مكان آخر، تسمى العينة نموذجًا أو نقطة بيانات أو ملاحظة.
        يشير ``n_samples`` إلى عدد العينات في مجموعة البيانات، وهو عدد
        الصفوف في مصفوفة البيانات :term:`X`.

    خاصية العينة
    خصائص العينة
        خاصية العينة هي بيانات لكل عينة (على سبيل المثال، مصفوفة بطول
        n_samples) يتم تمريرها إلى أسلوب مقدر أو دالة مماثلة،
        جنبًا إلى جنب مع :term:`الميزات` (``X``) و
        :term:`الهدف` (``y``) ولكنها مميزة عنها. المثال الأبرز هو
        :term:`sample_weight`؛ انظر أمثلة أخرى في :ref:`glossary_sample_props`.

        اعتبارًا من الإصدار 0.19، ليس لدينا نهج متسق للتعامل مع
        خصائص العينة وتوجيهها في :term:`مقدرات التعريف التلوي`، على الرغم من
        أنه غالبًا ما يتم استخدام معلمة ``fit_params``.


    scikit-learn-contrib
        مكان لنشر مكتبات متوافقة مع Scikit-learn تم
        ترخيصها على نطاق واسع من قبل المطورين الأساسيين ومجتمع contrib،
        ولكن لا تتم صيانتها من قبل فريق المطورين الأساسي.
        انظر https://scikit-learn-contrib.github.io.


    مقترحات تحسين scikit-learn
        تحدث التغييرات على مبادئ واجهة برمجة التطبيقات والتغييرات على التبعيات أو الإصدارات
        المدعومة عبر :ref:`SLEP <slep>` وتتبع عملية
        صنع القرار الموضحة في :ref:`governance`.
        بالنسبة لجميع عمليات التصويت، يجب أن يكون الاقتراح قد تم نشره ومناقشته قبل
        التصويت. يجب أن يكون هذا الاقتراح وثيقة موحدة، في شكل
        "اقتراح تحسين Scikit-Learn" (SLEP)، بدلاً من مناقشة طويلة حول
        مشكلة. يجب إرسال SLEP كطلب سحب إلى
        `مقترحات التحسين <https://scikit-learn-enhancement-proposals.readthedocs.io>`_ باستخدام
        `قالب SLEP <https://scikit-learn-enhancement-proposals.readthedocs.io/en/latest/slep_template.html>`_.



    شبه خاضع للإشراف
    التعلم شبه الخاضع للإشراف
        التعلم حيث يكون التنبؤ المتوقع (التسمية أو الحقيقة الأساسية) متاحًا فقط
        لبعض العينات المقدمة كبيانات تدريب عند :term:`ملاءمة`
        النموذج. نطبق عادةً التسمية ``-1``
        على العينات :term:`غير المُعلَّمة` في التصنيف شبه الخاضع للإشراف.


    مصفوفة متفرقة
    رسم بياني متفرق
        تمثيل للبيانات الرقمية ثنائية الأبعاد أكثر كفاءة في استخدام الذاكرة
        من مصفوفة numpy الكثيفة المقابلة حيث تكون جميع العناصر تقريبًا
        صفراً. نستخدم إطار عمل :mod:`scipy.sparse`، الذي يوفر
        العديد من تمثيلات البيانات المتفرقة الأساسية، أو *التنسيقات*.
        تكون بعض التنسيقات أكثر كفاءة من غيرها لمهام معينة، و
        عندما يوفر تنسيق معين فائدة خاصة، نحاول توثيق
        هذه الحقيقة في أوصاف معلمات Scikit-learn.

        تميز بعض تنسيقات المصفوفة المتفرقة (خاصة CSR و CSC و COO و LIL)
        بين الأصفار *الضمنية* و *الصريحة*. يتم تخزين الأصفار الصريحة
        (أي أنها تستهلك الذاكرة في مصفوفة ``data``) في بنية البيانات،
        بينما تتوافق الأصفار الضمنية مع كل عنصر غير مُعرَّف بطريقة أخرى
        في التخزين الصريح.

        يتم استخدام اثنين من دلالات المصفوفات المتفرقة في Scikit-learn:


        دلالات المصفوفة
            يتم تفسير المصفوفة المتفرقة على أنها مصفوفة مع تفسير الأصفار الضمنية
            والصريحة على أنها الرقم 0. هذا هو
            التفسير الأكثر استخدامًا، على سبيل المثال عندما يتم استخدام المصفوفات المتفرقة
            لمصفوفات الميزات أو :term:`مصفوفات مؤشر متعددة التسميات`.
        دلالات الرسم البياني
            كما هو الحال مع :mod:`scipy.sparse.csgraph`، يتم
            تفسير الأصفار الصريحة على أنها الرقم 0، لكن الأصفار الضمنية تشير إلى قيمة مُقنعة
            أو غائبة، مثل عدم وجود حافة بين رأسين
            لرسم بياني، حيث تشير القيمة الصريحة إلى وزن الحافة. يتم اعتماد هذا التفسير لتمثيل
            الاتصال في التجميع، وفي تمثيلات أقرب الجيران
            (على سبيل المثال :func:`neighbors.kneighbors_graph`)، ولتمثيل
            المسافة المحسوبة مسبقًا حيث تكون المسافات في جوار
            كل نقطة مطلوبة فقط.


        عند العمل مع المصفوفات المتفرقة، نفترض أنها متفرقة لسبب
        وجيه، ونتجنب كتابة كود يُكثِّف مصفوفة متفرقة يوفرها المستخدم،
        بدلاً من الحفاظ على التناثر أو طرح خطأ إذا لم يكن
        ذلك ممكنًا (أي إذا كان المقدر لا يدعم/لا يمكنه دعم المصفوفات
        المتفرقة).


    عديم الحالة
        يكون المقدر عديم الحالة إذا لم يُخزِّن أي معلومات يتم
        الحصول عليها أثناء :term:`fit`. يمكن أن تكون هذه المعلومات إما معلمات
        تم تعلمها أثناء :term:`fit` أو إحصائيات محسوبة من
        بيانات التدريب. يكون المقدر عديم الحالة إذا لم يكن لديه :term:`سمات`
        بصرف النظر عن تلك التي تم تعيينها في `__init__`. سيؤدي استدعاء :term:`fit` لهذه
        المقدرات إلى التحقق من صحة :term:`السمات` العامة التي تم تمريرها
        في `__init__` فقط.


    خاضع للإشراف
    التعلم الخاضع للإشراف
        التعلم حيث يكون التنبؤ المتوقع (التسمية أو الحقيقة الأساسية) متاحًا
        لكل عينة عند :term:`ملاءمة` النموذج، يتم توفيره كـ
        :term:`y`. هذا هو النهج المتبع في :term:`المصنف` أو
        :term:`مقدر الانحدار` من بين المقدرات الأخرى.

    الهدف
    الأهداف
        *المتغير التابع* في التعلم :term:`الخاضع للإشراف` (و
        :term:`شبه الخاضع للإشراف`)، يتم تمريره كـ :term:`y` إلى أسلوب
        :term:`fit` الخاص بالمقدر. يُعرف أيضًا باسم *المتغير التابع* أو *متغير
        النتيجة* أو *متغير الاستجابة* أو *الحقيقة الأساسية* أو *التسمية*. يعمل Scikit-learn
        مع الأهداف ذات البنية الدنيا: فئة من مجموعة محدودة،
        رقم ذو قيمة حقيقية محدودة، فئات متعددة، أو أرقام
        متعددة. انظر :ref:`glossary_target_types`.


    الاستنتاج
    استنتاجي
        أسلوب التعلم الآلي الاستنتاجي (على النقيض من :term:`الاستقرائي`) مُصمم
        لنمذجة مجموعة بيانات محددة، ولكن ليس لتطبيق هذا
        النموذج على البيانات غير المرئية. تشمل الأمثلة :class:`manifold.TSNE`،
        :class:`cluster.AgglomerativeClustering` و
        :class:`neighbors.LocalOutlierFactor`.

    غير مُعلَّم
    بيانات غير مُعلَّمة
        عينات ذات حقيقة أساسية غير معروفة عند الملاءمة؛ على نحو مكافئ،
        :term:`قيم مفقودة` في :term:`الهدف`. انظر أيضًا
        التعلم :term:`شبه الخاضع للإشراف` و :term:`غير الخاضع للإشراف`.


    غير خاضع للإشراف
    التعلم غير الخاضع للإشراف
        التعلم حيث لا يتوفر التنبؤ المتوقع (التسمية أو الحقيقة الأساسية)
        لكل عينة عند :term:`ملاءمة` النموذج، كما هو الحال في
        :term:`مُجمِّعات` و :term:`كاشفات القيم المتطرفة`. تتجاهل المقدرات
        غير الخاضعة للإشراف أي :term:`y` تم تمريره إلى :term:`fit`.




.. _glossary_estimator_types:

واجهات برمجة تطبيقات الفئات وأنواع المقدرات
==============================

.. glossary::

    مصنف
    المصنفات
        :term:`متنبئ` :term:`خاضع للإشراف` (أو :term:`شبه خاضع للإشراف`)
        مع مجموعة محدودة من قيم الإخراج المنفصلة الممكنة.

        يدعم المصنف نمذجة بعض :term:`الثنائية` أو
        :term:`متعددة الفئات` أو :term:`متعددة التسميات` أو :term:`متعددة الفئات
        متعددة المخرجات` الأهداف. ضمن scikit-learn، تدعم جميع المصنفات
        التصنيف متعدد الفئات، وتستخدم افتراضيًا استراتيجية واحد مقابل البقية
        على مشكلة التصنيف الثنائي.


        يجب على المصنفات تخزين سمة :term:`classes_` بعد الملاءمة،
        وعادةً ما ترث من :class:`base.ClassifierMixin`، التي تُعيِّن
        سمة :term:`_estimator_type` الخاصة بها.


        يمكن تمييز المصنف عن المقدرات الأخرى باستخدام
        :func:`~base.is_classifier`.


        يجب على المصنف تنفيذ:

        * :term:`fit`
        * :term:`predict`
        * :term:`score`


        قد يكون من المناسب أيضًا تنفيذ :term:`decision_function`،
        :term:`predict_proba` و :term:`predict_log_proba`.


    مُجمِّع
    المُجمِّعات
        :term:`متنبئ` :term:`غير خاضع للإشراف` مع مجموعة محدودة من قيم
        الإخراج المنفصلة.

        عادةً ما يُخزِّن المُجمِّع :term:`labels_` بعد الملاءمة، ويجب أن يفعل ذلك
        إذا كان :term:`استنتاجيًا`.


        يجب على المُجمِّع تنفيذ:

        * :term:`fit`
        * :term:`fit_predict` إذا كان :term:`استنتاجيًا`
        * :term:`predict` إذا كان :term:`استقرائيًا`


    مقدر الكثافة
        تقدير :term:`غير خاضع للإشراف` لدالة كثافة احتمالية الإدخال.
        التقنيات شائعة الاستخدام هي:

        * :ref:`kernel_density` - يستخدم دالة نواة، يتم التحكم فيها بواسطة
          معلمة عرض النطاق الترددي لتمثيل الكثافة؛
        * :ref:`خليط غاوسي <mixture>` - يستخدم خليطًا من نماذج غاوسية
          لتمثيل الكثافة.


    مقدر
    المقدرات
        كائن يُدير تقدير وفك تشفير نموذج. يتم تقدير النموذج كدالة حتمية لـ:

        * :term:`معلمات` مقدمة في إنشاء الكائن أو مع
          :term:`set_params`؛
        * حالة عشوائية :mod:`numpy.random` العالمية إذا تم تعيين
          معلمة :term:`random_state` الخاصة بالمقدر على لا شيء؛ و
        * أي بيانات أو :term:`خصائص عينة` تم تمريرها إلى أحدث
          استدعاء لـ :term:`fit`، :term:`fit_transform` أو :term:`fit_predict`،
          أو بيانات تم تمريرها بشكل مشابه في سلسلة من الاستدعاءات لـ
          :term:`partial_fit`.


        يتم تخزين النموذج المُقدَّر في :term:`سمات` عامة وخاصة
        على نموذج المقدر، مما يُسهِّل فك التشفير من خلال أساليب التنبؤ
        والتحويل.


        يجب أن توفر المقدرات أسلوب :term:`fit`، ويجب أن توفر
        :term:`set_params` و :term:`get_params`، على الرغم من أنها عادةً ما يتم
        توفيرها عن طريق الوراثة من :class:`base.BaseEstimator`.


        قد تتوفر الوظيفة الأساسية لبعض المقدرات أيضًا كـ
        :term:`دالة`.


    مستخرج الميزات
    مستخرجات الميزات
        :term:`محول` يأخذ مدخلات حيث لا يتم تمثيل كل عينة
        ككائن :term:`يشبه المصفوفة` بطول ثابت، و
        ينتج كائنًا :term:`يشبه المصفوفة` من :term:`الميزات` لكل
        عينة (وبالتالي مصفوفة ثنائية الأبعاد تشبه مجموعة من العينات).  بمعنى آخر،
        إنه يقوم بتعيين تمثيل بيانات غير مستطيل (مع فقد)
        إلى بيانات :term:`مستطيلة`.


        يجب أن تُنفذ مستخرجات الميزات على الأقل:

        * :term:`fit`
        * :term:`transform`
        * :term:`get_feature_names_out`

    مقدر التعريف التلوي
    مقدرات التعريف التلوي
        :term:`مقدر` يأخذ مقدرًا آخر كمعلمة.
        تشمل الأمثلة :class:`pipeline.Pipeline`،
        :class:`model_selection.GridSearchCV`،
        :class:`feature_selection.SelectFromModel` و
        :class:`ensemble.BaggingClassifier`.


        في أسلوب :term:`fit` الخاص بمقدر التعريف التلوي، يجب
        :term:`استنساخ` أي مقدرات مُضمنة قبل ملاءمتها (على الرغم من FIXME:
        لا يقوم Pipeline و FeatureUnion بذلك حاليًا). استثناء من ذلك هو
        أن المقدر قد يوثق صراحةً أنه يقبل مقدرًا تم توفيقه مسبقًا (على سبيل المثال،
        باستخدام ``prefit = True`` في
        :class:`feature_selection.SelectFromModel`). إحدى المشكلات المعروفة المتعلقة بهذا
        هي أن المقدر الملائم مسبقًا سيفقد نموذجه إذا تم
        استنساخ مقدر التعريف التلوي. يجب استدعاء ``fit`` لمقدر التعريف التلوي
        قبل التنبؤ، حتى لو كانت جميع المقدرات المُضمنة ملائمة مسبقًا.


        في الحالات التي تكون فيها السلوكيات الأساسية لمقدر التعريف التلوي (على سبيل المثال،
        تنفيذ :term:`predict` أو :term:`transform`) دوالًا لـ
        أساليب التنبؤ/التحويل الخاصة بـ *المقدر الأساسي* المقدم (أو
        مقدرات أساسية متعددة)، يجب أن يقدم مقدر التعريف التلوي على الأقل
        الأساليب القياسية التي يوفرها المقدر الأساسي. قد لا يكون
        من الممكن تحديد الأساليب التي يوفرها المقدر الأساسي حتى
        يتم :term:`ملاءمة` مقدر التعريف التلوي (انظر أيضًا
        :term:`كتابة البطة`)، والتي قد يساعد :func:`utils.metaestimators.available_if` فيها.
        يجب أيضًا أن يقدم (أو يُعدِّل) :term:`علامات المقدر` و
        سمة :term:`classes_` التي يوفرها المقدر الأساسي.


        يجب أن تكون مقدرات التعريف التلوي حريصة على التحقق من صحة البيانات بأقل قدر ممكن
        قبل تمريرها إلى مقدر أساسي. يوفر هذا
        وقت الحساب، وقد يسمح، على سبيل المثال، للمقدر
        الأساسي بالعمل بسهولة مع البيانات غير :term:`المستطيلة`.


    كاشف القيم المتطرفة
    كاشفات القيم المتطرفة
        :term:`متنبئ` ثنائي :term:`غير خاضع للإشراف` يُنمذج
        التمييز بين العينات الأساسية والمتطرفة.


        يجب أن تُنفذ كاشفات القيم المتطرفة:

        * :term:`fit`
        * :term:`fit_predict` إذا كان :term:`استنتاجيًا`
        * :term:`predict` إذا كان :term:`استقرائيًا`


        قد تُنفذ كاشفات القيم المتطرفة الاستقرائية أيضًا
        :term:`decision_function` لإعطاء درجة غير طبيعية طبيعية حيث
        تكون القيم المتطرفة ذات درجة أقل من 0. قد يوفر :term:`score_samples`
        درجة غير طبيعية لكل عينة.

    المتنبئ
    المتنبئات
        :term:`مقدر` يدعم :term:`predict` و/أو
        :term:`fit_predict`. يشمل هذا :term:`المصنف`،
        :term:`مقدر الانحدار`، :term:`كاشف القيم المتطرفة` و :term:`المُجمِّع`.

        في الإحصاء، تشير "المتنبئات" إلى :term:`الميزات`.



    مقدر الانحدار
    مقدرات الانحدار
        :term:`متنبئ` :term:`خاضع للإشراف` (أو :term:`شبه خاضع للإشراف`)
        بقيم ناتج :term:`مستمرة`.

        عادةً ما ترث مقدرات الانحدار من :class:`base.RegressorMixin`، والتي
        تُعيِّن سمة :term:`_estimator_type` الخاصة بها.

        يمكن تمييز مقدر الانحدار عن المقدرات الأخرى باستخدام
        :func:`~base.is_regressor`.

        يجب أن يُنفذ مقدر الانحدار:

        * :term:`fit`
        * :term:`predict`
        * :term:`score`


    المحول
    المحولات
        مقدر يدعم :term:`transform` و/أو :term:`fit_transform`.
        :term:`محول استنتاجي` بحت، مثل
        :class:`manifold.TSNE`، قد لا يُنفذ ``transform``.

    المحول المتجه
        انظر :term:`مستخرج الميزات`.


هناك المزيد من واجهات برمجة التطبيقات المتعلقة على وجه التحديد بعائلة صغيرة من المقدرات،
مثل:


.. glossary::

    مُقسِّم التحقق المتبادل
    مُولِّد التحقق المتبادل
        عائلة غير مقدرة من الفئات تُستخدم لتقسيم مجموعة بيانات إلى
        سلسلة من أجزاء التدريب والاختبار (انظر :ref:`cross_validation`)،
        عن طريق توفير أساليب :term:`split` و :term:`get_n_splits`.
        لاحظ أنه على عكس المقدرات، لا تحتوي هذه على أساليب :term:`fit`
        ولا توفر :term:`set_params` أو :term:`get_params`.
        قد يتم إجراء التحقق من صحة المعلمات في ``__init__``.



    مقدر التحقق المتبادل
        مقدر لديه إمكانيات تحقق متبادل مدمجة لـ
        تحديد أفضل المعلمات الفائقة تلقائيًا (انظر :ref:`دليل
        المستخدم <grid_search>`). بعض الأمثلة على مقدرات التحقق المتبادل
        هي :class:`ElasticNetCV <linear_model.ElasticNetCV>` و
        :class:`LogisticRegressionCV <linear_model.LogisticRegressionCV>`.
        يتم تسمية مقدرات التحقق المتبادل باسم `EstimatorCV` وتميل إلى
        أن تكون مكافئة تقريبًا لـ `GridSearchCV(Estimator()، ...)`.
        ميزة استخدام مقدر التحقق المتبادل على
        فئة :term:`المقدر` الأساسية جنبًا إلى جنب مع :ref:`البحث الشبكي <grid_search>` هي
        أنه يمكنهم الاستفادة من البدء الدافئ عن طريق إعادة استخدام النتائج المحسوبة
        مسبقًا في الخطوات السابقة من عملية التحقق المتبادل. يؤدي هذا
        عمومًا إلى تحسينات في السرعة. الاستثناء هو
        فئة :class:`RidgeCV <linear_model.RidgeCV>`، والتي يمكنها بدلاً من ذلك
        إجراء التحقق المتبادل Leave-One-Out (LOO) بكفاءة. افتراضيًا، سيتم إعادة
        ملاءمة جميع هذه المقدرات، باستثناء :class:`RidgeCV <linear_model.RidgeCV>`
        مع LOO-CV، على مجموعة بيانات التدريب الكاملة بعد العثور على
        أفضل مجموعة من المعلمات الفائقة.



    مسجِّل
        كائن قابل للاستدعاء غير مقدر يُقيِّم مقدرًا على بيانات اختبار معينة،
        ويُعيد رقمًا. على عكس :term:`مقاييس التقييم`،
        يجب أن يتوافق الرقم المُعاد الأكبر مع درجة *أفضل*.
        انظر :ref:`scoring_parameter`.


أمثلة إضافية:

* :class:`metrics.DistanceMetric`
* :class:`gaussian_process.kernels.Kernel`
* ``tree.Criterion``

.. _glossary_metadata_routing:

توجيه البيانات الوصفية
================


.. glossary::

    مستهلك
        كائن يستهلك :term:`بيانات وصفية`. عادةً ما يكون هذا الكائن
        :term:`مقدرًا` أو :term:`مسجِّلاً` أو :term:`مُقسِّم CV`. استهلاك
        البيانات الوصفية يعني استخدامها في العمليات الحسابية، على سبيل المثال استخدام
        :term:`sample_weight` لحساب نوع معين من الدرجات. كونك
        مستهلكًا لا يعني أن الكائن يتلقى دائمًا بيانات وصفية معينة،
        بل يعني أنه يمكنه استخدامها إذا تم توفيرها.



    بيانات وصفية
        البيانات المتعلقة ببيانات :term:`X` و :term:`y` المعينة، ولكن
        ليست جزءًا مباشرًا من البيانات، على سبيل المثال :term:`sample_weight` أو
        :term:`groups`، ويتم تمريرها إلى كائنات وأساليب مختلفة،
        على سبيل المثال إلى :term:`مسجِّل` أو :term:`مُقسِّم CV`.



    موجه
        كائن يُوجِّه البيانات الوصفية إلى :term:`المستهلكين <consumer>`. عادةً ما يكون هذا
        الكائن :term:`مقدر تعريف تلوي`، على سبيل المثال
        :class:`~pipeline.Pipeline` أو :class:`~model_selection.GridSearchCV`.
        يمكن أن يكون بعض الموجهات أيضًا مستهلكًا. يحدث هذا على سبيل المثال عندما يستخدم
        مقدر التعريف التلوي :term:`groups` المعينة، ويقوم أيضًا بتمريرها
        إلى بعض الكائنات الفرعية الخاصة به، مثل :term:`مُقسِّم CV`.

يرجى الرجوع إلى :ref:`دليل مستخدم توجيه البيانات الوصفية <metadata_routing>` لمزيد من
المعلومات.



.. _glossary_target_types:

أنواع الأهداف
============

.. glossary::

    ثنائي
        مشكلة تصنيف تتكون من فئتين. قد يتم تمثيل الهدف الثنائي
        لمشكلة :term:`متعددة الفئات` ولكن بتسميتين فقط. يتم تمثيل دالة القرار
        الثنائية كمصفوفة أحادية الأبعاد.

        دلاليًا، غالبًا ما تُعتبر إحدى الفئات الفئة "الإيجابية".
        ما لم يُحدد خلاف ذلك (على سبيل المثال، باستخدام :term:`pos_label` في
        :term:`مقاييس التقييم`)، فإننا نعتبر تسمية الفئة ذات القيمة
        الأكبر (عدديًا أو معجميًا) على أنها الفئة الإيجابية:
        من التسميات [0، 1]، 1 هي الفئة الإيجابية؛ من [1، 2]، 2 هي الفئة
        الإيجابية؛ من ["لا"، "نعم"]، "نعم" هي الفئة الإيجابية؛ من ["لا"، "نعم"]،
        "لا" هي الفئة الإيجابية. يؤثر هذا على ناتج
        :term:`decision_function`، على سبيل المثال.


        لاحظ أن مجموعة البيانات التي تم أخذ عينات منها من ``y`` متعدد الفئات أو
        ``y`` مستمر قد تبدو ثنائية.


        سيُعيد :func:`~utils.multiclass.type_of_target` القيمة "binary" لـ
        الإدخال الثنائي، أو مصفوفة مماثلة بفئة واحدة فقط موجودة.


    مستمر
        مشكلة انحدار حيث يكون هدف كل عينة هو رقم فاصلة عائمة محدود
        مُمثل كمصفوفة أحادية الأبعاد من العناصر العائمة (أو
        أحيانًا أعداد صحيحة).


        سيُعيد :func:`~utils.multiclass.type_of_target` القيمة "continuous" لـ
        الإدخال المستمر، ولكن إذا كانت جميع البيانات أعدادًا صحيحة، فسيتم
        تحديدها على أنها "multiclass".


    متعدد المخرجات مستمر
    مستمر متعدد المخرجات
        مشكلة انحدار حيث يتكون هدف كل عينة من ``n_outputs``
        :term:`مخرجات`، كل منها رقم فاصلة عائمة محدود، لـ
        عدد صحيح ثابت ``n_outputs > 1`` في مجموعة بيانات معينة.


        يتم تمثيل الأهداف المستمرة متعددة المخرجات كأهداف
        :term:`مستمرة` متعددة، مكدسة أفقيًا في مصفوفة
        ذات شكل ``(n_samples، n_outputs)``.

        سيُعيد :func:`~utils.multiclass.type_of_target`
        القيمة "continuous-multioutput" للإدخال المستمر متعدد المخرجات، ولكن إذا
        كانت جميع البيانات أعدادًا صحيحة، فسيتم تحديدها على أنها
        "multiclass-multioutput".


    متعدد الفئات
        مشكلة تصنيف تتكون من أكثر من فئتين.
        يمكن تمثيل الهدف متعدد الفئات كمصفوفة أحادية الأبعاد من
        السلاسل أو الأعداد الصحيحة. متجه عمود ثنائي الأبعاد من الأعداد الصحيحة (أي
        ناتج واحد من حيث :term:`multioutput`) مقبول أيضًا.


        لا ندعم رسميًا كائنات أخرى قابلة للترتيب وقابلة للتجزئة كتسميات فئات،
        حتى لو كانت المقدرات قد تعمل عند إعطاء أهداف تصنيف
        من هذا النوع.

        بالنسبة للتصنيف شبه الخاضع للإشراف، يجب أن تحتوي العينات :term:`غير المُعلَّمة`
        على التسمية الخاصة -1 في ``y``.

        ضمن scikit-learn، تدعم جميع المقدرات التي تدعم التصنيف الثنائي
        أيضًا التصنيف متعدد الفئات، باستخدام واحد مقابل البقية افتراضيًا.


        يساعد :class:`preprocessing.LabelEncoder` على تحويل أهداف
        متعددة الفئات إلى أعداد صحيحة.


        سيُعيد :func:`~utils.multiclass.type_of_target` القيمة "multiclass" لـ
        الإدخال متعدد الفئات. قد يرغب المستخدم أيضًا في التعامل مع الإدخال "الثنائي"
        بشكل مماثل لـ "multiclass".


    متعدد الفئات ومتعدد المخرجات
        مشكلة تصنيف حيث يتكون هدف كل عينة من
        ``n_outputs`` :term:`مخرجات`، كل منها تسمية فئة، لعدد صحيح ثابت
        ``n_outputs > 1`` في مجموعة بيانات معينة.  لكل ناتج مجموعة ثابتة
        من الفئات المتاحة، وكل عينة مُعلَّمة بفئة
        لكل ناتج. قد يكون الناتج ثنائيًا أو متعدد الفئات، وفي
        الحالة التي تكون فيها جميع المخرجات ثنائية، يكون الهدف
        :term:`متعدد التسميات`.


        يتم تمثيل الأهداف متعددة الفئات ومتعددة المخرجات كأهداف
        :term:`متعددة الفئات` متعددة، مكدسة أفقيًا في مصفوفة
        ذات شكل ``(n_samples, n_outputs)``.


        XXX: من أجل البساطة، قد لا ندعم دائمًا تسميات فئات السلاسل
        للمخرجات متعددة الفئات ومتعددة المخرجات، ويجب استخدام تسميات فئات الأعداد الصحيحة.



        يوفر :mod:`~sklearn.multioutput` مقدرات تُقدِّر المشكلات متعددة المخرجات
        باستخدام مقدرات متعددة أحادية الناتج. قد لا يُراعي هذا
        تمامًا التبعيات بين المخرجات المختلفة، والتي قد تعمل الأساليب
        التي تتعامل أصلاً مع الحالة متعددة المخرجات (على سبيل المثال، أشجار القرار،
        أقرب الجيران، الشبكات العصبية) بشكل أفضل.



        سيُعيد :func:`~utils.multiclass.type_of_target`
        القيمة "multiclass-multioutput" للإدخال متعدد الفئات ومتعدد المخرجات.



    متعدد التسميات
        هدف :term:`متعدد الفئات ومتعدد المخرجات` حيث يكون كل ناتج
        :term:`ثنائيًا`. قد يتم تمثيل هذا كمصفوفة ثنائية الأبعاد (كثيفة) أو
        مصفوفة متفرقة من الأعداد الصحيحة، بحيث يكون كل عمود هدفًا ثنائيًا منفصلاً،
        حيث تتم الإشارة إلى التسميات الإيجابية بالرقم 1 وعادةً ما تكون التسميات السلبية
        -1 أو 0. لا يتم دعم الأهداف المتفرقة متعددة التسميات
        في كل مكان يتم فيه دعم الأهداف الكثيفة متعددة التسميات.


        دلاليًا، يمكن اعتبار الهدف متعدد التسميات كمجموعة من التسميات
        لكل عينة. على الرغم من عدم استخدامه داخليًا،
        يتم توفير :class:`preprocessing.MultiLabelBinarizer` كأداة مساعدة لـ
        التحويل من قائمة التمثيلات المحددة إلى مصفوفة ثنائية الأبعاد أو مصفوفة
        متفرقة. يؤدي تشفير الهدف متعدد الفئات بشكل أحادي الاتجاه باستخدام
        :class:`preprocessing.LabelBinarizer` إلى تحويله إلى مشكلة متعددة
        التسميات.


        سيُعيد :func:`~utils.multiclass.type_of_target`
        القيمة "multilabel-indicator" للإدخال متعدد التسميات، سواء كان متفرقًا أو كثيفًا.


    متعدد المخرجات
        هدف حيث تحتوي كل عينة على تسميات تصنيف/انحدار
        متعددة. انظر :term:`multiclass multioutput` و :term:`continuous
        multioutput`. لا ندعم حاليًا نمذجة أهداف التصنيف والانحدار
        المختلطة.



.. _glossary_methods:

الأساليب
=======

.. glossary::

    ``decision_function``
        في :term:`مصنف` أو :term:`كاشف قيم متطرفة` ملائم، يتنبأ
        بدرجة "ناعمة" لكل عينة فيما يتعلق بكل فئة، بدلاً من
        التنبؤ الفئوي "الصعب" الذي ينتجه :term:`predict`.  يكون إدخاله
        عادةً مجرد بعض البيانات المرصودة، :term:`X`.

        إذا لم يكن المقدر :term:`ملائمًا` بالفعل، فيجب أن يطرح استدعاء هذا الأسلوب
        :class:`exceptions.NotFittedError`.


        اتفاقيات الإخراج:

        التصنيف الثنائي
            مصفوفة أحادية الأبعاد، حيث تشير القيم الأكبر من الصفر
            بشكل صارم إلى الفئة الإيجابية (أي الفئة الأخيرة في
            :term:`classes_`).


        التصنيف متعدد الفئات
            مصفوفة ثنائية الأبعاد، حيث يكون الحد الأقصى للوسيطة حسب الصف هو
            الفئة المتوقعة. يتم ترتيب الأعمدة وفقًا لـ
            :term:`classes_`.


        التصنيف متعدد التسميات
            Scikit-learn غير متسق في تمثيل دوال القرار :term:`متعددة التسميات`.
            قد يتم تمثيلها بإحدى طريقتين:


            - قائمة من المصفوفات ثنائية الأبعاد، كل مصفوفة ذات شكل: (`n_samples`، 2)، كما هو الحال في
              الإخراج متعدد الفئات ومتعدد المخرجات. القائمة بطول `n_labels`.


            - مصفوفة ثنائية الأبعاد مفردة ذات شكل (`n_samples`، `n_labels`)، مع كل
              "عمود" في المصفوفة يتوافق مع قرارات التصنيف الثنائي
              الفردية. هذا مطابق لتنسيق
              التصنيف متعدد الفئات، على الرغم من اختلاف دلالاته: يجب تفسيره، كما هو الحال في
              الحالة الثنائية، عن طريق تحديد العتبة عند
              0.

        تصنيف متعدد المخرجات
            قائمة من المصفوفات ثنائية الأبعاد، تقابل كل دالة قرار متعددة
            الفئات.


        كشف القيم المتطرفة
            مصفوفة أحادية الأبعاد، حيث تشير القيمة الأكبر من أو تساوي الصفر
            إلى قيمة داخلية.


    ``fit``
        يتم توفير أسلوب ``fit`` في كل مقدر. عادةً ما يأخذ بعض
        :term:`العينات` ``X``، :term:`الأهداف` ``y`` إذا كان النموذج خاضعًا للإشراف،
        وربما :term:`خصائص عينة` أخرى مثل
        :term:`sample_weight`.  يجب أن يقوم بما يلي:

        * مسح أي :term:`سمات` سابقة مخزنة على المقدر، ما لم
          يتم استخدام :term:`warm_start`؛
        * التحقق من صحة أي :term:`معلمات` وتفسيرها، ويفضل طرح
          خطأ إذا كانت غير صالحة؛
        * التحقق من صحة بيانات الإدخال؛
        * تقدير وتخزين سمات النموذج من المعلمات المقدرة و
          البيانات المقدمة؛ و
        * إرجاع المقدر :term:`الملائم` الآن لتسهيل تسلسل الأساليب.


        يصف :ref:`glossary_target_types` التنسيقات الممكنة لـ ``y``.


    ``fit_predict``
        يُستخدم خاصةً للمقدرات :term:`غير الخاضعة للإشراف` و :term:`الاستنتاجية`،
        يُلائم هذا النموذج ويُعيد التنبؤات (على غرار
        :term:`predict`) على بيانات التدريب. في المُجمِّعات، يتم أيضًا تخزين هذه التنبؤات
        في سمة :term:`labels_`، وعادةً ما يكون ناتج
        ``.fit_predict(X)`` مكافئًا لـ ``.fit(X).predict(X)``.
        معلمات ``fit_predict`` هي نفس معلمات ``fit``.


    ``fit_transform``
        أسلوب على :term:`المحولات` الذي يُلائم المقدر ويُعيد
        بيانات التدريب المُحوَّلة. يأخذ معلمات كما في :term:`fit`
        ويجب أن يكون ناتجه بنفس شكل استدعاء ``.fit(X،
        ...).transform(X)``. ومع ذلك، هناك حالات نادرة لا
        يُعيد فيها ``.fit_transform(X، ...)`` و ``.fit(X، ...).transform(X)`` نفس القيمة،
        حيث تحتاج بيانات التدريب إلى معالجة
        بشكل مختلف (بسبب مزج النماذج في المجموعات المكدسة، على سبيل المثال؛
        يجب توثيق هذه الحالات بوضوح).
        قد يوفر المحولات :term:`الاستنتاجية <transductive>` أيضًا
        ``fit_transform`` ولكن ليس :term:`transform`.

        أحد أسباب تنفيذ ``fit_transform`` هو أن إجراء ``fit``
        و ``transform`` بشكل منفصل سيكون أقل كفاءة من إجرائهما معًا.
        يوفر :class:`base.TransformerMixin` تنفيذًا افتراضيًا،
        مما يوفر واجهة متسقة عبر المحولات حيث
        ``fit_transform`` متخصص أو غير متخصص.


        في التعلم :term:`الاستقرائي` - حيث يكون الهدف هو تعلم
        نموذج معمم يمكن تطبيقه على بيانات جديدة - يجب على المستخدمين
        الحرص على عدم تطبيق ``fit_transform`` على مجموعة بيانات بأكملها
        (أي بيانات التدريب والاختبار معًا) قبل إجراء مزيد من النمذجة، حيث
        يؤدي هذا إلى :term:`تسرب البيانات`.


    ``get_feature_names_out``
        بشكل أساسي لـ :term:`مستخرجات الميزات`، ولكن أيضًا يُستخدم لمحولات
        أخرى لتوفير أسماء سلاسل لكل عمود في ناتج
        أسلوب :term:`transform` الخاص بالمقدر.  يُخرج مصفوفة من
        السلاسل وقد يأخذ مصفوفة تشبه السلاسل كمدخلات، تقابل
        أسماء أعمدة الإدخال التي يمكن من خلالها
        إنشاء أسماء أعمدة الإخراج. إذا لم يتم تمرير `input_features`، فسيتم
        استخدام سمة `feature_names_in_`. إذا لم يتم تعريف
        سمة `feature_names_in_`، فسيتم تسمية
        أسماء الإدخال `[x0, x1, ..., x(n_features_in_ - 1)]`.


    ``get_n_splits``
        على :term:`مُقسِّم CV` (ليس مقدرًا)، يُعيد عدد
        العناصر التي سيحصل عليها المرء إذا كرر من خلال القيمة المعادة
        لـ :term:`split` بالنظر إلى نفس المعلمات. يأخذ نفس معلمات
        split.


    ``get_params``
        يحصل على جميع :term:`المعلمات` وقيمها، والتي يمكن تعيينها باستخدام
        :term:`set_params`. يمكن استخدام معلمة ``deep``، عند تعيينها على
        False لإرجاع تلك المعلمات التي لا تتضمن ``__`` فقط، أي
        ليس بسبب التوجيه غير المباشر عبر المقدرات المُضمنة.



        تعتمد معظم المقدرات التعريف من :class:`base.BaseEstimator`،
        الذي يعتمد ببساطة المعلمات المُحددة لـ ``__init__``.
        :class:`pipeline.Pipeline`، من بين أمور أخرى، يُعيد تنفيذ ``get_params``
        للإعلان عن المقدرات المسماة في معلمات ``steps`` الخاصة به على
        أنها معلمات في حد ذاتها.


    ``partial_fit``
        يُسهِّل ملاءمة المقدر بطريقة عبر الإنترنت. على عكس ``fit``،
        لا يؤدي استدعاء ``partial_fit`` بشكل متكرر إلى مسح النموذج، ولكن
        يُحدِّثه بالبيانات المقدمة. قد يُطلق على جزء البيانات
        المقدم إلى ``partial_fit`` اسم دفعة صغيرة.
        يجب أن يكون كل دفعة صغيرة ذات شكل متسق، إلخ. في المقدرات
        التكرارية، غالبًا ما يُجري ``partial_fit`` تكرارًا واحدًا فقط.


        يمكن أيضًا استخدام ``partial_fit`` للتعلم :term:`خارج النواة`،
        على الرغم من أنه يقتصر عادةً على الحالة التي يمكن فيها إجراء التعلم
        عبر الإنترنت، أي أن النموذج قابل للاستخدام بعد كل ``partial_fit`` ولا
        توجد معالجة منفصلة مطلوبة لإنهاء النموذج.
        يُقدِّم :class:`cluster.Birch` الاصطلاح القائل بأن استدعاء
        ``partial_fit(X)`` سينتج نموذجًا غير مُنتهٍ، ولكن
        يمكن إنهاء النموذج عن طريق استدعاء ``partial_fit()`` أي بدون
        تمرير دفعة صغيرة أخرى.


        بشكل عام، لا ينبغي تعديل معلمات المقدر بين استدعاءات
        ``partial_fit``، على الرغم من أن ``partial_fit`` يجب أن يتحقق من صحتها
        بالإضافة إلى الدفعة الصغيرة الجديدة من البيانات. على النقيض من ذلك،
        يُستخدم ``warm_start`` لملاءمة نفس المقدر بشكل متكرر بنفس البيانات
        ولكن مع معلمات مختلفة.



        مثل ``fit``، يجب أن يُعيد ``partial_fit`` كائن المقدر.



        لمسح النموذج، يجب إنشاء مقدر جديد، على سبيل المثال
        باستخدام :func:`base.clone`.



        ملاحظة: يؤدي استخدام ``partial_fit`` بعد ``fit`` إلى سلوك غير مُحدد.


    ``predict``
        يُجري تنبؤًا لكل عينة، وعادةً ما يأخذ :term:`X` فقط كمدخلات
        (ولكن انظر أسفل اتفاقيات ناتج مقدر الانحدار أدناه). في
        :term:`المصنف` أو :term:`مقدر الانحدار`، يكون هذا التنبؤ في نفس
        مساحة الهدف المستخدمة في الملاءمة (على سبيل المثال، أحد {"أحمر"، "كهرماني"، "أخضر"}
        إذا كان ``y`` في الملاءمة يتكون من هذه السلاسل). على الرغم من ذلك، حتى
        عندما يكون ``y`` الذي تم تمريره إلى :term:`fit` عبارة عن قائمة أو مصفوفة أخرى تشبه المصفوفة،
        يجب أن يكون ناتج ``predict`` دائمًا مصفوفة أو مصفوفة متفرقة. في
        :term:`مُجمِّع` أو :term:`كاشف قيم متطرفة`، يكون التنبؤ
        عددًا صحيحًا.


        إذا لم يكن المقدر :term:`ملائمًا` بالفعل، فيجب أن يطرح استدعاء هذا الأسلوب
        :class:`exceptions.NotFittedError`.

        اتفاقيات الإخراج:

        مصنف
            مصفوفة ذات شكل ``(n_samples,)`` ``(n_samples, n_outputs)``.
            قد يتم تمثيل بيانات :term:`متعددة التسميات <multilabel>` كمصفوفة متفرقة
            إذا تم استخدام مصفوفة متفرقة في الملاءمة. يجب أن يكون كل عنصر
            أحد القيم في سمة :term:`classes_` الخاصة بالمصنف.



        مُجمِّع
            مصفوفة ذات شكل ``(n_samples,)`` حيث تكون كل قيمة من 0 إلى
            ``n_clusters - 1`` إذا تم تجميع العينة المقابلة،
            و -1 إذا لم يتم تجميع العينة، كما هو الحال في
            :func:`cluster.dbscan`.



        كاشف القيم المتطرفة
            مصفوفة ذات شكل ``(n_samples,)`` حيث تكون كل قيمة -1 للقيمة
            المتطرفة و 1 خلاف ذلك.



        مقدر الانحدار
            مصفوفة رقمية ذات شكل ``(n_samples,)``، عادةً float64.
            تحتوي بعض مقدرات الانحدار على خيارات إضافية في أسلوب ``predict`` الخاص بها،
            مما يسمح لها بإرجاع الانحراف المعياري (``return_std = True``)
            أو التباين المشترك (``return_cov = True``) بالنسبة إلى القيمة
            المتوقعة. في هذه الحالة، تكون القيمة المعادة عبارة عن tuple من المصفوفات
            المقابلة لـ (متوسط ​​التنبؤ، الانحراف المعياري، التباين المشترك) حسب الحاجة.


    ``predict_log_proba``
        اللوغاريتم الطبيعي لناتج :term:`predict_proba`، المقدم
        لتسهيل الاستقرار العددي.


    ``predict_proba``
        أسلوب في :term:`المصنفات` و :term:`المُجمِّعات` يمكنه
        إرجاع تقديرات الاحتمالية لكل فئة/كتلة.  يكون إدخاله
        عادةً مجرد بعض البيانات المرصودة، :term:`X`.



        إذا لم يكن المقدر :term:`ملائمًا` بالفعل، فيجب أن يطرح استدعاء هذا الأسلوب
        :class:`exceptions.NotFittedError`.



        تشبه اتفاقيات الإخراج تلك الخاصة بـ :term:`decision_function` باستثناء
        حالة التصنيف :term:`الثنائي`، حيث يتم إخراج عمود واحد
        لكل فئة (بينما يُخرج ``decision_function`` مصفوفة أحادية الأبعاد). بالنسبة
        للتنبؤات الثنائية ومتعددة الفئات، يجب أن يضيف كل صف إلى 1.


        مثل الأساليب الأخرى، يجب ألا يكون ``predict_proba`` موجودًا إلا عندما
        يمكن للمقدر إجراء تنبؤات احتمالية (انظر :term:`كتابة البطة`).
        هذا يعني أن وجود الأسلوب قد يعتمد على معلمات
        المقدر (على سبيل المثال، في :class:`linear_model.SGDClassifier`) أو بيانات
        التدريب (على سبيل المثال، في :class:`model_selection.GridSearchCV`) وقد لا
        يظهر إلا بعد الملاءمة.


    ``score``
        أسلوب على مقدر، عادةً :term:`متنبئ`، يُقيِّم
        تنبؤاته على مجموعة بيانات معينة، ويُعيد درجة
        عددية واحدة. يجب أن تشير قيمة الإرجاع الأكبر إلى تنبؤات أفضل؛
        يتم استخدام الدقة للمصنفات و R^2 لمقدرات الانحدار افتراضيًا.


        إذا لم يكن المقدر :term:`ملائمًا` بالفعل، فيجب أن يطرح استدعاء هذا الأسلوب
        :class:`exceptions.NotFittedError`.


        تُنفذ بعض المقدرات دالة تسجيل مخصصة خاصة بالمقدر،
        غالبًا احتمالية البيانات في ظل النموذج.

    ``score_samples``
        أسلوب يُعيد درجة لكل عينة معينة. التعريف الدقيق
        لـ *الدرجة* يختلف من فئة إلى أخرى. في حالة
        تقدير الكثافة، يمكن أن يكون نموذج كثافة السجل على البيانات، وفي
        حالة اكتشاف القيم المتطرفة، يمكن أن يكون عكس عامل
        القيم المتطرفة للبيانات.



        إذا لم يكن المقدر :term:`ملائمًا` بالفعل، فيجب أن يطرح استدعاء هذا الأسلوب
        :class:`exceptions.NotFittedError`.



    ``set_params``
        متاح في أي مقدر، يأخذ وسيطات ذات كلمات رئيسية تقابل
        المفاتيح في :term:`get_params`. يتم توفير قيمة جديدة لكل منها
        لتعيينها بحيث يعكس استدعاء ``get_params`` بعد ``set_params``
        :term:`المعلمات` التي تم تغييرها. تستخدم معظم المقدرات التنفيذ في
        :class:`base.BaseEstimator`، الذي يتعامل مع المعلمات المتداخلة و
        يُعيِّن المعلمة كسمة على المقدر.
        يتم تجاوز الأسلوب في :class:`pipeline.Pipeline` والمقدرات ذات الصلة.


    ``split``
        على :term:`مُقسِّم CV` (ليس مقدرًا)، يقبل هذا الأسلوب
        معلمات (:term:`X`، :term:`y`، :term:`groups`)، حيث قد تكون جميعها
        اختيارية، ويُعيد مُكرِّرًا على أزواج ``(train_idx, test_idx)``.
        كل من {train,test}_idx عبارة عن مصفوفة أعداد صحيحة أحادية الأبعاد، بقيم
        من 0 من ``X.shape[0] - 1`` بأي طول، بحيث لا تظهر أي قيم
        في كل من ``train_idx`` و ``test_idx`` المقابل لها.


    ``transform``
        في :term:`محول`، يُحوِّل الإدخال، عادةً :term:`X` فقط،
        إلى مساحة مُحوَّلة (يتم تدوينها تقليديًا على أنها :term:`Xt`).
        يكون الناتج عبارة عن مصفوفة أو مصفوفة متفرقة بطول :term:`n_samples` و
        مع عدد ثابت من الأعمدة بعد :term:`الملاءمة`.


        إذا لم يكن المقدر :term:`ملائمًا` بالفعل، فيجب أن يطرح استدعاء هذا الأسلوب
        :class:`exceptions.NotFittedError`.




.. _glossary_parameters:

المعلمات
==========


تظهر أسماء المعلمات الشائعة هذه، المستخدمة على وجه التحديد في إنشاء المقدر
(انظر المفهوم :term:`parameter`)، أحيانًا كمعلمات
للدوال أو منشئي غير مقدر.


.. glossary::

    ``class_weight``
        يُستخدم لتحديد أوزان العينة عند ملاءمة المصنفات كدالة
        لفئة :term:`الهدف`. حيث يتم أيضًا
        دعم :term:`sample_weight` وتقديمه، يتم ضربه في مساهمة ``class_weight``.
        وبالمثل، حيث يتم استخدام ``class_weight`` في مهام
        :term:`متعددة المخرجات` (بما في ذلك :term:`متعددة التسميات`)، يتم ضرب الأوزان
        عبر المخرجات (أي أعمدة ``y``).


        افتراضيًا، يكون لجميع العينات وزن متساوٍ بحيث يتم
        ترجيح الفئات بشكل فعال من خلال انتشارها في بيانات التدريب.
        يمكن تحقيق ذلك صراحةً باستخدام ``class_weight={label1: 1,
        label2: 1, ...}`` لجميع تسميات الفئات.


        بشكل أكثر عمومية، يتم تحديد ``class_weight`` كقاموس يقوم بتعيين تسميات الفئات
        إلى الأوزان (``{class_label: weight}``)، بحيث يتم إعطاء كل عينة
        من الفئة المسماة هذا الوزن.


        يمكن استخدام ``class_weight="balanced"`` لإعطاء جميع الفئات
        وزنًا متساويًا عن طريق إعطاء كل عينة وزنًا يتناسب عكسيًا
        مع انتشار فئتها في بيانات التدريب:
        ``n_samples / (n_classes * np.bincount(y))``. سيتم استخدام أوزان الفئات
        بشكل مختلف اعتمادًا على الخوارزمية: بالنسبة للنماذج الخطية (مثل
        SVM الخطي أو الانحدار اللوجستي)، ستُغير أوزان الفئات دالة
        الفقدان عن طريق ترجيح فقدان كل عينة بوزن فئتها.
        بالنسبة للخوارزميات المستندة إلى الشجرة، سيتم استخدام أوزان الفئات من أجل
        إعادة ترجيح معيار التقسيم.
        **لاحظ** مع ذلك أن إعادة التوازن هذه لا تأخذ وزن
        العينات في كل فئة في الاعتبار.



        بالنسبة للتصنيف متعدد المخرجات، يتم استخدام قائمة من القواميس لتحديد
        الأوزان لكل ناتج. على سبيل المثال، بالنسبة لأوزان التصنيف متعدد التسميات
        ذات الأربع فئات، يجب أن تكون ``[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1,
        1: 1}, {0: 1, 1: 1}]`` بدلاً من ``[{1:1}, {2:5}, {3:1}, {4:1}]``.


        يتم التحقق من صحة معلمة ``class_weight`` وتفسيرها باستخدام
        :func:`utils.class_weight.compute_class_weight`.


    ``cv``
        يُحدد استراتيجية تقسيم التحقق المتبادل، كما هو مستخدم في
        الإجراءات القائمة على التحقق المتبادل. ``cv`` متاح أيضًا في المقدرات
        مثل :class:`multioutput.ClassifierChain` أو
        :class:`calibration.CalibratedClassifierCV` التي تستخدم تنبؤات
        مقدر واحد كبيانات تدريب لمقدر آخر، لعدم الإفراط في ملاءمة
        إشراف التدريب.


        عادةً ما تكون المدخلات الممكنة لـ ``cv`` هي:


        - عدد صحيح، يُحدد عدد الطيات في التحقق المتبادل K-fold.
          سيتم تصنيف K-fold على الفئات إذا كان المقدر
          مصنفًا (مُحدد بواسطة :func:`base.is_classifier`) وقد تُمثل
          :term:`الأهداف` مشكلة تصنيف ثنائية أو متعددة الفئات (ولكن ليس
          متعددة المخرجات) (مُحددة بواسطة
          :func:`utils.multiclass.type_of_target`).
        - نموذج :term:`مقسِّم التحقق المتبادل`. ارجع إلى
          :ref:`دليل المستخدم <cross_validation>` للبحث عن المقسمات المتاحة
          ضمن Scikit-learn.
        - مُكرِّر ينتج عنه تقسيمات تدريب/اختبار.


        مع بعض الاستثناءات (خاصةً عندما لا يكون عدم استخدام التحقق المتبادل على
        الإطلاق خيارًا)، يكون الإعداد الافتراضي هو 5 أضعاف.



        يتم التحقق من صحة قيم ``cv`` وتفسيرها باستخدام
        :func:`model_selection.check_cv`.


    ``kernel``
        يُحدد دالة النواة التي سيتم استخدامها بواسطة خوارزميات أسلوب النواة.
        على سبيل المثال، المقدرات :class:`svm.SVC` و
        :class:`gaussian_process.GaussianProcessClassifier` كلاهما يحتوي على
        معلمة ``kernel`` تأخذ اسم النواة المراد استخدامها كسلسلة
        أو دالة نواة قابلة للاستدعاء تُستخدم لحساب مصفوفة النواة. لمزيد من
        المرجع، انظر :ref:`kernel_approximation` و
        :ref:`gaussian_process` أدلة المستخدم.


    ``max_iter``
        بالنسبة للمقدرات التي تتضمن تحسينًا تكراريًا، يُحدد هذا الحد الأقصى لعدد
        التكرارات التي سيتم إجراؤها في :term:`fit`.  إذا
        تم تشغيل تكرارات ``max_iter`` دون تقارب،
        فيجب طرح :class:`exceptions.ConvergenceWarning`. لاحظ أن
        تفسير "تكرار واحد" غير متسق عبر
        المقدرات: يستخدمه البعض، ولكن ليس الكل، للإشارة إلى حقبة واحدة (أي
        تمريرة على كل عينة في البيانات).


        FIXME ربما يجب أن يكون لدينا بعض الاختبارات الشائعة حول العلاقة
        بين ConvergenceWarning و max_iter.


    ``memory``
        تستخدم بعض المقدرات :class:`joblib.Memory` لـ
        تخزين الحلول الجزئية أثناء الملاءمة. وبالتالي، عند استدعاء ``fit``
        مرة أخرى، يتم حفظ هذه الحلول الجزئية في الذاكرة ويمكن إعادة استخدامها.


        يمكن تحديد معلمة ``memory`` كسلسلة مع مسار إلى
        دليل، أو يمكن استخدام نموذج :class:`joblib.Memory` (أو كائن بواجهة
        مماثلة، أي أسلوب ``cache``).


        يتم التحقق من صحة قيم ``memory`` وتفسيرها باستخدام
        :func:`utils.validation.check_memory`.


    ``metric``
        كمعلمة، هذا هو المخطط لتحديد المسافة بين
        نقطتي بيانات.  انظر :func:`metrics.pairwise_distances`.  من الناحية العملية،
        بالنسبة لبعض الخوارزميات، قد يتم استخدام مقياس مسافة غير صحيح (مقياس لا
        يطيع متباينة المثلث، مثل مسافة جيب التمام).



        XXX: يستخدم التجميع الهرمي ``affinity`` بهذا المعنى.



        نستخدم أيضًا *metric* للإشارة إلى :term:`مقاييس التقييم`، لكننا نتجنب
        استخدام هذا المعنى كاسم معلمة.


    ``n_components``
        عدد الميزات التي يجب أن يُحوِّل :term:`المحول`
        الإدخال إليها. انظر :term:`components_` للحالة الخاصة للإسقاط
        التآلفي.



    ``n_iter_no_change``
        عدد التكرارات التي لا يوجد فيها تحسين للانتظار قبل إيقاف الإجراء
        التكراري. يُعرف هذا أيضًا باسم معلمة *الصبر*.
        عادةً ما يتم استخدامه مع :term:`الإيقاف المبكر` لتجنب الإيقاف مبكرًا جدًا.


    ``n_jobs``
        تُستخدم هذه المعلمة لتحديد عدد العمليات أو
        المواضيع المتزامنة التي يجب استخدامها للإجراءات المتوازية مع
        :term:`joblib`.


        ``n_jobs`` هو عدد صحيح، يُحدد الحد الأقصى لعدد العمال
        قيد التشغيل بشكل متزامن. إذا تم إعطاء 1، فلن يتم استخدام توازي joblib على الإطلاق،
        وهو أمر مفيد لتصحيح الأخطاء. إذا تم تعيينها على -1، فسيتم استخدام جميع وحدات المعالجة المركزية.
        بالنسبة لـ ``n_jobs`` أقل من -1، يتم استخدام (n_cpus + 1 + n_jobs). على سبيل المثال،
        مع ``n_jobs = -2``، يتم استخدام جميع وحدات المعالجة المركزية باستثناء واحدة.


        ``n_jobs`` هي ``None`` افتراضيًا، مما يعني *غير معينة*؛ سيتم
        تفسيرها عمومًا على أنها ``n_jobs=1``، ما لم يُحدد خلاف ذلك في سياق
        الخلفية الحالي :class:`joblib.Parallel`.



        لاحظ أنه حتى لو كانت ``n_jobs = 1``، فقد يتم استخدام التوازي منخفض المستوى (عبر Numpy و OpenMP)
        في بعض التكوينات.



        لمزيد من التفاصيل حول استخدام ``joblib`` وتفاعلاتها مع
        scikit-learn، يرجى الرجوع إلى :ref:`ملاحظات التوازي
        الخاصة بنا <parallelism>`.


    ``pos_label``
        القيمة التي يجب أن تُرمَّز بها التسميات الإيجابية في مشكلات
        التصنيف الثنائي التي لا يُفترض فيها الفئة الإيجابية.
        تكون هذه القيمة مطلوبة عادةً لحساب مقاييس التقييم غير المتماثلة مثل
        الدقة والاستدعاء.


    ``random_state``
        كلما كانت العشوائية جزءًا من خوارزمية Scikit-learn،
        يمكن توفير معلمة ``random_state`` للتحكم في مُولِّد الأرقام العشوائية
        المستخدم. لاحظ أن مجرد وجود ``random_state`` لا
        يعني أن العشوائية تُستخدم دائمًا، حيث قد تعتمد على
        معلمة أخرى، على سبيل المثال ``shuffle``، يتم تعيينها.


        ستؤثر القيمة التي تم تمريرها على إمكانية تكرار
        النتائج التي تُعيدها الدالة (:term:`fit`، :term:`split`، أو أي
        دالة أخرى مثل :func:`~sklearn.cluster.k_means`). قد تكون قيمة `random_state`:


        لا شيء (افتراضي)
            استخدم نموذج الحالة العشوائية العالمية من :mod:`numpy.random`.
            سيؤدي استدعاء الدالة عدة مرات إلى إعادة استخدام
            نفس النموذج، وسينتج عنه نتائج مختلفة.



        عدد صحيح
            استخدم مُولِّد أرقام عشوائية جديد تم إنشاؤه بواسطة العدد الصحيح المحدد.
            سيؤدي استخدام عدد صحيح إلى إنتاج نفس النتائج عبر استدعاءات مختلفة. ومع ذلك، قد يكون
            من المفيد التحقق من استقرار نتائجك عبر
            عدد من بذور عشوائية مميزة مختلفة. بذور عشوائية أعداد صحيحة
            شائعة هي 0 و `42
            <https://en.wikipedia.org/wiki/Answer_to_the_Ultimate_Question_of_Life%2C_the_Universe%2C_and_Everything>`_.
            يجب أن تكون القيم الصحيحة في النطاق `[0، 2**32 - 1]`.



        نموذج :class:`numpy.random.RandomState`
            استخدم الحالة العشوائية المقدمة، مما يؤثر فقط على المستخدمين الآخرين
            لنفس نموذج الحالة العشوائية. سيؤدي استدعاء الدالة
            عدة مرات إلى إعادة استخدام نفس النموذج، و
            سينتج عنه نتائج مختلفة.


        يتم استخدام :func:`utils.check_random_state` داخليًا للتحقق من صحة
        ``random_state`` المدخلة وإرجاع نموذج :class:`~numpy.random.RandomState`.


        لمزيد من التفاصيل حول كيفية التحكم في عشوائية كائنات scikit-learn
        وتجنب الأخطاء الشائعة، يمكنك الرجوع إلى :ref:`randomness`.



    ``scoring``
        يُحدد دالة الدرجة التي سيتم تكبيرها (عادةً عن طريق :ref:`التحقق
        المتبادل <cross_validation>`)، أو - في بعض الحالات - دوال تسجيل متعددة
        ليتم الإبلاغ عنها. يمكن أن تكون دالة الدرجة سلسلة يقبلها
        :func:`metrics.get_scorer` أو :term:`مسجِّل` قابل للاستدعاء، لا ينبغي
        الخلط بينه وبين :term:`مقياس التقييم`، لأن الأخير لديه واجهة برمجة تطبيقات أكثر
        تنوعًا. قد يتم أيضًا تعيين ``scoring`` على لا شيء، وفي هذه الحالة
        يتم استخدام أسلوب :term:`score` الخاص بالمقدر.  انظر :ref:`scoring_parameter`
        في دليل المستخدم.

        حيث يمكن تقييم مقاييس متعددة، قد يتم إعطاء ``scoring``
        إما كقائمة من السلاسل الفريدة، أو قاموس بأسماء كمفاتيح وقيم
        قابلة للاستدعاء أو قيمة قابلة للاستدعاء تُعيد قاموسًا. لاحظ أن
        هذا *لا* يُحدد دالة الدرجة التي سيتم تكبيرها، و
        قد يتم استخدام معلمة أخرى مثل ``refit`` لهذا الغرض.


        يتم التحقق من صحة معلمة ``scoring`` وتفسيرها باستخدام
        :func:`metrics.check_scoring`.


    ``verbose``
        لا تتم معالجة التسجيل بشكل متسق للغاية في Scikit-learn في الوقت الحالي،
        ولكن عندما يتم توفيره كخيار، عادةً ما تتوفر معلمة ``verbose`` لاختيار عدم
        التسجيل (تعيين على False). يجب أن تُمكِّن أي قيمة True
        بعض التسجيل، ولكن قد تكون هناك حاجة إلى أعداد صحيحة أكبر (على سبيل المثال، أعلى من 10)
        للحصول على إطناب كامل. عادةً ما تتم طباعة سجلات مطولة إلى
        الإخراج القياسي.
        يجب ألا تُنتج المقدرات أي ناتج على الإخراج القياسي مع
        إعداد ``verbose`` الافتراضي.



    ``warm_start``
        عند ملاءمة مقدر بشكل متكرر على نفس مجموعة البيانات، ولكن
        لقيم معلمات متعددة (مثل العثور على القيمة التي تزيد الأداء
        كما في :ref:`البحث الشبكي <grid_search>`)، قد يكون من الممكن
        إعادة استخدام جوانب النموذج التي تم تعلمها من قيمة المعلمة السابقة،
        مما يوفر الوقت. عندما تكون ``warm_start`` صحيحة، يتم استخدام :term:`السمات`
        :term:`الملائمة` الحالية لتهيئة النموذج الجديد
        في استدعاء لاحق لـ :term:`fit`.



        لاحظ أن هذا ينطبق فقط على بعض النماذج وبعض
        المعلمات، وحتى بعض أوامر قيم المعلمات. بشكل عام، هناك
        تفاعل بين ``warm_start`` والمعلمة التي تتحكم في
        عدد تكرارات المقدر.



        بالنسبة للمقدرات المستوردة من :mod:`~sklearn.ensemble`،
        ستتفاعل ``warm_start`` مع ``n_estimators`` أو ``max_iter``.
        بالنسبة لهذه النماذج، يتوافق عدد التكرارات، المبلغ عنه عبر
        ``len(estimators_)`` أو ``n_iter_``، مع إجمالي عدد
        المقدرات/التكرارات التي تم تعلمها منذ تهيئة النموذج.
        وبالتالي، إذا كان النموذج قد تم تهيئته بالفعل بـ `N` من المقدرات، ويتم استدعاء `fit`
        مع تعيين ``n_estimators`` أو ``max_iter`` على `M`، فسيدرِّب النموذج
        `M - N` من المقدرات الجديدة.


        النماذج الأخرى، التي تستخدم عادةً أدوات حل تعتمد على التدرج، لها سلوك
        مختلف. تعرض جميعها معلمة ``max_iter``.
        يتوافق ``n_iter_`` المبلغ عنه مع عدد التكرارات التي تم إجراؤها أثناء آخر
        استدعاء لـ ``fit`` وسيكون على الأكثر ``max_iter``. وبالتالي، فإننا لا
        نأخذ في الاعتبار حالة المقدر منذ التهيئة.


        يحتفظ :term:`partial_fit` أيضًا بالنموذج بين الاستدعاءات، ولكنه يختلف:
        مع ``warm_start`` تتغير المعلمات وتكون البيانات
        (أكثر أو أقل) ثابتة عبر استدعاءات ``fit``؛ مع ``partial_fit``،
        تتغير الدفعة الصغيرة من البيانات وتبقى معلمات النموذج ثابتة.


        هناك حالات تريد فيها استخدام ``warm_start`` للملاءمة على
        بيانات مختلفة، لكنها وثيقة الصلة. على سبيل المثال، قد يتم الملاءمة
        في البداية لمجموعة فرعية من البيانات، ثم ضبط بحث المعلمة على
        مجموعة البيانات الكاملة. بالنسبة للتصنيف، يجب أن تتضمن جميع البيانات في سلسلة
        من استدعاءات ``warm_start`` لـ ``fit`` عينات من كل فئة.


.. _glossary_attributes:

السمات
==========

انظر المفهوم :term:`السمة`.


.. glossary::

    ``classes_``
        قائمة بتسميات الفئات المعروفة لـ :term:`المصنف`، تعيِّن كل
        تسمية إلى فهرس رقمي مستخدم في تمثيل النموذج أو ناتجنا.
        على سبيل المثال، تحتوي المصفوفة الناتجة من :term:`predict_proba` على أعمدة
        محاذية لـ ``classes_``. بالنسبة للمصنفات :term:`متعددة المخرجات`،
        يجب أن تكون ``classes_`` قائمة من القوائم، مع قائمة فئة واحدة
        لكل ناتج.  لكل ناتج، يجب فرز الفئات
        (عدديًا أو معجميًا للسلاسل).


        غالبًا ما تتم إدارة ``classes_`` والتعيين إلى الفهارس باستخدام
        :class:`preprocessing.LabelEncoder`.


    ``components_``
        مصفوفة تحويل تآلفي ذات شكل ``(n_components, n_features)``
        تُستخدم في العديد من :term:`المحولات` الخطية حيث :term:`n_components` هو
        عدد ميزات الإخراج و :term:`n_features` هو عدد ميزات
        الإدخال.


        انظر أيضًا :term:`components_` وهي سمة مماثلة للمتنبئات
        الخطية.


    ``coef_``
        مصفوفة الوزن/المعامل لنموذج خطي معمم
        :term:`متنبئ`، ذات شكل ``(n_features,)`` للتصنيف الثنائي
        والانحدار أحادي الناتج، ``(n_classes, n_features)`` لـ
        التصنيف متعدد الفئات و ``(n_targets, n_features)`` لـ
        الانحدار متعدد المخرجات. لاحظ أن هذا لا يتضمن مصطلح التقاطع
        (أو التحيز)، والذي يتم تخزينه في ``intercept_``.



        عندما تكون متاحة، لا يتم توفير ``feature_importances_`` عادةً أيضًا،
        ولكن يمكن حسابها كمعيار إدخال كل ميزة في
        ``coef_``.


        انظر أيضًا :term:`components_` وهي سمة مماثلة للمحولات
        الخطية.


    ``embedding_``
        تضمين لبيانات التدريب في مقدرات :ref:`تعلم متعدد الشعب
        <manifold>`، ذات شكل ``(n_samples, n_components)``،
        مطابق لناتج :term:`fit_transform`.  انظر أيضًا
        :term:`labels_`.


    ``n_iter_``
        عدد التكرارات التي تم إجراؤها فعليًا عند ملاءمة مقدر تكراري
        قد يتوقف عند التقارب. انظر أيضًا :term:`max_iter`.


    ``feature_importances_``
        متجه ذو شكل ``(n_features,)`` متاح في بعض
        :term:`المتنبئات` لتوفير مقياس نسبي لأهمية
        كل ميزة في تنبؤات النموذج.



    ``labels_``
        متجه يحتوي على تسمية كتلة لكل عينة من بيانات التدريب
        في :term:`المُجمِّعات`، مطابق لناتج
        :term:`fit_predict`.  انظر أيضًا :term:`embedding_`.


.. _glossary_sample_props:

خصائص البيانات والعينة
==========================


انظر المفهوم :term:`خاصية العينة`.


.. glossary::

    ``groups``
        يُستخدم في إجراءات التحقق المتبادل لتحديد العينات المترابطة.
        كل قيمة هي مُعرِّف بحيث، في :term:`مُقسِّم CV` داعم،
        قد لا تظهر العينات من قيمة ``groups`` في كل من مجموعة التدريب
        ومجموعة الاختبار المقابلة لها.
        انظر :ref:`group_cv`.


    ``sample_weight``
        وزن نسبي لكل عينة.  بشكل حدسي، إذا كانت جميع الأوزان
        أعدادًا صحيحة، فيجب أن يكون النموذج أو الدرجة الموزونة مكافئة لتلك
        المحسوبة عند تكرار العينة بعدد المرات المحددة في
        الوزن. قد يتم تحديد الأوزان كعناصر عشرية، بحيث تكون أوزان العينة
        عادةً مكافئة لعامل قياس ثابت موجب.


        FIXME هل هذا التفسير هو الحال دائمًا في الممارسة؟ ليس لدينا
        اختبارات شائعة.


        تدعم بعض المقدرات، مثل أشجار القرار، الأوزان السلبية.
        FIXME: قد لا يتم اختبار هذه الميزة أو غيابها أو توثيقها في
        العديد من المقدرات.



        هذا ليس هو الحال تمامًا عندما تأخذ معلمات أخرى للنموذج
        في الاعتبار عدد العينات في منطقة ما، كما هو الحال مع ``min_samples`` في
        :class:`cluster.DBSCAN`. في هذه الحالة، يصبح عدد العينات
        مجموع أوزانها.


        في التصنيف، يمكن أيضًا تحديد أوزان العينة كدالة
        للفئة مع :term:`معلمة` المقدر :term:`class_weight`.


    ``X``
        يشير إلى البيانات التي يتم ملاحظتها في وقت التدريب والتنبؤ، وتُستخدم كـ
        متغيرات مستقلة في التعلم. يكون الترميز بأحرف كبيرة للإشارة
        إلى أنه عادةً ما يكون مصفوفة (انظر :term:`مستطيلي`).
        عندما تكون مصفوفة، يمكن تمثيل كل عينة بواسطة متجه :term:`ميزة`،
        أو متجه :term:`محسوب مسبقًا` (عدم) تشابه مع كل
        عينة تدريب. قد لا يكون ``X`` مصفوفة أيضًا، وقد يتطلب
        :term:`مستخرج ميزات` أو :term:`مقياس زوجي` لتحويله إلى
        واحد قبل تعلم نموذج.



    ``Xt``
        اختصار لـ "X :term:`مُحوَّل`".

    ``y``
    ``Y``
        يشير إلى البيانات التي قد يتم ملاحظتها في وقت التدريب كمتغير
        تابع في التعلم، ولكنها غير متوفرة في وقت التنبؤ، و
        عادةً ما تكون :term:`هدف` التنبؤ. قد يكون الترميز
        بأحرف كبيرة للإشارة إلى أنه مصفوفة، يمثل
        :term:`مخرجات متعددة`، على سبيل المثال؛ ولكن عادةً ما نستخدم ``y`` و
        أحيانًا نفعل ذلك حتى عند افتراض مخرجات متعددة.



