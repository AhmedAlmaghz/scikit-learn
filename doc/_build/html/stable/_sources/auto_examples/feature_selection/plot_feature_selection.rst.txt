
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/feature_selection/plot_feature_selection.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_feature_selection_plot_feature_selection.py>`
        to download the full example code. or to run this example in your browser via JupyterLite or Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_feature_selection_plot_feature_selection.py:


===============================
اختيار الميزة أحادية المتغير
===============================

هذا الدفتر هو مثال على استخدام اختيار الميزات أحادي المتغير
لتحسين دقة التصنيف على مجموعة بيانات صاخبة.

في هذا المثال، تتم إضافة بعض الميزات الصاخبة (غير المعلوماتية) إلى
مجموعة بيانات iris. يتم استخدام آلة متجه الدعم (SVM) لتصنيف
مجموعة البيانات قبل وبعد تطبيق اختيار الميزات أحادي المتغير.
لكل ميزة، نرسم قيم p لاختيار الميزات أحادي المتغير
والأوزان المقابلة لـ SVMs. مع هذا، سنقارن دقة النموذج
ونفحص تأثير اختيار الميزات أحادي المتغير على أوزان النموذج.

.. GENERATED FROM PYTHON SOURCE LINES 17-21

.. code-block:: Python


    # Authors: The scikit-learn developers
    # SPDX-License-Identifier: BSD-3-Clause








.. GENERATED FROM PYTHON SOURCE LINES 22-25

توليد بيانات العينة
--------------------


.. GENERATED FROM PYTHON SOURCE LINES 25-42

.. code-block:: Python

    import numpy as np

    from sklearn.datasets import load_iris
    from sklearn.model_selection import train_test_split

    # The iris dataset
    X, y = load_iris(return_X_y=True)

    # Some noisy data not correlated
    E = np.random.RandomState(42).uniform(0, 0.1, size=(X.shape[0], 20))

    # Add the noisy data to the informative features
    X = np.hstack((X, E))

    # Split dataset to select feature and evaluate the classifier
    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=0)








.. GENERATED FROM PYTHON SOURCE LINES 43-49

اختيار الميزات أحادي المتغير
----------------------------

اختيار الميزات أحادي المتغير مع اختبار F لتسجيل الميزات.
نستخدم دالة الاختيار الافتراضية لتحديد
أهم أربع ميزات.

.. GENERATED FROM PYTHON SOURCE LINES 49-56

.. code-block:: Python

    from sklearn.feature_selection import SelectKBest, f_classif

    selector = SelectKBest(f_classif, k=4)
    selector.fit(X_train, y_train)
    scores = -np.log10(selector.pvalues_)
    scores /= scores.max()








.. GENERATED FROM PYTHON SOURCE LINES 57-68

.. code-block:: Python

    import matplotlib.pyplot as plt

    X_indices = np.arange(X.shape[-1])
    plt.figure(1)
    plt.clf()
    plt.bar(X_indices - 0.05, scores, width=0.2)
    plt.title("درجة الميزة أحادية المتغير")
    plt.xlabel("رقم الميزة")
    plt.ylabel(r"Univariate score ($-Log(p_{value})$)")
    plt.show()




.. image-sg:: /auto_examples/feature_selection/images/sphx_glr_plot_feature_selection_001.png
   :alt: درجة الميزة أحادية المتغير
   :srcset: /auto_examples/feature_selection/images/sphx_glr_plot_feature_selection_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 69-71

في المجموعة الكلية من الميزات، فقط 4 من الميزات الأصلية مهمة.
يمكننا أن نرى أن لديهم أعلى درجة مع اختيار الميزات أحادي المتغير.

.. GENERATED FROM PYTHON SOURCE LINES 74-78

المقارنة مع SVMs
-----------------

بدون اختيار الميزات أحادي المتغير

.. GENERATED FROM PYTHON SOURCE LINES 78-93

.. code-block:: Python

    from sklearn.pipeline import make_pipeline
    from sklearn.preprocessing import MinMaxScaler
    from sklearn.svm import LinearSVC

    clf = make_pipeline(MinMaxScaler(), LinearSVC())
    clf.fit(X_train, y_train)
    print(
        "دقة التصنيف بدون اختيار الميزات: {:.3f}".format(
            clf.score(X_test, y_test)
        )
    )

    svm_weights = np.abs(clf[-1].coef_).sum(axis=0)
    svm_weights /= svm_weights.sum()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    دقة التصنيف بدون اختيار الميزات: 0.789




.. GENERATED FROM PYTHON SOURCE LINES 94-95

بعد اختيار الميزات أحادي المتغير

.. GENERATED FROM PYTHON SOURCE LINES 95-106

.. code-block:: Python

    clf_selected = make_pipeline(SelectKBest(f_classif, k=4), MinMaxScaler(), LinearSVC())
    clf_selected.fit(X_train, y_train)
    print(
        "دقة التصنيف بعد اختيار الميزات أحادي المتغير: {:.3f}".format(
            clf_selected.score(X_test, y_test)
        )
    )

    svm_weights_selected = np.abs(clf_selected[-1].coef_).sum(axis=0)
    svm_weights_selected /= svm_weights_selected.sum()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    دقة التصنيف بعد اختيار الميزات أحادي المتغير: 0.868




.. GENERATED FROM PYTHON SOURCE LINES 107-127

.. code-block:: Python

    plt.bar(
        X_indices - 0.45, scores, width=0.2, label=r"Univariate score ($-Log(p_{value})$)"
    )

    plt.bar(X_indices - 0.25, svm_weights, width=0.2, label="SVM weight")

    plt.bar(
        X_indices[selector.get_support()] - 0.05,
        svm_weights_selected,
        width=0.2,
        label="SVM weights after selection",
    )

    plt.title("مقارنة اختيار الميزات")
    plt.xlabel("رقم الميزة")
    plt.yticks(())
    plt.axis("tight")
    plt.legend(loc="upper right")
    plt.show()




.. image-sg:: /auto_examples/feature_selection/images/sphx_glr_plot_feature_selection_002.png
   :alt: مقارنة اختيار الميزات
   :srcset: /auto_examples/feature_selection/images/sphx_glr_plot_feature_selection_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 128-133

بدون اختيار الميزات أحادي المتغير، تعين SVM وزنًا كبيرًا
لأول 4 ميزات أصلية مهمة، ولكنها تختار أيضًا العديد من
الميزات غير المعلوماتية. تطبيق اختيار الميزات أحادي المتغير قبل
SVM يزيد من وزن SVM المنسوب إلى الميزات المهمة،
وبالتالي سيحسن التصنيف.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 0.327 seconds)


.. _sphx_glr_download_auto_examples_feature_selection_plot_feature_selection.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/scikit-learn/scikit-learn/main?urlpath=lab/tree/notebooks/auto_examples/feature_selection/plot_feature_selection.ipynb
        :alt: Launch binder
        :width: 150 px

    .. container:: lite-badge

      .. image:: images/jupyterlite_badge_logo.svg
        :target: ../../lite/lab/index.html?path=auto_examples/feature_selection/plot_feature_selection.ipynb
        :alt: Launch JupyterLite
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_feature_selection.ipynb <plot_feature_selection.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_feature_selection.py <plot_feature_selection.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_feature_selection.zip <plot_feature_selection.zip>`


.. include:: plot_feature_selection.recommendations


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
