
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/linear_model/plot_lasso_model_selection.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_linear_model_plot_lasso_model_selection.py>`
        to download the full example code. or to run this example in your browser via JupyterLite or Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_linear_model_plot_lasso_model_selection.py:


========================================================================
نموذج لاصو: اختيار النموذج باستخدام معايير AIC-BIC والتحقق المتقاطع
========================================================================

يركز هذا المثال على اختيار النموذج لنموذج لاصو، وهي نماذج خطية مع عقوبة L1 لمشاكل الانحدار.

في الواقع، يمكن استخدام عدة استراتيجيات لاختيار قيمة معامل التنظيم: من خلال التحقق المتقاطع أو باستخدام معيار المعلومات، مثل AIC أو BIC.

فيما يلي، سنناقش بالتفصيل الاستراتيجيات المختلفة.

.. GENERATED FROM PYTHON SOURCE LINES 12-15

.. code-block:: Python

    # المؤلفون: مطوري سكايت-ليرن
    # معرف الترخيص: BSD-3-Clause








.. GENERATED FROM PYTHON SOURCE LINES 16-19

مجموعة البيانات
-------
في هذا المثال، سنستخدم مجموعة بيانات مرض السكري.

.. GENERATED FROM PYTHON SOURCE LINES 19-24

.. code-block:: Python

    from sklearn.datasets import load_diabetes

    X, y = load_diabetes(return_X_y=True, as_frame=True)
    X.head()






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>age</th>
          <th>sex</th>
          <th>bmi</th>
          <th>bp</th>
          <th>s1</th>
          <th>s2</th>
          <th>s3</th>
          <th>s4</th>
          <th>s5</th>
          <th>s6</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>0.038076</td>
          <td>0.050680</td>
          <td>0.061696</td>
          <td>0.021872</td>
          <td>-0.044223</td>
          <td>-0.034821</td>
          <td>-0.043401</td>
          <td>-0.002592</td>
          <td>0.019907</td>
          <td>-0.017646</td>
        </tr>
        <tr>
          <th>1</th>
          <td>-0.001882</td>
          <td>-0.044642</td>
          <td>-0.051474</td>
          <td>-0.026328</td>
          <td>-0.008449</td>
          <td>-0.019163</td>
          <td>0.074412</td>
          <td>-0.039493</td>
          <td>-0.068332</td>
          <td>-0.092204</td>
        </tr>
        <tr>
          <th>2</th>
          <td>0.085299</td>
          <td>0.050680</td>
          <td>0.044451</td>
          <td>-0.005670</td>
          <td>-0.045599</td>
          <td>-0.034194</td>
          <td>-0.032356</td>
          <td>-0.002592</td>
          <td>0.002861</td>
          <td>-0.025930</td>
        </tr>
        <tr>
          <th>3</th>
          <td>-0.089063</td>
          <td>-0.044642</td>
          <td>-0.011595</td>
          <td>-0.036656</td>
          <td>0.012191</td>
          <td>0.024991</td>
          <td>-0.036038</td>
          <td>0.034309</td>
          <td>0.022688</td>
          <td>-0.009362</td>
        </tr>
        <tr>
          <th>4</th>
          <td>0.005383</td>
          <td>-0.044642</td>
          <td>-0.036385</td>
          <td>0.021872</td>
          <td>0.003935</td>
          <td>0.015596</td>
          <td>0.008142</td>
          <td>-0.002592</td>
          <td>-0.031988</td>
          <td>-0.046641</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 25-27

بالإضافة إلى ذلك، سنضيف بعض الميزات العشوائية إلى البيانات الأصلية لتوضيح
بشكل أفضل عملية اختيار الميزات التي يقوم بها نموذج لاصو.

.. GENERATED FROM PYTHON SOURCE LINES 27-40

.. code-block:: Python

    import numpy as np
    import pandas as pd

    rng = np.random.RandomState(42)
    n_random_features = 14
    X_random = pd.DataFrame(
        rng.randn(X.shape[0], n_random_features),
        columns=[f"random_{i:02d}" for i in range(n_random_features)],
    )
    X = pd.concat([X, X_random], axis=1)
    # عرض مجموعة فرعية فقط من الأعمدة
    X[X.columns[::3]].head()






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>age</th>
          <th>bp</th>
          <th>s3</th>
          <th>s6</th>
          <th>random_02</th>
          <th>random_05</th>
          <th>random_08</th>
          <th>random_11</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>0.038076</td>
          <td>0.021872</td>
          <td>-0.043401</td>
          <td>-0.017646</td>
          <td>0.647689</td>
          <td>-0.234137</td>
          <td>-0.469474</td>
          <td>-0.465730</td>
        </tr>
        <tr>
          <th>1</th>
          <td>-0.001882</td>
          <td>-0.026328</td>
          <td>0.074412</td>
          <td>-0.092204</td>
          <td>-1.012831</td>
          <td>-1.412304</td>
          <td>0.067528</td>
          <td>0.110923</td>
        </tr>
        <tr>
          <th>2</th>
          <td>0.085299</td>
          <td>-0.005670</td>
          <td>-0.032356</td>
          <td>-0.025930</td>
          <td>-0.601707</td>
          <td>-1.057711</td>
          <td>0.208864</td>
          <td>0.196861</td>
        </tr>
        <tr>
          <th>3</th>
          <td>-0.089063</td>
          <td>-0.036656</td>
          <td>-0.036038</td>
          <td>-0.009362</td>
          <td>-1.478522</td>
          <td>1.057122</td>
          <td>0.324084</td>
          <td>0.611676</td>
        </tr>
        <tr>
          <th>4</th>
          <td>0.005383</td>
          <td>0.021872</td>
          <td>0.008142</td>
          <td>-0.046641</td>
          <td>0.331263</td>
          <td>-0.185659</td>
          <td>0.812526</td>
          <td>1.003533</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 41-52

اختيار نموذج لاصو باستخدام معيار المعلومات
--------------------------------------------
:class:`~sklearn.linear_model.LassoLarsIC` يوفر نموذج لاصو يستخدم معيار
معلومات أكايكي (AIC) أو معيار معلومات بايز (BIC) لاختيار القيمة المثلى لمعامل
التنظيم alpha.

قبل ملاءمة النموذج، سنقوم بتوحيد البيانات باستخدام
:class:`~sklearn.preprocessing.StandardScaler`. بالإضافة إلى ذلك، سنقوم
بقياس الوقت لملاءمة وضبط معامل alpha لكي نقارن مع استراتيجية التحقق المتقاطع.

سنقوم أولاً بملاءمة نموذج لاصو باستخدام معيار AIC.

.. GENERATED FROM PYTHON SOURCE LINES 52-62

.. code-block:: Python

    import time

    from sklearn.linear_model import LassoLarsIC
    from sklearn.pipeline import make_pipeline
    from sklearn.preprocessing import StandardScaler

    start_time = time.time()
    lasso_lars_ic = make_pipeline(StandardScaler(), LassoLarsIC(criterion="aic")).fit(X, y)
    fit_time = time.time() - start_time








.. GENERATED FROM PYTHON SOURCE LINES 63-64

سنخزن معيار AIC لكل قيمة من قيم alpha المستخدمة خلال `fit`.

.. GENERATED FROM PYTHON SOURCE LINES 64-72

.. code-block:: Python

    results = pd.DataFrame(
        {
            "alphas": lasso_lars_ic[-1].alphas_,
            "AIC criterion": lasso_lars_ic[-1].criterion_,
        }
    ).set_index("alphas")
    alpha_aic = lasso_lars_ic[-1].alpha_








.. GENERATED FROM PYTHON SOURCE LINES 73-74

الآن، سنقوم بنفس التحليل باستخدام معيار BIC.

.. GENERATED FROM PYTHON SOURCE LINES 74-79

.. code-block:: Python

    lasso_lars_ic.set_params(lassolarsic__criterion="bic").fit(X, y)
    results["BIC criterion"] = lasso_lars_ic[-1].criterion_
    alpha_bic = lasso_lars_ic[-1].alpha_









.. GENERATED FROM PYTHON SOURCE LINES 80-81

يمكننا التحقق من قيمة `alpha` التي تؤدي إلى الحد الأدنى من AIC وBIC.

.. GENERATED FROM PYTHON SOURCE LINES 81-88

.. code-block:: Python

    def highlight_min(x):
        x_min = x.min()
        return ["font-weight: bold" if v == x_min else "" for v in x]


    results.style.apply(highlight_min)






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <style type="text/css">
    #T_5df86_row6_col1, #T_5df86_row21_col0 {
      font-weight: bold;
    }
    </style>
    <table id="T_5df86">
      <thead>
        <tr>
          <th class="blank level0" >&nbsp;</th>
          <th id="T_5df86_level0_col0" class="col_heading level0 col0" >AIC criterion</th>
          <th id="T_5df86_level0_col1" class="col_heading level0 col1" >BIC criterion</th>
        </tr>
        <tr>
          <th class="index_name level0" >alphas</th>
          <th class="blank col0" >&nbsp;</th>
          <th class="blank col1" >&nbsp;</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th id="T_5df86_level0_row0" class="row_heading level0 row0" >45.160030</th>
          <td id="T_5df86_row0_col0" class="data row0 col0" >5244.764779</td>
          <td id="T_5df86_row0_col1" class="data row0 col1" >5244.764779</td>
        </tr>
        <tr>
          <th id="T_5df86_level0_row1" class="row_heading level0 row1" >42.300343</th>
          <td id="T_5df86_row1_col0" class="data row1 col0" >5208.250639</td>
          <td id="T_5df86_row1_col1" class="data row1 col1" >5212.341949</td>
        </tr>
        <tr>
          <th id="T_5df86_level0_row2" class="row_heading level0 row2" >21.542052</th>
          <td id="T_5df86_row2_col0" class="data row2 col0" >4928.018900</td>
          <td id="T_5df86_row2_col1" class="data row2 col1" >4936.201520</td>
        </tr>
        <tr>
          <th id="T_5df86_level0_row3" class="row_heading level0 row3" >15.034077</th>
          <td id="T_5df86_row3_col0" class="data row3 col0" >4869.678359</td>
          <td id="T_5df86_row3_col1" class="data row3 col1" >4881.952289</td>
        </tr>
        <tr>
          <th id="T_5df86_level0_row4" class="row_heading level0 row4" >6.189631</th>
          <td id="T_5df86_row4_col0" class="data row4 col0" >4815.437362</td>
          <td id="T_5df86_row4_col1" class="data row4 col1" >4831.802601</td>
        </tr>
        <tr>
          <th id="T_5df86_level0_row5" class="row_heading level0 row5" >5.329616</th>
          <td id="T_5df86_row5_col0" class="data row5 col0" >4810.423641</td>
          <td id="T_5df86_row5_col1" class="data row5 col1" >4830.880191</td>
        </tr>
        <tr>
          <th id="T_5df86_level0_row6" class="row_heading level0 row6" >4.306012</th>
          <td id="T_5df86_row6_col0" class="data row6 col0" >4803.573491</td>
          <td id="T_5df86_row6_col1" class="data row6 col1" >4828.121351</td>
        </tr>
        <tr>
          <th id="T_5df86_level0_row7" class="row_heading level0 row7" >4.124225</th>
          <td id="T_5df86_row7_col0" class="data row7 col0" >4804.126502</td>
          <td id="T_5df86_row7_col1" class="data row7 col1" >4832.765671</td>
        </tr>
        <tr>
          <th id="T_5df86_level0_row8" class="row_heading level0 row8" >3.820705</th>
          <td id="T_5df86_row8_col0" class="data row8 col0" >4803.621645</td>
          <td id="T_5df86_row8_col1" class="data row8 col1" >4836.352124</td>
        </tr>
        <tr>
          <th id="T_5df86_level0_row9" class="row_heading level0 row9" >3.750389</th>
          <td id="T_5df86_row9_col0" class="data row9 col0" >4805.012521</td>
          <td id="T_5df86_row9_col1" class="data row9 col1" >4841.834310</td>
        </tr>
        <tr>
          <th id="T_5df86_level0_row10" class="row_heading level0 row10" >3.570655</th>
          <td id="T_5df86_row10_col0" class="data row10 col0" >4805.290075</td>
          <td id="T_5df86_row10_col1" class="data row10 col1" >4846.203174</td>
        </tr>
        <tr>
          <th id="T_5df86_level0_row11" class="row_heading level0 row11" >3.550213</th>
          <td id="T_5df86_row11_col0" class="data row11 col0" >4807.075887</td>
          <td id="T_5df86_row11_col1" class="data row11 col1" >4852.080295</td>
        </tr>
        <tr>
          <th id="T_5df86_level0_row12" class="row_heading level0 row12" >3.358295</th>
          <td id="T_5df86_row12_col0" class="data row12 col0" >4806.878051</td>
          <td id="T_5df86_row12_col1" class="data row12 col1" >4855.973770</td>
        </tr>
        <tr>
          <th id="T_5df86_level0_row13" class="row_heading level0 row13" >3.259297</th>
          <td id="T_5df86_row13_col0" class="data row13 col0" >4807.706026</td>
          <td id="T_5df86_row13_col1" class="data row13 col1" >4860.893055</td>
        </tr>
        <tr>
          <th id="T_5df86_level0_row14" class="row_heading level0 row14" >3.237703</th>
          <td id="T_5df86_row14_col0" class="data row14 col0" >4809.440409</td>
          <td id="T_5df86_row14_col1" class="data row14 col1" >4866.718747</td>
        </tr>
        <tr>
          <th id="T_5df86_level0_row15" class="row_heading level0 row15" >2.850031</th>
          <td id="T_5df86_row15_col0" class="data row15 col0" >4805.989341</td>
          <td id="T_5df86_row15_col1" class="data row15 col1" >4867.358990</td>
        </tr>
        <tr>
          <th id="T_5df86_level0_row16" class="row_heading level0 row16" >2.384338</th>
          <td id="T_5df86_row16_col0" class="data row16 col0" >4801.702266</td>
          <td id="T_5df86_row16_col1" class="data row16 col1" >4867.163224</td>
        </tr>
        <tr>
          <th id="T_5df86_level0_row17" class="row_heading level0 row17" >2.296575</th>
          <td id="T_5df86_row17_col0" class="data row17 col0" >4802.594754</td>
          <td id="T_5df86_row17_col1" class="data row17 col1" >4872.147022</td>
        </tr>
        <tr>
          <th id="T_5df86_level0_row18" class="row_heading level0 row18" >2.031555</th>
          <td id="T_5df86_row18_col0" class="data row18 col0" >4801.236720</td>
          <td id="T_5df86_row18_col1" class="data row18 col1" >4874.880298</td>
        </tr>
        <tr>
          <th id="T_5df86_level0_row19" class="row_heading level0 row19" >1.618263</th>
          <td id="T_5df86_row19_col0" class="data row19 col0" >4798.484109</td>
          <td id="T_5df86_row19_col1" class="data row19 col1" >4876.218997</td>
        </tr>
        <tr>
          <th id="T_5df86_level0_row20" class="row_heading level0 row20" >1.526599</th>
          <td id="T_5df86_row20_col0" class="data row20 col0" >4799.543841</td>
          <td id="T_5df86_row20_col1" class="data row20 col1" >4881.370039</td>
        </tr>
        <tr>
          <th id="T_5df86_level0_row21" class="row_heading level0 row21" >0.586798</th>
          <td id="T_5df86_row21_col0" class="data row21 col0" >4794.238744</td>
          <td id="T_5df86_row21_col1" class="data row21 col1" >4880.156252</td>
        </tr>
        <tr>
          <th id="T_5df86_level0_row22" class="row_heading level0 row22" >0.445978</th>
          <td id="T_5df86_row22_col0" class="data row22 col0" >4795.589715</td>
          <td id="T_5df86_row22_col1" class="data row22 col1" >4885.598533</td>
        </tr>
        <tr>
          <th id="T_5df86_level0_row23" class="row_heading level0 row23" >0.259031</th>
          <td id="T_5df86_row23_col0" class="data row23 col0" >4796.966981</td>
          <td id="T_5df86_row23_col1" class="data row23 col1" >4891.067109</td>
        </tr>
        <tr>
          <th id="T_5df86_level0_row24" class="row_heading level0 row24" >0.032179</th>
          <td id="T_5df86_row24_col0" class="data row24 col0" >4794.662409</td>
          <td id="T_5df86_row24_col1" class="data row24 col1" >4888.762537</td>
        </tr>
        <tr>
          <th id="T_5df86_level0_row25" class="row_heading level0 row25" >0.019069</th>
          <td id="T_5df86_row25_col0" class="data row25 col0" >4794.652739</td>
          <td id="T_5df86_row25_col1" class="data row25 col1" >4888.752867</td>
        </tr>
        <tr>
          <th id="T_5df86_level0_row26" class="row_heading level0 row26" >0.000000</th>
          <td id="T_5df86_row26_col0" class="data row26 col0" >4796.626286</td>
          <td id="T_5df86_row26_col1" class="data row26 col1" >4894.817724</td>
        </tr>
      </tbody>
    </table>

    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 89-92

أخيراً، يمكننا رسم قيم AIC وBIC لمختلف قيم alpha.
الخطوط العمودية في الرسم البياني تقابل قيمة alpha المختارة لكل معيار.
قيمة alpha المختارة تقابل الحد الأدنى من معيار AIC أو BIC.

.. GENERATED FROM PYTHON SOURCE LINES 92-117

.. code-block:: Python

    ax = results.plot()
    ax.vlines(
        alpha_aic,
        results["AIC criterion"].min(),
        results["AIC criterion"].max(),
        label="alpha: AIC estimate",
        linestyles="--",
        color="tab:blue",
    )
    ax.vlines(
        alpha_bic,
        results["BIC criterion"].min(),
        results["BIC criterion"].max(),
        label="alpha: BIC estimate",
        linestyle="--",
        color="tab:orange",
    )
    ax.set_xlabel(r"$\alpha$")
    ax.set_ylabel("criterion")
    ax.set_xscale("log")
    ax.legend()
    _ = ax.set_title(
        f"Information-criterion for model selection (training time {fit_time:.2f}s)"
    )




.. image-sg:: /auto_examples/linear_model/images/sphx_glr_plot_lasso_model_selection_001.png
   :alt: Information-criterion for model selection (training time 0.01s)
   :srcset: /auto_examples/linear_model/images/sphx_glr_plot_lasso_model_selection_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 118-146

اختيار النموذج باستخدام معيار المعلومات سريع للغاية. يعتمد على
حساب المعيار على مجموعة العينات المقدمة إلى `fit`. كلا المعيارين
يقدران خطأ تعميم النموذج بناءً على خطأ مجموعة التدريب ويعاقبان هذا الخطأ
المتفائل بشكل مفرط. ومع ذلك، تعتمد هذه العقوبة على تقدير صحيح لدرجات الحرية
وتقلب الضوضاء. يتم اشتقاق كلاهما للعينات الكبيرة (النتائج التقاربية) ويفترض
أن النموذج صحيح، أي أن البيانات يتم توليدها بالفعل بواسطة هذا النموذج.

تميل هذه النماذج أيضًا إلى التعطل عندما تكون المشكلة سيئة التكييف (أكثر
من الميزات من العينات). عندها يكون من الضروري توفير تقدير لتقلب الضوضاء.

اختيار نموذج لاصو باستخدام التحقق المتقاطع
------------------------------------
يمكن تنفيذ نموذج لاصو باستخدام محسنات مختلفة: الانحدار المنسق والانحدار
بزاوية أقل. تختلف هذه المحسنات فيما يتعلق بسرعة التنفيذ ومصادر الأخطاء
العددية.

في سكايت-ليرن، هناك محسنان مختلفان متاحان مع التحقق المتقاطع المدمج:
:class:`~sklearn.linear_model.LassoCV` و:class:`~sklearn.linear_model.LassoLarsCV`
اللذان يحلان المشكلة باستخدام الانحدار المنسق والانحدار بزاوية أقل على
التوالي.

في بقية هذا القسم، سنقدم كلا النهجين. بالنسبة لكلا الخوارزميتين، سنستخدم
استراتيجية التحقق المتقاطع 20-fold.

نموذج لاصو باستخدام الانحدار المنسق
............................
دعنا نبدأ بضبط المعامل باستخدام
:class:`~sklearn.linear_model.LassoCV`.

.. GENERATED FROM PYTHON SOURCE LINES 146-152

.. code-block:: Python

    from sklearn.linear_model import LassoCV

    start_time = time.time()
    model = make_pipeline(StandardScaler(), LassoCV(cv=20)).fit(X, y)
    fit_time = time.time() - start_time








.. GENERATED FROM PYTHON SOURCE LINES 153-175

.. code-block:: Python

    import matplotlib.pyplot as plt

    ymin, ymax = 2300, 3800
    lasso = model[-1]
    plt.semilogx(lasso.alphas_, lasso.mse_path_, linestyle=":")
    plt.plot(
        lasso.alphas_,
        lasso.mse_path_.mean(axis=-1),
        color="black",
        label="Average across the folds",
        linewidth=2,
    )
    plt.axvline(lasso.alpha_, linestyle="--", color="black", label="alpha: CV estimate")

    plt.ylim(ymin, ymax)
    plt.xlabel(r"$\alpha$")
    plt.ylabel("Mean square error")
    plt.legend()
    _ = plt.title(
        f"Mean square error on each fold: coordinate descent (train time: {fit_time:.2f}s)"
    )




.. image-sg:: /auto_examples/linear_model/images/sphx_glr_plot_lasso_model_selection_002.png
   :alt: Mean square error on each fold: coordinate descent (train time: 0.35s)
   :srcset: /auto_examples/linear_model/images/sphx_glr_plot_lasso_model_selection_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 176-180

نموذج لاصو باستخدام الانحدار بزاوية أقل
................................
دعنا نبدأ بضبط المعامل باستخدام
:class:`~sklearn.linear_model.LassoLarsCV`.

.. GENERATED FROM PYTHON SOURCE LINES 180-186

.. code-block:: Python

    from sklearn.linear_model import LassoLarsCV

    start_time = time.time()
    model = make_pipeline(StandardScaler(), LassoLarsCV(cv=20)).fit(X, y)
    fit_time = time.time() - start_time








.. GENERATED FROM PYTHON SOURCE LINES 187-204

.. code-block:: Python

    lasso = model[-1]
    plt.semilogx(lasso.cv_alphas_, lasso.mse_path_, ":")
    plt.semilogx(
        lasso.cv_alphas_,
        lasso.mse_path_.mean(axis=-1),
        color="black",
        label="Average across the folds",
        linewidth=2,
    )
    plt.axvline(lasso.alpha_, linestyle="--", color="black", label="alpha CV")

    plt.ylim(ymin, ymax)
    plt.xlabel(r"$\alpha$")
    plt.ylabel("Mean square error")
    plt.legend()
    _ = plt.title(f"Mean square error on each fold: Lars (train time: {fit_time:.2f}s)")




.. image-sg:: /auto_examples/linear_model/images/sphx_glr_plot_lasso_model_selection_003.png
   :alt: Mean square error on each fold: Lars (train time: 0.08s)
   :srcset: /auto_examples/linear_model/images/sphx_glr_plot_lasso_model_selection_003.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 205-238

ملخص نهج التحقق المتقاطع
....................................
كلا الخوارزميتين تعطيان نتائج متشابهة تقريبًا.

يحسب Lars مسار الحل فقط لكل انحناء في المسار. ونتيجة لذلك، فهو فعال
للغاية عندما يكون هناك عدد قليل من الانحناءات، وهو الحال إذا كان هناك عدد
قليل من الميزات أو العينات. كما أنه قادر على حساب المسار الكامل دون
ضبط أي معامل. على العكس، يحسب الانحدار المنسق نقاط المسار على شبكة
محددة مسبقًا (هنا نستخدم الافتراضية).
وبالتالي فهو أكثر كفاءة إذا كان عدد نقاط الشبكة أصغر من عدد الانحناءات
في المسار. يمكن أن تكون هذه الاستراتيجية مثيرة للاهتمام إذا كان عدد
الميزات كبيرًا جدًا وكان هناك ما يكفي من العينات ليتم اختيارها في كل
طية من طيات التحقق المتقاطع. من حيث الأخطاء العددية، بالنسبة للمتغيرات
المترابطة بشدة، سيتراكم Lars المزيد من الأخطاء، بينما سيقوم خوارزمية
الانحدار المنسق باختيار المسار فقط على شبكة.

لاحظ كيف تختلف القيمة المثلى لـ alpha لكل طية. يوضح هذا لماذا يعد
التحقق المتقاطع المضمن استراتيجية جيدة عند محاولة تقييم أداء طريقة يتم
اختيار معامل لها بواسطة التحقق المتقاطع: قد لا يكون هذا الاختيار
للمعامل الأمثل للتقييم النهائي على مجموعة اختبار غير مرئية فقط.

الخلاصة
----------
في هذا البرنامج التعليمي، قدمنا نهجين لاختيار أفضل معامل
`alpha`: استراتيجية واحدة تجد القيمة المثلى لـ `alpha`
باستخدام مجموعة التدريب فقط وبعض معايير المعلومات، واستراتيجية أخرى
تعتمد على التحقق المتقاطع.

في هذا المثال، يعمل كلا النهجين بشكل مشابه. اختيار المعامل داخل العينة
يظهر حتى فعاليته من حيث الأداء الحسابي. ومع ذلك، يمكن استخدامه فقط
عندما يكون عدد العينات كبيرًا بما فيه الكفاية مقارنةً بعدد الميزات.

لهذا السبب، يعد ضبط المعامل باستخدام التحقق المتقاطع استراتيجية آمنة:
تعمل في إعدادات مختلفة.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 1.165 seconds)


.. _sphx_glr_download_auto_examples_linear_model_plot_lasso_model_selection.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/scikit-learn/scikit-learn/main?urlpath=lab/tree/notebooks/auto_examples/linear_model/plot_lasso_model_selection.ipynb
        :alt: Launch binder
        :width: 150 px

    .. container:: lite-badge

      .. image:: images/jupyterlite_badge_logo.svg
        :target: ../../lite/lab/index.html?path=auto_examples/linear_model/plot_lasso_model_selection.ipynb
        :alt: Launch JupyterLite
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_lasso_model_selection.ipynb <plot_lasso_model_selection.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_lasso_model_selection.py <plot_lasso_model_selection.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_lasso_model_selection.zip <plot_lasso_model_selection.zip>`


.. include:: plot_lasso_model_selection.recommendations


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
