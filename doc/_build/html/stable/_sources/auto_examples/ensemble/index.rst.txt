

.. _sphx_glr_auto_examples_ensemble:

.. _ensemble_examples:

طرق المجموعة
--------------
Ensemble methods

أمثلة تتعلق بوحدة :mod:`sklearn.ensemble`.


.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Stacking refers to a method to blend estimators. In this strategy, some estimators are individually fitted on some training data while a final estimator is trained using the stacked predictions of these base estimators.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_stack_predictors_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_stack_predictors.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Combine predictors using stacking</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="An example to compare multi-output regression with random forest and the multiclass meta-estimator.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_random_forest_regression_multioutput_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_random_forest_regression_multioutput.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Comparing random forests and the multi-output meta estimator</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="histogram_based_gradient_boosting (HGBT) models may be one of the most useful supervised learning models in scikit-learn. They are based on a modern gradient boosting implementation comparable to LightGBM and XGBoost. As such, HGBT models are more feature rich than and often outperform alternative models like random forests, especially when the number of samples is larger than some ten thousands (see sphx_glr_auto_examples_ensemble_plot_forest_hist_grad_boosting_comparison.py).">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_hgbt_regression_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_hgbt_regression.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Features in Histogram Gradient Boosting Trees</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates Gradient Boosting to produce a predictive model from an ensemble of weak predictive models. Gradient boosting can be used for regression and classification problems. Here, we will train a model to tackle a diabetes regression task. We will obtain the results from GradientBoostingRegressor with least squares loss and 500 regression trees of depth 4.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_gradient_boosting_regression_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_gradient_boosting_regression.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Gradient Boosting regression</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Illustration of the effect of different regularization strategies for Gradient Boosting. The example is taken from Hastie et al 2009 [1]_.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_gradient_boosting_regularization_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_gradient_boosting_regularization.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Gradient Boosting regularization</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="RandomTreesEmbedding provides a way to map data to a very high-dimensional, sparse representation, which might be beneficial for classification. The mapping is completely unsupervised and very efficient.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_random_forest_embedding_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_random_forest_embedding.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Hashing feature transformation using Totally Random Trees</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="An example using IsolationForest for anomaly detection.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_isolation_forest_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_isolation_forest.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">IsolationForest example</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example illustrates the effect of monotonic constraints on a gradient boosting estimator.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_monotonic_constraints_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_monotonic_constraints.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Monotonic Constraints</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Plot the class probabilities of the first sample in a toy dataset predicted by three different classifiers and averaged by the VotingClassifier.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_voting_probas_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_voting_probas.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Plot class probabilities calculated by the VotingClassifier</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="A voting regressor is an ensemble meta-estimator that fits several base regressors, each on the whole dataset. Then it averages the individual predictions to form a final prediction. We will use three different regressors to predict the data: GradientBoostingRegressor, RandomForestRegressor, and LinearRegression). Then the above 3 regressors will be used for the VotingRegressor.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_voting_regressor_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_voting_regressor.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Plot individual and voting regression predictions</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Plot the decision boundaries of a VotingClassifier for two features of the Iris dataset.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_voting_decision_regions_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_voting_decision_regions.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Plot the decision boundaries of a VotingClassifier</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows how quantile regression can be used to create prediction intervals. See sphx_glr_auto_examples_ensemble_plot_hgbt_regression.py for an example showcasing some other features of HistGradientBoostingRegressor.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_gradient_boosting_quantile_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_gradient_boosting_quantile.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Prediction Intervals for Gradient Boosting Regression</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="تم تدريب خوارزمية RandomForestClassifier باستخدام bootstrap aggregation، حيث يتم ملاءمة كل شجرة جديدة من عينة bootstrap من الملاحظات التدريبية z_i = (x_i, y_i). خطأ out-of-bag (OOB) هو متوسط الخطأ لكل z_i محسوبة باستخدام تنبؤات من الأشجار التي لا تحتوي على z_i في عينة bootstrap الخاصة بها. يسمح هذا لخوارزمية RandomForestClassifier بالتدريب والتحقق أثناء التدريب [1]_.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_ensemble_oob_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_ensemble_oob.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">أخطاء OOB لخوارزمية Random Forests</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="هذا المثال يوضح استخدام غابة من الأشجار لتقييم أهمية الميزات في مهمة تصنيف اصطناعية. تمثل الأعمدة الزرقاء أهمية الميزات للغابة، إلى جانب تباينها بين الأشجار الذي يمثله خطأ الأعمدة.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_forest_importances_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_forest_importances.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">أهمية الميزات باستخدام غابة من الأشجار</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Gradient Boosting هي تقنية تجميعية تجمع بين عدة متعلمين ضعفاء، عادةً ما تكون أشجار القرار، لإنشاء نموذج تنبؤي قوي ومتين. تقوم بذلك بطريقة تكرارية، حيث تقوم كل مرحلة جديدة (شجرة) بتصحيح أخطاء المراحل السابقة.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_gradient_boosting_early_stopping_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_gradient_boosting_early_stopping.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">إيقاف التدريب المبكر في Gradient Boosting</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="شجرة القرار معززة باستخدام خوارزمية AdaBoost.R2 [1]_ على مجموعة بيانات جيبية أحادية البعد مع كمية صغيرة من الضوضاء الغاوسية. يتم مقارنة 299 دفعة (300 شجرة قرار) مع منظم شجرة قرار واحد. مع زيادة عدد الدفعات، يمكن لمنظم الانحدار أن يلائم المزيد من التفاصيل.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_adaboost_regression_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_adaboost_regression.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">انحدار شجرة القرار مع AdaBoost</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="قم بتحويل ميزاتك إلى مساحة متفرقة ذات أبعاد أعلى. ثم قم بتدريب نموذج خطي على هذه الميزات.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_feature_transformation_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_feature_transformation.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">تحويل الميزات باستخدام مجموعات الأشجار</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="هذا المثال يقوم بتدريب نموذج شجرة قرار معزز باستخدام AdaBoost على مجموعة بيانات تصنيف غير خطية، مكونة من مجموعتين &quot;Gaussian quantiles&quot; (انظر: sklearn.datasets.make_gaussian_quantiles) ويعرض حدود القرار ودرجات القرار. يتم عرض توزيعات درجات القرار بشكل منفصل للعينات من الفئة A والفئة B. يتم تحديد تسمية الفئة المتوقعة لكل عينة بناءً على إشارة درجة القرار. يتم تصنيف العينات التي لها درجات قرار أكبر من الصفر على أنها من الفئة B، وإلا يتم تصنيفها على أنها من الفئة A. يحدد مقدار درجة القرار درجة التشابه مع تسمية الفئة المتوقعة. بالإضافة إلى ذلك، يمكن بناء مجموعة بيانات جديدة تحتوي على نقاء مرغوب فيه من الفئة B، على سبيل المثال، عن طريق اختيار العينات فقط بدرجة قرار أعلى من قيمة معينة.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_adaboost_twoclass_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_adaboost_twoclass.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">تصنيف ثنائي باستخدام AdaBoost</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="تقديرات Gradient Boosting Out-of-Bag">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_gradient_boosting_oob_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_gradient_boosting_oob.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">تقديرات Gradient Boosting Out-of-Bag</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="في هذا المثال، سنقارن أوقات التدريب وأداء التنبؤ لـ HistGradientBoostingRegressor مع استراتيجيات الترميز المختلفة للميزات التصنيفية. على وجه الخصوص، سنقيم:">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_gradient_boosting_categorical_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_gradient_boosting_categorical.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">دعم الميزات التصنيفية في التدرج التعزيزي</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="ارسم أسطح القرار لغابات الأشجار العشوائية المدربة على أزواج من سمات مجموعة بيانات إيريس.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_forest_iris_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_forest_iris.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">رسم أسطح القرار لمجموعات الأشجار على مجموعة بيانات إيريس</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="هذا المثال يوضح كيف يمكن لتقنية التعزيز (Boosting) أن تحسن دقة التنبؤ في مشكلة تصنيف متعددة التصنيفات. وهو يعيد إنتاج تجربة مشابهة لما هو موضح في الشكل 1 في بحث Zhu et al [1]_.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_adaboost_multiclass_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_adaboost_multiclass.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">شجرة قرارات معززة متعددة الفئات</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="يوضح هذا المثال ويقارن تحليل الانحياز والتشتت للخطأ التربيعي المتوسط المتوقع لمقدر فردي مقابل مجموعة تجميع.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_bias_variance_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_bias_variance.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">مقارنة بين المُقدر الفردي والتجميع: تحليل الانحياز والتشتت</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="في هذا المثال، نقارن بين أداء نموذج الغابة العشوائية (RF) ونموذج رفع التدرج بالرسم البياني (HGBT) من حيث النتيجة ووقت الحساب لمجموعة بيانات الانحدار، على الرغم من أن جميع المفاهيم المقدمة هنا تنطبق على التصنيف أيضًا.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_forest_hist_grad_boosting_comparison_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_forest_hist_grad_boosting_comparison.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">مقارنة بين نماذج الغابات العشوائية ورفع التدرج بالرسم البياني</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


.. toctree::
   :hidden:

   /auto_examples/ensemble/plot_stack_predictors
   /auto_examples/ensemble/plot_random_forest_regression_multioutput
   /auto_examples/ensemble/plot_hgbt_regression
   /auto_examples/ensemble/plot_gradient_boosting_regression
   /auto_examples/ensemble/plot_gradient_boosting_regularization
   /auto_examples/ensemble/plot_random_forest_embedding
   /auto_examples/ensemble/plot_isolation_forest
   /auto_examples/ensemble/plot_monotonic_constraints
   /auto_examples/ensemble/plot_voting_probas
   /auto_examples/ensemble/plot_voting_regressor
   /auto_examples/ensemble/plot_voting_decision_regions
   /auto_examples/ensemble/plot_gradient_boosting_quantile
   /auto_examples/ensemble/plot_ensemble_oob
   /auto_examples/ensemble/plot_forest_importances
   /auto_examples/ensemble/plot_gradient_boosting_early_stopping
   /auto_examples/ensemble/plot_adaboost_regression
   /auto_examples/ensemble/plot_feature_transformation
   /auto_examples/ensemble/plot_adaboost_twoclass
   /auto_examples/ensemble/plot_gradient_boosting_oob
   /auto_examples/ensemble/plot_gradient_boosting_categorical
   /auto_examples/ensemble/plot_forest_iris
   /auto_examples/ensemble/plot_adaboost_multiclass
   /auto_examples/ensemble/plot_bias_variance
   /auto_examples/ensemble/plot_forest_hist_grad_boosting_comparison

