
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/ensemble/plot_forest_hist_grad_boosting_comparison.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_ensemble_plot_forest_hist_grad_boosting_comparison.py>`
        to download the full example code. or to run this example in your browser via JupyterLite or Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_ensemble_plot_forest_hist_grad_boosting_comparison.py:


===============================================================
مقارنة بين نماذج الغابات العشوائية ورفع التدرج بالرسم البياني
===============================================================

في هذا المثال، نقارن بين أداء نموذج الغابة العشوائية (RF) ونموذج رفع التدرج بالرسم البياني (HGBT) من حيث النتيجة ووقت الحساب لمجموعة بيانات الانحدار، على الرغم من أن **جميع المفاهيم المقدمة هنا تنطبق على التصنيف أيضًا**.

تتم المقارنة عن طريق تغيير المعلمات التي تتحكم في عدد الأشجار وفقًا لكل مقدر:

- `n_estimators` يتحكم في عدد الأشجار في الغابة. إنه رقم ثابت.
- `max_iter` هو العدد الأقصى للدورات في نموذج يعتمد على رفع التدرج. يتوافق عدد الدورات مع عدد الأشجار لمشاكل الانحدار والتصنيف الثنائي. علاوة على ذلك، يعتمد العدد الفعلي للأشجار التي يحتاجها النموذج على معايير التوقف.

يستخدم HGBT رفع التدرج لتحسين أداء النموذج بشكل تكراري عن طريق ملاءمة كل شجرة للانحدار السلبي لدالة الخسارة فيما يتعلق بالقيمة المتوقعة. من ناحية أخرى، تستند RFs على طريقة التجميع وتستخدم تصويت الأغلبية للتنبؤ بالنتيجة.

راجع :ref:`User Guide <ensemble>` لمزيد من المعلومات حول نماذج التجميع أو راجع :ref:`sphx_glr_auto_examples_ensemble_plot_hgbt_regression.py` لمثال يبرز بعض الميزات الأخرى لنماذج HGBT.

.. GENERATED FROM PYTHON SOURCE LINES 17-20

.. code-block:: Python

    # المؤلفون: مطوري scikit-learn
    # SPDX-License-Identifier: BSD-3-Clause








.. GENERATED FROM PYTHON SOURCE LINES 21-23

تحميل مجموعة البيانات
------------

.. GENERATED FROM PYTHON SOURCE LINES 23-36

.. code-block:: Python


    from plotly.subplots import make_subplots
    import plotly.express as px
    import plotly.colors as colors
    from sklearn.model_selection import GridSearchCV, KFold
    from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor
    import pandas as pd
    import joblib
    from sklearn.datasets import fetch_california_housing

    X, y = fetch_california_housing(return_X_y=True, as_frame=True)
    n_samples, n_features = X.shape








.. GENERATED FROM PYTHON SOURCE LINES 37-41

يستخدم HGBT خوارزمية تعتمد على الرسم البياني لقيم الميزات التي يمكنها
التعامل بكفاءة مع مجموعات البيانات الكبيرة (عشرات الآلاف من العينات أو أكثر) مع
عدد كبير من الميزات (انظر :ref:`Why_it's_faster`). لا يستخدم تنفيذ scikit-learn لـ RF التجميع ويعتمد على التقسيم الدقيق، والذي
يمكن أن يكون مكلفًا من الناحية الحسابية.

.. GENERATED FROM PYTHON SOURCE LINES 41-44

.. code-block:: Python


    print(f"تتكون مجموعة البيانات من {n_samples} عينات و {n_features} ميزات")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    تتكون مجموعة البيانات من 20640 عينات و 8 ميزات




.. GENERATED FROM PYTHON SOURCE LINES 45-57

حساب النتيجة وأوقات الحساب
-----------------------------------

لاحظ أن العديد من أجزاء تنفيذ
:class:`~sklearn.ensemble.HistGradientBoostingClassifier` و
:class:`~sklearn.ensemble.HistGradientBoostingRegressor` موازية بشكل افتراضي.

يمكن أيضًا تشغيل تنفيذ :class:`~sklearn.ensemble.RandomForestRegressor` و
:class:`~sklearn.ensemble.RandomForestClassifier` على عدة
أنوية باستخدام معلمة `n_jobs`، هنا تم تعيينها لمطابقة عدد
الأنوية المادية على الجهاز المضيف. راجع :ref:`parallelism` لمزيد من
المعلومات.

.. GENERATED FROM PYTHON SOURCE LINES 57-62

.. code-block:: Python



    N_CORES = joblib.cpu_count(only_physical_cores=True)
    print(f"عدد الأنوية المادية: {N_CORES}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    عدد الأنوية المادية: 2




.. GENERATED FROM PYTHON SOURCE LINES 63-70

على عكس RF، توفر نماذج HGBT خيار التوقف المبكر (انظر
:ref:`sphx_glr_auto_examples_ensemble_plot_gradient_boosting_early_stopping.py`)
لتجنب إضافة أشجار غير ضرورية. داخليًا، يستخدم الخوارزمية مجموعة خارج العينة لحساب أداء تعميم النموذج
عند كل إضافة لشجرة. وبالتالي، إذا لم يتحسن أداء التعميم لأكثر من `n_iter_no_change` دورات، فإنه يتوقف عن إضافة الأشجار.

تم ضبط المعلمات الأخرى لكلا النموذجين ولكن الإجراء غير موضح
هنا للحفاظ على بساطة المثال.

.. GENERATED FROM PYTHON SOURCE LINES 70-97

.. code-block:: Python



    models = {
        "Random Forest": RandomForestRegressor(
            min_samples_leaf=5, random_state=0, n_jobs=N_CORES
        ),
        "Hist Gradient Boosting": HistGradientBoostingRegressor(
            max_leaf_nodes=15, random_state=0, early_stopping=False
        ),
    }
    param_grids = {
        "Random Forest": {"n_estimators": [10, 20, 50, 100]},
        "Hist Gradient Boosting": {"max_iter": [10, 20, 50, 100, 300, 500]},
    }
    cv = KFold(n_splits=4, shuffle=True, random_state=0)
    results = []
    for name, model in models.items():
        grid_search = GridSearchCV(
            estimator=model,
            param_grid=param_grids[name],
            return_train_score=True,
            cv=cv,
        ).fit(X, y)
        result = {"model": name, "cv_results": pd.DataFrame(
            grid_search.cv_results_)}
        results.append(result)








.. GENERATED FROM PYTHON SOURCE LINES 98-110

.. Note::
 ضبط `n_estimators` لـ RF يؤدي عادة إلى إهدار طاقة الكمبيوتر. في الممارسة العملية، يحتاج المرء فقط إلى التأكد من أنه كبير بما يكفي بحيث
 لا يؤدي مضاعفة قيمته إلى تحسين كبير لنتيجة الاختبار.

رسم النتائج
------------
يمكننا استخدام `plotly.express.scatter
<https://plotly.com/python-api-reference/generated/plotly.express.scatter.html>`_
لتصور المقايضة بين وقت الحساب المنقضي ومتوسط نتيجة الاختبار.
تمرير المؤشر فوق نقطة معينة يعرض المعلمات المقابلة.
أشرطة الخطأ تقابل انحرافًا معياريًا واحدًا كما هو محدد في الطيات المختلفة
للتحقق المتقاطع.

.. GENERATED FROM PYTHON SOURCE LINES 110-180

.. code-block:: Python



    fig = make_subplots(
        rows=1,
        cols=2,
        shared_yaxes=True,
        subplot_titles=["Train time vs score", "Predict time vs score"],
    )
    model_names = [result["model"] for result in results]
    colors_list = colors.qualitative.Plotly * (
        len(model_names) // len(colors.qualitative.Plotly) + 1
    )

    for idx, result in enumerate(results):
        cv_results = result["cv_results"].round(3)
        model_name = result["model"]
        param_name = list(param_grids[model_name].keys())[0]
        cv_results[param_name] = cv_results["param_" + param_name]
        cv_results["model"] = model_name

        scatter_fig = px.scatter(
            cv_results,
            x="mean_fit_time",
            y="mean_test_score",
            error_x="std_fit_time",
            error_y="std_test_score",
            hover_data=param_name,
            color="model",
        )
        line_fig = px.line(
            cv_results,
            x="mean_fit_time",
            y="mean_test_score",
        )

        scatter_trace = scatter_fig["data"][0]
        line_trace = line_fig["data"][0]
        scatter_trace.update(marker=dict(color=colors_list[idx]))
        line_trace.update(line=dict(color=colors_list[idx]))
        fig.add_trace(scatter_trace, row=1, col=1)
        fig.add_trace(line_trace, row=1, col=1)

        scatter_fig = px.scatter(
            cv_results,
            x="mean_score_time",
            y="mean_test_score",
            error_x="std_score_time",
            error_y="std_test_score",
            hover_data=param_name,
        )
        line_fig = px.line(
            cv_results,
            x="mean_score_time",
            y="mean_test_score",
        )

        scatter_trace = scatter_fig["data"][0]
        line_trace = line_fig["data"][0]
        scatter_trace.update(marker=dict(color=colors_list[idx]))
        line_trace.update(line=dict(color=colors_list[idx]))
        fig.add_trace(scatter_trace, row=1, col=2)
        fig.add_trace(line_trace, row=1, col=2)

    fig.update_layout(
        xaxis=dict(title="Train time (s) - lower is better"),
        yaxis=dict(title="Test R2 score - higher is better"),
        xaxis2=dict(title="Predict time (s) - lower is better"),
        legend=dict(x=0.72, y=0.05, traceorder="normal", borderwidth=1),
        title=dict(x=0.5, text="Speed-score trade-off of tree-based ensembles"),
    )





.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script><script type="text/javascript">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}</script>                <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
            <script charset="utf-8" src="https://cdn.plot.ly/plotly-2.35.2.min.js"></script>                <div id="068b3dda-896b-48c0-b45d-ad01b2dbd3a6" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("068b3dda-896b-48c0-b45d-ad01b2dbd3a6")) {                    Plotly.newPlot(                        "068b3dda-896b-48c0-b45d-ad01b2dbd3a6",                        [{"customdata":[[10],[20],[50],[100]],"error_x":{"array":[0.08,0.011,0.053,0.116]},"error_y":{"array":[0.011,0.011,0.009,0.009]},"hovertemplate":"model=Random Forest\u003cbr\u003emean_fit_time=%{x}\u003cbr\u003emean_test_score=%{y}\u003cbr\u003en_estimators=%{customdata[0]}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"Random Forest","marker":{"color":"#636EFA","symbol":"circle"},"mode":"markers","name":"Random Forest","orientation":"v","showlegend":true,"x":[0.565,1.045,2.605,5.179],"xaxis":"x","y":[0.793,0.799,0.803,0.805],"yaxis":"y","type":"scatter"},{"hovertemplate":"mean_fit_time=%{x}\u003cbr\u003emean_test_score=%{y}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"","line":{"color":"#636EFA","dash":"solid"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"x":[0.565,1.045,2.605,5.179],"xaxis":"x","y":[0.793,0.799,0.803,0.805],"yaxis":"y","type":"scatter"},{"customdata":[[10],[20],[50],[100]],"error_x":{"array":[0.001,0.0,0.005,0.005]},"error_y":{"array":[0.011,0.011,0.009,0.009]},"hovertemplate":"mean_score_time=%{x}\u003cbr\u003emean_test_score=%{y}\u003cbr\u003en_estimators=%{customdata[0]}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"","marker":{"color":"#636EFA","symbol":"circle"},"mode":"markers","name":"","orientation":"v","showlegend":false,"x":[0.016,0.015,0.03,0.054],"xaxis":"x2","y":[0.793,0.799,0.803,0.805],"yaxis":"y2","type":"scatter"},{"hovertemplate":"mean_score_time=%{x}\u003cbr\u003emean_test_score=%{y}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"","line":{"color":"#636EFA","dash":"solid"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"x":[0.016,0.015,0.03,0.054],"xaxis":"x2","y":[0.793,0.799,0.803,0.805],"yaxis":"y2","type":"scatter"},{"customdata":[[10],[20],[50],[100],[300],[500]],"error_x":{"array":[0.012,0.007,0.006,0.01,0.03,0.073]},"error_y":{"array":[0.007,0.008,0.006,0.003,0.003,0.003]},"hovertemplate":"model=Hist Gradient Boosting\u003cbr\u003emean_fit_time=%{x}\u003cbr\u003emean_test_score=%{y}\u003cbr\u003emax_iter=%{customdata[0]}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"Hist Gradient Boosting","marker":{"color":"#EF553B","symbol":"circle"},"mode":"markers","name":"Hist Gradient Boosting","orientation":"v","showlegend":true,"x":[0.047,0.065,0.113,0.206,0.582,0.985],"xaxis":"x","y":[0.577,0.714,0.8,0.823,0.843,0.848],"yaxis":"y","type":"scatter"},{"hovertemplate":"mean_fit_time=%{x}\u003cbr\u003emean_test_score=%{y}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"","line":{"color":"#EF553B","dash":"solid"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"x":[0.047,0.065,0.113,0.206,0.582,0.985],"xaxis":"x","y":[0.577,0.714,0.8,0.823,0.843,0.848],"yaxis":"y","type":"scatter"},{"customdata":[[10],[20],[50],[100],[300],[500]],"error_x":{"array":[0.001,0.0,0.003,0.001,0.001,0.009]},"error_y":{"array":[0.007,0.008,0.006,0.003,0.003,0.003]},"hovertemplate":"mean_score_time=%{x}\u003cbr\u003emean_test_score=%{y}\u003cbr\u003emax_iter=%{customdata[0]}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"","marker":{"color":"#EF553B","symbol":"circle"},"mode":"markers","name":"","orientation":"v","showlegend":false,"x":[0.005,0.006,0.014,0.022,0.056,0.099],"xaxis":"x2","y":[0.577,0.714,0.8,0.823,0.843,0.848],"yaxis":"y2","type":"scatter"},{"hovertemplate":"mean_score_time=%{x}\u003cbr\u003emean_test_score=%{y}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"","line":{"color":"#EF553B","dash":"solid"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"x":[0.005,0.006,0.014,0.022,0.056,0.099],"xaxis":"x2","y":[0.577,0.714,0.8,0.823,0.843,0.848],"yaxis":"y2","type":"scatter"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}},"xaxis":{"anchor":"y","domain":[0.0,0.45],"title":{"text":"Train time (s) - lower is better"}},"yaxis":{"anchor":"x","domain":[0.0,1.0],"title":{"text":"Test R2 score - higher is better"}},"xaxis2":{"anchor":"y2","domain":[0.55,1.0],"title":{"text":"Predict time (s) - lower is better"}},"yaxis2":{"anchor":"x2","domain":[0.0,1.0],"matches":"y","showticklabels":false},"annotations":[{"font":{"size":16},"showarrow":false,"text":"Train time vs score","x":0.225,"xanchor":"center","xref":"paper","y":1.0,"yanchor":"bottom","yref":"paper"},{"font":{"size":16},"showarrow":false,"text":"Predict time vs score","x":0.775,"xanchor":"center","xref":"paper","y":1.0,"yanchor":"bottom","yref":"paper"}],"legend":{"x":0.72,"y":0.05,"traceorder":"normal","borderwidth":1},"title":{"x":0.5,"text":"Speed-score trade-off of tree-based ensembles"}},                        {"responsive": true}                    )                };                            </script>        </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 181-203

يتحسن كل من نماذج HGBT وRF عند زيادة عدد الأشجار في
التجميع. ومع ذلك، تصل النتائج إلى مستوى ثابت حيث يؤدي إضافة أشجار جديدة فقط
إلى جعل الملاءمة والتسجيل أبطأ. يصل نموذج RF إلى هذا المستوى الثابت في وقت سابق
ولا يمكنه أبدًا الوصول إلى نتيجة اختبار أكبر نموذج HGBDT.

لاحظ أن النتائج المعروضة في الرسم البياني أعلاه يمكن أن تتغير قليلاً عبر الجولات
وحتى بشكل أكبر عند تشغيلها على أجهزة أخرى: حاول تشغيل هذا
المثال على جهازك المحلي.

بشكل عام، يجب أن يلاحظ المرء غالبًا أن نماذج رفع التدرج القائمة على الرسم البياني
تهيمن بشكل موحد على نماذج الغابات العشوائية في "نتيجة الاختبار مقابل
مقايضة سرعة التدريب" (يجب أن يكون منحنى HGBDT في أعلى يسار منحنى RF، دون
أن يتقاطع أبدًا). يمكن أيضًا أن تكون مقايضة "نتيجة الاختبار مقابل سرعة التنبؤ"
أكثر تنازعًا، ولكنها في معظم الأحيان مواتية لـ HGBDT. من الجيد دائمًا التحقق من كلا النوعين من النماذج
(مع ضبط فرط المعلمات) ومقارنة أدائها على مشكلتك المحددة لتحديد النموذج الذي
أفضل ملاءمة ولكن **HGBT توفر دائمًا مقايضة سرعة-دقة أكثر ملاءمة من RF**، إما مع فرط المعلمات الافتراضية أو بما في ذلك
تكلفة ضبط فرط المعلمات.

هناك استثناء واحد لهذه القاعدة العامة على الرغم من ذلك: عند تدريب
نموذج تصنيف متعدد الفئات مع عدد كبير من الفئات المحتملة، يلائم HGBDT داخليًا شجرة واحدة لكل فئة في كل دورة رفع التدرج بينما الأشجار
التي تستخدمها نماذج RF متعددة الفئات بشكل طبيعي والتي يجب أن تحسن مقايضة السرعة والدقة
من نماذج RF في هذه الحالة.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 59.719 seconds)


.. _sphx_glr_download_auto_examples_ensemble_plot_forest_hist_grad_boosting_comparison.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/scikit-learn/scikit-learn/main?urlpath=lab/tree/notebooks/auto_examples/ensemble/plot_forest_hist_grad_boosting_comparison.ipynb
        :alt: Launch binder
        :width: 150 px

    .. container:: lite-badge

      .. image:: images/jupyterlite_badge_logo.svg
        :target: ../../lite/lab/index.html?path=auto_examples/ensemble/plot_forest_hist_grad_boosting_comparison.ipynb
        :alt: Launch JupyterLite
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_forest_hist_grad_boosting_comparison.ipynb <plot_forest_hist_grad_boosting_comparison.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_forest_hist_grad_boosting_comparison.py <plot_forest_hist_grad_boosting_comparison.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_forest_hist_grad_boosting_comparison.zip <plot_forest_hist_grad_boosting_comparison.zip>`


.. include:: plot_forest_hist_grad_boosting_comparison.recommendations


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
