
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/calibration/plot_calibration.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_calibration_plot_calibration.py>`
        to download the full example code. or to run this example in your browser via JupyterLite or Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_calibration_plot_calibration.py:


======================================
معايرة احتمالات المصنفات
======================================

عند إجراء التصنيف، غالبًا ما تريد التنبؤ ليس فقط
بتسمية الفئة، ولكن أيضًا الاحتمالية المرتبطة بها. هذه الاحتمالية
تعطيك نوعًا من الثقة في التنبؤ. ومع ذلك، لا توفر جميع
المصنفات احتمالات معايرة جيدًا، بعضها مفرط الثقة
في حين أن البعض الآخر غير واثق. لذلك، غالبًا ما تكون معايرة الاحتمالات المتوقعة
مرغوبة كعملية ما بعد المعالجة. يوضح هذا المثال
طريقتان مختلفتان لهذه المعايرة ويقيم جودة الاحتمالات المعادة باستخدام درجة Brier
(انظر https://en.wikipedia.org/wiki/Brier_score).

يتم مقارنة الاحتمالية المقدرة باستخدام مصنف خوارزمية بايز الساذجة الغاوسية
دون معايرة، مع معايرة سيجمويد، ومع معايرة غير معلمية
إيزوتونية. يمكن ملاحظة أن النموذج غير المعلمي فقط هو
قادر على توفير معايرة احتمالية تعيد احتمالات قريبة
من المتوقع 0.5 لمعظم العينات التي تنتمي إلى المجموعة الوسطى
مع تسميات متغايرة. يؤدي هذا إلى تحسن كبير
في درجة Brier.

.. GENERATED FROM PYTHON SOURCE LINES 24-28

.. code-block:: Python


    # المؤلفون: مطوري سكايلرن
    # معرف الترخيص: BSD-3-Clause








.. GENERATED FROM PYTHON SOURCE LINES 29-31

إنشاء مجموعة بيانات اصطناعية
--------------------------

.. GENERATED FROM PYTHON SOURCE LINES 31-60

.. code-block:: Python

    from matplotlib import cm
    import matplotlib.pyplot as plt
    from sklearn.naive_bayes import GaussianNB
    from sklearn.metrics import brier_score_loss
    from sklearn.calibration import CalibratedClassifierCV
    import numpy as np

    from sklearn.datasets import make_blobs
    from sklearn.model_selection import train_test_split

    n_samples = 50000
    n_bins = 3  # استخدم 3 صناديق لمعايرة المنحنى حيث لدينا 3 مجموعات هنا

    # إنشاء 3 مجموعات مع فئتين حيث تحتوي المجموعة الثانية على
    # نصف العينات الإيجابية ونصف العينات السلبية. الاحتمالية في هذه
    # المجموعة هي 0.5.
    centers = [(-5, -5), (0, 0), (5, 5)]
    X, y = make_blobs(n_samples=n_samples, centers=centers,
                      shuffle=False, random_state=42)

    y[: n_samples // 2] = 0
    y[n_samples // 2:] = 1
    sample_weight = np.random.RandomState(42).rand(y.shape[0])

    # تقسيم البيانات إلى مجموعات التدريب والاختبار للمعايرة
    X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(
        X, y, sample_weight, test_size=0.9, random_state=42
    )








.. GENERATED FROM PYTHON SOURCE LINES 61-63

خوارزمية بايز الساذجة الغاوسية
--------------------

.. GENERATED FROM PYTHON SOURCE LINES 63-93

.. code-block:: Python


    # بدون معايرة
    clf = GaussianNB()
    # خوارزمية بايز الساذجة الغاوسية نفسها لا تدعم الأوزان العشوائية
    clf.fit(X_train, y_train)
    prob_pos_clf = clf.predict_proba(X_test)[:, 1]

    # مع معايرة إيزوتونية
    clf_isotonic = CalibratedClassifierCV(clf, cv=2, method="isotonic")
    clf_isotonic.fit(X_train, y_train, sample_weight=sw_train)
    prob_pos_isotonic = clf_isotonic.predict_proba(X_test)[:, 1]

    # مع معايرة سيجمويد
    clf_sigmoid = CalibratedClassifierCV(clf, cv=2, method="sigmoid")
    clf_sigmoid.fit(X_train, y_train, sample_weight=sw_train)
    prob_pos_sigmoid = clf_sigmoid.predict_proba(X_test)[:, 1]

    print("Brier score losses: (the smaller the better)")

    clf_score = brier_score_loss(y_test, prob_pos_clf, sample_weight=sw_test)
    print("No calibration: %1.3f" % clf_score)

    clf_isotonic_score = brier_score_loss(
        y_test, prob_pos_isotonic, sample_weight=sw_test)
    print("With isotonic calibration: %1.3f" % clf_isotonic_score)

    clf_sigmoid_score = brier_score_loss(
        y_test, prob_pos_sigmoid, sample_weight=sw_test)
    print("With sigmoid calibration: %1.3f" % clf_sigmoid_score)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Brier score losses: (the smaller the better)
    No calibration: 0.104
    With isotonic calibration: 0.084
    With sigmoid calibration: 0.109




.. GENERATED FROM PYTHON SOURCE LINES 94-96

رسم البيانات والاحتمالات المتوقعة
-----------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 96-145

.. code-block:: Python


    plt.figure()
    y_unique = np.unique(y)
    colors = cm.rainbow(np.linspace(0.0, 1.0, y_unique.size))
    for this_y, color in zip(y_unique, colors):
        this_X = X_train[y_train == this_y]
        this_sw = sw_train[y_train == this_y]
        plt.scatter(
            this_X[:, 0],
            this_X[:, 1],
            s=this_sw * 50,
            c=color[np.newaxis, :],
            alpha=0.5,
            edgecolor="k",
            label="Class %s" % this_y,
        )
    plt.legend(loc="best")
    plt.title("Data")

    plt.figure()

    order = np.lexsort((prob_pos_clf,))
    plt.plot(prob_pos_clf[order], "r", label="No calibration (%1.3f)" % clf_score)
    plt.plot(
        prob_pos_isotonic[order],
        "g",
        linewidth=3,
        label="Isotonic calibration (%1.3f)" % clf_isotonic_score,
    )
    plt.plot(
        prob_pos_sigmoid[order],
        "b",
        linewidth=3,
        label="Sigmoid calibration (%1.3f)" % clf_sigmoid_score,
    )
    plt.plot(
        np.linspace(0, y_test.size, 51)[1::2],
        y_test[order].reshape(25, -1).mean(1),
        "k",
        linewidth=3,
        label=r"Empirical",
    )
    plt.ylim([-0.05, 1.05])
    plt.xlabel("Instances sorted according to predicted probability (uncalibrated GNB)")
    plt.ylabel("P(y=1)")
    plt.legend(loc="upper left")
    plt.title("Gaussian naive Bayes probabilities")

    plt.show()



.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/calibration/images/sphx_glr_plot_calibration_001.png
         :alt: Data
         :srcset: /auto_examples/calibration/images/sphx_glr_plot_calibration_001.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/calibration/images/sphx_glr_plot_calibration_002.png
         :alt: Gaussian naive Bayes probabilities
         :srcset: /auto_examples/calibration/images/sphx_glr_plot_calibration_002.png
         :class: sphx-glr-multi-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 0.370 seconds)


.. _sphx_glr_download_auto_examples_calibration_plot_calibration.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/scikit-learn/scikit-learn/main?urlpath=lab/tree/notebooks/auto_examples/calibration/plot_calibration.ipynb
        :alt: Launch binder
        :width: 150 px

    .. container:: lite-badge

      .. image:: images/jupyterlite_badge_logo.svg
        :target: ../../lite/lab/index.html?path=auto_examples/calibration/plot_calibration.ipynb
        :alt: Launch JupyterLite
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_calibration.ipynb <plot_calibration.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_calibration.py <plot_calibration.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_calibration.zip <plot_calibration.zip>`


.. include:: plot_calibration.recommendations


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
