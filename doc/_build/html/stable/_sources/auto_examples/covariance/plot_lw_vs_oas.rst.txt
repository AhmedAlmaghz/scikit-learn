
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/covariance/plot_lw_vs_oas.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_covariance_plot_lw_vs_oas.py>`
        to download the full example code. or to run this example in your browser via JupyterLite or Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_covariance_plot_lw_vs_oas.py:


=============================
تقدير Ledoit-Wolf مقابل OAS
=============================

يمكن تنظيم تقدير أقصى احتمال للتغاير المعتاد
باستخدام الانكماش. اقترح Ledoit و Wolf صيغة مغلقة لحساب
معامل الانكماش الأمثل بشكل مقارب (تقليل معيار MSE
)، مما ينتج عنه تقدير التغاير Ledoit-Wolf.

اقترح Chen وآخرون تحسينًا لمعامل انكماش Ledoit-Wolf،
معامل OAS، الذي يكون تقاربه أفضل بكثير
بافتراض أن البيانات غاوسية.

يوضح هذا المثال، المستوحى من منشور Chen [1]، مقارنة
بين MSE المقدرة لطريقة LW و OAS، باستخدام
بيانات موزعة غاوسية.

[1] "Shrinkage Algorithms for MMSE Covariance Estimation"
Chen et al., IEEE Trans. on Sign. Proc., Volume 58, Issue 10, October 2010.

.. GENERATED FROM PYTHON SOURCE LINES 23-34

.. code-block:: Python


    # Authors: The scikit-learn developers
    # SPDX-License-Identifier: BSD-3-Clause

    import matplotlib.pyplot as plt
    import numpy as np
    from scipy.linalg import cholesky, toeplitz

    from sklearn.covariance import OAS, LedoitWolf

    np.random.seed(0)







.. GENERATED FROM PYTHON SOURCE LINES 35-110

.. code-block:: Python

    n_features = 100
    # مصفوفة التغاير المحاكاة (عملية AR(1))
    r = 0.1
    real_cov = toeplitz(r ** np.arange(n_features))
    coloring_matrix = cholesky(real_cov)

    n_samples_range = np.arange(6, 31, 1)
    repeat = 100
    lw_mse = np.zeros((n_samples_range.size, repeat))
    oa_mse = np.zeros((n_samples_range.size, repeat))
    lw_shrinkage = np.zeros((n_samples_range.size, repeat))
    oa_shrinkage = np.zeros((n_samples_range.size, repeat))
    for i, n_samples in enumerate(n_samples_range):
        for j in range(repeat):
            X = np.dot(np.random.normal(
                size=(n_samples, n_features)), coloring_matrix.T)

            lw = LedoitWolf(store_precision=False, assume_centered=True)
            lw.fit(X)
            lw_mse[i, j] = lw.error_norm(real_cov, scaling=False)
            lw_shrinkage[i, j] = lw.shrinkage_

            oa = OAS(store_precision=False, assume_centered=True)
            oa.fit(X)
            oa_mse[i, j] = oa.error_norm(real_cov, scaling=False)
            oa_shrinkage[i, j] = oa.shrinkage_

    # رسم MSE
    plt.subplot(2, 1, 1)
    plt.errorbar(
        n_samples_range,
        lw_mse.mean(1),
        yerr=lw_mse.std(1),
        label="Ledoit-Wolf",
        color="navy",
        lw=2,
    )
    plt.errorbar(
        n_samples_range,
        oa_mse.mean(1),
        yerr=oa_mse.std(1),
        label="OAS",
        color="darkorange",
        lw=2,
    )
    plt.ylabel("الخطأ التربيعي")
    plt.legend(loc="upper right")
    plt.title("مقارنة مقدرات التغاير")
    plt.xlim(5, 31)

    # رسم معامل الانكماش
    plt.subplot(2, 1, 2)
    plt.errorbar(
        n_samples_range,
        lw_shrinkage.mean(1),
        yerr=lw_shrinkage.std(1),
        label="Ledoit-Wolf",
        color="navy",
        lw=2,
    )
    plt.errorbar(
        n_samples_range,
        oa_shrinkage.mean(1),
        yerr=oa_shrinkage.std(1),
        label="OAS",
        color="darkorange",
        lw=2,
    )
    plt.xlabel("n_samples")
    plt.ylabel("الانكماش")
    plt.legend(loc="lower right")
    plt.ylim(plt.ylim()[0], 1.0 + (plt.ylim()[1] - plt.ylim()[0]) / 10.0)
    plt.xlim(5, 31)

    plt.show()



.. image-sg:: /auto_examples/covariance/images/sphx_glr_plot_lw_vs_oas_001.png
   :alt: مقارنة مقدرات التغاير
   :srcset: /auto_examples/covariance/images/sphx_glr_plot_lw_vs_oas_001.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 2.682 seconds)


.. _sphx_glr_download_auto_examples_covariance_plot_lw_vs_oas.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/scikit-learn/scikit-learn/main?urlpath=lab/tree/notebooks/auto_examples/covariance/plot_lw_vs_oas.ipynb
        :alt: Launch binder
        :width: 150 px

    .. container:: lite-badge

      .. image:: images/jupyterlite_badge_logo.svg
        :target: ../../lite/lab/index.html?path=auto_examples/covariance/plot_lw_vs_oas.ipynb
        :alt: Launch JupyterLite
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_lw_vs_oas.ipynb <plot_lw_vs_oas.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_lw_vs_oas.py <plot_lw_vs_oas.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_lw_vs_oas.zip <plot_lw_vs_oas.zip>`


.. include:: plot_lw_vs_oas.recommendations


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
