
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/model_selection/plot_underfitting_overfitting.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_model_selection_plot_underfitting_overfitting.py>`
        to download the full example code. or to run this example in your browser via JupyterLite or Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_model_selection_plot_underfitting_overfitting.py:


======================================
عدم الملاءمة مقابل الإفراط في الملاءمة
======================================

هذا المثال يوضح مشكلتي عدم الملاءمة والإفراط في الملاءمة وكيف يمكننا استخدام الانحدار الخطي مع الميزات متعددة الحدود لتقريب الدوال غير الخطية. يوضح الرسم البياني الدالة التي نريد تقريبها، والتي هي جزء من دالة جيب التمام. بالإضافة إلى ذلك، يتم عرض العينات من الدالة الحقيقية وتقديرات النماذج المختلفة. تمتلك النماذج ميزات متعددة الحدود بدرجات مختلفة. يمكننا أن نرى أن الدالة الخطية (متعددة الحدود من الدرجة 1) غير كافية لملاءمة العينات التدريبية. يُطلق على هذا **عدم الملاءمة**. تقترب متعددة الحدود من الدرجة 4 من الدالة الحقيقية بشكل مثالي تقريبًا. ومع ذلك، بالنسبة للدرجات الأعلى، فإن النموذج سوف **يبالغ في الملاءمة** لبيانات التدريب، أي أنه يتعلم ضوضاء بيانات التدريب.

نقيّم **الإفراط في الملاءمة** و **عدم الملاءمة** بشكل كمي باستخدام التحقق المتقاطع. نحسب متوسط مربع الخطأ (MSE) على مجموعة التحقق، كلما كان أعلى، كلما قلت احتمالية تعميم النموذج بشكل صحيح من بيانات التدريب.

.. GENERATED FROM PYTHON SOURCE LINES 10-68



.. image-sg:: /auto_examples/model_selection/images/sphx_glr_plot_underfitting_overfitting_001.png
   :alt: Degree 1 MSE = 4.08e-01(+/- 4.25e-01), Degree 4 MSE = 4.32e-02(+/- 7.08e-02), Degree 15 MSE = 1.81e+08(+/- 5.44e+08)
   :srcset: /auto_examples/model_selection/images/sphx_glr_plot_underfitting_overfitting_001.png
   :class: sphx-glr-single-img





.. code-block:: Python

    # المؤلفون: مطوري سكايلرن
    # معرف الترخيص: BSD-3-Clause

    import matplotlib.pyplot as plt
    import numpy as np

    from sklearn.linear_model import LinearRegression
    from sklearn.model_selection import cross_val_score
    from sklearn.pipeline import Pipeline
    from sklearn.preprocessing import PolynomialFeatures


    def true_fun(X):
        return np.cos(1.5 * np.pi * X)


    np.random.seed(0)

    n_samples = 30
    degrees = [1, 4, 15]

    X = np.sort(np.random.rand(n_samples))
    y = true_fun(X) + np.random.randn(n_samples) * 0.1

    plt.figure(figsize=(14, 5))
    for i in range(len(degrees)):
        ax = plt.subplot(1, len(degrees), i + 1)
        plt.setp(ax, xticks=(), yticks=())

        polynomial_features = PolynomialFeatures(degree=degrees[i], include_bias=False)
        linear_regression = LinearRegression()
        pipeline = Pipeline(
            [
                ("polynomial_features", polynomial_features),
                ("linear_regression", linear_regression),
            ]
        )
        pipeline.fit(X[:, np.newaxis], y)

        # تقييم النماذج باستخدام التحقق المتقاطع
        scores = cross_val_score(
            pipeline, X[:, np.newaxis], y, scoring="neg_mean_squared_error", cv=10
        )

        X_test = np.linspace(0, 1, 100)
        plt.plot(X_test, pipeline.predict(X_test[:, np.newaxis]), label="Model")
        plt.plot(X_test, true_fun(X_test), label="True function")
        plt.scatter(X, y, edgecolor="b", s=20, label="Samples")
        plt.xlabel("x")
        plt.ylabel("y")
        plt.xlim((0, 1))
        plt.ylim((-2, 2))
        plt.legend(loc="best")
        plt.title(
            "Degree {}\nMSE = {:.2e}(+/- {:.2e})".format(
                degrees[i], -scores.mean(), scores.std()
            )
        )
    plt.show()

.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 0.243 seconds)


.. _sphx_glr_download_auto_examples_model_selection_plot_underfitting_overfitting.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/scikit-learn/scikit-learn/main?urlpath=lab/tree/notebooks/auto_examples/model_selection/plot_underfitting_overfitting.ipynb
        :alt: Launch binder
        :width: 150 px

    .. container:: lite-badge

      .. image:: images/jupyterlite_badge_logo.svg
        :target: ../../lite/lab/index.html?path=auto_examples/model_selection/plot_underfitting_overfitting.ipynb
        :alt: Launch JupyterLite
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_underfitting_overfitting.ipynb <plot_underfitting_overfitting.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_underfitting_overfitting.py <plot_underfitting_overfitting.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_underfitting_overfitting.zip <plot_underfitting_overfitting.zip>`


.. include:: plot_underfitting_overfitting.recommendations


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
