.. currentmodule:: sklearn.model_selection

.. _TunedThresholdClassifierCV:

===================================
ضبط عتبة القرار لتنبؤ الفئة
===================================

من الأفضل تقسيم التصنيف إلى جزأين:

* المشكلة الإحصائية لتعلم نموذج للتنبؤ، بشكل مثالي، باحتمالات الفئة؛
* مشكلة القرار لاتخاذ إجراء ملموس بناءً على تنبؤات الاحتمال تلك.

لنأخذ مثالًا مباشرًا يتعلق بالتنبؤ بالطقس: النقطة الأولى تتعلق بالإجابة على "ما هو احتمال هطول الأمطار غدًا؟" بينما تتعلق النقطة الثانية بالإجابة على "هل يجب أن آخذ مظلة غدًا؟".

عندما يتعلق الأمر بواجهة برمجة تطبيقات scikit-learn، تتم معالجة النقطة الأولى من خلال توفير الدرجات باستخدام :term:`predict_proba` أو :term:`decision_function`.
ترجع الأولى تقديرات الاحتمال الشرطي :math:`P(y|X)` لكل فئة، بينما تُرجع الأخيرة درجة قرار لكل فئة.

يتم الحصول على القرار المقابل للتسميات باستخدام :term:`predict`.
في التصنيف الثنائي، يتم بعد ذلك تعريف قاعدة قرار أو إجراء عن طريق تحديد عتبة للدرجات، مما يؤدي إلى التنبؤ بتسمية فئة واحدة لكل عينة.
بالنسبة للتصنيف الثنائي في scikit-learn، يتم الحصول على تنبؤات تسميات الفئات من خلال قواعد قطع مشفرة: يتم توقع فئة إيجابية عندما يكون الاحتمال الشرطي :math:`P(y|X)` أكبر من 0.5 (يتم الحصول عليه باستخدام :term:`predict_proba`) أو إذا كانت درجة القرار أكبر من 0 (يتم الحصول عليها باستخدام :term:`decision_function`).

نوضح هنا مثالًا يوضح العلاقة بين تقديرات الاحتمال الشرطي :math:`P(y|X)` وتسميات الفئات::

    >>> from sklearn.datasets import make_classification
    >>> from sklearn.tree import DecisionTreeClassifier
    >>> X, y = make_classification(random_state=0)
    >>> classifier = DecisionTreeClassifier(max_depth=2, random_state=0).fit(X, y)
    >>> classifier.predict_proba(X[:4])
    array([[0.94     , 0.06     ],
           [0.94     , 0.06     ],
           [0.0416..., 0.9583...],
           [0.0416..., 0.9583...]])
    >>> classifier.predict(X[:4])
    array([0, 0, 1, 1])

بينما قد تبدو هذه القواعد المشفرة في البداية معقولة كسلوك افتراضي، إلا أنها بالتأكيد ليست مثالية لمعظم حالات الاستخدام.
دعونا نوضح بمثال.

ضع في اعتبارك سيناريو يتم فيه نشر نموذج تنبؤي لمساعدة الأطباء في اكتشاف الأورام.
في هذا الإعداد، من المرجح أن يهتم الأطباء بتحديد جميع المرضى المصابين بالسرطان وعدم تفويت أي شخص مصاب بالسرطان حتى يتمكنوا من تزويدهم بالعلاج المناسب.
بمعنى آخر، يعطي الأطباء الأولوية لتحقيق معدل استدعاء مرتفع.
يأتي هذا التركيز على الاستدعاء، بالطبع، مع مقايضة التنبؤات الإيجابية الكاذبة المحتملة، مما يقلل من دقة النموذج.
هذا خطر على استعداد الأطباء لتحمله لأن تكلفة السرطان المفقود أعلى بكثير من تكلفة إجراء المزيد من الاختبارات التشخيصية.
وبالتالي، عندما يتعلق الأمر بتحديد ما إذا كان سيتم تصنيف المريض على أنه مصاب بالسرطان أم لا، فقد يكون من المفيد تصنيفهم على أنهم إيجابيون للسرطان عندما يكون تقدير الاحتمال الشرطي أقل بكثير من 0.5.

ضبط عتبة القرار بعد التدريب
==================================

أحد الحلول لمعالجة المشكلة المذكورة في المقدمة هو ضبط عتبة قرار المصنف بمجرد تدريب النموذج.
:class:`~sklearn.model_selection.TunedThresholdClassifierCV`  يضبط هذه العتبة باستخدام التحقق المتبادل الداخلي.
يتم اختيار العتبة المثلى لزيادة مقياس معين.

توضح الصورة التالية ضبط عتبة القرار لمصنف تعزيز التدرج.
بينما يوفر المصنفان الفانيليا والمضبوط نفس مخرجات :term:`predict_proba` وبالتالي نفس منحنيات خاصية تشغيل المستقبل (ROC) والدقة والاستدعاء، تختلف تنبؤات تسمية الفئة بسبب عتبة القرار المضبوطة.
يتنبأ مصنف الفانيليا بفئة الاهتمام لاحتمال شرطي أكبر من 0.5 بينما يتنبأ المصنف المضبوط بفئة الاهتمام لاحتمال منخفض جدًا (حوالي 0.02).
تقوم عتبة القرار هذه بتحسين مقياس المنفعة المحدد من قبل الشركة (في هذه الحالة شركة تأمين).

.. figure:: ../auto_examples/model_selection/images/sphx_glr_plot_cost_sensitive_learning_002.png
   :target: ../auto_examples/model_selection/plot_cost_sensitive_learning.html
   :align: center

 خيارات لضبط عتبة القرار
-----------------------------

يمكن ضبط عتبة القرار من خلال استراتيجيات مختلفة يتم التحكم فيها بواسطة معلمة `scoring`.

إحدى طرق ضبط العتبة هي زيادة مقياس scikit-learn محدد مسبقًا.
يمكن العثور على هذه المقاييس عن طريق استدعاء الدالة :func:`~sklearn.metrics.get_scorer_names`.
افتراضيًا، تكون الدقة المتوازنة هي المقياس المستخدم، ولكن يجب أن تدرك أنه يجب على المرء اختيار مقياس ذي مغزى لحالة الاستخدام الخاصة به.

.. note::

    من المهم ملاحظة أن هذه المقاييس تأتي مع معلمات افتراضية، لا سيما تسمية فئة الاهتمام (أي `pos_label`).
    وبالتالي، إذا لم تكن هذه التسمية هي التسمية الصحيحة لتطبيقك، فأنت بحاجة إلى تحديد مسجل وتمرير `pos_label` الصحيح (معلمات إضافية) باستخدام :func:`~sklearn.metrics.make_scorer`.
    راجع :ref:`scoring` للحصول على معلومات لتعريف دالة التسجيل الخاصة بك.
    على سبيل المثال، نوضح كيفية تمرير المعلومات إلى المسجل بأن تسمية الاهتمام هي `0` عند زيادة :func:`~sklearn.metrics.f1_score`::

        >>> from sklearn.linear_model import LogisticRegression
        >>> from sklearn.model_selection import TunedThresholdClassifierCV
        >>> from sklearn.metrics import make_scorer, f1_score
        >>> X, y = make_classification(
        ...   n_samples=1_000, weights=[0.1, 0.9], random_state=0)
        >>> pos_label = 0
        >>> scorer = make_scorer(f1_score, pos_label=pos_label)
        >>> base_model = LogisticRegression()
        >>> model = TunedThresholdClassifierCV(base_model, scoring=scorer)
        >>> scorer(model.fit(X, y), X, y)
        0.88...
        >>> # قارنها بالدرجة الداخلية التي تم العثور عليها عن طريق التحقق المتبادل
        >>> model.best_score_
        0.86...

ملاحظات مهمة بخصوص التحقق المتبادل الداخلي
-------------------------------------------------

افتراضيًا، يستخدم :class:`~sklearn.model_selection.TunedThresholdClassifierCV`  التحقق المتبادل الطبقي ذي 5 طيات لضبط عتبة القرار.
تسمح المعلمة `cv` بالتحكم في استراتيجية التحقق المتبادل.
من الممكن تجاوز التحقق المتبادل عن طريق تعيين `cv="prefit"` وتوفير مصنف مناسب.
في هذه الحالة، يتم ضبط عتبة القرار على البيانات المقدمة إلى طريقة `fit`.

ومع ذلك، يجب أن تكون حذرًا للغاية عند استخدام هذا الخيار.
يجب ألا تستخدم أبدًا نفس البيانات لتدريب المصنف وضبط عتبة القرار بسبب خطر الإفراط في التجهيز.
راجع قسم المثال التالي لمزيد من التفاصيل (راجع :ref:`TunedThresholdClassifierCV_no_cv`).
إذا كانت مواردك محدودة، ففكر في استخدام رقم عائم لـ `cv` للحد من تقسيم القطار والاختبار الداخلي الفردي.

يجب استخدام الخيار `cv="prefit"` فقط عندما يكون المصنف المقدم قد تم تدريبه بالفعل، وتريد فقط العثور على أفضل عتبة قرار باستخدام مجموعة تحقق جديدة.

.. _FixedThresholdClassifier:

تعيين عتبة القرار يدويًا
---------------------------------------

ناقشت الأقسام السابقة استراتيجيات للعثور على عتبة قرار مثالية.
من الممكن أيضًا تعيين عتبة القرار يدويًا باستخدام الفئة :class:`~sklearn.model_selection.FixedThresholdClassifier`.
في حالة عدم رغبتك في إعادة ملاءمة النموذج عند استدعاء `fit`، يمكنك تعيين المعلمة `prefit=True`.

أمثلة
--------

- انظر المثال المعنون
  :ref:`sphx_glr_auto_examples_model_selection/plot_tuned_decision_threshold.py`،
  للحصول على رؤى حول ضبط عتبة القرار بعد التدريب.
- انظر المثال المعنون
  :ref:`sphx_glr_auto_examples_model_selection/plot_cost_sensitive_learning.py`،
  للتعرف على التعلم الحساس للتكلفة وضبط عتبة القرار.


