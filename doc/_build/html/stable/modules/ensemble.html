
<!DOCTYPE html>


<html lang="ar" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="1.11. المجموعات: تعزيز التدرج، الغابات العشوائية، التجميع، التصويت، التكديس" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://scikit-learn/stable/modules/ensemble.html" />
<meta property="og:site_name" content="scikit-learn" />
<meta property="og:description" content="أساليب المجموعات تجمع تنبؤات العديد من المُقدِّرات الأساسية المبنية بخوارزمية تعلم مُعطاة من أجل تحسين قابلية التعميم / المتانة على مُقدِّر واحد. مثالان مشهوران جدًا لأساليب المجموعات هما أشجار مُع..." />
<meta property="og:image" content="https://scikit-learn/stable/_images/sphx_glr_plot_gradient_boosting_regression_001.png" />
<meta property="og:image:alt" content="scikit-learn" />
<meta name="description" content="أساليب المجموعات تجمع تنبؤات العديد من المُقدِّرات الأساسية المبنية بخوارزمية تعلم مُعطاة من أجل تحسين قابلية التعميم / المتانة على مُقدِّر واحد. مثالان مشهوران جدًا لأساليب المجموعات هما أشجار مُع..." />

    <title>1.11. المجموعات: تعزيز التدرج، الغابات العشوائية، التجميع، التصويت، التكديس &#8212; scikit-learn 1.6.dev0 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css?v=7f9a90b1" />
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Vibur" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyterlite_sphinx.css?v=ca70e7f1" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/colors.css?v=cc94ab7d" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/custom.css?v=85b0813d" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="../_static/documentation_options.js?v=3cd28d06"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=97f0b27d"></script>
    <script src="../_static/jupyterlite_sphinx.js?v=d6bdf5f8"></script>
    <script src="../_static/translations.js?v=87cb2081"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script data-domain="scikit-learn.org" defer="defer" src="https://views.scientific-python.org/js/script.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'modules/ensemble';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.0';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://scikit-learn.org/dev/_static/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '1.6.dev0';
        DOCUMENTATION_OPTIONS.show_version_warning_banner = true;
        </script>
    <script src="../_static/scripts/dropdown.js?v=e2048168"></script>
    <script src="../_static/scripts/version-switcher.js?v=a6dd8357"></script>
    <link rel="icon" href="../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="search" title="بحث" href="../search.html" />
    <link rel="next" title="1.12. خوارزميات متعددة التصنيف ومتعددة الإخراج" href="multiclass.html" />
    <link rel="prev" title="1.10. شجرة القرار" href="tree.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="ar"/>
  <meta name="docsearch:version" content="1.6" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/scikit-learn-logo-small.png" class="logo__image only-light" alt="scikit-learn homepage"/>
    <img src="../_static/scikit-learn-logo-small.png" class="logo__image only-dark pst-js-only" alt="scikit-learn homepage"/>
  
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../install.html">
    Install
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../user_guide.html">
    دليل المستخدم
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api/index.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../auto_examples/index.html">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://blog.scikit-learn.org/">
    Community
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../getting_started.html">
    البدء
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../whats_new.html">
    Release History
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../glossary.html">
    Glossary
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../developers/index.html">
    Development
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../faq.html">
    FAQ
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../support.html">
    الدعم الفني
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../related_projects.html">
    مشاريع ذات علاقة
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../roadmap.html">
    Roadmap
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../governance.html">
    Governance
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../about.html">
    من نحن
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="بحث" aria-label="بحث" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/scikit-learn/scikit-learn" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
      
        <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="بحث" aria-label="بحث" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../install.html">
    Install
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../user_guide.html">
    دليل المستخدم
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api/index.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../auto_examples/index.html">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://blog.scikit-learn.org/">
    Community
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../getting_started.html">
    البدء
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../whats_new.html">
    Release History
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../glossary.html">
    Glossary
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../developers/index.html">
    Development
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../faq.html">
    FAQ
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../support.html">
    الدعم الفني
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../related_projects.html">
    مشاريع ذات علاقة
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../roadmap.html">
    Roadmap
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../governance.html">
    Governance
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../about.html">
    من نحن
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/scikit-learn/scikit-learn" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
        
          <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../supervised_learning.html">1. التعليم الخاضع للإشراف</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="linear_model.html">1.1. النماذج الخطية</a></li>
<li class="toctree-l2"><a class="reference internal" href="lda_qda.html">1.2. تحليل التمييز الخطي والتربيعي</a></li>
<li class="toctree-l2"><a class="reference internal" href="kernel_ridge.html">1.3. انحدار حافة النواة</a></li>
<li class="toctree-l2"><a class="reference internal" href="svm.html">1.4. آلات الدعم المتجهية (SVM)</a></li>
<li class="toctree-l2"><a class="reference internal" href="sgd.html">1.5. التحسين التدريجي العشوائي</a></li>
<li class="toctree-l2"><a class="reference internal" href="neighbors.html">1.6. أقرب الجيران</a></li>
<li class="toctree-l2"><a class="reference internal" href="gaussian_process.html">1.7. العمليات الغاوسية</a></li>
<li class="toctree-l2"><a class="reference internal" href="cross_decomposition.html">1.8. التحليل المتقاطع</a></li>
<li class="toctree-l2"><a class="reference internal" href="naive_bayes.html">1.9. خوارزميات بايز الساذجة</a></li>
<li class="toctree-l2"><a class="reference internal" href="tree.html">1.10. شجرة القرار</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">1.11. المجموعات: تعزيز التدرج، الغابات العشوائية، التجميع، التصويت، التكديس</a></li>
<li class="toctree-l2"><a class="reference internal" href="multiclass.html">1.12. خوارزميات متعددة التصنيف ومتعددة الإخراج</a></li>
<li class="toctree-l2"><a class="reference internal" href="feature_selection.html">1.13. اختيار الميزات</a></li>
<li class="toctree-l2"><a class="reference internal" href="semi_supervised.html">1.14. التعليم شبه الخاضع للإشراف</a></li>
<li class="toctree-l2"><a class="reference internal" href="isotonic.html">1.15. الانحدار المتساوي التوتر</a></li>
<li class="toctree-l2"><a class="reference internal" href="calibration.html">1.16. معايرة الاحتمال</a></li>
<li class="toctree-l2"><a class="reference internal" href="neural_networks_supervised.html">1.17. نماذج الشبكات العصبية (الخاضعة للإشراف)</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../unsupervised_learning.html">2. التعليم الغير خاضع للإشراف</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="mixture.html">2.1. نماذج خليط غاوسي</a></li>
<li class="toctree-l2"><a class="reference internal" href="manifold.html">2.2. تعلم المشعبات</a></li>
<li class="toctree-l2"><a class="reference internal" href="clustering.html">2.3. التجميع</a></li>
<li class="toctree-l2"><a class="reference internal" href="biclustering.html">2.4. التجميع الثنائي</a></li>
<li class="toctree-l2"><a class="reference internal" href="decomposition.html">2.5. تحليل الإشارات إلى مكونات (مشاكل تحليل المصفوفات)</a></li>
<li class="toctree-l2"><a class="reference internal" href="covariance.html">2.6. تقدير التباين المشترك</a></li>
<li class="toctree-l2"><a class="reference internal" href="outlier_detection.html">2.7. كشف القيم الغريبة والقيم المتطرفة</a></li>
<li class="toctree-l2"><a class="reference internal" href="density.html">2.8. تقدير الكثافة</a></li>
<li class="toctree-l2"><a class="reference internal" href="neural_networks_unsupervised.html">2.9. نماذج الشبكة العصبية (غير خاضعة للإشراف)</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../model_selection.html">3. تقييم وإختيار النموذج</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="cross_validation.html">3.1. التحقق المتبادل: تقييم أداء المقدر</a></li>
<li class="toctree-l2"><a class="reference internal" href="grid_search.html">3.2. ضبط المعلمات الفائقة لمُقدِّر</a></li>
<li class="toctree-l2"><a class="reference internal" href="classification_threshold.html">3.3. ضبط عتبة القرار لتنبؤ الفئة</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_evaluation.html">3.4. المقاييس والتهديف: تحديد جودة التنبؤات</a></li>
<li class="toctree-l2"><a class="reference internal" href="learning_curve.html">3.5. منحنيات التحقق من الصحة: رسم الدرجات لتقييم النماذج</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../inspection.html">4. الفحص</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="partial_dependence.html">4.1. مخططات الاعتماد الجزئي والتوقع الشرطي الفردي</a></li>
<li class="toctree-l2"><a class="reference internal" href="permutation_importance.html">4.2. أهمية التبديل</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../visualizations.html">5. التصورات المرئية</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../data_transforms.html">6. تحويلات مجموعات البيانات</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="compose.html">6.1. خطوط الأنابيب والمقدرات المركبة</a></li>
<li class="toctree-l2"><a class="reference internal" href="feature_extraction.html">6.2. استخراج الميزات</a></li>
<li class="toctree-l2"><a class="reference internal" href="preprocessing.html">6.3. المعالجة المسبقة للبيانات</a></li>
<li class="toctree-l2"><a class="reference internal" href="impute.html">6.4. تعويض القيم المفقودة</a></li>
<li class="toctree-l2"><a class="reference internal" href="unsupervised_reduction.html">6.5. تخفيض الأبعاد غير الخاضع للإشراف</a></li>
<li class="toctree-l2"><a class="reference internal" href="random_projection.html">6.6. الإسقاط العشوائي</a></li>
<li class="toctree-l2"><a class="reference internal" href="kernel_approximation.html">6.7. Kernel Approximation</a></li>
<li class="toctree-l2"><a class="reference internal" href="metrics.html">6.8. مقاييس المقارنة الزوجية، والصلات، والنوى (Kernels)</a></li>
<li class="toctree-l2"><a class="reference internal" href="preprocessing_targets.html">6.9. تحويل هدف التنبؤ (<code class="docutils literal notranslate"><span class="pre">y</span></code>)</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets/toy_dataset.html">7. مجموعات البيانات التجريبية</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets/real_world.html">8. مجموعات بيانات العالم الحقيقي</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets/sample_generators.html">9. مجموعات البيانات المُولَّدة</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets/loading_other_datasets.html">10. تحميل مجموعات بيانات أخرى</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../computing.html">11. الحوسبة مع scikit-learn</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../computing/scaling_strategies.html">11.1. استراتيجيات للقياس حسابيًا: بيانات أكبر</a></li>
<li class="toctree-l2"><a class="reference internal" href="../computing/computational_performance.html">11.2. الأداء الحسابي</a></li>
<li class="toctree-l2"><a class="reference internal" href="../computing/parallelism.html">11.3. التوازي وإدارة الموارد والتهيئة</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../model_persistence.html">12. حفظ النموذج</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common_pitfalls.html">13. المزالق الشائعة والممارسات الموصى بها</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../dispatching.html">14. Dispatching</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="array_api.html">14.1. دعم المدخلات المتوافقة مع <code class="docutils literal notranslate"><span class="pre">Array</span> <span class="pre">API</span></code></a></li>

</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../machine_learning_map.html">15. اختيار المقدر المناسب</a></li>
<li class="toctree-l1"><a class="reference internal" href="../presentations.html">16. المصادر الخارجية ومقاطع الفيديو والمحادثات</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../user_guide.html" class="nav-link">دليل المستخدم</a></li>
    
    
    <li class="breadcrumb-item"><a href="../supervised_learning.html" class="nav-link"><span class="section-number">1. </span>التعليم الخاضع للإشراف</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis"><span class="section-number">1.11. </span>المجموعات: تعزيز التدرج، الغابات العشوائية، التجميع، التصويت، التكديس</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="ensemble">
<span id="id1"></span><h1><span class="section-number">1.11. </span>المجموعات: تعزيز التدرج، الغابات العشوائية، التجميع، التصويت، التكديس<a class="headerlink" href="#ensemble" title="Link to this heading">#</a></h1>
<p><strong>أساليب المجموعات</strong> تجمع تنبؤات العديد من
المُقدِّرات الأساسية المبنية بخوارزمية تعلم مُعطاة من أجل تحسين
قابلية التعميم / المتانة على مُقدِّر واحد.</p>
<p>مثالان مشهوران جدًا لأساليب المجموعات هما <a class="reference internal" href="#gradient-boosting"><span class="std std-ref">أشجار مُعززة بالتدرج</span></a> و <a class="reference internal" href="#forest"><span class="std std-ref">الغابات العشوائية</span></a>.</p>
<p>بشكل عام، يمكن تطبيق نماذج المجموعات على أي مُتعلم أساسي يتجاوز
الأشجار، في أساليب المتوسط مثل <a class="reference internal" href="#bagging"><span class="std std-ref">أساليب التجميع</span></a>،
<a class="reference internal" href="#stacking"><span class="std std-ref">تكديس النماذج</span></a>، أو <a class="reference internal" href="#voting-classifier"><span class="std std-ref">التصويت</span></a>، أو في
التعزيز، مثل <a class="reference internal" href="#adaboost"><span class="std std-ref">AdaBoost</span></a>.</p>
<section id="gradient-boosting">
<span id="id2"></span><h2><span class="section-number">1.11.1. </span>أشجار مُعززة بالتدرج<a class="headerlink" href="#gradient-boosting" title="Link to this heading">#</a></h2>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Gradient_boosting">تعزيز شجرة التدرج</a>
أو أشجار القرار المُعززة بالتدرج (GBDT) هي تعميم
للتعزيز لدوال الخسارة القابلة للاشتقاق التعسفية، انظر العمل الأساسي لـ
<a class="reference internal" href="#friedman2001" id="id4"><span>[Friedman2001]</span></a>. GBDT هو نموذج ممتاز لكل من الانحدار و
التصنيف، خاصةً لبيانات الجدول.</p>
<aside class="topic">
<p class="topic-title"><code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingClassifier</span></code> مقابل <code class="xref py py-class docutils literal notranslate"><span class="pre">HistGradientBoostingClassifier</span></code></p>
<p>يُوفر Scikit-learn تطبيقين لأشجار مُعززة بالتدرج:
<code class="xref py py-class docutils literal notranslate"><span class="pre">HistGradientBoostingClassifier</span></code> مقابل
<code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingClassifier</span></code> للتصنيف، والفئات
المُقابلة للانحدار. يمكن أن يكون الأول <strong>أسرع بأعداد مُضاعفة</strong>
من الأخير عندما يكون عدد العينات
أكبر من عشرات الآلاف من العينات.</p>
<p>يتم دعم القيم المفقودة والبيانات الفئوية أصلاً بواسطة
إصدار Hist...، مما يُلغي الحاجة إلى مُعالجة مُسبقة إضافية مثل
التعويض.</p>
<p>قد يُفضل <code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingClassifier</span></code> و
<code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingRegressor</span></code> لأحجام العينات الصغيرة لأن
التجميع قد يؤدي إلى نقاط تقسيم تقريبية جدًا
في هذا الإعداد.</p>
</aside>
<section id="histogram-based-gradient-boosting">
<span id="id5"></span><h3><span class="section-number">1.11.1.1. </span>تعزيز التدرج القائم على الرسم البياني<a class="headerlink" href="#histogram-based-gradient-boosting" title="Link to this heading">#</a></h3>
<p>قدّم Scikit-learn 0.21 تطبيقين جديدين لـ
أشجار مُعززة بالتدرج، وهما <code class="xref py py-class docutils literal notranslate"><span class="pre">HistGradientBoostingClassifier</span></code>
و <code class="xref py py-class docutils literal notranslate"><span class="pre">HistGradientBoostingRegressor</span></code>، مُستوحى من
<a class="reference external" href="https://github.com/Microsoft/LightGBM">LightGBM</a> (انظر <a class="reference internal" href="#lightgbm" id="id6"><span>[LightGBM]</span></a>).</p>
<p>يمكن أن يكون هذان المُقدِّران القائمان على الرسم البياني <strong>أسرع بأعداد مُضاعفة</strong>
من <code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingClassifier</span></code> و
<code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingRegressor</span></code> عندما يكون عدد العينات أكبر
من عشرات الآلاف من العينات.</p>
<p>لديهم أيضًا دعم مُدمج للقيم المفقودة، مما يُتجنب الحاجة
إلى مُعوض.</p>
<p>يقوم هذان المُقدِّران السريعان أولاً بتجميع عينات الإدخال <code class="docutils literal notranslate"><span class="pre">X</span></code> في
صناديق ذات قيم صحيحة (عادةً 256 صندوقًا) مما يُقلل بشكل كبير من
عدد نقاط التقسيم التي يجب أخذها في الاعتبار، ويسمح للخوارزمية بـ
الاستفادة من هياكل البيانات القائمة على الأعداد الصحيحة (الرسوم البيانية) بدلاً من الاعتماد على
قيم مُستمرة مُرتبة عند بناء الأشجار. واجهة برمجة التطبيقات لهؤلاء
المُقدِّرين مُختلفة قليلاً، وبعض ميزات
<code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingClassifier</span></code> و <code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingRegressor</span></code>
غير مدعومة حتى الآن، على سبيل المثال بعض دوال الخسارة.</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/inspection/plot_partial_dependence.html#sphx-glr-auto-examples-inspection-plot-partial-dependence-py"><span class="std std-ref">مخططات التبعية الجزئية والتوقع الشرطي الفردي</span></a></p></li>
<li><p><a class="reference internal" href="../auto_examples/ensemble/plot_forest_hist_grad_boosting_comparison.html#sphx-glr-auto-examples-ensemble-plot-forest-hist-grad-boosting-comparison-py"><span class="std std-ref">مقارنة بين نماذج الغابات العشوائية ورفع التدرج بالرسم البياني</span></a></p></li>
</ul>
<section id="id7">
<h4><span class="section-number">1.11.1.1.1. </span>الاستخدام<a class="headerlink" href="#id7" title="Link to this heading">#</a></h4>
<p>معظم المعلمات لم تتغير من
<code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingClassifier</span></code> و <code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingRegressor</span></code>.
استثناء واحد هو المعلمة <code class="docutils literal notranslate"><span class="pre">max_iter</span></code> التي تحل محل <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code>، و
تتحكم في عدد تكرارات عملية التعزيز:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">HistGradientBoostingClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_hastie_10_2</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_hastie_10_2</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="mi">2000</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="mi">2000</span><span class="p">:]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="mi">2000</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="mi">2000</span><span class="p">:]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">HistGradientBoostingClassifier</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="go">0.8965</span>
</pre></div>
</div>
<p>الخسائر المتاحة لـ <strong>الانحدار</strong> هي:</p>
<ul class="simple">
<li><p>'squared_error'، وهي خسارة افتراضية؛</p></li>
<li><p>'absolute_error'، وهي أقل حساسية للقيم المتطرفة من الخطأ التربيعي؛</p></li>
<li><p>'gamma'، وهي مُناسبة جدًا لنمذجة النتائج الإيجابية تمامًا؛</p></li>
<li><p>'poisson'، وهي مُناسبة جدًا لنمذجة الأعداد والترددات؛</p></li>
<li><p>'quantile'، الذي يسمح بتقدير مُكمِّم شرطي يمكن استخدامه لاحقًا
للحصول على فترات تنبؤ.</p></li>
</ul>
<p>بالنسبة لـ <strong>التصنيف</strong>، فإن 'log_loss' هو الخيار الوحيد. بالنسبة للتصنيف الثنائي،
فإنه يستخدم خسارة السجل الثنائي، والمعروفة أيضًا باسم انحراف ذات الحدين أو
الانتروبيا المتقاطعة الثنائية. بالنسبة لـ <code class="docutils literal notranslate"><span class="pre">n_classes</span> <span class="pre">&gt;=</span> <span class="pre">3</span></code>، فإنه يستخدم دالة خسارة السجل
متعددة الفئات، مع الانحراف متعدد الحدود والانتروبيا المتقاطعة الفئوية
كأسماء بديلة.
يتم تحديد إصدار الخسارة المناسب بناءً على <a class="reference internal" href="../glossary.html#term-y"><span class="xref std std-term">y</span></a> الذي تم تمريره إلى
<a class="reference internal" href="../glossary.html#term-fit"><span class="xref std std-term">fit</span></a>.</p>
<p>يمكن التحكم في حجم الأشجار من خلال معلمات <code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code> و
<code class="docutils literal notranslate"><span class="pre">max_depth</span></code> و <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code>.</p>
<p>يتم التحكم في عدد الصناديق المُستخدمة لتجميع البيانات باستخدام معلمة <code class="docutils literal notranslate"><span class="pre">max_bins</span></code>.
يُعد استخدام صناديق أقل شكلًا من أشكال التنظيم. يُوصى عمومًا باستخدام أكبر عدد ممكن
من الصناديق (255)، وهو الإعداد الافتراضي.</p>
<p>تعمل المعلمة <code class="docutils literal notranslate"><span class="pre">l2_regularization</span></code> كمنظم لدالة الخسارة، و
تقابل <span class="math notranslate nohighlight">\(\lambda\)</span> في التعبير التالي (انظر المعادلة (2)
في <a class="reference internal" href="#xgboost" id="id8"><span>[XGBoost]</span></a>):</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}(\phi) =  \sum_i l(\hat{y}_i, y_i) + \frac12 \sum_k \lambda ||w_k||^2\]</div>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="تفاصيل-حول-تنظيم-l2">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">تفاصيل حول تنظيم l2<a class="headerlink" href="#تفاصيل-حول-تنظيم-l2" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">من المهم ملاحظة أن مُصطلح الخسارة <span class="math notranslate nohighlight">\(l(\hat{y}_i, y_i)\)</span> يصف
فقط نصف دالة الخسارة الفعلية باستثناء خسارة الكرة والدبوس والخطأ
المُطلق.</p>
<p class="sd-card-text">يشير الفهرس <span class="math notranslate nohighlight">\(k\)</span> إلى الشجرة k في مجموعة الأشجار. في حالة
الانحدار والتصنيف الثنائي، تُنمي نماذج تعزيز التدرج شجرة واحدة لكل
تكرار، ثم يمتد <span class="math notranslate nohighlight">\(k\)</span> حتى <code class="docutils literal notranslate"><span class="pre">max_iter</span></code>. في حالة
مشاكل التصنيف متعددة الفئات، تكون القيمة القصوى للفهرس <span class="math notranslate nohighlight">\(k\)</span> هي
<code class="docutils literal notranslate"><span class="pre">n_classes</span></code> <span class="math notranslate nohighlight">\(\times\)</span> <code class="docutils literal notranslate"><span class="pre">max_iter</span></code>.</p>
<p class="sd-card-text">إذا كان <span class="math notranslate nohighlight">\(T_k\)</span> يُشير إلى عدد الأوراق في الشجرة k، فإن <span class="math notranslate nohighlight">\(w_k\)</span>
هو متجه بطول <span class="math notranslate nohighlight">\(T_k\)</span>، والذي يحتوي على قيم الأوراق بالشكل <code class="docutils literal notranslate"><span class="pre">w</span>
<span class="pre">=</span> <span class="pre">-sum_gradient</span> <span class="pre">/</span> <span class="pre">(sum_hessian</span> <span class="pre">+</span> <span class="pre">l2_regularization)</span></code> (انظر المعادلة (5) في
<a class="reference internal" href="#xgboost" id="id9"><span>[XGBoost]</span></a>).</p>
<p class="sd-card-text">يتم اشتقاق قيم الأوراق <span class="math notranslate nohighlight">\(w_k\)</span> عن طريق قسمة مجموع تدرجات
دالة الخسارة على المجموع المُجتمع للهيسيات. إضافة التنظيم إلى
المقام يُعاقب الأوراق ذات الهيسيات الصغيرة (المناطق المسطحة)،
مما يؤدي إلى تحديثات أصغر. تُساهم قيم <span class="math notranslate nohighlight">\(w_k\)</span> هذه بعد ذلك في
تنبؤ النموذج لإدخال مُعين ينتهي به المطاف في الورقة المُقابلة.
التنبؤ النهائي هو مجموع التنبؤ الأساسي ومساهمات من
كل شجرة. ثم يتم تحويل نتيجة هذا المجموع بواسطة دالة الربط
العكسي اعتمادًا على اختيار دالة الخسارة (انظر
<a class="reference internal" href="#gradient-boosting-formulation"><span class="std std-ref">الصيغة الرياضية</span></a>).</p>
<p class="sd-card-text">لاحظ أن الورقة الأصلية <a class="reference internal" href="#xgboost" id="id10"><span>[XGBoost]</span></a> تُقدم مُصطلحًا <span class="math notranslate nohighlight">\(\gamma\sum_k
T_k\)</span> يعاقب عدد الأوراق (مما يجعلها نسخة سلسة من
<code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code>) غير مُقدمة هنا لأنه غير مُطبق في scikit-learn؛
بينما <span class="math notranslate nohighlight">\(\lambda\)</span> يعاقب حجم تنبؤات الشجرة الفردية قبل
إعادة تغيير مقياسها بواسطة مُعدل التعلم، انظر
<a class="reference internal" href="#gradient-boosting-shrinkage"><span class="std std-ref">الانكماش عبر مُعدل التعلم</span></a>.</p>
</div>
</details><p>لاحظ أنه <strong>يتم تمكين الإيقاف المُبكر افتراضيًا إذا كان عدد العينات
أكبر من 10000</strong>. يتم التحكم في سلوك الإيقاف المُبكر عبر
معلمات <code class="docutils literal notranslate"><span class="pre">early_stopping</span></code> و <code class="docutils literal notranslate"><span class="pre">scoring</span></code> و <code class="docutils literal notranslate"><span class="pre">validation_fraction</span></code> و
<code class="docutils literal notranslate"><span class="pre">n_iter_no_change</span></code> و <code class="docutils literal notranslate"><span class="pre">tol</span></code>. من الممكن الإيقاف المُبكر
باستخدام <span class="xref std std-term">مُسجل</span> عشوائي، أو مجرد خسارة التدريب أو التحقق من الصحة.
لاحظ أنه لأسباب فنية، فإن استخدام دالة قابلة للاستدعاء كمُسجل أبطأ بكثير
من استخدام الخسارة. افتراضيًا، يتم إجراء الإيقاف المُبكر إذا كان هناك على الأقل
10000 عينة في مجموعة التدريب، باستخدام خسارة التحقق من الصحة.</p>
</section>
<section id="nan-support-hgbt">
<span id="id11"></span><h4><span class="section-number">1.11.1.1.2. </span>دعم القيم المفقودة<a class="headerlink" href="#nan-support-hgbt" title="Link to this heading">#</a></h4>
<p><code class="xref py py-class docutils literal notranslate"><span class="pre">HistGradientBoostingClassifier</span></code> و
<code class="xref py py-class docutils literal notranslate"><span class="pre">HistGradientBoostingRegressor</span></code> لديهما دعم مُدمج للقيم
المفقودة (NaNs).</p>
<p>أثناء التدريب، يتعلم مُنمي الشجرة عند كل نقطة تقسيم ما إذا كانت العينات
ذات القيم المفقودة يجب أن تذهب إلى الطفل الأيسر أو الأيمن، بناءً على
المكسب المُحتمل. عند التنبؤ، يتم تعيين العينات ذات القيم المفقودة إلى
الطفل الأيسر أو الأيمن تبعًا لذلك:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">HistGradientBoostingClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">gbdt</span> <span class="o">=</span> <span class="n">HistGradientBoostingClassifier</span><span class="p">(</span><span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gbdt</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">array([0, 0, 1, 1])</span>
</pre></div>
</div>
<p>عندما يكون نمط الفقد تنبؤيًا، يمكن إجراء التقسيمات على
ما إذا كانت قيمة الميزة مفقودة أم لا:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gbdt</span> <span class="o">=</span> <span class="n">HistGradientBoostingClassifier</span><span class="p">(</span><span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="gp">... </span>                                      <span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="gp">... </span>                                      <span class="n">learning_rate</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="gp">... </span>                                      <span class="n">max_iter</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gbdt</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">array([0, 1, 0, 0, 1])</span>
</pre></div>
</div>
<p>إذا لم تتم مصادفة أي قيم مفقودة لميزة مُعينة أثناء التدريب،
فسيتم تعيين العينات ذات القيم المفقودة إلى أي طفل لديه معظم
العينات.</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/ensemble/plot_hgbt_regression.html#sphx-glr-auto-examples-ensemble-plot-hgbt-regression-py"><span class="std std-ref">الميزات في أشجار التعزيز المتدرج للهيستوغرام</span></a></p></li>
</ul>
</section>
<section id="sw-hgbdt">
<span id="id12"></span><h4><span class="section-number">1.11.1.1.3. </span>دعم وزن العينة<a class="headerlink" href="#sw-hgbdt" title="Link to this heading">#</a></h4>
<p><code class="xref py py-class docutils literal notranslate"><span class="pre">HistGradientBoostingClassifier</span></code> و
<code class="xref py py-class docutils literal notranslate"><span class="pre">HistGradientBoostingRegressor</span></code> يدعمان أوزان العينات أثناء
<a class="reference internal" href="../glossary.html#term-fit"><span class="xref std std-term">fit</span></a>.</p>
<p>يوضح المثال التوضيحي التالي أن العينات ذات وزن عينة صفري يتم تجاهلها:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>     <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>     <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>     <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># تجاهل عينتي التدريب الأوليين عن طريق تعيين وزنهما إلى 0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sample_weight</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gb</span> <span class="o">=</span> <span class="n">HistGradientBoostingClassifier</span><span class="p">(</span><span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
<span class="go">HistGradientBoostingClassifier(...)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gb</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="go">array([1])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gb</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="go">0.99...</span>
</pre></div>
</div>
<p>كما ترى، يتم تصنيف <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">0]</span></code> بشكل مريح على أنه <code class="docutils literal notranslate"><span class="pre">1</span></code> نظرًا لتجاهل
العينتين الأوليين بسبب أوزان العينات الخاصة بهما.</p>
<p>تفاصيل التطبيق: يُعادل أخذ أوزان العينات في الاعتبار
ضرب التدرجات (والهيسيات) بأوزان العينات. لاحظ أن
مرحلة التجميع (على وجه التحديد حساب المُكمِّمات) لا تأخذ الأوزان
في الاعتبار.</p>
</section>
<section id="categorical-support-gbdt">
<span id="id13"></span><h4><span class="section-number">1.11.1.1.4. </span>دعم الميزات الفئوية<a class="headerlink" href="#categorical-support-gbdt" title="Link to this heading">#</a></h4>
<p><code class="xref py py-class docutils literal notranslate"><span class="pre">HistGradientBoostingClassifier</span></code> و
<code class="xref py py-class docutils literal notranslate"><span class="pre">HistGradientBoostingRegressor</span></code> لديهما دعم أصلي لـ
الميزات الفئوية: يمكنهما اعتبار التقسيمات على البيانات الفئوية غير المُرتبة.</p>
<p>بالنسبة لمجموعات البيانات ذات الميزات الفئوية، غالبًا ما يكون استخدام الدعم الفئوي
الأصلي أفضل من الاعتماد على الترميز الأحادي الساخن
(<a class="reference internal" href="generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder" title="sklearn.preprocessing.OneHotEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">OneHotEncoder</span></code></a>)، لأن الترميز الأحادي الساخن
يتطلب عمق شجرة أكبر لتحقيق تقسيمات مُكافئة. من الأفضل أيضًا عادةً
الاعتماد على الدعم الفئوي الأصلي بدلاً من مُعالجة
الميزات الفئوية على أنها مُستمرة (ترتيبية)، وهو ما يحدث للبيانات الفئوية المُرمَّزة
ترتيبيًا، نظرًا لأن الفئات هي كميات اسمية حيث لا يهم الترتيب.</p>
<p>لتمكين الدعم الفئوي، يمكن تمرير قناع منطقي إلى
معلمة <code class="docutils literal notranslate"><span class="pre">categorical_features</span></code>، مُشيرًا إلى الميزة الفئوية. في
ما يلي، سيتم مُعالجة الميزة الأولى على أنها فئوية والميزة
الثانية على أنها عددية:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">gbdt</span> <span class="o">=</span> <span class="n">HistGradientBoostingClassifier</span><span class="p">(</span><span class="n">categorical_features</span><span class="o">=</span><span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">])</span>
</pre></div>
</div>
<p>بالتساوي، يمكن للمرء تمرير قائمة من الأعداد الصحيحة التي تُشير إلى مؤشرات
الميزات الفئوية:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">gbdt</span> <span class="o">=</span> <span class="n">HistGradientBoostingClassifier</span><span class="p">(</span><span class="n">categorical_features</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
<p>عندما يكون الإدخال DataFrame، من الممكن أيضًا تمرير قائمة بأسماء الأعمدة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">gbdt</span> <span class="o">=</span> <span class="n">HistGradientBoostingClassifier</span><span class="p">(</span><span class="n">categorical_features</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;site&quot;</span><span class="p">,</span> <span class="s2">&quot;manufacturer&quot;</span><span class="p">])</span>
</pre></div>
</div>
<p>أخيرًا، عندما يكون الإدخال DataFrame، يمكننا استخدام
<code class="docutils literal notranslate"><span class="pre">categorical_features=&quot;from_dtype&quot;</span></code> وفي هذه الحالة سيتم مُعالجة جميع الأعمدة ذات
<code class="docutils literal notranslate"><span class="pre">dtype</span></code> الفئوي كميزات فئوية.</p>
<p>يجب أن تكون عدد العناصر في كل ميزة فئوية أقل من معلمة <code class="docutils literal notranslate"><span class="pre">max_bins</span></code>.
لمثال على استخدام تعزيز التدرج القائم على الرسم البياني على الميزات
الفئوية، انظر
<a class="reference internal" href="../auto_examples/ensemble/plot_gradient_boosting_categorical.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-categorical-py"><span class="std std-ref">دعم الميزات التصنيفية في التدرج التعزيزي</span></a>.</p>
<p>إذا كانت هناك قيم مفقودة أثناء التدريب، فسيتم
مُعالجة القيم المفقودة على أنها فئة مناسبة. إذا لم تكن هناك قيم مفقودة أثناء التدريب،
فعند التنبؤ، يتم تعيين القيم المفقودة إلى العقدة التابعة التي تحتوي على
معظم العينات (تمامًا مثل الميزات المُستمرة). عند التنبؤ،
سيتم مُعالجة الفئات التي لم تتم رؤيتها أثناء وقت الملاءمة كقيم
مفقودة.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="إيجاد-التقسيم-مع-الميزات-الفئوية">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">إيجاد التقسيم مع الميزات الفئوية<a class="headerlink" href="#إيجاد-التقسيم-مع-الميزات-الفئوية" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">الطريقة الأساسية للنظر في التقسيمات الفئوية في شجرة هي النظر في
جميع أقسام <span class="math notranslate nohighlight">\(2^{K - 1} - 1\)</span>، حيث <span class="math notranslate nohighlight">\(K\)</span> هو عدد
الفئات. يمكن أن يصبح هذا باهظ الثمن بسرعة عندما يكون <span class="math notranslate nohighlight">\(K\)</span> كبيرًا.
لحسن الحظ، نظرًا لأن أشجار تعزيز التدرج هي دائمًا أشجار انحدار (حتى
لمشاكل التصنيف)، يوجد إستراتيجية أسرع يمكن أن تُعطي
تقسيمات مُكافئة. أولاً، يتم فرز فئات الميزة وفقًا لـ
تباين الهدف، لكل فئة <code class="docutils literal notranslate"><span class="pre">k</span></code>. بمجرد فرز الفئات،
يمكن للمرء النظر في <em>أقسام مُستمرة</em>، أي مُعالجة الفئات
كما لو كانت قيمًا مُستمرة مُرتبة (انظر Fisher <a class="reference internal" href="#fisher1958" id="id14"><span>[Fisher1958]</span></a> لإثبات
رسمي). نتيجة لذلك، لا يلزم النظر إلا في <span class="math notranslate nohighlight">\(K - 1\)</span> تقسيمًا
بدلاً من <span class="math notranslate nohighlight">\(2^{K - 1} - 1\)</span>. الفرز الأولي هو
عملية <span class="math notranslate nohighlight">\(\mathcal{O}(K \log(K))\)</span>، مما يؤدي إلى تعقيد إجمالي قدره
<span class="math notranslate nohighlight">\(\mathcal{O}(K \log(K) + K)\)</span>، بدلاً من <span class="math notranslate nohighlight">\(\mathcal{O}(2^K)\)</span>.</p>
</div>
</details><p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/ensemble/plot_gradient_boosting_categorical.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-categorical-py"><span class="std std-ref">دعم الميزات التصنيفية في التدرج التعزيزي</span></a></p></li>
</ul>
</section>
<section id="monotonic-cst-gbdt">
<span id="id15"></span><h4><span class="section-number">1.11.1.1.5. </span>قيود رتيبة<a class="headerlink" href="#monotonic-cst-gbdt" title="Link to this heading">#</a></h4>
<p>اعتمادًا على المشكلة المطروحة، قد يكون لديك معرفة مُسبقة تُشير
إلى أن ميزة مُعينة يجب أن يكون لها بشكل عام تأثير إيجابي (أو سلبي)
على القيمة المستهدفة. على سبيل المثال، مع تساوي كل شيء آخر، يجب أن تؤدي درجة الائتمان الأعلى إلى زيادة احتمالية الموافقة على قرض.
تسمح لك القيود الرتيبة بدمج هذه المعرفة المُسبقة في
النموذج.</p>
<p>بالنسبة للمتنبئ <span class="math notranslate nohighlight">\(F\)</span> بميزتين:</p>
<ul>
<li><p><strong>قيد الزيادة الرتيبة</strong> هو قيد بالشكل:</p>
<div class="math notranslate nohighlight">
\[x_1 \leq x_1' \implies F(x_1, x_2) \leq F(x_1', x_2)\]</div>
</li>
<li><p><strong>قيد النقصان الرتيب</strong> هو قيد بالشكل:</p>
<div class="math notranslate nohighlight">
\[x_1 \leq x_1' \implies F(x_1, x_2) \geq F(x_1', x_2)\]</div>
</li>
</ul>
<p>يمكنك تحديد قيد رتيب على كل ميزة باستخدام
معلمة <code class="docutils literal notranslate"><span class="pre">monotonic_cst</span></code>. لكل ميزة، تُشير القيمة 0 إلى عدم وجود
قيد، بينما تُشير 1 و -1 إلى قيد زيادة رتيبة و
قيد نقصان رتيب، على التوالي:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">HistGradientBoostingRegressor</span>

<span class="go">... # زيادة رتيبة، نقصان رتيب، وعدم وجود قيد على الميزات الثلاث</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gbdt</span> <span class="o">=</span> <span class="n">HistGradientBoostingRegressor</span><span class="p">(</span><span class="n">monotonic_cst</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
<p>في سياق التصنيف الثنائي، يعني فرض قيد زيادة رتيبة (نقصان) أن القيم الأعلى للميزة من المُفترض
أن يكون لها تأثير إيجابي (سلبي) على احتمالية العينات
للانتماء إلى الفئة الإيجابية.</p>
<p>ومع ذلك، فإن القيود الرتيبة تُقيّد بشكل هامشي فقط تأثيرات الميزات على الناتج.
على سبيل المثال، لا يمكن استخدام قيود الزيادة والنقصان الرتيبة لفرض
قيد النمذجة التالي:</p>
<div class="math notranslate nohighlight">
\[x_1 \leq x_1' \implies F(x_1, x_2) \leq F(x_1', x_2')\]</div>
<p>أيضًا، القيود الرتيبة غير مدعومة للتصنيف متعدد الفئات.</p>
<div class="admonition note">
<p class="admonition-title">ملاحظة</p>
<p>نظرًا لأن الفئات هي كميات غير مُرتبة، فليس من الممكن فرض
قيود رتيبة على الميزات الفئوية.</p>
</div>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/ensemble/plot_monotonic_constraints.html#sphx-glr-auto-examples-ensemble-plot-monotonic-constraints-py"><span class="std std-ref">القيود الرتيبة</span></a></p></li>
<li><p><a class="reference internal" href="../auto_examples/ensemble/plot_hgbt_regression.html#sphx-glr-auto-examples-ensemble-plot-hgbt-regression-py"><span class="std std-ref">الميزات في أشجار التعزيز المتدرج للهيستوغرام</span></a></p></li>
</ul>
</section>
<section id="interaction-cst-hgbt">
<span id="id16"></span><h4><span class="section-number">1.11.1.1.6. </span>قيود التفاعل<a class="headerlink" href="#interaction-cst-hgbt" title="Link to this heading">#</a></h4>
<p>من حيث المبدأ، يُسمح لأشجار تعزيز التدرج الرسم البياني باستخدام أي ميزة
لتقسيم عقدة إلى عقد تابعة. هذا يخلق ما يسمى بالتفاعلات بين
الميزات، أي استخدام ميزات مُختلفة كتقسيم على طول فرع. في بعض الأحيان،
يريد المرء تقييد التفاعلات الممكنة، انظر <a class="reference internal" href="#mayer2022" id="id17"><span>[Mayer2022]</span></a>. يمكن
القيام بذلك بواسطة المعلمة <code class="docutils literal notranslate"><span class="pre">interaction_cst</span></code>، حيث يمكن للمرء تحديد مؤشرات
الميزات المسموح لها بالتفاعل.
على سبيل المثال، مع 3 ميزات إجمالاً، <code class="docutils literal notranslate"><span class="pre">interaction_cst=[{0},</span> <span class="pre">{1},</span> <span class="pre">{2}]</span></code>
يمنع جميع التفاعلات.
تُحدد القيود <code class="docutils literal notranslate"><span class="pre">[{0,</span> <span class="pre">1},</span> <span class="pre">{1,</span> <span class="pre">2}]</span></code> مجموعتين من الميزات التي يُحتمل
أن تتفاعل. قد تتفاعل الميزات 0 و 1 مع بعضها البعض، وكذلك
الميزات 1 و 2. لكن لاحظ أنه يُمنع تفاعل الميزات 0 و 2.
يُصوِّر ما يلي شجرة والتقسيمات الممكنة للشجرة:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>   1      &lt;- يمكن تطبيق مجموعتي القيود من الآن فصاعدًا
  / \
 1   2    &lt;- لا يزال التقسيم الأيسر يُلبي مجموعتي القيود.
/ \ / \      التقسيم الأيمن عند الميزة 2 لديه المجموعة {1، 2} فقط من الآن فصاعدًا.
</pre></div>
</div>
<p>يستخدم LightGBM نفس المنطق للمجموعات المتداخلة.</p>
<p>لاحظ أن الميزات غير المدرجة في <code class="docutils literal notranslate"><span class="pre">interaction_cst</span></code> يتم تعيينها تلقائيًا
مجموعة تفاعل لأنفسهم. مع 3 ميزات مرة أخرى، هذا
يعني أن <code class="docutils literal notranslate"><span class="pre">[{0}]</span></code> يُعادل <code class="docutils literal notranslate"><span class="pre">[{0},</span> <span class="pre">{1,</span> <span class="pre">2}]</span></code>.</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/inspection/plot_partial_dependence.html#sphx-glr-auto-examples-inspection-plot-partial-dependence-py"><span class="std std-ref">مخططات التبعية الجزئية والتوقع الشرطي الفردي</span></a></p></li>
</ul>
<p class="rubric">المراجع</p>
<div role="list" class="citation-list">
<div class="citation" id="mayer2022" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id17">Mayer2022</a><span class="fn-bracket">]</span></span>
<p>M. Mayer, S.C. Bourassa, M. Hoesli, and D.F. Scognamiglio.
2022. <a class="reference external" href="https://doi.org/10.3390/jrfm15050193">تطبيقات التعلم الآلي لتقييم الأراضي والهياكل</a>.
Journal of Risk and Financial Management 15, no. 5: 193</p>
</div>
</div>
</section>
<section id="id18">
<h4><span class="section-number">1.11.1.1.7. </span>التوازي منخفض المستوى<a class="headerlink" href="#id18" title="Link to this heading">#</a></h4>
<p><code class="xref py py-class docutils literal notranslate"><span class="pre">HistGradientBoostingClassifier</span></code> و
<code class="xref py py-class docutils literal notranslate"><span class="pre">HistGradientBoostingRegressor</span></code> يستخدمان OpenMP
للتوازي من خلال Cython. لمزيد من التفاصيل حول كيفية التحكم في
عدد سلاسل العمليات، يُرجى الرجوع إلى ملاحظات <span class="xref std std-ref">التوازي</span> الخاصة بنا.</p>
<p>الأجزاء التالية متوازية:</p>
<ul class="simple">
<li><p>تعيين العينات من القيم الحقيقية إلى الصناديق ذات القيم الصحيحة (إيجاد عتبات
الصناديق هو تسلسلي)</p></li>
<li><p>بناء الرسوم البيانية متوازي على الميزات</p></li>
<li><p>إيجاد أفضل نقطة تقسيم عند عقدة متوازي على الميزات</p></li>
<li><p>أثناء الملاءمة، تعيين العينات في العقد التابعة اليسرى واليمنى
متوازي على العينات</p></li>
<li><p>حسابات التدرج والهيسيات متوازية على العينات</p></li>
<li><p>التنبؤ متوازي على العينات</p></li>
</ul>
</section>
<section id="why-it-s-faster">
<span id="id19"></span><h4><span class="section-number">1.11.1.1.8. </span>لماذا هو أسرع<a class="headerlink" href="#why-it-s-faster" title="Link to this heading">#</a></h4>
<p>عنق الزجاجة في إجراء تعزيز التدرج هو بناء أشجار القرار.
يتطلب بناء شجرة قرار تقليدية (كما هو الحال في GBDTs الأخرى
<code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingClassifier</span></code> و <code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingRegressor</span></code>)
فرز العينات عند كل عقدة (لكل
ميزة). الفرز ضروري بحيث يمكن حساب المكسب المُحتمل لنقطة تقسيم
بكفاءة. وبالتالي، فإن تقسيم عقدة واحدة له تعقيد
<span class="math notranslate nohighlight">\(\mathcal{O}(n_\text{features} \times n \log(n))\)</span> حيث <span class="math notranslate nohighlight">\(n\)</span>
هو عدد العينات عند العقدة.</p>
<p><code class="xref py py-class docutils literal notranslate"><span class="pre">HistGradientBoostingClassifier</span></code> و
<code class="xref py py-class docutils literal notranslate"><span class="pre">HistGradientBoostingRegressor</span></code>، على النقيض من ذلك، لا يتطلبان فرز
قيم الميزات ويستخدمان بدلاً من ذلك بنية بيانات تسمى الرسم البياني، حيث
يتم ترتيب العينات ضمنيًا. بناء رسم بياني له
تعقيد <span class="math notranslate nohighlight">\(\mathcal{O}(n)\)</span>، لذا فإن إجراء تقسيم العقدة له
تعقيد <span class="math notranslate nohighlight">\(\mathcal{O}(n_\text{features} \times n)\)</span>، أصغر بكثير
من السابق. بالإضافة إلى ذلك، بدلاً من النظر في <span class="math notranslate nohighlight">\(n\)</span> نقاط تقسيم،
نحن نعتبر فقط <code class="docutils literal notranslate"><span class="pre">max_bins</span></code> نقاط تقسيم، والتي قد تكون أصغر
بكثير.</p>
<p>من أجل بناء الرسوم البيانية، يجب تجميع بيانات الإدخال <code class="docutils literal notranslate"><span class="pre">X</span></code> في
صناديق ذات قيم صحيحة. يتطلب إجراء التجميع هذا فرز قيم الميزات،
ولكنه يحدث مرة واحدة فقط في بداية عملية التعزيز
(ليس عند كل عقدة، كما هو الحال في <code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingClassifier</span></code> و
<code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingRegressor</span></code>).</p>
<p>أخيرًا، العديد من أجزاء تطبيق
<code class="xref py py-class docutils literal notranslate"><span class="pre">HistGradientBoostingClassifier</span></code> و
<code class="xref py py-class docutils literal notranslate"><span class="pre">HistGradientBoostingRegressor</span></code> متوازية.</p>
<p class="rubric">المراجع</p>
<div role="list" class="citation-list">
<div class="citation" id="xgboost" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>XGBoost<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id8">1</a>,<a role="doc-backlink" href="#id9">2</a>,<a role="doc-backlink" href="#id10">3</a>)</span>
<p>Tianqi Chen, Carlos Guestrin, <a class="reference external" href="https://arxiv.org/abs/1603.02754">&quot;XGBoost: نظام تعزيز شجرة قابل للتطوير&quot;</a></p>
</div>
<div class="citation" id="lightgbm" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id6">LightGBM</a><span class="fn-bracket">]</span></span>
<p>Ke et. al. <a class="reference external" href="https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree">&quot;LightGBM: شجرة قرار تعزيز تدرج فعالة للغاية&quot;</a></p>
</div>
<div class="citation" id="fisher1958" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id14">Fisher1958</a><span class="fn-bracket">]</span></span>
<p>Fisher, W.D. (1958). <a class="reference external" href="http://csiss.ncgia.ucsb.edu/SPACE/workshops/2004/SAC/files/fisher.pdf">&quot;حول التجميع لأقصى تجانس&quot;</a>
Journal of the American Statistical Association, 53, 789-798.</p>
</div>
</div>
</section>
</section>
<section id="gradientboostingclassifier-gradientboostingregressor">
<h3><span class="section-number">1.11.1.2. </span><code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingClassifier</span></code> و <code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingRegressor</span></code><a class="headerlink" href="#gradientboostingclassifier-gradientboostingregressor" title="Link to this heading">#</a></h3>
<p>يتم وصف استخدام ومعلمات <code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingClassifier</span></code> و
<code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingRegressor</span></code> أدناه. أهم معلمتين
لهؤلاء المُقدِّرين هما <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code> و <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code>.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="التصنيف">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">التصنيف<a class="headerlink" href="#التصنيف" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingClassifier</span></code> يدعم التصنيف الثنائي ومتعدد
الفئات.
يوضح المثال التالي كيفية ملاءمة مُصنف تعزيز التدرج
مع 100 جدعة قرار كمُتعلمين ضعفاء:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_hastie_10_2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_hastie_10_2</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="mi">2000</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="mi">2000</span><span class="p">:]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="mi">2000</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="mi">2000</span><span class="p">:]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="go">0.913...</span>
</pre></div>
</div>
<p class="sd-card-text">يتم التحكم في عدد المُتعلمين الضعفاء (أي أشجار الانحدار) بواسطة
المعلمة <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code>؛ <a class="reference internal" href="#gradient-boosting-tree-size"><span class="std std-ref">حجم كل شجرة</span></a> يمكن التحكم فيه إما عن طريق تعيين عمق الشجرة
عبر <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> أو عن طريق تعيين عدد العقد الورقية عبر
<code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code>. <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> هي معلمة فائقة في النطاق
(0.0، 1.0] التي تتحكم في التجاوز عبر <a class="reference internal" href="#gradient-boosting-shrinkage"><span class="std std-ref">الانكماش</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">ملاحظة</p>
<p class="sd-card-text">يتطلب التصنيف مع أكثر من فئتين حث
<code class="docutils literal notranslate"><span class="pre">n_classes</span></code> أشجار انحدار في كل تكرار،
وبالتالي، فإن العدد الإجمالي للأشجار المُستحثة يساوي
<code class="docutils literal notranslate"><span class="pre">n_classes</span> <span class="pre">*</span> <span class="pre">n_estimators</span></code>. بالنسبة لمجموعات البيانات التي تحتوي على عدد كبير
من الفئات، نوصي بشدة باستخدام
<code class="xref py py-class docutils literal notranslate"><span class="pre">HistGradientBoostingClassifier</span></code> كبديل لـ
<code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingClassifier</span></code>.</p>
</div>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="الانحدار">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">الانحدار<a class="headerlink" href="#الانحدار" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingRegressor</span></code> يدعم عددًا من
<a class="reference internal" href="#gradient-boosting-loss"><span class="std std-ref">دوال الخسارة المختلفة</span></a>
للانحدار والتي يمكن تحديدها عبر الوسيطة
<code class="docutils literal notranslate"><span class="pre">loss</span></code>؛ دالة الخسارة الافتراضية للانحدار هي الخطأ التربيعي
(<code class="docutils literal notranslate"><span class="pre">'squared_error'</span></code>).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_friedman1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingRegressor</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_friedman1</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1200</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="mi">200</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="mi">200</span><span class="p">:]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="mi">200</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="mi">200</span><span class="p">:]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">est</span> <span class="o">=</span> <span class="n">GradientBoostingRegressor</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;squared_error&#39;</span>
<span class="gp">... </span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">est</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
<span class="go">5.00...</span>
</pre></div>
</div>
<p class="sd-card-text">يوضح الشكل أدناه نتائج تطبيق <code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingRegressor</span></code>
مع خسارة المربعات الصغرى و 500 مُتعلم أساسي على مجموعة بيانات مرض السكري
(<a class="reference internal" href="generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes" title="sklearn.datasets.load_diabetes"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.datasets.load_diabetes</span></code></a>).
يوضح الرسم البياني خطأ التدريب والاختبار في كل تكرار.
يتم تخزين خطأ التدريب في كل تكرار في
السمة <code class="docutils literal notranslate"><span class="pre">train_score_</span></code> لنموذج تعزيز التدرج.
يمكن الحصول على خطأ الاختبار في كل تكرار
عبر أسلوب <code class="xref py py-meth docutils literal notranslate"><span class="pre">staged_predict</span></code> الذي يُعيد
مُولِّدًا يُعطي التنبؤات في كل مرحلة. يمكن استخدام الرسوم البيانية مثل هذه
لتحديد العدد الأمثل للأشجار (أي <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code>) عن طريق الإيقاف المُبكر.</p>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/ensemble/plot_gradient_boosting_regression.html"><img alt="../_images/sphx_glr_plot_gradient_boosting_regression_001.png" src="../_images/sphx_glr_plot_gradient_boosting_regression_001.png" style="width: 450.0px; height: 450.0px;" />
</a>
</figure>
</div>
</details><p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/ensemble/plot_gradient_boosting_regression.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-regression-py"><span class="std std-ref">انحدار التعزيز المتدرج</span></a></p></li>
<li><p><a class="reference internal" href="../auto_examples/ensemble/plot_gradient_boosting_oob.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-oob-py"><span class="std std-ref">تقديرات Gradient Boosting Out-of-Bag</span></a></p></li>
</ul>
<section id="gradient-boosting-warm-start">
<span id="id22"></span><h4><span class="section-number">1.11.1.2.1. </span>ملاءمة مُتعلمين ضعفاء إضافيين<a class="headerlink" href="#gradient-boosting-warm-start" title="Link to this heading">#</a></h4>
<p>يدعم كل من <code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingRegressor</span></code> و <code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingClassifier</span></code>
<code class="docutils literal notranslate"><span class="pre">warm_start=True</span></code> الذي يسمح لك بإضافة المزيد من المُقدِّرات إلى نموذج مُناسب
بالفعل.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_friedman1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingRegressor</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_friedman1</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1200</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="mi">200</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="mi">200</span><span class="p">:]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="mi">200</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="mi">200</span><span class="p">:]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">est</span> <span class="o">=</span> <span class="n">GradientBoostingRegressor</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="gp">... </span>     <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;squared_error&#39;</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">est</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>  <span class="c1"># ملاءمة مع 100 شجرة</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">est</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
<span class="go">5.00...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">warm_start</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># تعيين warm_start وزيادة عدد الأشجار</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="c1"># ملاءمة 100 شجرة إضافية إلى est</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">est</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
<span class="go">3.84...</span>
</pre></div>
</div>
</section>
<section id="gradient-boosting-tree-size">
<span id="id23"></span><h4><span class="section-number">1.11.1.2.2. </span>التحكم في حجم الشجرة<a class="headerlink" href="#gradient-boosting-tree-size" title="Link to this heading">#</a></h4>
<p>يُحدد حجم مُتعلمي أساس شجرة الانحدار مستوى تفاعلات المتغيرات
التي يمكن التقاطها بواسطة نموذج تعزيز التدرج. بشكل عام،
يمكن لشجرة بعمق <code class="docutils literal notranslate"><span class="pre">h</span></code> التقاط تفاعلات من الرتبة <code class="docutils literal notranslate"><span class="pre">h</span></code>.
هناك طريقتان للتحكم في حجم أشجار الانحدار الفردية.</p>
<p>إذا حددت <code class="docutils literal notranslate"><span class="pre">max_depth=h</span></code>، فسيتم تنمية أشجار ثنائية كاملة
بعمق <code class="docutils literal notranslate"><span class="pre">h</span></code>. سيكون لهذه الأشجار (على الأكثر) <code class="docutils literal notranslate"><span class="pre">2**h</span></code> عقد ورقية
و <code class="docutils literal notranslate"><span class="pre">2**h</span> <span class="pre">-</span> <span class="pre">1</span></code> عقد تقسيم.</p>
<p>بدلاً من ذلك، يمكنك التحكم في حجم الشجرة عن طريق تحديد عدد
العقد الورقية عبر المعلمة <code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code>. في هذه الحالة،
سيتم تنمية الأشجار باستخدام بحث أفضل أولاً حيث يتم توسيع العقد ذات أعلى تحسين
في النجاسة أولاً.
شجرة ذات <code class="docutils literal notranslate"><span class="pre">max_leaf_nodes=k</span></code> تحتوي على <code class="docutils literal notranslate"><span class="pre">k</span> <span class="pre">-</span> <span class="pre">1</span></code> عقد تقسيم وبالتالي يمكنها
نمذجة تفاعلات تصل إلى رتبة <code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span> <span class="pre">-</span> <span class="pre">1</span></code>.</p>
<p>وجدنا أن <code class="docutils literal notranslate"><span class="pre">max_leaf_nodes=k</span></code> تُعطي نتائج مُقارنة لـ <code class="docutils literal notranslate"><span class="pre">max_depth=k-1</span></code>
ولكنها أسرع بشكل ملحوظ في التدريب على حساب خطأ تدريب أعلى قليلاً.
تقابل المعلمة <code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code> المتغير <code class="docutils literal notranslate"><span class="pre">J</span></code> في
الفصل الخاص بتعزيز التدرج في <a class="reference internal" href="#friedman2001" id="id24"><span>[Friedman2001]</span></a> وترتبط بالمعلمة
<code class="docutils literal notranslate"><span class="pre">interaction.depth</span></code> في حزمة gbm في R حيث <code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span> <span class="pre">==</span> <span class="pre">interaction.depth</span> <span class="pre">+</span> <span class="pre">1</span></code>.</p>
</section>
<section id="gradient-boosting-formulation">
<span id="id25"></span><h4><span class="section-number">1.11.1.2.3. </span>الصيغة الرياضية<a class="headerlink" href="#gradient-boosting-formulation" title="Link to this heading">#</a></h4>
<p>نُقدم أولاً GBRT للانحدار، ثم نُفصِّل حالة
التصنيف.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="الانحدار-2">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">الانحدار<a class="headerlink" href="#الانحدار-2" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">مُنحدرات GBRT هي نماذج مضافة يكون تنبؤها <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> لـ
إدخال مُعين <span class="math notranslate nohighlight">\(x_i\)</span> بالشكل التالي:</p>
<div class="math notranslate nohighlight">
\[\hat{y}_i = F_M(x_i) = \sum_{m=1}^{M} h_m(x_i)\]</div>
<p class="sd-card-text">حيث <span class="math notranslate nohighlight">\(h_m\)</span> هي مُقدِّرات تُسمى <em>مُتعلمين ضعفاء</em> في سياق
التعزيز. يستخدم تعزيز شجرة التدرج <a class="reference internal" href="tree.html#tree"><span class="std std-ref">مُنحدرات شجرة القرار</span></a> ذات حجم ثابت كمُتعلمين ضعفاء. الثابت M يقابل
معلمة <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code>.</p>
<p class="sd-card-text">على غرار خوارزميات التعزيز الأخرى، يتم بناء GBRT بطريقة جشعة:</p>
<div class="math notranslate nohighlight">
\[F_m(x) = F_{m-1}(x) + h_m(x),\]</div>
<p class="sd-card-text">حيث يتم ملاءمة الشجرة المُضافة حديثًا <span class="math notranslate nohighlight">\(h_m\)</span> من أجل تقليل مجموع
الخسائر <span class="math notranslate nohighlight">\(L_m\)</span>، بالنظر إلى المجموعة السابقة <span class="math notranslate nohighlight">\(F_{m-1}\)</span>:</p>
<div class="math notranslate nohighlight">
\[h_m =  \arg\min_{h} L_m = \arg\min_{h} \sum_{i=1}^{n}
l(y_i, F_{m-1}(x_i) + h(x_i)),\]</div>
<p class="sd-card-text">حيث يتم تعريف <span class="math notranslate nohighlight">\(l(y_i, F(x_i))\)</span> بواسطة معلمة <code class="docutils literal notranslate"><span class="pre">loss</span></code>، مُفصَّلة
في القسم التالي.</p>
<p class="sd-card-text">افتراضيًا، يتم اختيار النموذج الأولي <span class="math notranslate nohighlight">\(F_{0}\)</span> كثابت
يُقلل الخسارة: بالنسبة لخسارة المربعات الصغرى، هذا هو المتوسط التجريبي لـ
القيم المستهدفة. يمكن أيضًا تحديد النموذج الأولي عبر وسيطة <code class="docutils literal notranslate"><span class="pre">init</span></code>.</p>
<p class="sd-card-text">باستخدام تقريب تايلور من الدرجة الأولى، يمكن
تقريب قيمة <span class="math notranslate nohighlight">\(l\)</span> على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[l(y_i, F_{m-1}(x_i) + h_m(x_i)) \approx
l(y_i, F_{m-1}(x_i))
+ h_m(x_i)
\left[ \frac{\partial l(y_i, F(x_i))}{\partial F(x_i)} \right]_{F=F_{m - 1}}.\]</div>
<div class="admonition note">
<p class="admonition-title">ملاحظة</p>
<p class="sd-card-text">باختصار، يقول تقريب تايلور من الدرجة الأولى أن
<span class="math notranslate nohighlight">\(l(z) \approx l(a) + (z - a) \frac{\partial l}{\partial z}(a)\)</span>.
هنا، <span class="math notranslate nohighlight">\(z\)</span> يقابل <span class="math notranslate nohighlight">\(F_{m - 1}(x_i) + h_m(x_i)\)</span>، و
<span class="math notranslate nohighlight">\(a\)</span> يقابل <span class="math notranslate nohighlight">\(F_{m-1}(x_i)\)</span></p>
</div>
<p class="sd-card-text">الكمية <span class="math notranslate nohighlight">\(\left[ \frac{\partial l(y_i, F(x_i))}{\partial F(x_i)}
\right]_{F=F_{m - 1}}\)</span> هي مُشتق الخسارة بالنسبة لمعلمتها
الثانية، مُقيَّمة عند <span class="math notranslate nohighlight">\(F_{m-1}(x)\)</span>. من السهل حسابها لـ
أي <span class="math notranslate nohighlight">\(F_{m - 1}(x_i)\)</span> مُعطى في شكل مُغلق لأن الخسارة
قابلة للاشتقاق. سنُشير إليها بـ <span class="math notranslate nohighlight">\(g_i\)</span>.</p>
<p class="sd-card-text">بإزالة المُصطلحات الثابتة، لدينا:</p>
<div class="math notranslate nohighlight">
\[h_m \approx \arg\min_{h} \sum_{i=1}^{n} h(x_i) g_i\]</div>
<p class="sd-card-text">يتم تقليل هذا إذا تم ملاءمة <span class="math notranslate nohighlight">\(h(x_i)\)</span> للتنبؤ بقيمة
تتناسب مع التدرج السالب <span class="math notranslate nohighlight">\(-g_i\)</span>. لذلك، في كل
تكرار، <strong>يتم ملاءمة المُقدِّر</strong> <span class="math notranslate nohighlight">\(h_m\)</span> <strong>للتنبؤ بالتدرجات
السالبة للعينات</strong>. يتم تحديث التدرجات في كل تكرار.
يمكن اعتبار هذا نوعًا من النزول التدرجي في فضاء
دالة.</p>
<div class="admonition note">
<p class="admonition-title">ملاحظة</p>
<p class="sd-card-text">بالنسبة لبعض الخسائر، على سبيل المثال <code class="docutils literal notranslate"><span class="pre">'absolute_error'</span></code> حيث التدرجات
هي <span class="math notranslate nohighlight">\(\pm 1\)</span>، فإن القيم التي يتنبأ بها <span class="math notranslate nohighlight">\(h_m\)</span> المُناسب ليست
دقيقة بما يكفي: يمكن للشجرة إخراج قيم صحيحة فقط. نتيجة لذلك،
يتم تعديل قيم أوراق الشجرة <span class="math notranslate nohighlight">\(h_m\)</span> بمجرد ملاءمة الشجرة،
بحيث تُقلل قيم الأوراق من الخسارة <span class="math notranslate nohighlight">\(L_m\)</span>. التحديث يعتمد على
الخسارة: بالنسبة لخسارة الخطأ المُطلق، يتم تحديث قيمة
ورقة إلى متوسط العينات في تلك الورقة.</p>
</div>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="التصنيف-2">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">التصنيف<a class="headerlink" href="#التصنيف-2" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">يشبه تعزيز التدرج للتصنيف حالة الانحدار إلى حد كبير.
ومع ذلك، فإن مجموع الأشجار <span class="math notranslate nohighlight">\(F_M(x_i) = \sum_m h_m(x_i)\)</span> ليس
متجانسًا مع التنبؤ: لا يمكن أن يكون فئة، لأن الأشجار تتنبأ
بقيم مُستمرة.</p>
<p class="sd-card-text">التعيين من القيمة <span class="math notranslate nohighlight">\(F_M(x_i)\)</span> إلى فئة أو احتمال
يعتمد على الخسارة. بالنسبة لخسارة السجل، يتم نمذجة احتمال أن
<span class="math notranslate nohighlight">\(x_i\)</span> ينتمي إلى الفئة الإيجابية على أنه <span class="math notranslate nohighlight">\(p(y_i = 1 |
x_i) = \sigma(F_M(x_i))\)</span> حيث <span class="math notranslate nohighlight">\(\sigma\)</span> هي دالة السيني أو
expit.</p>
<p class="sd-card-text">بالنسبة للتصنيف متعدد الفئات، يتم بناء K شجرة (لفئات K) في كل
من تكرارات <span class="math notranslate nohighlight">\(M\)</span>. احتمال أن <span class="math notranslate nohighlight">\(x_i\)</span> ينتمي إلى الفئة
k مُنمذج على أنه softmax لقيم <span class="math notranslate nohighlight">\(F_{M,k}(x_i)\)</span>.</p>
<p class="sd-card-text">لاحظ أنه حتى بالنسبة لمهمة تصنيف، فإن المُقدِّر الفرعي <span class="math notranslate nohighlight">\(h_m\)</span>
لا يزال مُنحدِرًا، وليس مُصنِّفًا. هذا لأن المُقدِّرات الفرعية
مُدرَّبة للتنبؤ بـ <em>تدرجات</em> (سالبة)، وهي دائمًا كميات
مُستمرة.</p>
</div>
</details></section>
<section id="gradient-boosting-loss">
<span id="id26"></span><h4><span class="section-number">1.11.1.2.4. </span>دوال الخسارة<a class="headerlink" href="#gradient-boosting-loss" title="Link to this heading">#</a></h4>
<p>يتم دعم دوال الخسارة التالية ويمكن تحديدها باستخدام
معلمة <code class="docutils literal notranslate"><span class="pre">loss</span></code>:</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="الانحدار-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">الانحدار<a class="headerlink" href="#الانحدار-3" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text">الخطأ التربيعي (<code class="docutils literal notranslate"><span class="pre">'squared_error'</span></code>): الخيار الطبيعي للانحدار
نظرًا لخصائصه الحسابية المُتفوقة. النموذج الأولي
مُعطى بمتوسط القيم المستهدفة.</p></li>
<li><p class="sd-card-text">الخطأ المُطلق (<code class="docutils literal notranslate"><span class="pre">'absolute_error'</span></code>): دالة خسارة قوية لـ
الانحدار. النموذج الأولي مُعطى بمتوسط
القيم المستهدفة.</p></li>
<li><p class="sd-card-text">Huber (<code class="docutils literal notranslate"><span class="pre">'huber'</span></code>): دالة خسارة قوية أخرى تجمع بين
المربعات الصغرى وانحراف المُطلق الأقل؛ استخدم <code class="docutils literal notranslate"><span class="pre">alpha</span></code> لـ
التحكم في الحساسية فيما يتعلق بالقيم المتطرفة (انظر <a class="reference internal" href="#friedman2001" id="id27"><span>[Friedman2001]</span></a> لـ
مزيد من التفاصيل).</p></li>
<li><p class="sd-card-text">المُكمِّم (<code class="docutils literal notranslate"><span class="pre">'quantile'</span></code>): دالة خسارة لانحدار المُكمِّم.
استخدم <code class="docutils literal notranslate"><span class="pre">0</span> <span class="pre">&lt;</span> <span class="pre">alpha</span> <span class="pre">&lt;</span> <span class="pre">1</span></code> لتحديد المُكمِّم. يمكن استخدام دالة الخسارة هذه لإنشاء فترات تنبؤ
(انظر <a class="reference internal" href="../auto_examples/ensemble/plot_gradient_boosting_quantile.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-quantile-py"><span class="std std-ref">فترات التنبؤ لانحدار التعزيز المتدرج</span></a>).</p></li>
</ul>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="التصنيف-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">التصنيف<a class="headerlink" href="#التصنيف-3" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text">خسارة السجل الثنائية (<code class="docutils literal notranslate"><span class="pre">'log-loss'</span></code>): ذات الحدين
دالة خسارة الاحتمالية السالبة للتصنيف الثنائي. إنها تُوفر
تقديرات احتمالية. النموذج الأولي مُعطى بواسطة
نسبة احتمالات السجل.</p></li>
<li><p class="sd-card-text">خسارة السجل متعددة الفئات (<code class="docutils literal notranslate"><span class="pre">'log-loss'</span></code>): متعددة الحدود
دالة خسارة الاحتمالية السالبة للتصنيف متعدد الفئات مع
<code class="docutils literal notranslate"><span class="pre">n_classes</span></code> فئات مُتبادلة الاستبعاد. إنها تُوفر
تقديرات احتمالية. النموذج الأولي مُعطى بواسطة
الاحتمال المُسبق لكل فئة. في كل تكرار <code class="docutils literal notranslate"><span class="pre">n_classes</span></code>
يجب إنشاء أشجار انحدار مما يجعل GBRT
غير فعال لمجموعات البيانات التي تحتوي على عدد كبير من الفئات.</p></li>
<li><p class="sd-card-text">الخسارة الأسية (<code class="docutils literal notranslate"><span class="pre">'exponential'</span></code>): نفس دالة الخسارة
مثل <code class="xref py py-class docutils literal notranslate"><span class="pre">AdaBoostClassifier</span></code>. أقل قوة للأمثلة
ذات التصنيف الخاطئ من <code class="docutils literal notranslate"><span class="pre">'log-loss'</span></code>؛ لا يمكن استخدامها إلا للتصنيف
الثنائي.</p></li>
</ul>
</div>
</details></section>
<section id="gradient-boosting-shrinkage">
<span id="id28"></span><h4><span class="section-number">1.11.1.2.5. </span>الانكماش عبر مُعدل التعلم<a class="headerlink" href="#gradient-boosting-shrinkage" title="Link to this heading">#</a></h4>
<p><a class="reference internal" href="#friedman2001" id="id29"><span>[Friedman2001]</span></a> اقترح إستراتيجية تنظيم بسيطة تُغيّر مقياس
مساهمة كل مُتعلم ضعيف بواسطة عامل ثابت <span class="math notranslate nohighlight">\(\nu\)</span>:</p>
<div class="math notranslate nohighlight">
\[F_m(x) = F_{m-1}(x) + \nu h_m(x)\]</div>
<p>تُسمى المعلمة <span class="math notranslate nohighlight">\(\nu\)</span> أيضًا <strong>مُعدل التعلم</strong> لأنها
تُغيّر مقياس طول الخطوة لإجراء النزول التدرجي؛ يمكن
تعيينها عبر معلمة <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code>.</p>
<p>تتفاعل المعلمة <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> بقوة مع المعلمة
<code class="docutils literal notranslate"><span class="pre">n_estimators</span></code>، عدد المُتعلمين الضعفاء المناسبين. القيم الأصغر
لـ <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> تتطلب أعدادًا أكبر من المُتعلمين الضعفاء للحفاظ على
خطأ تدريب ثابت. تُشير الأدلة التجريبية إلى أن القيم الصغيرة
لـ <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> تُفضل خطأ اختبار أفضل. <a class="reference internal" href="#htf" id="id30"><span>[HTF]</span></a>
يوصي بتعيين مُعدل التعلم إلى ثابت صغير
(على سبيل المثال <code class="docutils literal notranslate"><span class="pre">learning_rate</span> <span class="pre">&lt;=</span> <span class="pre">0.1</span></code>) واختيار <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code> كبيرًا بما يكفي
لتطبيق الإيقاف المُبكر،
انظر <a class="reference internal" href="../auto_examples/ensemble/plot_gradient_boosting_early_stopping.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-early-stopping-py"><span class="std std-ref">إيقاف التدريب المبكر في Gradient Boosting</span></a>
لمناقشة أكثر تفصيلاً للتفاعل بين
<code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> و <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code> انظر <a class="reference internal" href="#r2007" id="id31"><span>[R2007]</span></a>.</p>
</section>
<section id="id32">
<h4><span class="section-number">1.11.1.2.6. </span>أخذ عينات فرعية<a class="headerlink" href="#id32" title="Link to this heading">#</a></h4>
<p><a class="reference internal" href="#friedman2002" id="id33"><span>[Friedman2002]</span></a> اقترح تعزيز التدرج العشوائي، الذي يجمع بين تعزيز
التدرج ومتوسط التمهيد (التجميع). في كل تكرار
يتم تدريب المُصنف الأساسي على جزء <code class="docutils literal notranslate"><span class="pre">subsample</span></code> من
بيانات التدريب المتاحة. يتم رسم العينة الفرعية بدون استبدال.
قيمة نموذجية لـ <code class="docutils literal notranslate"><span class="pre">subsample</span></code> هي 0.5.</p>
<p>يوضح الشكل أدناه تأثير الانكماش وأخذ العينات الفرعية
على جودة ملاءمة النموذج. يمكننا أن نرى بوضوح أن الانكماش
يتفوق على عدم الانكماش. يمكن لأخذ العينات الفرعية مع الانكماش زيادة
دقة النموذج بشكل أكبر. من ناحية أخرى، فإن أخذ العينات الفرعية بدون انكماش
يؤدي بشكل سيئ.</p>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/ensemble/plot_gradient_boosting_regularization.html"><img alt="../_images/sphx_glr_plot_gradient_boosting_regularization_001.png" src="../_images/sphx_glr_plot_gradient_boosting_regularization_001.png" style="width: 480.0px; height: 360.0px;" />
</a>
</figure>
<p>إستراتيجية أخرى لتقليل التباين هي عن طريق أخذ عينات فرعية من الميزات
بشكل مُماثل للتقسيمات العشوائية في <code class="xref py py-class docutils literal notranslate"><span class="pre">RandomForestClassifier</span></code>.
يمكن التحكم في عدد الميزات التي تم أخذ عينات فرعية منها عبر معلمة <code class="docutils literal notranslate"><span class="pre">max_features</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">ملاحظة</p>
<p>يمكن أن يؤدي استخدام قيمة <code class="docutils literal notranslate"><span class="pre">max_features</span></code> صغيرة إلى تقليل وقت التشغيل بشكل كبير.</p>
</div>
<p>يسمح تعزيز التدرج العشوائي بحساب تقديرات خارج الحقيبة
لانحراف الاختبار عن طريق حساب التحسين في الانحراف على الأمثلة التي
لم يتم تضمينها في عينة التمهيد (أي أمثلة خارج الحقيبة).
يتم تخزين التحسينات في السمة <code class="docutils literal notranslate"><span class="pre">oob_improvement_</span></code>.
<code class="docutils literal notranslate"><span class="pre">oob_improvement_[i]</span></code> يحمل التحسين من حيث الخسارة على عينات OOB
إذا أضفت المرحلة i إلى التنبؤات الحالية.
يمكن استخدام التقديرات خارج الحقيبة لاختيار النموذج، على سبيل المثال لتحديد
العدد الأمثل للتكرارات. عادةً ما تكون تقديرات OOB متشائمة جدًا، وبالتالي
نوصي باستخدام التحقق المتبادل بدلاً من ذلك واستخدام OOB فقط إذا كان التحقق
المتبادل يستغرق وقتًا طويلاً جدًا.</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/ensemble/plot_gradient_boosting_regularization.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-regularization-py"><span class="std std-ref">تنظيم التعزيز المتدرج</span></a></p></li>
<li><p><a class="reference internal" href="../auto_examples/ensemble/plot_gradient_boosting_oob.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-oob-py"><span class="std std-ref">تقديرات Gradient Boosting Out-of-Bag</span></a></p></li>
<li><p><a class="reference internal" href="../auto_examples/ensemble/plot_ensemble_oob.html#sphx-glr-auto-examples-ensemble-plot-ensemble-oob-py"><span class="std std-ref">أخطاء OOB لخوارزمية Random Forests</span></a></p></li>
</ul>
</section>
<section id="id34">
<h4><span class="section-number">1.11.1.2.7. </span>تفسير مع أهمية الميزة<a class="headerlink" href="#id34" title="Link to this heading">#</a></h4>
<p>يمكن تفسير أشجار القرار الفردية بسهولة عن طريق ببساطة
تصور هيكل الشجرة. نماذج تعزيز التدرج، مع ذلك،
تتكون من مئات من أشجار الانحدار، وبالتالي لا يمكن تفسيرها بسهولة
عن طريق الفحص البصري للأشجار الفردية. لحسن الحظ،
تم اقتراح عدد من التقنيات لتلخيص وتفسير
نماذج تعزيز التدرج.</p>
<p>غالبًا لا تُساهم الميزات بالتساوي في التنبؤ باستجابة
الهدف؛ في كثير من الحالات، تكون غالبية الميزات في الواقع
غير ذات صلة.
عند تفسير نموذج، فإن السؤال الأول عادةً ما يكون: ما هي
تلك الميزات المهمة وكيف تُساهم في التنبؤ
باستجابة الهدف؟</p>
<p>تؤدي أشجار القرار الفردية اختيار الميزات بشكل جوهري عن طريق اختيار
نقاط تقسيم مناسبة. يمكن استخدام هذه المعلومات لقياس
أهمية كل ميزة؛ الفكرة الأساسية هي: كلما زاد استخدام
ميزة في نقاط تقسيم الشجرة، زادت أهمية تلك
الميزة. يمكن توسيع مفهوم الأهمية هذا ليشمل مجموعات شجرة القرار
عن طريق حساب متوسط أهمية الميزة القائمة على النجاسة لكل شجرة (انظر
<a class="reference internal" href="#random-forest-feature-importance"><span class="std std-ref">تقييم أهمية الميزة</span></a> لمزيد من التفاصيل).</p>
<p>يمكن الوصول إلى درجات أهمية الميزة لنموذج تعزيز التدرج المُناسب
عبر الخاصية <code class="docutils literal notranslate"><span class="pre">feature_importances_</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_hastie_10_2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_hastie_10_2</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">feature_importances_</span>
<span class="go">array([0.10..., 0.10..., 0.11..., ...</span>
</pre></div>
</div>
<p>لاحظ أن حساب أهمية الميزة هذا يعتمد على الانتروبيا، و
إنه مُختلف عن <a class="reference internal" href="generated/sklearn.inspection.permutation_importance.html#sklearn.inspection.permutation_importance" title="sklearn.inspection.permutation_importance"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.inspection.permutation_importance</span></code></a> الذي
يعتمد على تبديل الميزات.</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/ensemble/plot_gradient_boosting_regression.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-regression-py"><span class="std std-ref">انحدار التعزيز المتدرج</span></a></p></li>
</ul>
<p class="rubric">المراجع</p>
<div role="list" class="citation-list">
<div class="citation" id="friedman2001" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Friedman2001<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id4">1</a>,<a role="doc-backlink" href="#id24">2</a>,<a role="doc-backlink" href="#id27">3</a>,<a role="doc-backlink" href="#id29">4</a>)</span>
<p>Friedman, J.H. (2001). <a class="reference external" href="https://doi.org/10.1214/aos/1013203451">تقريب دالة جشع: آلة تعزيز التدرج</a>.
Annals of Statistics, 29, 1189-1232.</p>
</div>
<div class="citation" id="friedman2002" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id33">Friedman2002</a><span class="fn-bracket">]</span></span>
<p>Friedman, J.H. (2002). <a class="reference external" href="https://statweb.stanford.edu/~jhf/ftp/stobst.pdf">تعزيز التدرج العشوائي.</a>.
Computational Statistics &amp; Data Analysis, 38, 367-378.</p>
</div>
<div class="citation" id="r2007" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id31">R2007</a><span class="fn-bracket">]</span></span>
<p>G. Ridgeway (2006). <a class="reference external" href="https://cran.r-project.org/web/packages/gbm/vignettes/gbm.pdf">نماذج مُعززة مُعممة: دليل لحزمة gbm</a></p>
</div>
</div>
</section>
</section>
</section>
<section id="forest">
<span id="id36"></span><h2><span class="section-number">1.11.2. </span>الغابات العشوائية ومجموعات الأشجار العشوائية الأخرى<a class="headerlink" href="#forest" title="Link to this heading">#</a></h2>
<p>تتضمن وحدة <a class="reference internal" href="../api/sklearn.ensemble.html#module-sklearn.ensemble" title="sklearn.ensemble"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.ensemble</span></code></a> خوارزميتين للمتوسط بناءً على
<a class="reference internal" href="tree.html#tree"><span class="std std-ref">أشجار القرار</span></a> العشوائية: خوارزمية RandomForest
وأسلوب Extra-Trees. كلتا الخوارزميتين هما تقنيات اضطراب وتجميع
<a class="reference internal" href="#b1998" id="id37"><span>[B1998]</span></a> مُصممة خصيصًا للأشجار. هذا يعني مجموعة مُتنوعة
من المُصنِّفات يتم إنشاؤها عن طريق إدخال العشوائية في مُنشئ
المُصنف. يتم إعطاء تنبؤ المجموعة على أنه متوسط
تنبؤ المُصنِّفات الفردية.</p>
<p>مثل المُصنِّفات الأخرى، يجب ملاءمة مُصنِّفات الغابات بمصفوفتين:
مصفوفة متفرقة أو كثيفة X ذات شكل <code class="docutils literal notranslate"><span class="pre">(n_samples,</span> <span class="pre">n_features)</span></code>
تحمل عينات التدريب، ومصفوفة Y ذات شكل <code class="docutils literal notranslate"><span class="pre">(n_samples,)</span></code>
تحمل القيم المستهدفة (تصنيفات الفئات) لعينات التدريب:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
</pre></div>
</div>
<p>مثل <a class="reference internal" href="tree.html#tree"><span class="std std-ref">أشجار القرار</span></a>، تمتد غابات الأشجار أيضًا إلى
<a class="reference internal" href="tree.html#tree-multioutput"><span class="std std-ref">مشاكل الإخراج المتعدد</span></a> (إذا كانت Y مصفوفة
ذات شكل <code class="docutils literal notranslate"><span class="pre">(n_samples,</span> <span class="pre">n_outputs)</span></code>).</p>
<section id="id38">
<h3><span class="section-number">1.11.2.1. </span>الغابات العشوائية<a class="headerlink" href="#id38" title="Link to this heading">#</a></h3>
<p>في الغابات العشوائية (انظر فئات <code class="xref py py-class docutils literal notranslate"><span class="pre">RandomForestClassifier</span></code> و
<code class="xref py py-class docutils literal notranslate"><span class="pre">RandomForestRegressor</span></code>)، يتم بناء كل شجرة في المجموعة
من عينة مرسومة مع استبدال (أي عينة تمهيد) من
مجموعة التدريب.</p>
<p>علاوة على ذلك، عند تقسيم كل عقدة أثناء بناء شجرة،
يتم إيجاد أفضل تقسيم من خلال بحث شامل عن قيم الميزات لـ
إما جميع ميزات الإدخال أو مجموعة فرعية عشوائية من الحجم <code class="docutils literal notranslate"><span class="pre">max_features</span></code>.
(راجع <a class="reference internal" href="#random-forest-parameters"><span class="std std-ref">إرشادات ضبط المعلمات</span></a> لمزيد من التفاصيل.)</p>
<p>الغرض من هذين المصدرين للعشوائية هو تقليل تباين
مُقدِّر الغابة. في الواقع، تُظهر أشجار القرار الفردية عادةً تباينًا عاليًا وتميل إلى
التجاوز. ينتج عن العشوائية المحقونة في الغابات أشجار قرار ذات أخطاء تنبؤ
مفصولة إلى حد ما. عن طريق حساب متوسط تلك
التنبؤات، يمكن إلغاء بعض الأخطاء. تُحقق الغابات العشوائية تباينًا
مُنخفضًا من خلال دمج الأشجار المُتنوعة، وأحيانًا على حساب زيادة طفيفة في
التحيز. في الممارسة العملية، غالبًا ما يكون تقليل التباين كبيرًا، مما يؤدي إلى
نموذج أفضل بشكل عام.</p>
<p>على عكس المنشور الأصلي <a class="reference internal" href="#b2001" id="id39"><span>[B2001]</span></a>، فإن تطبيق scikit-learn
يجمع المُصنِّفات عن طريق حساب متوسط تنبؤها الاحتمالي،
بدلاً من السماح لكل مُصنف بالتصويت على فئة واحدة.</p>
<p>بديل تنافسي للغابات العشوائية هو
نماذج <a class="reference internal" href="#histogram-based-gradient-boosting"><span class="std std-ref">تعزيز التدرج القائم على الرسم البياني</span></a> (HGBT):</p>
<ul class="simple">
<li><p>بناء الأشجار: تعتمد الغابات العشوائية عادةً على الأشجار العميقة (التي تُفرط
في الملاءمة بشكل فردي) والتي تستخدم الكثير من موارد الحساب، حيث تتطلب
العديد من التقسيمات وتقييمات التقسيمات المُرشحة. نماذج التعزيز
تبني أشجارًا ضحلة (تُفرط في الملاءمة بشكل فردي) وهي أسرع في الملاءمة
والتنبؤ.</p></li>
<li><p>التعزيز المتسلسل: في HGBT، يتم بناء أشجار القرار بالتسلسل،
حيث يتم تدريب كل شجرة لتصحيح الأخطاء التي ارتكبتها الأشجار السابقة.
هذا يسمح لهم بتحسين أداء النموذج بشكل متكرر باستخدام
عدد قليل نسبيًا من الأشجار. على النقيض من ذلك، تستخدم الغابات العشوائية تصويت الأغلبية لـ
التنبؤ بالنتيجة، الأمر الذي قد يتطلب عددًا أكبر من الأشجار لتحقيق
نفس مستوى الدقة.</p></li>
<li><p>التجميع الفعال: يستخدم HGBT خوارزمية تجميع فعالة يمكنها التعامل مع
مجموعات البيانات الكبيرة التي تحتوي على عدد كبير من الميزات. يمكن لخوارزمية التجميع
مُعالجة البيانات مُسبقًا لتسريع بناء الشجرة اللاحق (انظر
<a class="reference internal" href="#why-it-s-faster"><span class="std std-ref">لماذا هو أسرع</span></a>). على النقيض من ذلك، تطبيق scikit-learn
للغابات العشوائية لا يستخدم التجميع ويعتمد على التقسيم
الدقيق، والذي قد يكون مكلفًا من الناحية الحسابية.</p></li>
</ul>
<p>بشكل عام، تعتمد التكلفة الحسابية لـ HGBT مقابل RF على الخصائص المحددة
لمجموعة البيانات ومهمة النمذجة. إنها لفكرة جيدة
تجربة كلا النموذجين ومقارنة أدائهما وكفاءتهما الحسابية
في مشكلتك المحددة لتحديد النموذج الأنسب.</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/ensemble/plot_forest_hist_grad_boosting_comparison.html#sphx-glr-auto-examples-ensemble-plot-forest-hist-grad-boosting-comparison-py"><span class="std std-ref">مقارنة بين نماذج الغابات العشوائية ورفع التدرج بالرسم البياني</span></a></p></li>
</ul>
</section>
<section id="id40">
<h3><span class="section-number">1.11.2.2. </span>أشجار عشوائية للغاية<a class="headerlink" href="#id40" title="Link to this heading">#</a></h3>
<p>في الأشجار العشوائية للغاية (انظر فئات <code class="xref py py-class docutils literal notranslate"><span class="pre">ExtraTreesClassifier</span></code>
و <code class="xref py py-class docutils literal notranslate"><span class="pre">ExtraTreesRegressor</span></code>)، تذهب العشوائية خطوة أخرى إلى الأمام في طريقة حساب
التقسيمات. كما هو الحال في الغابات العشوائية، يتم استخدام
مجموعة فرعية عشوائية من الميزات المُرشحة، ولكن بدلاً من البحث عن
العتبات الأكثر تمييزًا، يتم رسم العتبات عشوائيًا لكل
ميزة مُرشحة ويتم اختيار أفضل هذه العتبات التي تم إنشاؤها عشوائيًا
كقاعدة تقسيم. هذا يسمح عادةً بتقليل تباين
النموذج أكثر قليلاً، على حساب زيادة طفيفة في
التحيز:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">ExtraTreesClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="go">0.98...</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="go">0.999...</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">ExtraTreesClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.999</span>
<span class="go">True</span>
</pre></div>
</div>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/ensemble/plot_forest_iris.html"><img alt="../_images/sphx_glr_plot_forest_iris_001.png" src="../_images/sphx_glr_plot_forest_iris_001.png" style="width: 480.0px; height: 360.0px;" />
</a>
</figure>
</section>
<section id="random-forest-parameters">
<span id="id41"></span><h3><span class="section-number">1.11.2.3. </span>المعلمات<a class="headerlink" href="#random-forest-parameters" title="Link to this heading">#</a></h3>
<p>المعلمات الرئيسية التي يجب تعديلها عند استخدام هذه الأساليب هي <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code> و
<code class="docutils literal notranslate"><span class="pre">max_features</span></code>. الأولى هي عدد الأشجار في الغابة. كلما زاد
كان ذلك أفضل، ولكن أيضًا كلما استغرق حسابه وقتًا أطول. بالإضافة إلى ذلك، لاحظ أن
النتائج ستتوقف عن التحسن بشكل كبير بعدد حرج من
الأشجار. الأخيرة هي حجم المجموعات الفرعية العشوائية من الميزات التي يجب مراعاتها
عند تقسيم عقدة. كلما انخفض، زاد تقليل التباين، ولكن
أيضًا زادت الزيادة في التحيز. قيم افتراضية تجريبية جيدة هي
<code class="docutils literal notranslate"><span class="pre">max_features=1.0</span></code> أو بشكل مُكافئ <code class="docutils literal notranslate"><span class="pre">max_features=None</span></code> (مع مراعاة
جميع الميزات دائمًا بدلاً من مجموعة فرعية عشوائية) لمشاكل الانحدار، و
<code class="docutils literal notranslate"><span class="pre">max_features=&quot;sqrt&quot;</span></code> (باستخدام مجموعة فرعية عشوائية من الحجم <code class="docutils literal notranslate"><span class="pre">sqrt(n_features)</span></code>)
لمهام التصنيف (حيث <code class="docutils literal notranslate"><span class="pre">n_features</span></code> هو عدد الميزات في
البيانات). القيمة الافتراضية لـ <code class="docutils literal notranslate"><span class="pre">max_features=1.0</span></code> تُعادل الأشجار المُجمَّعة
ويمكن تحقيق المزيد من العشوائية عن طريق تعيين قيم أصغر (على سبيل المثال 0.3
هو افتراضي نموذجي في الأدبيات). غالبًا ما يتم تحقيق نتائج جيدة عند
تعيين <code class="docutils literal notranslate"><span class="pre">max_depth=None</span></code> مع <code class="docutils literal notranslate"><span class="pre">min_samples_split=2</span></code> (أي
عند تطوير الأشجار بالكامل). ضع في اعتبارك أن هذه القيم
عادةً ما لا تكون مثالية، وقد تؤدي إلى نماذج تستهلك الكثير من ذاكرة الوصول العشوائي.
يجب دائمًا التحقق من أفضل قيم المعلمات بشكل متبادل. بالإضافة إلى ذلك، لاحظ
أنه في الغابات العشوائية، يتم استخدام عينات التمهيد افتراضيًا
(<code class="docutils literal notranslate"><span class="pre">bootstrap=True</span></code>) بينما الإستراتيجية الافتراضية للأشجار الإضافية هي استخدام
مجموعة البيانات بأكملها (<code class="docutils literal notranslate"><span class="pre">bootstrap=False</span></code>). عند استخدام أخذ عينات التمهيد،
يمكن تقدير خطأ التعميم على العينات المتروكة أو خارج الحقيبة.
يمكن تمكين ذلك عن طريق تعيين <code class="docutils literal notranslate"><span class="pre">oob_score=True</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">ملاحظة</p>
<p>حجم النموذج بالمعلمات الافتراضية هو <span class="math notranslate nohighlight">\(O( M * N * log (N) )\)</span>،
حيث <span class="math notranslate nohighlight">\(M\)</span> هو عدد الأشجار و <span class="math notranslate nohighlight">\(N\)</span> هو عدد العينات.
لتقليل حجم النموذج، يمكنك تغيير هذه المعلمات:
<code class="docutils literal notranslate"><span class="pre">min_samples_split</span></code> و <code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code> و <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> و <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code>.</p>
</div>
</section>
<section id="id42">
<h3><span class="section-number">1.11.2.4. </span>التوازي<a class="headerlink" href="#id42" title="Link to this heading">#</a></h3>
<p>أخيرًا، تُظهر هذه الوحدة أيضًا البناء المتوازي للأشجار
والحساب المتوازي للتنبؤات من خلال المعلمة <code class="docutils literal notranslate"><span class="pre">n_jobs</span></code>.
إذا كانت <code class="docutils literal notranslate"><span class="pre">n_jobs=k</span></code>، فسيتم تقسيم الحسابات إلى
<code class="docutils literal notranslate"><span class="pre">k</span></code> وظائف، وتشغيلها على <code class="docutils literal notranslate"><span class="pre">k</span></code> نوى للآلة. إذا كانت <code class="docutils literal notranslate"><span class="pre">n_jobs=-1</span></code>،
فسيتم استخدام جميع النوى المتاحة على الآلة. لاحظ أنه بسبب
النفقات العامة للاتصال بين العمليات، قد لا يكون التسريع خطيًا
(أي أن استخدام <code class="docutils literal notranslate"><span class="pre">k</span></code> وظائف للأسف لن يكون أسرع <code class="docutils literal notranslate"><span class="pre">k</span></code> مرة).
لا يزال من الممكن تحقيق تسريع كبير عند بناء
عدد كبير من الأشجار، أو عندما يتطلب بناء شجرة واحدة قدرًا
لا بأس به من الوقت (على سبيل المثال، على مجموعات البيانات الكبيرة).</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/ensemble/plot_forest_iris.html#sphx-glr-auto-examples-ensemble-plot-forest-iris-py"><span class="std std-ref">رسم أسطح القرار لمجموعات الأشجار على مجموعة بيانات إيريس</span></a></p></li>
<li><p><span class="xref std std-ref">sphx_glr_auto_examples_ensemble_plot_forest_importances_faces.py</span></p></li>
<li><p><a class="reference internal" href="../auto_examples/miscellaneous/plot_multioutput_face_completion.html#sphx-glr-auto-examples-miscellaneous-plot-multioutput-face-completion-py"><span class="std std-ref">Face completion with a multi-output estimators</span></a></p></li>
</ul>
<p class="rubric">المراجع</p>
<div role="list" class="citation-list">
<div class="citation" id="b2001" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id39">B2001</a><span class="fn-bracket">]</span></span>
<ol class="upperalpha simple" start="12">
<li><p>Breiman, &quot;الغابات العشوائية&quot;, Machine Learning, 45(1), 5-32, 2001.</p></li>
</ol>
</div>
<div class="citation" id="b1998" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id37">B1998</a><span class="fn-bracket">]</span></span>
<ol class="upperalpha simple" start="12">
<li><p>Breiman, &quot;مُصنِّفات الأقواس&quot;, Annals of Statistics 1998.</p></li>
</ol>
</div>
</div>
<ul class="simple">
<li><p>P. Geurts, D. Ernst., and L. Wehenkel, &quot;أشجار
عشوائية للغاية&quot;, Machine Learning, 63(1), 3-42, 2006.</p></li>
</ul>
</section>
<section id="random-forest-feature-importance">
<span id="id43"></span><h3><span class="section-number">1.11.2.5. </span>تقييم أهمية الميزة<a class="headerlink" href="#random-forest-feature-importance" title="Link to this heading">#</a></h3>
<p>يمكن استخدام الرتبة النسبية (أي العمق) لميزة تُستخدم كعقدة قرار في
شجرة لتقييم الأهمية النسبية لتلك الميزة فيما يتعلق بـ
قابلية التنبؤ بالمتغير الهدف. تُساهم الميزات المُستخدمة في
أعلى الشجرة في قرار التنبؤ النهائي لـ
جزء أكبر من عينات الإدخال. <strong>الجزء المتوقع من
العينات</strong> التي تُساهم فيها يمكن استخدامه كتقدير لـ
<strong>الأهمية النسبية للميزات</strong>. في scikit-learn، يتم دمج جزء
العينات التي تُساهم فيها ميزة مع انخفاض النجاسة
من تقسيمها لإنشاء تقدير مُقيَّس للقدرة التنبؤية
لتلك الميزة.</p>
<p>عن طريق <strong>حساب متوسط</strong> تقديرات القدرة التنبؤية على عدة
أشجار عشوائية، يمكن للمرء <strong>تقليل تباين</strong> هذا التقدير واستخدامه لـ
اختيار الميزات. يُعرف هذا باسم متوسط الانخفاض في النجاسة، أو MDI.
راجع <a class="reference internal" href="#l2014" id="id44"><span>[L2014]</span></a> لمزيد من المعلومات حول MDI وتقييم أهمية
الميزات مع الغابات العشوائية.</p>
<div class="admonition warning">
<p class="admonition-title">تحذير</p>
<p>أهمية الميزات القائمة على النجاسة المحسوبة على النماذج القائمة على الأشجار تعاني
من عيبين يمكن أن يؤديا إلى استنتاجات مُضللة. أولاً، يتم
حسابها على إحصاءات مُشتقة من مجموعة بيانات التدريب، وبالتالي <strong>لا
تُخبرنا بالضرورة عن الميزات الأكثر أهمية لإجراء تنبؤات جيدة على
مجموعة بيانات مُخصصة للاختبار</strong>. ثانيًا، <strong>تُفضل
الميزات ذات العدد الكبير من العناصر</strong>، أي الميزات ذات العديد من القيم الفريدة.
<a class="reference internal" href="permutation_importance.html#permutation-importance"><span class="std std-ref">أهمية التبديل</span></a> هو بديل لأهمية الميزات القائمة على النجاسة
التي لا تعاني من هذه العيوب. يتم استكشاف هاتين الطريقتين لـ</p>
</div>
<p>الحصول على أهمية الميزات في:
<a class="reference internal" href="../auto_examples/inspection/plot_permutation_importance.html#sphx-glr-auto-examples-inspection-plot-permutation-importance-py"><span class="std std-ref">أهمية التبديل مقابل أهمية ميزة الغابة العشوائية (MDI)</span></a>.</p>
<p>يوضح المثال التالي تمثيلًا مُرمَّزًا بالألوان لـ
أهمية كل بكسل فردي لمهمة التعرف على الوجه باستخدام
نموذج <code class="xref py py-class docutils literal notranslate"><span class="pre">ExtraTreesClassifier</span></code>.</p>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/ensemble/plot_forest_importances_faces.html"><img alt="auto_examples/ensemble/images/sphx_glr_plot_forest_importances_faces_001.png" src="auto_examples/ensemble/images/sphx_glr_plot_forest_importances_faces_001.png" />
<aside class="system-message">
<p class="system-message-title">System Message: WARNING/2 (<span class="docutils literal">/project/workspace/doc/modules/ensemble.rst</span>, line 1152)</p>
<p>Cannot scale image!
  Could not get size from &quot;auto_examples/ensemble/images/sphx_glr_plot_forest_importances_faces_001.png&quot;:
  [Errno 2] No such file or directory: '/project/workspace/doc/auto_examples/ensemble/images/sphx_glr_plot_forest_importances_faces_001.png'</p>
</aside>
</a>
</figure>
<p>في الممارسة العملية، يتم تخزين هذه التقديرات كسمة تُسمى
<code class="docutils literal notranslate"><span class="pre">feature_importances_</span></code> على النموذج المُناسب. هذه مصفوفة ذات شكل
<code class="docutils literal notranslate"><span class="pre">(n_features,)</span></code> قيمها موجبة ومجموعها 1.0. كلما ارتفعت
القيمة، زادت أهمية مساهمة الميزة المُطابقة
لدالة التنبؤ.</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><span class="xref std std-ref">sphx_glr_auto_examples_ensemble_plot_forest_importances_faces.py</span></p></li>
<li><p><a class="reference internal" href="../auto_examples/ensemble/plot_forest_importances.html#sphx-glr-auto-examples-ensemble-plot-forest-importances-py"><span class="std std-ref">أهمية الميزات باستخدام غابة من الأشجار</span></a></p></li>
</ul>
<p class="rubric">المراجع</p>
<div role="list" class="citation-list">
<div class="citation" id="l2014" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id44">L2014</a><span class="fn-bracket">]</span></span>
<p>G. Louppe, <a class="reference external" href="https://arxiv.org/abs/1407.7502">&quot;فهم الغابات العشوائية: من النظرية إلى
الممارسة&quot;</a>،
أطروحة دكتوراه، جامعة لييج، 2014.</p>
</div>
</div>
</section>
<section id="random-trees-embedding">
<span id="id45"></span><h3><span class="section-number">1.11.2.6. </span>تضمين الأشجار العشوائية تمامًا<a class="headerlink" href="#random-trees-embedding" title="Link to this heading">#</a></h3>
<p><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomTreesEmbedding</span></code> يُطبق تحويلًا غير خاضع للإشراف لـ
البيانات. باستخدام غابة من الأشجار العشوائية تمامًا، <code class="xref py py-class docutils literal notranslate"><span class="pre">RandomTreesEmbedding</span></code>
يُرمِّز البيانات بواسطة مؤشرات الأوراق التي تنتهي بها نقطة البيانات. هذا
الفهرس يتم ترميزه بعد ذلك بطريقة واحد من K، مما يؤدي إلى ترميز ثنائي متفرق عالي
الأبعاد.
يمكن حساب هذا الترميز بكفاءة عالية ويمكن استخدامه كأساس
لمهام التعلم الأخرى.
يمكن التأثير على حجم وتفرق الكود عن طريق اختيار عدد
الأشجار والحد الأقصى للعمق لكل شجرة. لكل شجرة في المجموعة،
يحتوي الترميز على إدخال واحد من واحد. حجم الترميز هو على الأكثر <code class="docutils literal notranslate"><span class="pre">n_estimators</span> <span class="pre">*</span> <span class="pre">2</span>
<span class="pre">**</span> <span class="pre">max_depth</span></code>، الحد الأقصى لعدد الأوراق في الغابة.</p>
<p>نظرًا لأن نقاط البيانات المجاورة من المرجح أن تقع داخل نفس ورقة
الشجرة، فإن التحويل يُجري تقديرًا ضمنيًا غير معلمي
للكثافة.</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/ensemble/plot_random_forest_embedding.html#sphx-glr-auto-examples-ensemble-plot-random-forest-embedding-py"><span class="std std-ref">تحويل ميزة التجزئة باستخدام الأشجار العشوائية تمامًا</span></a></p></li>
<li><p><a class="reference internal" href="../auto_examples/manifold/plot_lle_digits.html#sphx-glr-auto-examples-manifold-plot-lle-digits-py"><span class="std std-ref">Manifold learning on handwritten digits: Locally Linear Embedding, Isomap...</span></a> تُقارن تقنيات
تقليل الأبعاد غير الخطية على الأرقام المكتوبة بخط اليد.</p></li>
<li><p><a class="reference internal" href="../auto_examples/ensemble/plot_feature_transformation.html#sphx-glr-auto-examples-ensemble-plot-feature-transformation-py"><span class="std std-ref">تحويل الميزات باستخدام مجموعات الأشجار</span></a> تُقارن
تحويلات الميزات القائمة على الأشجار الخاضعة للإشراف وغير الخاضعة للإشراف.</p></li>
</ul>
<div class="admonition seealso">
<p class="admonition-title">شاهد أيضا</p>
<p>يمكن أن تكون تقنيات <span class="xref std std-ref">manifold</span> مفيدة أيضًا لاشتقاق تمثيلات غير خطية
لمساحة الميزات، كما تُركز هذه الأساليب أيضًا على
تقليل الأبعاد.</p>
</div>
</section>
<section id="tree-ensemble-warm-start">
<span id="id46"></span><h3><span class="section-number">1.11.2.7. </span>ملاءمة أشجار إضافية<a class="headerlink" href="#tree-ensemble-warm-start" title="Link to this heading">#</a></h3>
<p>RandomForest و Extra-Trees و مُقدِّرات <code class="xref py py-class docutils literal notranslate"><span class="pre">RandomTreesEmbedding</span></code> تدعم جميعها
<code class="docutils literal notranslate"><span class="pre">warm_start=True</span></code> الذي يسمح لك بإضافة المزيد من الأشجار إلى نموذج مُناسب
بالفعل.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>  <span class="c1"># ملاءمة مع 10 أشجار</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">len</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">estimators_</span><span class="p">)</span>
<span class="go">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># تعيين warm_start وزيادة عدد المُقدِّرات</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">warm_start</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="c1"># ملاءمة 10 أشجار إضافية</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">len</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">estimators_</span><span class="p">)</span>
<span class="go">20</span>
</pre></div>
</div>
<p>عندما يتم تعيين <code class="docutils literal notranslate"><span class="pre">random_state</span></code> أيضًا، يتم أيضًا الحفاظ على الحالة العشوائية الداخلية
بين استدعاءات <code class="docutils literal notranslate"><span class="pre">fit</span></code>. هذا يعني أن تدريب نموذج مرة واحدة مع <code class="docutils literal notranslate"><span class="pre">n</span></code> مُقدِّر هو
نفس بناء النموذج بشكل متكرر عبر استدعاءات <code class="docutils literal notranslate"><span class="pre">fit</span></code> متعددة، حيث
العدد النهائي للمُقدِّرات يساوي <code class="docutils literal notranslate"><span class="pre">n</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>  <span class="c1"># تعيين `n_estimators` إلى 10 + 10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>  <span class="c1"># ملاءمة `estimators_` ستكون نفس `clf` أعلاه</span>
</pre></div>
</div>
<p>لاحظ أن هذا يختلف عن السلوك المعتاد لـ <a class="reference internal" href="../glossary.html#term-random_state"><span class="xref std std-term">random_state</span></a> من حيث أنه <em>لا</em> يؤدي
إلى نفس النتيجة عبر استدعاءات مختلفة.</p>
</section>
</section>
<section id="bagging">
<span id="id47"></span><h2><span class="section-number">1.11.3. </span>مُقدِّر التعريف التجميعي<a class="headerlink" href="#bagging" title="Link to this heading">#</a></h2>
<p>في خوارزميات المجموعات، تُشكِّل أساليب التجميع فئة من الخوارزميات التي تبني
العديد من مثيلات مُقدِّر الصندوق الأسود على مجموعات فرعية عشوائية من
مجموعة التدريب الأصلية ثم تجمع تنبؤاتها الفردية لتشكيل
تنبؤ نهائي. تُستخدم هذه الأساليب كطريقة لتقليل تباين
مُقدِّر أساسي (على سبيل المثال، شجرة قرار)، عن طريق إدخال العشوائية في
إجراء بنائه ثم صنع مجموعة منه. في كثير من الحالات،
تُشكِّل أساليب التجميع طريقة بسيطة للغاية للتحسين فيما يتعلق بـ
نموذج واحد، دون جعل من الضروري تكييف خوارزمية
الأساس الأساسية. نظرًا لأنها تُوفر طريقة لتقليل التجاوز، فإن أساليب التجميع تعمل
بشكل أفضل مع النماذج القوية والمعقدة (على سبيل المثال، أشجار القرار المُطوَّرة بالكامل)،
على عكس أساليب التعزيز التي تعمل عادةً بشكل أفضل مع النماذج الضعيفة (على سبيل المثال،
أشجار القرار الضحلة).</p>
<p>تأتي أساليب التجميع في العديد من النكهات ولكنها تختلف في الغالب عن بعضها البعض بالطريقة
التي ترسم بها مجموعات فرعية عشوائية من مجموعة التدريب:</p>
<ul class="simple">
<li><p>عندما يتم رسم مجموعات فرعية عشوائية من مجموعة البيانات كمجموعات فرعية عشوائية من
العينات، تُعرف هذه الخوارزمية باسم اللصق <a class="reference internal" href="#b1999" id="id48"><span>[B1999]</span></a>.</p></li>
<li><p>عندما يتم رسم العينات مع الاستبدال، تُعرف الطريقة باسم
التجميع <a class="reference internal" href="#b1996" id="id49"><span>[B1996]</span></a>.</p></li>
<li><p>عندما يتم رسم مجموعات فرعية عشوائية من مجموعة البيانات كمجموعات فرعية عشوائية من
الميزات، تُعرف الطريقة باسم الفضاءات الفرعية العشوائية <a class="reference internal" href="#h1998" id="id50"><span>[H1998]</span></a>.</p></li>
<li><p>أخيرًا، عندما يتم بناء المُقدِّرات الأساسية على مجموعات فرعية من كل من العينات و
الميزات، تُعرف الطريقة باسم الرقع العشوائية <a class="reference internal" href="#lg2012" id="id51"><span>[LG2012]</span></a>.</p></li>
</ul>
<p>في scikit-learn، يتم تقديم أساليب التجميع كوحدة
مُقدِّر التعريف <code class="xref py py-class docutils literal notranslate"><span class="pre">BaggingClassifier</span></code> (أو <code class="xref py py-class docutils literal notranslate"><span class="pre">BaggingRegressor</span></code>)،
مع أخذ مُقدِّر مُحدد من قبل المستخدم كمدخلات جنبًا إلى جنب مع معلمات
تُحدد إستراتيجية رسم مجموعات فرعية عشوائية. على وجه الخصوص، <code class="docutils literal notranslate"><span class="pre">max_samples</span></code>
و <code class="docutils literal notranslate"><span class="pre">max_features</span></code> يتحكمان في حجم المجموعات الفرعية (من حيث العينات و
الميزات)، بينما يتحكم <code class="docutils literal notranslate"><span class="pre">bootstrap</span></code> و <code class="docutils literal notranslate"><span class="pre">bootstrap_features</span></code> فيما إذا
كانت العينات والميزات مرسومة مع أو بدون استبدال. عند استخدام مجموعة فرعية
من العينات المتاحة، يمكن تقدير دقة التعميم مع
العينات خارج الحقيبة عن طريق تعيين <code class="docutils literal notranslate"><span class="pre">oob_score=True</span></code>. على سبيل المثال،
يوضح المقتطف أدناه كيفية إنشاء مجموعة تجميع من
مُقدِّرات <a class="reference internal" href="generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier" title="sklearn.neighbors.KNeighborsClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">KNeighborsClassifier</span></code></a>، كل منها مبني على مجموعات فرعية
عشوائية من 50% من العينات و 50% من الميزات.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">BaggingClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bagging</span> <span class="o">=</span> <span class="n">BaggingClassifier</span><span class="p">(</span><span class="n">KNeighborsClassifier</span><span class="p">(),</span>
<span class="gp">... </span>                            <span class="n">max_samples</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/ensemble/plot_bias_variance.html#sphx-glr-auto-examples-ensemble-plot-bias-variance-py"><span class="std std-ref">مقارنة بين المُقدر الفردي والتجميع: تحليل الانحياز والتشتت</span></a></p></li>
</ul>
<p class="rubric">المراجع</p>
<div role="list" class="citation-list">
<div class="citation" id="b1999" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id48">B1999</a><span class="fn-bracket">]</span></span>
<p>L. Breiman, &quot;لصق أصوات صغيرة للتصنيف في قواعد بيانات
كبيرة وعلى الإنترنت&quot;, Machine Learning, 36(1), 85-103, 1999.</p>
</div>
<div class="citation" id="b1996" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id49">B1996</a><span class="fn-bracket">]</span></span>
<p>L. Breiman, &quot;مُتنبِّئات التجميع&quot;, Machine Learning, 24(2),
123-140, 1996.</p>
</div>
<div class="citation" id="h1998" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id50">H1998</a><span class="fn-bracket">]</span></span>
<p>T. Ho, &quot;أسلوب الفضاء الفرعي العشوائي لبناء غابات
القرار&quot;, Pattern Analysis and Machine Intelligence, 20(8), 832-844, 1998.</p>
</div>
<div class="citation" id="lg2012" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id51">LG2012</a><span class="fn-bracket">]</span></span>
<p>G. Louppe and P. Geurts, &quot;المجموعات على الرقع العشوائية&quot;,
Machine Learning and Knowledge Discovery in Databases, 346-361, 2012.</p>
</div>
</div>
</section>
<section id="voting-classifier">
<span id="id52"></span><h2><span class="section-number">1.11.4. </span>مُصنف التصويت<a class="headerlink" href="#voting-classifier" title="Link to this heading">#</a></h2>
<p>الفكرة وراء <code class="xref py py-class docutils literal notranslate"><span class="pre">VotingClassifier</span></code> هي دمج
مُصنِّفات التعلم الآلي المختلفة من الناحية النظرية واستخدام تصويت الأغلبية
أو متوسط الاحتمالات المتوقعة (التصويت الناعم) للتنبؤ بتصنيفات
الفئات.
يمكن أن يكون هذا المُصنف مفيدًا لمجموعة من النماذج ذات الأداء الجيد على حد سواء
من أجل موازنة نقاط ضعفها الفردية.</p>
<section id="id53">
<h3><span class="section-number">1.11.4.1. </span>تصنيفات فئات الأغلبية (التصويت بالأغلبية / الصلب)<a class="headerlink" href="#id53" title="Link to this heading">#</a></h3>
<p>في التصويت بالأغلبية، يكون تصنيف الفئة المتوقع لعينة مُعينة
هو تصنيف الفئة الذي يُمثِّل أغلبية (الوضع) تصنيفات الفئات
المتوقعة بواسطة كل مُصنف فردي.</p>
<p>على سبيل المثال، إذا كان التنبؤ لعينة مُعينة هو</p>
<ul class="simple">
<li><p>المُصنف 1 -&gt; الفئة 1</p></li>
<li><p>المُصنف 2 -&gt; الفئة 1</p></li>
<li><p>المُصنف 3 -&gt; الفئة 2</p></li>
</ul>
<p>فإن VotingClassifier (مع <code class="docutils literal notranslate"><span class="pre">voting='hard'</span></code>) سيُصنف العينة
على أنها &quot;الفئة 1&quot; بناءً على تصنيف الفئة الأكثر شيوعًا.</p>
<p>في حالات التعادل، سيختار <code class="xref py py-class docutils literal notranslate"><span class="pre">VotingClassifier</span></code> الفئة
بناءً على ترتيب الفرز التصاعدي. على سبيل المثال، في السيناريو التالي</p>
<ul class="simple">
<li><p>المُصنف 1 -&gt; الفئة 2</p></li>
<li><p>المُصنف 2 -&gt; الفئة 1</p></li>
</ul>
<p>سيتم تعيين تصنيف الفئة 1 للعينة.</p>
</section>
<section id="id54">
<h3><span class="section-number">1.11.4.2. </span>الاستخدام<a class="headerlink" href="#id54" title="Link to this heading">#</a></h3>
<p>يوضح المثال التالي كيفية ملاءمة مُصنف قاعدة الأغلبية:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">VotingClassifier</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">],</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">clf1</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf2</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf3</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">eclf</span> <span class="o">=</span> <span class="n">VotingClassifier</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">estimators</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="n">clf1</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;rf&#39;</span><span class="p">,</span> <span class="n">clf2</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;gnb&#39;</span><span class="p">,</span> <span class="n">clf3</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">voting</span><span class="o">=</span><span class="s1">&#39;hard&#39;</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">clf</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="n">clf1</span><span class="p">,</span> <span class="n">clf2</span><span class="p">,</span> <span class="n">clf3</span><span class="p">,</span> <span class="n">eclf</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Logistic Regression&#39;</span><span class="p">,</span> <span class="s1">&#39;Random Forest&#39;</span><span class="p">,</span> <span class="s1">&#39;naive Bayes&#39;</span><span class="p">,</span> <span class="s1">&#39;Ensemble&#39;</span><span class="p">]):</span>
<span class="gp">... </span>    <span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy: </span><span class="si">%0.2f</span><span class="s2"> (+/- </span><span class="si">%0.2f</span><span class="s2">) [</span><span class="si">%s</span><span class="s2">]&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">scores</span><span class="o">.</span><span class="n">std</span><span class="p">(),</span> <span class="n">label</span><span class="p">))</span>
<span class="go">Accuracy: 0.95 (+/- 0.04) [Logistic Regression]</span>
<span class="go">Accuracy: 0.94 (+/- 0.04) [Random Forest]</span>
<span class="go">Accuracy: 0.91 (+/- 0.04) [naive Bayes]</span>
<span class="go">Accuracy: 0.95 (+/- 0.04) [Ensemble]</span>
</pre></div>
</div>
</section>
<section id="id55">
<h3><span class="section-number">1.11.4.3. </span>متوسط الاحتمالات الموزونة (التصويت الناعم)<a class="headerlink" href="#id55" title="Link to this heading">#</a></h3>
<p>على عكس التصويت بالأغلبية (التصويت الصلب)، يُعيد التصويت الناعم
تصنيف الفئة كـ argmax لمجموع الاحتمالات المتوقعة.</p>
<p>يمكن تعيين أوزان مُحددة لكل مُصنف عبر معلمة <code class="docutils literal notranslate"><span class="pre">weights</span></code>.
عندما يتم توفير الأوزان، يتم جمع احتمالات الفئة المتوقعة
لكل مُصنف، وضربها في وزن المُصنف،
وحساب متوسطها. ثم يتم اشتقاق تصنيف الفئة النهائي من تصنيف
الفئة ذات أعلى احتمال متوسط.</p>
<p>لتوضيح ذلك بمثال بسيط، لنفترض أن لدينا 3
مُصنِّفات ومشاكل تصنيف من 3 فئات حيث نُعيِّن
أوزانًا متساوية لجميع المُصنِّفات: w1 = 1، w2 = 1، w3 = 1.</p>
<p>ثم يتم حساب متوسط الاحتمالات الموزونة لعينة
على النحو التالي:</p>
<p>هنا، تصنيف الفئة المتوقع هو 2، نظرًا لأنه يحتوي على
أعلى احتمال متوسط.</p>
<p>يوضح المثال التالي كيف يمكن أن تتغير مناطق القرار
عند استخدام <code class="xref py py-class docutils literal notranslate"><span class="pre">VotingClassifier</span></code> ناعم بناءً على آلة متجه
دعم خطية وشجرة قرار ومُصنف أقرب جار K:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">product</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">VotingClassifier</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># تحميل بعض بيانات المثال</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">[:,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># تدريب المُصنِّفات</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf1</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf2</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf3</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="n">probability</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eclf</span> <span class="o">=</span> <span class="n">VotingClassifier</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;dt&#39;</span><span class="p">,</span> <span class="n">clf1</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;knn&#39;</span><span class="p">,</span> <span class="n">clf2</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;svc&#39;</span><span class="p">,</span> <span class="n">clf3</span><span class="p">)],</span>
<span class="gp">... </span>                        <span class="n">voting</span><span class="o">=</span><span class="s1">&#39;soft&#39;</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">clf1</span> <span class="o">=</span> <span class="n">clf1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf2</span> <span class="o">=</span> <span class="n">clf2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf3</span> <span class="o">=</span> <span class="n">clf3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eclf</span> <span class="o">=</span> <span class="n">eclf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/ensemble/plot_voting_decision_regions.html"><img alt="../_images/sphx_glr_plot_voting_decision_regions_001.png" src="../_images/sphx_glr_plot_voting_decision_regions_001.png" style="width: 750.0px; height: 600.0px;" />
</a>
</figure>
</section>
<section id="id56">
<h3><span class="section-number">1.11.4.4. </span>الاستخدام<a class="headerlink" href="#id56" title="Link to this heading">#</a></h3>
<p>من أجل التنبؤ بتصنيفات الفئات بناءً على
احتمالات الفئة المتوقعة (يجب أن تدعم مُقدِّرات scikit-learn في VotingClassifier
أسلوب <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code>):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">eclf</span> <span class="o">=</span> <span class="n">VotingClassifier</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">estimators</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="n">clf1</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;rf&#39;</span><span class="p">,</span> <span class="n">clf2</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;gnb&#39;</span><span class="p">,</span> <span class="n">clf3</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">voting</span><span class="o">=</span><span class="s1">&#39;soft&#39;</span>
<span class="gp">... </span><span class="p">)</span>
</pre></div>
</div>
<p>اختياريًا، يمكن توفير أوزان للمُصنِّفات الفردية:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">eclf</span> <span class="o">=</span> <span class="n">VotingClassifier</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">estimators</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="n">clf1</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;rf&#39;</span><span class="p">,</span> <span class="n">clf2</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;gnb&#39;</span><span class="p">,</span> <span class="n">clf3</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">voting</span><span class="o">=</span><span class="s1">&#39;soft&#39;</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
<span class="gp">... </span><span class="p">)</span>
</pre></div>
</div>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="استخدام-votingclassifier-مع-gridsearchcv">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">استخدام <code class="xref py py-class docutils literal notranslate"><span class="pre">VotingClassifier</span></code> مع <a class="reference internal" href="generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" title="sklearn.model_selection.GridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">GridSearchCV</span></code></a><a class="headerlink" href="#استخدام-votingclassifier-مع-gridsearchcv" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">يمكن أيضًا استخدام <code class="xref py py-class docutils literal notranslate"><span class="pre">VotingClassifier</span></code> مع
<a class="reference internal" href="generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" title="sklearn.model_selection.GridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">GridSearchCV</span></code></a> من أجل ضبط
المعلمات الفائقة للمُقدِّرات الفردية:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf1</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf2</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf3</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eclf</span> <span class="o">=</span> <span class="n">VotingClassifier</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">estimators</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="n">clf1</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;rf&#39;</span><span class="p">,</span> <span class="n">clf2</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;gnb&#39;</span><span class="p">,</span> <span class="n">clf3</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">voting</span><span class="o">=</span><span class="s1">&#39;soft&#39;</span>
<span class="gp">... </span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;lr__C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">],</span> <span class="s1">&#39;rf__n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">200</span><span class="p">]}</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">eclf</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">params</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grid</span> <span class="o">=</span> <span class="n">grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details></section>
</section>
<section id="voting-regressor">
<span id="id57"></span><h2><span class="section-number">1.11.5. </span>مُنحدِر التصويت<a class="headerlink" href="#voting-regressor" title="Link to this heading">#</a></h2>
<p>الفكرة وراء <code class="xref py py-class docutils literal notranslate"><span class="pre">VotingRegressor</span></code> هي دمج مُنحدرات
التعلم الآلي المختلفة من الناحية النظرية وإعادة القيم المتوقعة
المتوسطة.
يمكن أن يكون هذا المُنحدِر مفيدًا لمجموعة من النماذج ذات الأداء الجيد
على حد سواء من أجل موازنة نقاط ضعفها الفردية.</p>
<section id="id58">
<h3><span class="section-number">1.11.5.1. </span>الاستخدام<a class="headerlink" href="#id58" title="Link to this heading">#</a></h3>
<p>يوضح المثال التالي كيفية ملاءمة VotingRegressor:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">VotingRegressor</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># تحميل بعض بيانات المثال</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># تدريب المُصنِّفات</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg1</span> <span class="o">=</span> <span class="n">GradientBoostingRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg2</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg3</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ereg</span> <span class="o">=</span> <span class="n">VotingRegressor</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;gb&#39;</span><span class="p">,</span> <span class="n">reg1</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;rf&#39;</span><span class="p">,</span> <span class="n">reg2</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="n">reg3</span><span class="p">)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ereg</span> <span class="o">=</span> <span class="n">ereg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/ensemble/plot_voting_regressor.html"><img alt="../_images/sphx_glr_plot_voting_regressor_001.png" src="../_images/sphx_glr_plot_voting_regressor_001.png" style="width: 480.0px; height: 360.0px;" />
</a>
</figure>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/ensemble/plot_voting_regressor.html#sphx-glr-auto-examples-ensemble-plot-voting-regressor-py"><span class="std std-ref">رسم تنبؤات الانحدار الفردية والتصويتية</span></a></p></li>
</ul>
</section>
</section>
<section id="stacking">
<span id="id59"></span><h2><span class="section-number">1.11.6. </span>التعميم المُكدَّس<a class="headerlink" href="#stacking" title="Link to this heading">#</a></h2>
<p>التعميم المُكدَّس هو أسلوب لدمج المُقدِّرات لتقليل
انحيازاتها <a class="reference internal" href="#w1992" id="id60"><span>[W1992]</span></a> <a class="reference internal" href="#htf" id="id61"><span>[HTF]</span></a>. بشكل أكثر تحديدًا، يتم تجميع تنبؤات كل مُقدِّر
فردي معًا واستخدامها كمدخلات لمُقدِّر نهائي لـ
حساب التنبؤ. يتم تدريب هذا المُقدِّر النهائي من خلال
التحقق المتبادل.</p>
<p>يُوفر <code class="xref py py-class docutils literal notranslate"><span class="pre">StackingClassifier</span></code> و <code class="xref py py-class docutils literal notranslate"><span class="pre">StackingRegressor</span></code> هذه
الإستراتيجيات التي يمكن تطبيقها على مشاكل التصنيف والانحدار.</p>
<p>تقابل معلمة <code class="docutils literal notranslate"><span class="pre">estimators</span></code> قائمة المُقدِّرات التي
يتم تجميعها معًا بالتوازي على بيانات الإدخال. يجب إعطاؤها كـ
قائمة من الأسماء والمُقدِّرات:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">RidgeCV</span><span class="p">,</span> <span class="n">LassoCV</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimators</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">&#39;ridge&#39;</span><span class="p">,</span> <span class="n">RidgeCV</span><span class="p">()),</span>
<span class="gp">... </span>              <span class="p">(</span><span class="s1">&#39;lasso&#39;</span><span class="p">,</span> <span class="n">LassoCV</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)),</span>
<span class="gp">... </span>              <span class="p">(</span><span class="s1">&#39;knr&#39;</span><span class="p">,</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
<span class="gp">... </span>                                          <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">))]</span>
</pre></div>
</div>
<p>سيستخدم <code class="docutils literal notranslate"><span class="pre">final_estimator</span></code> تنبؤات <code class="docutils literal notranslate"><span class="pre">estimators</span></code> كمدخلات.
يجب أن يكون مُصنفًا أو مُنحدِرًا عند استخدام <code class="xref py py-class docutils literal notranslate"><span class="pre">StackingClassifier</span></code>
أو <code class="xref py py-class docutils literal notranslate"><span class="pre">StackingRegressor</span></code>، على التوالي:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">StackingRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">final_estimator</span> <span class="o">=</span> <span class="n">GradientBoostingRegressor</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">subsample</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span> <span class="o">=</span> <span class="n">StackingRegressor</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">estimators</span><span class="o">=</span><span class="n">estimators</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">final_estimator</span><span class="o">=</span><span class="n">final_estimator</span><span class="p">)</span>
</pre></div>
</div>
<p>لتدريب <code class="docutils literal notranslate"><span class="pre">estimators</span></code> و <code class="docutils literal notranslate"><span class="pre">final_estimator</span></code>، يجب استدعاء أسلوب <code class="docutils literal notranslate"><span class="pre">fit</span></code>
على بيانات التدريب:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
<span class="gp">... </span>                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="go">StackingRegressor(...)</span>
</pre></div>
</div>
<p>أثناء التدريب، يتم ملاءمة <code class="docutils literal notranslate"><span class="pre">estimators</span></code> على بيانات التدريب الكاملة
<code class="docutils literal notranslate"><span class="pre">X_train</span></code>. سيتم استخدامها عند استدعاء <code class="docutils literal notranslate"><span class="pre">predict</span></code> أو <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code>. لـ
التعميم وتجنب التجاوز، يتم تدريب <code class="docutils literal notranslate"><span class="pre">final_estimator</span></code> على
عينات خارجية باستخدام <a class="reference internal" href="generated/sklearn.model_selection.cross_val_predict.html#sklearn.model_selection.cross_val_predict" title="sklearn.model_selection.cross_val_predict"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.model_selection.cross_val_predict</span></code></a> داخليًا.</p>
<p>بالنسبة لـ <code class="xref py py-class docutils literal notranslate"><span class="pre">StackingClassifier</span></code>، لاحظ أن ناتج <code class="docutils literal notranslate"><span class="pre">estimators</span></code>
يتم التحكم فيه بواسطة المعلمة <code class="docutils literal notranslate"><span class="pre">stack_method</span></code> ويتم استدعاؤه بواسطة كل مُقدِّر.
هذه المعلمة إما سلسلة، وهي أسماء أساليب المُقدِّر، أو <code class="docutils literal notranslate"><span class="pre">'auto'</span></code>
التي ستُحدد تلقائيًا أسلوبًا مُتاحًا اعتمادًا على
التوفر، ويتم اختبارها بترتيب التفضيل: <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> و
<code class="docutils literal notranslate"><span class="pre">decision_function</span></code> و <code class="docutils literal notranslate"><span class="pre">predict</span></code>.</p>
<p>يمكن استخدام <code class="xref py py-class docutils literal notranslate"><span class="pre">StackingRegressor</span></code> و <code class="xref py py-class docutils literal notranslate"><span class="pre">StackingClassifier</span></code> كـ
أي مُنحدِر أو مُصنف آخر، يُظهِر أسلوب <code class="docutils literal notranslate"><span class="pre">predict</span></code> أو <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> أو
<code class="docutils literal notranslate"><span class="pre">decision_function</span></code>، على سبيل المثال:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;R2 score: </span><span class="si">{:.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)))</span>
<span class="go">R2 score: 0.53</span>
</pre></div>
</div>
<p>لاحظ أنه من الممكن أيضًا الحصول على ناتج <code class="docutils literal notranslate"><span class="pre">estimators</span></code>
المُكدَّس باستخدام أسلوب <code class="docutils literal notranslate"><span class="pre">transform</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="go">array([[142..., 138..., 146...],</span>
<span class="go">       [179..., 182..., 151...],</span>
<span class="go">       [139..., 132..., 158...],</span>
<span class="go">       [286..., 292..., 225...],</span>
<span class="go">       [126..., 124..., 164...]])</span>
</pre></div>
</div>
<p>عمليًا، يتنبأ مُتنبئ التكديس بنفس جودة أفضل مُتنبئ للطبقة
الأساسية، بل ويتفوق عليه في بعض الأحيان من خلال الجمع بين نقاط القوة المختلفة
لهؤلاء المُتنبئين. ومع ذلك، فإن تدريب مُتنبئ التكديس
مكلف من الناحية الحسابية.</p>
<div class="admonition note">
<p class="admonition-title">ملاحظة</p>
<p>بالنسبة لـ <code class="xref py py-class docutils literal notranslate"><span class="pre">StackingClassifier</span></code>، عند استخدام <code class="docutils literal notranslate"><span class="pre">stack_method_='predict_proba'</span></code>،
يتم إسقاط العمود الأول عندما تكون المشكلة مشكلة تصنيف
ثنائية. في الواقع، كلا عمودي الاحتمال المتوقعين بواسطة كل مُقدِّر
متساويان تمامًا.</p>
</div>
<div class="admonition note">
<p class="admonition-title">ملاحظة</p>
<p>يمكن تحقيق طبقات تكديس متعددة عن طريق تعيين <code class="docutils literal notranslate"><span class="pre">final_estimator</span></code> إلى
<code class="xref py py-class docutils literal notranslate"><span class="pre">StackingClassifier</span></code> أو <code class="xref py py-class docutils literal notranslate"><span class="pre">StackingRegressor</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">final_layer_rfr</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_leaf_nodes</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">final_layer_gbr</span> <span class="o">=</span> <span class="n">GradientBoostingRegressor</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_leaf_nodes</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">final_layer</span> <span class="o">=</span> <span class="n">StackingRegressor</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">estimators</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;rf&#39;</span><span class="p">,</span> <span class="n">final_layer_rfr</span><span class="p">),</span>
<span class="gp">... </span>                <span class="p">(</span><span class="s1">&#39;gbrt&#39;</span><span class="p">,</span> <span class="n">final_layer_gbr</span><span class="p">)],</span>
<span class="gp">... </span>    <span class="n">final_estimator</span><span class="o">=</span><span class="n">RidgeCV</span><span class="p">()</span>
<span class="gp">... </span>    <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">multi_layer_regressor</span> <span class="o">=</span> <span class="n">StackingRegressor</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">estimators</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;ridge&#39;</span><span class="p">,</span> <span class="n">RidgeCV</span><span class="p">()),</span>
<span class="gp">... </span>                <span class="p">(</span><span class="s1">&#39;lasso&#39;</span><span class="p">,</span> <span class="n">LassoCV</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)),</span>
<span class="gp">... </span>                <span class="p">(</span><span class="s1">&#39;knr&#39;</span><span class="p">,</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
<span class="gp">... </span>                                            <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">))],</span>
<span class="gp">... </span>    <span class="n">final_estimator</span><span class="o">=</span><span class="n">final_layer</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">multi_layer_regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="go">StackingRegressor(...)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;R2 score: </span><span class="si">{:.2f}</span><span class="s1">&#39;</span>
<span class="gp">... </span>      <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">multi_layer_regressor</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
<span class="go">R2 score: 0.53</span>
</pre></div>
</div>
</div>
<p class="rubric">المراجع</p>
<div role="list" class="citation-list">
<div class="citation" id="w1992" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id60">W1992</a><span class="fn-bracket">]</span></span>
<p>Wolpert, David H. &quot;التعميم المُكدَّس.&quot; Neural networks 5.2
(1992): 241-259.</p>
</div>
</div>
</section>
<section id="adaboost">
<span id="id62"></span><h2><span class="section-number">1.11.7. </span>AdaBoost<a class="headerlink" href="#adaboost" title="Link to this heading">#</a></h2>
<p>تتضمن الوحدة <a class="reference internal" href="../api/sklearn.ensemble.html#module-sklearn.ensemble" title="sklearn.ensemble"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.ensemble</span></code></a> خوارزمية التعزيز الشهيرة
AdaBoost، التي تم تقديمها في عام 1995 بواسطة Freund و Schapire <a class="reference internal" href="#fs1995" id="id63"><span>[FS1995]</span></a>.</p>
<p>المبدأ الأساسي لـ AdaBoost هو ملاءمة تسلسل من المُتعلمين الضعفاء (أي
النماذج التي هي أفضل قليلاً فقط من التخمين العشوائي، مثل أشجار القرار
الصغيرة) على إصدارات مُعدلة بشكل متكرر من البيانات. ثم يتم دمج
التنبؤات من جميعها من خلال تصويت الأغلبية الموزون (أو المجموع) لـ
إنتاج التنبؤ النهائي. تتكون تعديلات البيانات في كل ما يسمى بتكرار
التعزيز من تطبيق أوزان <span class="math notranslate nohighlight">\(w_1\)</span> و <span class="math notranslate nohighlight">\(w_2\)</span> و ... و <span class="math notranslate nohighlight">\(w_N\)</span>
على كل من عينات التدريب. في البداية، يتم تعيين جميع هذه الأوزان إلى
<span class="math notranslate nohighlight">\(w_i = 1/N\)</span>، بحيث تُدرِّب الخطوة الأولى ببساطة مُتعلمًا ضعيفًا على
البيانات الأصلية. لكل تكرار لاحق، يتم
تعديل أوزان العينة بشكل فردي ويتم إعادة تطبيق خوارزمية التعلم على البيانات
المُعاد وزنها. في خطوة مُعينة، عينات التدريب التي تم التنبؤ بها بشكل غير صحيح
بواسطة النموذج المُعزز المُستحث في الخطوة السابقة تزداد أوزانها،
بينما تتناقص الأوزان بالنسبة لتلك التي تم التنبؤ بها بشكل صحيح. مع
استمرار التكرارات، تتلقى الأمثلة التي يصعب التنبؤ بها
تأثيرًا متزايدًا باستمرار. وبالتالي، يُجبر كل مُتعلم ضعيف لاحق على
التركيز على الأمثلة التي فاتها المُتعلمون السابقون في التسلسل
<a class="reference internal" href="#htf" id="id64"><span>[HTF]</span></a>.</p>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/ensemble/plot_adaboost_multiclass.html"><img alt="../_images/sphx_glr_plot_adaboost_multiclass_001.png" src="../_images/sphx_glr_plot_adaboost_multiclass_001.png" style="width: 480.0px; height: 360.0px;" />
</a>
</figure>
<p>يمكن استخدام AdaBoost لكل من مشاكل التصنيف والانحدار:</p>
<ul class="simple">
<li><p>للتصنيف متعدد الفئات، <code class="xref py py-class docutils literal notranslate"><span class="pre">AdaBoostClassifier</span></code> يُطبق
AdaBoost.SAMME <a class="reference internal" href="#zzrh2009" id="id65"><span>[ZZRH2009]</span></a>.</p></li>
<li><p>للانحدار، <code class="xref py py-class docutils literal notranslate"><span class="pre">AdaBoostRegressor</span></code> يُطبق AdaBoost.R2 <a class="reference internal" href="#d1997" id="id66"><span>[D1997]</span></a>.</p></li>
</ul>
<section id="id67">
<h3><span class="section-number">1.11.7.1. </span>الاستخدام<a class="headerlink" href="#id67" title="Link to this heading">#</a></h3>
<p>يوضح المثال التالي كيفية ملاءمة مُصنف AdaBoost مع 100 مُتعلم
ضعيف:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;SAMME&quot;</span><span class="p">,)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="go">0.9...</span>
</pre></div>
</div>
<p>يتم التحكم في عدد المُتعلمين الضعفاء بواسطة المعلمة <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code>.
تتحكم معلمة <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> في مساهمة المُتعلمين الضعفاء في
المجموعة النهائية. افتراضيًا، المُتعلمون الضعفاء هم جذوع القرار. يمكن تحديد
مُتعلمين ضعفاء مُختلفين من خلال المعلمة <code class="docutils literal notranslate"><span class="pre">estimator</span></code>.
المعلمات الرئيسية التي يجب ضبطها للحصول على نتائج جيدة هي <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code> و
تعقيد المُقدِّرات الأساسية (على سبيل المثال، عمقها <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> أو
الحد الأدنى لعدد العينات المطلوب للنظر في تقسيم <code class="docutils literal notranslate"><span class="pre">min_samples_split</span></code>).</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/ensemble/plot_adaboost_multiclass.html#sphx-glr-auto-examples-ensemble-plot-adaboost-multiclass-py"><span class="std std-ref">شجرة قرارات معززة متعددة الفئات</span></a> يُظهر أداء
AdaBoost على مشكلة متعددة الفئات.</p></li>
<li><p><a class="reference internal" href="../auto_examples/ensemble/plot_adaboost_twoclass.html#sphx-glr-auto-examples-ensemble-plot-adaboost-twoclass-py"><span class="std std-ref">تصنيف ثنائي باستخدام AdaBoost</span></a> يُظهر حدود القرار
وقيم دالة القرار لمشكلة ثنائية الفئات غير قابلة للفصل خطيًا
باستخدام AdaBoost-SAMME.</p></li>
<li><p><a class="reference internal" href="../auto_examples/ensemble/plot_adaboost_regression.html#sphx-glr-auto-examples-ensemble-plot-adaboost-regression-py"><span class="std std-ref">انحدار شجرة القرار مع AdaBoost</span></a> يُوضح الانحدار
مع خوارزمية AdaBoost.R2.</p></li>
</ul>
<p class="rubric">المراجع</p>
<div role="list" class="citation-list">
<div class="citation" id="fs1995" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id63">FS1995</a><span class="fn-bracket">]</span></span>
<p>Y. Freund, and R. Schapire, &quot;تعميم نظري للقرار
للتعلم على الإنترنت وتطبيق على التعزيز&quot;, 1997.</p>
</div>
<div class="citation" id="zzrh2009" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id65">ZZRH2009</a><span class="fn-bracket">]</span></span>
<ol class="upperalpha simple" start="10">
<li><p>Zhu, H. Zou, S. Rosset, T. Hastie. &quot;AdaBoost متعدد الفئات&quot;, 2009.</p></li>
</ol>
</div>
<div class="citation" id="d1997" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id66">D1997</a><span class="fn-bracket">]</span></span>
<ol class="upperalpha simple" start="8">
<li><p>Drucker. &quot;تحسين المُنحدرات باستخدام تقنيات التعزيز&quot;, 1997.</p></li>
</ol>
</div>
<div class="citation" id="htf" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>HTF<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id30">1</a>,<a role="doc-backlink" href="#id61">2</a>,<a role="doc-backlink" href="#id64">3</a>)</span>
<p>T. Hastie, R. Tibshirani and J. Friedman, &quot;عناصر التعلم الإحصائي
الطبعة الثانية&quot;, Springer, 2009.</p>
</div>
</div>
</section>
</section>
</section>


                </article>
              
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="prev-next-area">
    <a class="left-prev"
       href="tree.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">السابق</p>
        <p class="prev-next-title"><span class="section-number">1.10. </span>شجرة القرار</p>
      </div>
    </a>
    <a class="right-next"
       href="multiclass.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">التالي</p>
        <p class="prev-next-title"><span class="section-number">1.12. </span>خوارزميات متعددة التصنيف ومتعددة الإخراج</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>
                </footer>
              
              
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-boosting">1.11.1. أشجار مُعززة بالتدرج</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#histogram-based-gradient-boosting">1.11.1.1. تعزيز التدرج القائم على الرسم البياني</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">1.11.1.1.1. الاستخدام</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#nan-support-hgbt">1.11.1.1.2. دعم القيم المفقودة</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#sw-hgbdt">1.11.1.1.3. دعم وزن العينة</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#categorical-support-gbdt">1.11.1.1.4. دعم الميزات الفئوية</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#monotonic-cst-gbdt">1.11.1.1.5. قيود رتيبة</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#interaction-cst-hgbt">1.11.1.1.6. قيود التفاعل</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id18">1.11.1.1.7. التوازي منخفض المستوى</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#why-it-s-faster">1.11.1.1.8. لماذا هو أسرع</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gradientboostingclassifier-gradientboostingregressor">1.11.1.2. <code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingClassifier</span></code> و <code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingRegressor</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-boosting-warm-start">1.11.1.2.1. ملاءمة مُتعلمين ضعفاء إضافيين</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-boosting-tree-size">1.11.1.2.2. التحكم في حجم الشجرة</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-boosting-formulation">1.11.1.2.3. الصيغة الرياضية</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-boosting-loss">1.11.1.2.4. دوال الخسارة</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-boosting-shrinkage">1.11.1.2.5. الانكماش عبر مُعدل التعلم</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id32">1.11.1.2.6. أخذ عينات فرعية</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id34">1.11.1.2.7. تفسير مع أهمية الميزة</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#forest">1.11.2. الغابات العشوائية ومجموعات الأشجار العشوائية الأخرى</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id38">1.11.2.1. الغابات العشوائية</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id40">1.11.2.2. أشجار عشوائية للغاية</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forest-parameters">1.11.2.3. المعلمات</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id42">1.11.2.4. التوازي</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forest-feature-importance">1.11.2.5. تقييم أهمية الميزة</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-trees-embedding">1.11.2.6. تضمين الأشجار العشوائية تمامًا</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tree-ensemble-warm-start">1.11.2.7. ملاءمة أشجار إضافية</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bagging">1.11.3. مُقدِّر التعريف التجميعي</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#voting-classifier">1.11.4. مُصنف التصويت</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id53">1.11.4.1. تصنيفات فئات الأغلبية (التصويت بالأغلبية / الصلب)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id54">1.11.4.2. الاستخدام</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id55">1.11.4.3. متوسط الاحتمالات الموزونة (التصويت الناعم)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id56">1.11.4.4. الاستخدام</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#voting-regressor">1.11.5. مُنحدِر التصويت</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id58">1.11.5.1. الاستخدام</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stacking">1.11.6. التعميم المُكدَّس</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#adaboost">1.11.7. AdaBoost</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id67">1.11.7.1. الاستخدام</a></li>
</ul>
</li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">

  <div class="tocsection sourcelink">
    <a href="../_sources/modules/ensemble.rst.txt">
      <i class="fa-solid fa-file-lines"></i> إظهار المصدر
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2007 - 2024, scikit-learn developers (BSD License) ### Translate into Arabic Eng. Ahmed Almaghz - 2024.
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
</div>

  </footer>
  </body>
</html>