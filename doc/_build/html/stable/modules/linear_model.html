
<!DOCTYPE html>


<html lang="ar" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="1.1. النماذج الخطية" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://scikit-learn/stable/modules/linear_model.html" />
<meta property="og:site_name" content="scikit-learn" />
<meta property="og:description" content="فيما يلي مجموعة من الأساليب المُخصصة للانحدار حيث من المُتوقع أن تكون القيمة المستهدفة عبارة عن تركيبة خطية من الميزات. في الصيغة الرياضية، إذا كانت\hat{y} هي القيمة المُتوقعة.\hat{y}(w, x) = w_0 +..." />
<meta property="og:image" content="https://scikit-learn/stable/_images/sphx_glr_plot_ols_001.png" />
<meta property="og:image:alt" content="scikit-learn" />
<meta name="description" content="فيما يلي مجموعة من الأساليب المُخصصة للانحدار حيث من المُتوقع أن تكون القيمة المستهدفة عبارة عن تركيبة خطية من الميزات. في الصيغة الرياضية، إذا كانت\hat{y} هي القيمة المُتوقعة.\hat{y}(w, x) = w_0 +..." />

    <title>1.1. النماذج الخطية &#8212; scikit-learn 1.6.dev0 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css?v=7f9a90b1" />
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Vibur" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyterlite_sphinx.css?v=ca70e7f1" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/colors.css?v=cc94ab7d" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/custom.css?v=85b0813d" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="../_static/documentation_options.js?v=3cd28d06"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=97f0b27d"></script>
    <script src="../_static/jupyterlite_sphinx.js?v=d6bdf5f8"></script>
    <script src="../_static/translations.js?v=87cb2081"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script data-domain="scikit-learn.org" defer="defer" src="https://views.scientific-python.org/js/script.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'modules/linear_model';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.0';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://scikit-learn.org/dev/_static/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '1.6.dev0';
        DOCUMENTATION_OPTIONS.show_version_warning_banner = true;
        </script>
    <script src="../_static/scripts/dropdown.js?v=e2048168"></script>
    <script src="../_static/scripts/version-switcher.js?v=a6dd8357"></script>
    <link rel="icon" href="../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="search" title="بحث" href="../search.html" />
    <link rel="next" title="1.2. تحليل التمييز الخطي والتربيعي" href="lda_qda.html" />
    <link rel="prev" title="1. التعليم الخاضع للإشراف" href="../supervised_learning.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="ar"/>
  <meta name="docsearch:version" content="1.6" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/scikit-learn-logo-small.png" class="logo__image only-light" alt="scikit-learn homepage"/>
    <img src="../_static/scikit-learn-logo-small.png" class="logo__image only-dark pst-js-only" alt="scikit-learn homepage"/>
  
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../install.html">
    Install
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../user_guide.html">
    دليل المستخدم
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api/index.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../auto_examples/index.html">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://blog.scikit-learn.org/">
    Community
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../getting_started.html">
    البدء
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../whats_new.html">
    Release History
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../glossary.html">
    Glossary
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../developers/index.html">
    Development
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../faq.html">
    FAQ
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../support.html">
    الدعم الفني
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../related_projects.html">
    مشاريع ذات علاقة
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../roadmap.html">
    Roadmap
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../governance.html">
    Governance
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../about.html">
    من نحن
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="بحث" aria-label="بحث" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/scikit-learn/scikit-learn" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
      
        <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="بحث" aria-label="بحث" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../install.html">
    Install
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../user_guide.html">
    دليل المستخدم
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api/index.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../auto_examples/index.html">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://blog.scikit-learn.org/">
    Community
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../getting_started.html">
    البدء
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../whats_new.html">
    Release History
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../glossary.html">
    Glossary
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../developers/index.html">
    Development
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../faq.html">
    FAQ
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../support.html">
    الدعم الفني
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../related_projects.html">
    مشاريع ذات علاقة
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../roadmap.html">
    Roadmap
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../governance.html">
    Governance
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../about.html">
    من نحن
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/scikit-learn/scikit-learn" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
        
          <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../supervised_learning.html">1. التعليم الخاضع للإشراف</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">1.1. النماذج الخطية</a></li>
<li class="toctree-l2"><a class="reference internal" href="lda_qda.html">1.2. تحليل التمييز الخطي والتربيعي</a></li>
<li class="toctree-l2"><a class="reference internal" href="kernel_ridge.html">1.3. انحدار حافة النواة</a></li>
<li class="toctree-l2"><a class="reference internal" href="svm.html">1.4. آلات الدعم المتجهية (SVM)</a></li>
<li class="toctree-l2"><a class="reference internal" href="sgd.html">1.5. التحسين التدريجي العشوائي</a></li>
<li class="toctree-l2"><a class="reference internal" href="neighbors.html">1.6. أقرب الجيران</a></li>
<li class="toctree-l2"><a class="reference internal" href="gaussian_process.html">1.7. العمليات الغاوسية</a></li>
<li class="toctree-l2"><a class="reference internal" href="cross_decomposition.html">1.8. التحليل المتقاطع</a></li>
<li class="toctree-l2"><a class="reference internal" href="naive_bayes.html">1.9. خوارزميات بايز الساذجة</a></li>
<li class="toctree-l2"><a class="reference internal" href="tree.html">1.10. شجرة القرار</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble.html">1.11. المجموعات: تعزيز التدرج، الغابات العشوائية، التجميع، التصويت، التكديس</a></li>
<li class="toctree-l2"><a class="reference internal" href="multiclass.html">1.12. خوارزميات متعددة التصنيف ومتعددة الإخراج</a></li>
<li class="toctree-l2"><a class="reference internal" href="feature_selection.html">1.13. اختيار الميزات</a></li>
<li class="toctree-l2"><a class="reference internal" href="semi_supervised.html">1.14. التعليم شبه الخاضع للإشراف</a></li>
<li class="toctree-l2"><a class="reference internal" href="isotonic.html">1.15. الانحدار المتساوي التوتر</a></li>
<li class="toctree-l2"><a class="reference internal" href="calibration.html">1.16. معايرة الاحتمال</a></li>
<li class="toctree-l2"><a class="reference internal" href="neural_networks_supervised.html">1.17. نماذج الشبكات العصبية (الخاضعة للإشراف)</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../unsupervised_learning.html">2. التعليم الغير خاضع للإشراف</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="mixture.html">2.1. نماذج خليط غاوسي</a></li>
<li class="toctree-l2"><a class="reference internal" href="manifold.html">2.2. تعلم المشعبات</a></li>
<li class="toctree-l2"><a class="reference internal" href="clustering.html">2.3. التجميع</a></li>
<li class="toctree-l2"><a class="reference internal" href="biclustering.html">2.4. التجميع الثنائي</a></li>
<li class="toctree-l2"><a class="reference internal" href="decomposition.html">2.5. تحليل الإشارات إلى مكونات (مشاكل تحليل المصفوفات)</a></li>
<li class="toctree-l2"><a class="reference internal" href="covariance.html">2.6. تقدير التباين المشترك</a></li>
<li class="toctree-l2"><a class="reference internal" href="outlier_detection.html">2.7. كشف القيم الغريبة والقيم المتطرفة</a></li>
<li class="toctree-l2"><a class="reference internal" href="density.html">2.8. تقدير الكثافة</a></li>
<li class="toctree-l2"><a class="reference internal" href="neural_networks_unsupervised.html">2.9. نماذج الشبكة العصبية (غير خاضعة للإشراف)</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../model_selection.html">3. تقييم وإختيار النموذج</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="cross_validation.html">3.1. التحقق المتبادل: تقييم أداء المقدر</a></li>
<li class="toctree-l2"><a class="reference internal" href="grid_search.html">3.2. ضبط المعلمات الفائقة لمُقدِّر</a></li>
<li class="toctree-l2"><a class="reference internal" href="classification_threshold.html">3.3. ضبط عتبة القرار لتنبؤ الفئة</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_evaluation.html">3.4. المقاييس والتهديف: تحديد جودة التنبؤات</a></li>
<li class="toctree-l2"><a class="reference internal" href="learning_curve.html">3.5. منحنيات التحقق من الصحة: رسم الدرجات لتقييم النماذج</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../inspection.html">4. الفحص</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="partial_dependence.html">4.1. مخططات الاعتماد الجزئي والتوقع الشرطي الفردي</a></li>
<li class="toctree-l2"><a class="reference internal" href="permutation_importance.html">4.2. أهمية التبديل</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../visualizations.html">5. التصورات المرئية</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../data_transforms.html">6. تحويلات مجموعات البيانات</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="compose.html">6.1. خطوط الأنابيب والمقدرات المركبة</a></li>
<li class="toctree-l2"><a class="reference internal" href="feature_extraction.html">6.2. استخراج الميزات</a></li>
<li class="toctree-l2"><a class="reference internal" href="preprocessing.html">6.3. المعالجة المسبقة للبيانات</a></li>
<li class="toctree-l2"><a class="reference internal" href="impute.html">6.4. تعويض القيم المفقودة</a></li>
<li class="toctree-l2"><a class="reference internal" href="unsupervised_reduction.html">6.5. تخفيض الأبعاد غير الخاضع للإشراف</a></li>
<li class="toctree-l2"><a class="reference internal" href="random_projection.html">6.6. الإسقاط العشوائي</a></li>
<li class="toctree-l2"><a class="reference internal" href="kernel_approximation.html">6.7. Kernel Approximation</a></li>
<li class="toctree-l2"><a class="reference internal" href="metrics.html">6.8. مقاييس المقارنة الزوجية، والصلات، والنوى (Kernels)</a></li>
<li class="toctree-l2"><a class="reference internal" href="preprocessing_targets.html">6.9. تحويل هدف التنبؤ (<code class="docutils literal notranslate"><span class="pre">y</span></code>)</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets/toy_dataset.html">7. مجموعات بيانات تجريبية</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets/real_world.html">8. مجموعات بيانات العالم الحقيقي</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets/sample_generators.html">9. مجموعات بيانات مولدة</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets/loading_other_datasets.html">10. تحميل مجموعات بيانات أخرى</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../computing.html">11. الحوسبة مع scikit-learn</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../computing/scaling_strategies.html">11.1. استراتيجيات للقياس حسابيًا: بيانات أكبر</a></li>
<li class="toctree-l2"><a class="reference internal" href="../computing/computational_performance.html">11.2. الأداء الحسابي</a></li>
<li class="toctree-l2"><a class="reference internal" href="../computing/parallelism.html">11.3. التوازي وإدارة الموارد والتهيئة</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../model_persistence.html">12. حفظ النموذج</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common_pitfalls.html">13. المزالق الشائعة والممارسات الموصى بها</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../dispatching.html">14. Dispatching</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="array_api.html">14.1. دعم المدخلات المتوافقة مع <code class="docutils literal notranslate"><span class="pre">Array</span> <span class="pre">API</span></code></a></li>

</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../machine_learning_map.html">15. اختيار المقدر المناسب</a></li>
<li class="toctree-l1"><a class="reference internal" href="../presentations.html">16. المصادر الخارجية ومقاطع الفيديو والمحادثات</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../user_guide.html" class="nav-link">دليل المستخدم</a></li>
    
    
    <li class="breadcrumb-item"><a href="../supervised_learning.html" class="nav-link"><span class="section-number">1. </span>التعليم الخاضع للإشراف</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis"><span class="section-number">1.1. </span>النماذج الخطية</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="linear-model">
<span id="id1"></span><h1><span class="section-number">1.1. </span>النماذج الخطية<a class="headerlink" href="#linear-model" title="Link to this heading">#</a></h1>
<p>فيما يلي مجموعة من الأساليب المُخصصة للانحدار حيث
من المُتوقع أن تكون القيمة المستهدفة عبارة عن تركيبة خطية من الميزات.
في الصيغة الرياضية، إذا كانت <span class="math notranslate nohighlight">\(\hat{y}\)</span> هي القيمة
المُتوقعة.</p>
<div class="math notranslate nohighlight">
\[\hat{y}(w, x) = w_0 + w_1 x_1 + ... + w_p x_p\]</div>
<p>عبر الوحدة، نُشير إلى المتجه <span class="math notranslate nohighlight">\(w = (w_1,
..., w_p)\)</span> كـ <code class="docutils literal notranslate"><span class="pre">coef_</span></code> و <span class="math notranslate nohighlight">\(w_0\)</span> كـ <code class="docutils literal notranslate"><span class="pre">intercept_</span></code>.</p>
<p>لإجراء التصنيف باستخدام النماذج الخطية المُعممة، انظر
<a class="reference internal" href="#logistic-regression"><span class="std std-ref">الانحدار اللوجستي</span></a>.</p>
<section id="ordinary-least-squares">
<span id="id2"></span><h2><span class="section-number">1.1.1. </span>المربعات الصغرى العادية<a class="headerlink" href="#ordinary-least-squares" title="Link to this heading">#</a></h2>
<p><a class="reference internal" href="generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression" title="sklearn.linear_model.LinearRegression"><code class="xref py py-class docutils literal notranslate"><span class="pre">LinearRegression</span></code></a> يُناسب نموذجًا خطيًا بمعاملات
<span class="math notranslate nohighlight">\(w = (w_1, ..., w_p)\)</span> لتقليل مجموع البواقي
من المربعات بين الأهداف المُلاحظة في مجموعة البيانات، و
الأهداف التي تنبأ بها التقريب الخطي. رياضيًا، يحل
مشكلة بالشكل:</p>
<div class="math notranslate nohighlight">
\[\min_{w} || X w - y||_2^2\]</div>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/linear_model/plot_ols.html"><img alt="../_images/sphx_glr_plot_ols_001.png" src="../_images/sphx_glr_plot_ols_001.png" style="width: 500.0px; height: 250.0px;" />
</a>
</figure>
<p>سيأخذ <a class="reference internal" href="generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression" title="sklearn.linear_model.LinearRegression"><code class="xref py py-class docutils literal notranslate"><span class="pre">LinearRegression</span></code></a> في أسلوبه <code class="docutils literal notranslate"><span class="pre">fit</span></code> مصفوفات <code class="docutils literal notranslate"><span class="pre">X</span></code> و <code class="docutils literal notranslate"><span class="pre">y</span></code>
ويُخزن المعاملات <span class="math notranslate nohighlight">\(w\)</span> للنموذج الخطي في عضويته
<code class="docutils literal notranslate"><span class="pre">coef_</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LinearRegression</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="go">LinearRegression()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span><span class="o">.</span><span class="n">coef_</span>
<span class="go">array([0.5, 0.5])</span>
</pre></div>
</div>
<p>تعتمد تقديرات المعاملات للمربعات الصغرى العادية على
استقلال الميزات. عندما تكون الميزات مُرتبطة و
أعمدة مصفوفة التصميم <span class="math notranslate nohighlight">\(X\)</span> لها تبعية خطية تقريبية،
تصبح مصفوفة التصميم قريبة من المفردة
ونتيجة لذلك، يصبح تقدير المربعات الصغرى حساسًا للغاية
للأخطاء العشوائية في الهدف المُلاحظ، مما يُنتج تباينًا
كبيرًا. يمكن أن تنشأ حالة <em>التعدد الخطي</em> هذه، على
سبيل المثال، عندما يتم جمع البيانات بدون تصميم تجريبي.</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py"><span class="std std-ref">Ordinary Least Squares Example</span></a></p></li>
</ul>
<section id="id3">
<h3><span class="section-number">1.1.1.1. </span>المربعات الصغرى غير السالبة<a class="headerlink" href="#id3" title="Link to this heading">#</a></h3>
<p>من الممكن تقييد جميع المعاملات لتكون غير سالبة، وهو ما قد
يكون مفيدًا عندما تُمثِّل بعض الكميات المادية أو غير السالبة
بشكل طبيعي (على سبيل المثال، عدد الترددات أو أسعار السلع).
<a class="reference internal" href="generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression" title="sklearn.linear_model.LinearRegression"><code class="xref py py-class docutils literal notranslate"><span class="pre">LinearRegression</span></code></a> يقبل معلمة منطقية <code class="docutils literal notranslate"><span class="pre">positive</span></code>:
عند تعيينها إلى <code class="docutils literal notranslate"><span class="pre">True</span></code>، يتم تطبيق <a class="reference external" href="https://en.wikipedia.org/wiki/Non-negative_least_squares">المربعات الصغرى غير السالبة</a>.</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/linear_model/plot_nnls.html#sphx-glr-auto-examples-linear-model-plot-nnls-py"><span class="std std-ref">Non-negative least squares</span></a></p></li>
</ul>
</section>
<section id="id5">
<h3><span class="section-number">1.1.1.2. </span>تعقيد المربعات الصغرى العادية<a class="headerlink" href="#id5" title="Link to this heading">#</a></h3>
<p>يتم حساب حل المربعات الصغرى باستخدام تحليل القيمة
المنفردة لـ X. إذا كانت X مصفوفة ذات شكل <code class="docutils literal notranslate"><span class="pre">(n_samples,</span> <span class="pre">n_features)</span></code>،
فإن هذه الطريقة لها تكلفة
<span class="math notranslate nohighlight">\(O(n_{\text{samples}} n_{\text{features}}^2)\)</span>، بافتراض أن
<span class="math notranslate nohighlight">\(n_{\text{samples}} \geq n_{\text{features}}\)</span>.</p>
</section>
</section>
<section id="ridge-regression">
<span id="id6"></span><h2><span class="section-number">1.1.2. </span>انحدار ريدج والتصنيف<a class="headerlink" href="#ridge-regression" title="Link to this heading">#</a></h2>
<section id="id7">
<h3><span class="section-number">1.1.2.1. </span>الانحدار<a class="headerlink" href="#id7" title="Link to this heading">#</a></h3>
<p>يعالج انحدار <a class="reference internal" href="generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge" title="sklearn.linear_model.Ridge"><code class="xref py py-class docutils literal notranslate"><span class="pre">Ridge</span></code></a> بعض مشاكل
<span class="xref std std-ref">المربعات الصغرى العادية</span> عن طريق فرض عقوبة على حجم
المعاملات. تُقلل معاملات ريدج مجموع البواقي
المُعاقب من المربعات:</p>
<div class="math notranslate nohighlight">
\[\min_{w} || X w - y||_2^2 + \alpha ||w||_2^2\]</div>
<p>تتحكم معلمة التعقيد <span class="math notranslate nohighlight">\(\alpha \geq 0\)</span> في مقدار
الانكماش: كلما زادت قيمة <span class="math notranslate nohighlight">\(\alpha\)</span>، زاد مقدار
الانكماش وبالتالي أصبحت المعاملات أكثر قوة للتعددية الخطية.</p>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/linear_model/plot_ridge_path.html"><img alt="../_images/sphx_glr_plot_ridge_path_001.png" src="../_images/sphx_glr_plot_ridge_path_001.png" style="width: 320.0px; height: 240.0px;" />
</a>
</figure>
<p>كما هو الحال مع النماذج الخطية الأخرى، سيأخذ <a class="reference internal" href="generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge" title="sklearn.linear_model.Ridge"><code class="xref py py-class docutils literal notranslate"><span class="pre">Ridge</span></code></a> في أسلوبه <code class="docutils literal notranslate"><span class="pre">fit</span></code>
مصفوفات <code class="docutils literal notranslate"><span class="pre">X</span></code> و <code class="docutils literal notranslate"><span class="pre">y</span></code> ويُخزن المعاملات <span class="math notranslate nohighlight">\(w\)</span> للنموذج الخطي في
عضويته <code class="docutils literal notranslate"><span class="pre">coef_</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">.5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="go">Ridge(alpha=0.5)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span><span class="o">.</span><span class="n">coef_</span>
<span class="go">array([0.34545455, 0.34545455])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span><span class="o">.</span><span class="n">intercept_</span>
<span class="go">0.13636...</span>
</pre></div>
</div>
<p>لاحظ أن الفئة <a class="reference internal" href="generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge" title="sklearn.linear_model.Ridge"><code class="xref py py-class docutils literal notranslate"><span class="pre">Ridge</span></code></a> تسمح للمستخدم بتحديد أنه
يجب اختيار المحلل تلقائيًا عن طريق تعيين <code class="docutils literal notranslate"><span class="pre">solver=&quot;auto&quot;</span></code>. عند تحديد هذا الخيار،
سيختار <a class="reference internal" href="generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge" title="sklearn.linear_model.Ridge"><code class="xref py py-class docutils literal notranslate"><span class="pre">Ridge</span></code></a> بين محللات <code class="docutils literal notranslate"><span class="pre">&quot;lbfgs&quot;</span></code> و <code class="docutils literal notranslate"><span class="pre">&quot;cholesky&quot;</span></code>
و <code class="docutils literal notranslate"><span class="pre">&quot;sparse_cg&quot;</span></code>. سيبدأ <a class="reference internal" href="generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge" title="sklearn.linear_model.Ridge"><code class="xref py py-class docutils literal notranslate"><span class="pre">Ridge</span></code></a> في فحص الشروط
الموضحة في الجدول التالي من أعلى إلى أسفل. إذا كان الشرط صحيحًا،
فسيتم اختيار المحلل المُقابل.</p>
</section>
<section id="id8">
<h3><span class="section-number">1.1.2.2. </span>التصنيف<a class="headerlink" href="#id8" title="Link to this heading">#</a></h3>
<p>يحتوي مُنحدِر <a class="reference internal" href="generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge" title="sklearn.linear_model.Ridge"><code class="xref py py-class docutils literal notranslate"><span class="pre">Ridge</span></code></a> على مُتغير مُصنف:
<a class="reference internal" href="generated/sklearn.linear_model.RidgeClassifier.html#sklearn.linear_model.RidgeClassifier" title="sklearn.linear_model.RidgeClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">RidgeClassifier</span></code></a>. يُحوِّل هذا المُصنف أولاً الأهداف الثنائية إلى
<code class="docutils literal notranslate"><span class="pre">{-1,</span> <span class="pre">1}</span></code> ثم يُعامل المشكلة كمهمة انحدار، ويُحسِّن
نفس الهدف على النحو الوارد أعلاه. تُقابل الفئة المُتوقعة إشارة
تنبؤ المُنحدِر. بالنسبة للتصنيف متعدد الفئات، يتم مُعالجة المشكلة
على أنها انحدار متعدد المخرجات، وتُقابل الفئة المُتوقعة
الإخراج ذي القيمة الأعلى.</p>
<p>قد يبدو من المشكوك فيه استخدام خسارة المربعات الصغرى (المُعاقبة) لملاءمة
نموذج تصنيف بدلاً من خسائر اللوجستية أو المفصلية
الأكثر تقليدية. ومع ذلك، من الناحية العملية، يمكن أن تؤدي جميع هذه النماذج إلى درجات
تحقق متبادل مُتشابهة من حيث الدقة أو الدقة / الاستدعاء، بينما
خسارة المربعات الصغرى المُعاقبة التي يستخدمها <a class="reference internal" href="generated/sklearn.linear_model.RidgeClassifier.html#sklearn.linear_model.RidgeClassifier" title="sklearn.linear_model.RidgeClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">RidgeClassifier</span></code></a> تسمح
باختيار مُختلف تمامًا للمحللات العددية مع ملفات تعريف أداء
حسابية مُتميزة.</p>
<p>يمكن أن يكون <a class="reference internal" href="generated/sklearn.linear_model.RidgeClassifier.html#sklearn.linear_model.RidgeClassifier" title="sklearn.linear_model.RidgeClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">RidgeClassifier</span></code></a> أسرع بكثير من على سبيل المثال
<a class="reference internal" href="generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="sklearn.linear_model.LogisticRegression"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogisticRegression</span></code></a> مع عدد كبير من الفئات لأنه يمكنه
حساب مصفوفة الإسقاط <span class="math notranslate nohighlight">\((X^T X)^{-1} X^T\)</span> مرة واحدة فقط.</p>
<p>يُشار أحيانًا إلى هذا المُصنف باسم <a class="reference external" href="https://en.wikipedia.org/wiki/Least-squares_support-vector_machine">آلات متجه دعم المربعات الصغرى</a>
مع نواة خطية.</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/linear_model/plot_ridge_path.html#sphx-glr-auto-examples-linear-model-plot-ridge-path-py"><span class="std std-ref">Plot Ridge coefficients as a function of the regularization</span></a></p></li>
<li><p><a class="reference internal" href="../auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py"><span class="std std-ref">Classification of text documents using sparse features</span></a></p></li>
<li><p><a class="reference internal" href="../auto_examples/inspection/plot_linear_model_coefficient_interpretation.html#sphx-glr-auto-examples-inspection-plot-linear-model-coefficient-interpretation-py"><span class="std std-ref">Common pitfalls in the interpretation of coefficients of linear models</span></a></p></li>
</ul>
</section>
<section id="id10">
<h3><span class="section-number">1.1.2.3. </span>تعقيد ريدج<a class="headerlink" href="#id10" title="Link to this heading">#</a></h3>
<p>هذه الطريقة لها نفس ترتيب التعقيد مثل
<span class="xref std std-ref">المربعات الصغرى العادية</span>.</p>
</section>
<section id="id11">
<h3><span class="section-number">1.1.2.4. </span>تعيين معلمة التنظيم: التحقق المتبادل لترك واحد<a class="headerlink" href="#id11" title="Link to this heading">#</a></h3>
<p><a class="reference internal" href="generated/sklearn.linear_model.RidgeCV.html#sklearn.linear_model.RidgeCV" title="sklearn.linear_model.RidgeCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">RidgeCV</span></code></a> و <a class="reference internal" href="generated/sklearn.linear_model.RidgeClassifierCV.html#sklearn.linear_model.RidgeClassifierCV" title="sklearn.linear_model.RidgeClassifierCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">RidgeClassifierCV</span></code></a> يُطبقان
انحدار / تصنيف ريدج مع التحقق المتبادل المُدمج لمعلمة alpha.
يعملان بنفس طريقة <a class="reference internal" href="generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" title="sklearn.model_selection.GridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">GridSearchCV</span></code></a> باستثناء
أنه يتم تعيينه افتراضيًا إلى التحقق المتبادل الفعال لترك واحد.
عند استخدام التحقق <span class="xref std std-term">المتبادل</span> الافتراضي، لا يمكن أن تكون alpha 0 بسبب
الصيغة المُستخدمة لحساب خطأ ترك واحد. انظر <a class="reference internal" href="#rl2007" id="id12"><span>[RL2007]</span></a> للتفاصيل.</p>
<p>مثال على الاستخدام:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">RidgeCV</span><span class="p">(</span><span class="n">alphas</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">13</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="go">RidgeCV(alphas=array([1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01,</span>
<span class="go">      1.e+02, 1.e+03, 1.e+04, 1.e+05, 1.e+06]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span><span class="o">.</span><span class="n">alpha_</span>
<span class="go">0.01</span>
</pre></div>
</div>
<p>سيؤدي تحديد قيمة سمة <a class="reference internal" href="../glossary.html#term-cv"><span class="xref std std-term">cv</span></a> إلى تشغيل استخدام
التحقق المتبادل باستخدام <a class="reference internal" href="generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" title="sklearn.model_selection.GridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">GridSearchCV</span></code></a>،
على سبيل المثال <code class="docutils literal notranslate"><span class="pre">cv=10</span></code> للتحقق المتبادل من 10 طيات، بدلاً من التحقق
المتبادل لترك واحد.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<div role="list" class="citation-list">
<div class="citation" id="rl2007" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id12">RL2007</a><span class="fn-bracket">]</span></span>
<p class="sd-card-text">&quot;ملاحظات حول المربعات الصغرى المُنظّمة&quot;, Rifkin &amp; Lippert (التقرير
الفني &lt;<a class="reference external" href="http://cbcl.mit.edu/publications/ps/MIT-CSAIL-TR-2007-025.pdf">http://cbcl.mit.edu/publications/ps/MIT-CSAIL-TR-2007-025.pdf</a>&gt;`_،
<a class="reference external" href="https://www.mit.edu/~9.520/spring07/Classes/rlsslides.pdf">شرائح الدورة</a>).</p>
</div>
</div>
</div>
</details></section>
</section>
<section id="lasso">
<span id="id14"></span><h2><span class="section-number">1.1.3. </span>Lasso<a class="headerlink" href="#lasso" title="Link to this heading">#</a></h2>
<p><a class="reference internal" href="generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso" title="sklearn.linear_model.Lasso"><code class="xref py py-class docutils literal notranslate"><span class="pre">Lasso</span></code></a> هو نموذج خطي يُقدِّر معاملات متفرقة.
إنه مفيد في بعض السياقات نظرًا لميله إلى تفضيل الحلول
التي تحتوي على عدد أقل من المعاملات غير الصفرية، مما يُقلل بشكل فعال من عدد
الميزات التي يعتمد عليها الحل المُعين. لهذا السبب،
يُعد Lasso ومتغيراته أساسيين في مجال الاستشعار
المضغوط.
في ظل ظروف مُعينة، يمكنه استرداد مجموعة المعاملات
غير الصفرية الدقيقة (انظر
<a class="reference internal" href="../auto_examples/applications/plot_tomography_l1_reconstruction.html#sphx-glr-auto-examples-applications-plot-tomography-l1-reconstruction-py"><span class="std std-ref">Compressive sensing: tomography reconstruction with L1 prior (Lasso)</span></a>).</p>
<p>رياضيًا، يتكون من نموذج خطي مع مُصطلح تنظيم مُضاف.
دالة الهدف التي يجب تقليلها هي:</p>
<div class="math notranslate nohighlight">
\[\min_{w} { \frac{1}{2n_{\text{samples}}} ||X w - y||_2 ^ 2 + \alpha ||w||_1}\]</div>
<p>وبالتالي، يحل تقدير lasso تقليل
عقوبة المربعات الصغرى مع إضافة <span class="math notranslate nohighlight">\(\alpha ||w||_1\)</span>، حيث
<span class="math notranslate nohighlight">\(\alpha\)</span> ثابت و <span class="math notranslate nohighlight">\(||w||_1\)</span> هي قاعدة <span class="math notranslate nohighlight">\(\ell_1\)</span> لـ
متجه المعاملات.</p>
<p>يستخدم التطبيق في الفئة <a class="reference internal" href="generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso" title="sklearn.linear_model.Lasso"><code class="xref py py-class docutils literal notranslate"><span class="pre">Lasso</span></code></a> النزول الإحداثي كـ
خوارزمية لملاءمة المعاملات. انظر <a class="reference internal" href="#least-angle-regression"><span class="std std-ref">انحدار الزاوية الصغرى</span></a>
للحصول على تطبيق آخر:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">Lasso</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="go">Lasso(alpha=0.1)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="go">array([0.8])</span>
</pre></div>
</div>
<p>تُعد دالة <a class="reference internal" href="generated/sklearn.linear_model.lasso_path.html#sklearn.linear_model.lasso_path" title="sklearn.linear_model.lasso_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">lasso_path</span></code></a> مفيدة للمهام ذات المستوى الأدنى،
حيث إنها تحسب المعاملات على طول المسار الكامل للقيم المُمكنة.</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/linear_model/plot_lasso_and_elasticnet.html#sphx-glr-auto-examples-linear-model-plot-lasso-and-elasticnet-py"><span class="std std-ref">L1-based models for Sparse Signals</span></a></p></li>
<li><p><a class="reference internal" href="../auto_examples/applications/plot_tomography_l1_reconstruction.html#sphx-glr-auto-examples-applications-plot-tomography-l1-reconstruction-py"><span class="std std-ref">Compressive sensing: tomography reconstruction with L1 prior (Lasso)</span></a></p></li>
<li><p><a class="reference internal" href="../auto_examples/inspection/plot_linear_model_coefficient_interpretation.html#sphx-glr-auto-examples-inspection-plot-linear-model-coefficient-interpretation-py"><span class="std std-ref">Common pitfalls in the interpretation of coefficients of linear models</span></a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">ملاحظة</p>
<p><strong>اختيار الميزات باستخدام Lasso</strong></p>
<p>نظرًا لأن انحدار Lasso يُعطي نماذج متفرقة، فإنه
يمكن استخدامه لاختيار الميزات، كما هو مُفصَّل في
<a class="reference internal" href="feature_selection.html#l1-feature-selection"><span class="std std-ref">اختيار الميزات القائم على L1</span></a>.</p>
</div>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-2">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-2" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">يشرح المرجعان التاليان التكرارات
المُستخدمة في محلل النزول الإحداثي لـ scikit-learn، وكذلك
حساب فجوة الازدواجية المُستخدم للتحكم في التقارب.</p>
<ul class="simple">
<li><p class="sd-card-text">&quot;مسار التنظيم للنماذج الخطية المُعممة عن طريق النزول الإحداثي&quot;,
Friedman, Hastie &amp; Tibshirani, J Stat Softw, 2010 (<a class="reference external" href="https://www.jstatsoft.org/article/view/v033i01/v33i01.pdf">الورقة</a>).</p></li>
<li><p class="sd-card-text">&quot;أسلوب نقطة داخلية للمربعات الصغرى المُنظّمة بـ L1 واسعة النطاق,&quot;
S. J. Kim, K. Koh, M. Lustig, S. Boyd and D. Gorinevsky,
في IEEE Journal of Selected Topics in Signal Processing، 2007
(<a class="reference external" href="https://web.stanford.edu/~boyd/papers/pdf/l1_ls.pdf">الورقة</a>)</p></li>
</ul>
</div>
</details><section id="id15">
<h3><span class="section-number">1.1.3.1. </span>تعيين معلمة التنظيم<a class="headerlink" href="#id15" title="Link to this heading">#</a></h3>
<p>تتحكم معلمة <code class="docutils literal notranslate"><span class="pre">alpha</span></code> في درجة تفرق المعاملات
المُقدّرة.</p>
<section id="id16">
<h4><span class="section-number">1.1.3.1.1. </span>استخدام التحقق المتبادل<a class="headerlink" href="#id16" title="Link to this heading">#</a></h4>
<p>يُظهِر scikit-learn الكائنات التي تُعيِّن معلمة Lasso <code class="docutils literal notranslate"><span class="pre">alpha</span></code> عن طريق
التحقق المتبادل: <a class="reference internal" href="generated/sklearn.linear_model.LassoCV.html#sklearn.linear_model.LassoCV" title="sklearn.linear_model.LassoCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">LassoCV</span></code></a> و <a class="reference internal" href="generated/sklearn.linear_model.LassoLarsCV.html#sklearn.linear_model.LassoLarsCV" title="sklearn.linear_model.LassoLarsCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">LassoLarsCV</span></code></a>.
<a class="reference internal" href="generated/sklearn.linear_model.LassoLarsCV.html#sklearn.linear_model.LassoLarsCV" title="sklearn.linear_model.LassoLarsCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">LassoLarsCV</span></code></a> يعتمد على خوارزمية <a class="reference internal" href="#least-angle-regression"><span class="std std-ref">انحدار الزاوية الصغرى</span></a>
الموضحة أدناه.</p>
<p>بالنسبة لمجموعات البيانات عالية الأبعاد ذات العديد من الميزات الخطية،
<a class="reference internal" href="generated/sklearn.linear_model.LassoCV.html#sklearn.linear_model.LassoCV" title="sklearn.linear_model.LassoCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">LassoCV</span></code></a> غالبًا ما يكون مُفضلًا. ومع ذلك، فإن <a class="reference internal" href="generated/sklearn.linear_model.LassoLarsCV.html#sklearn.linear_model.LassoLarsCV" title="sklearn.linear_model.LassoLarsCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">LassoLarsCV</span></code></a> له
ميزة استكشاف المزيد من قيم معلمة <code class="docutils literal notranslate"><span class="pre">alpha</span></code> ذات الصلة، و
إذا كان عدد العينات صغيرًا جدًا مُقارنةً بعدد
الميزات، فإنه غالبًا ما يكون أسرع من <a class="reference internal" href="generated/sklearn.linear_model.LassoCV.html#sklearn.linear_model.LassoCV" title="sklearn.linear_model.LassoCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">LassoCV</span></code></a>.</p>
<p class="centered">
<strong><a class="reference external" href="../auto_examples/linear_model/plot_lasso_model_selection.html"><img alt="lasso_cv_1" src="../_images/sphx_glr_plot_lasso_model_selection_002.png" style="width: 307.2px; height: 230.39999999999998px;" /></a> <a class="reference external" href="../auto_examples/linear_model/plot_lasso_model_selection.html"><img alt="lasso_cv_2" src="../_images/sphx_glr_plot_lasso_model_selection_003.png" style="width: 307.2px; height: 230.39999999999998px;" /></a></strong></p></section>
<section id="lasso-lars-ic">
<span id="id17"></span><h4><span class="section-number">1.1.3.1.2. </span>اختيار النموذج القائم على معيار المعلومات<a class="headerlink" href="#lasso-lars-ic" title="Link to this heading">#</a></h4>
<p>بدلاً من ذلك، يقترح المُقدِّر <a class="reference internal" href="generated/sklearn.linear_model.LassoLarsIC.html#sklearn.linear_model.LassoLarsIC" title="sklearn.linear_model.LassoLarsIC"><code class="xref py py-class docutils literal notranslate"><span class="pre">LassoLarsIC</span></code></a> استخدام
معيار معلومات Akaike (AIC) ومعيار معلومات Bayes (BIC).
إنه بديل أقل تكلفة من الناحية الحسابية للعثور على القيمة المثلى لـ alpha
حيث يتم حساب مسار التنظيم مرة واحدة فقط بدلاً من k + 1 مرة
عند استخدام التحقق المتبادل k-fold.</p>
<p>في الواقع، يتم حساب هذه المعايير على مجموعة التدريب داخل العينة. باختصار،
يعاقبون الدرجات المُتفائلة جدًا لنماذج Lasso المختلفة بواسطة
مرونتها (راجع قسم &quot;التفاصيل الرياضية&quot; أدناه).</p>
<p>ومع ذلك، تحتاج هذه المعايير إلى تقدير مناسب لدرجات حرية
الحل، ويتم اشتقاقها لعينات كبيرة (نتائج مقاربة) وتفترض أن
النموذج الصحيح هو مرشح قيد التحقيق. كما أنها تميل إلى الانهيار عندما
تكون المشكلة سيئة الشرط (على سبيل المثال، المزيد من الميزات من العينات).</p>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/linear_model/plot_lasso_lars_ic.html"><img alt="../_images/sphx_glr_plot_lasso_lars_ic_001.png" src="../_images/sphx_glr_plot_lasso_lars_ic_001.png" style="width: 320.0px; height: 240.0px;" />
</a>
</figure>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/linear_model/plot_lasso_model_selection.html#sphx-glr-auto-examples-linear-model-plot-lasso-model-selection-py"><span class="std std-ref">Lasso model selection: AIC-BIC / cross-validation</span></a></p></li>
<li><p><a class="reference internal" href="../auto_examples/linear_model/plot_lasso_lars_ic.html#sphx-glr-auto-examples-linear-model-plot-lasso-lars-ic-py"><span class="std std-ref">Lasso model selection via information criteria</span></a></p></li>
</ul>
</section>
<section id="aic-bic">
<span id="id18"></span><h4><span class="section-number">1.1.3.1.3. </span>معايير AIC و BIC<a class="headerlink" href="#aic-bic" title="Link to this heading">#</a></h4>
<p>قد يختلف تعريف AIC (وبالتالي BIC) في الأدبيات. في هذا
القسم، نُقدم المزيد من المعلومات حول المعيار المحسوب في
scikit-learn.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="التفاصيل-الرياضية">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">التفاصيل الرياضية<a class="headerlink" href="#التفاصيل-الرياضية" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">يتم تعريف معيار AIC على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[AIC = -2 \log(\hat{L}) + 2 d\]</div>
<p class="sd-card-text">حيث <span class="math notranslate nohighlight">\(\hat{L}\)</span> هو أقصى احتمالية للنموذج و
<span class="math notranslate nohighlight">\(d\)</span> هو عدد المعلمات (يُشار إليها أيضًا بدرجات الحرية
في القسم السابق).</p>
<p class="sd-card-text">يستبدل تعريف BIC الثابت <span class="math notranslate nohighlight">\(2\)</span> بـ <span class="math notranslate nohighlight">\(\log(N)\)</span>:</p>
<div class="math notranslate nohighlight">
\[BIC = -2 \log(\hat{L}) + \log(N) d\]</div>
<p class="sd-card-text">حيث <span class="math notranslate nohighlight">\(N\)</span> هو عدد العينات.</p>
<p class="sd-card-text">بالنسبة لنموذج غاوسي خطي، يتم تعريف أقصى احتمالية للسجل على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[\log(\hat{L}) = - \frac{n}{2} \log(2 \pi) - \frac{n}{2} \ln(\sigma^2) - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{2\sigma^2}\]</div>
<p class="sd-card-text">حيث <span class="math notranslate nohighlight">\(\sigma^2\)</span> هو تقدير لتباين الضوضاء،
<span class="math notranslate nohighlight">\(y_i\)</span> و <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> هما الأهداف الحقيقية والمتوقعة
على التوالي، و <span class="math notranslate nohighlight">\(n\)</span> هو عدد العينات.</p>
<p class="sd-card-text">يؤدي توصيل أقصى احتمالية للسجل في صيغة AIC إلى:</p>
<div class="math notranslate nohighlight">
\[AIC = n \log(2 \pi \sigma^2) + \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sigma^2} + 2 d\]</div>
<p class="sd-card-text">يتم تجاهل المصطلح الأول من التعبير أعلاه أحيانًا لأنه
ثابت عندما يتم توفير <span class="math notranslate nohighlight">\(\sigma^2\)</span>. بالإضافة إلى ذلك،
يُذكر أحيانًا أن AIC يُعادل إحصائية <span class="math notranslate nohighlight">\(C_p\)</span>
<a class="footnote-reference brackets" href="#id21" id="id19" role="doc-noteref"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></a>. ومع ذلك، بمعنى دقيق، فإنه يُعادل فقط حتى ثابت
مُعين وعامل ضربي.</p>
<p class="sd-card-text">أخيرًا، ذكرنا أعلاه أن <span class="math notranslate nohighlight">\(\sigma^2\)</span> هو تقدير لـ
تباين الضوضاء. في <a class="reference internal" href="generated/sklearn.linear_model.LassoLarsIC.html#sklearn.linear_model.LassoLarsIC" title="sklearn.linear_model.LassoLarsIC"><code class="xref py py-class docutils literal notranslate"><span class="pre">LassoLarsIC</span></code></a> عندما لا يتم توفير معلمة
<code class="docutils literal notranslate"><span class="pre">noise_variance</span></code> (افتراضي)، يتم تقدير تباين الضوضاء عبر
المُقدِّر غير المُتحيز <a class="footnote-reference brackets" href="#id22" id="id20" role="doc-noteref"><span class="fn-bracket">[</span>13<span class="fn-bracket">]</span></a> المُعرَّف على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[\sigma^2 = \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{n - p}\]</div>
<p class="sd-card-text">حيث <span class="math notranslate nohighlight">\(p\)</span> هو عدد الميزات و <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> هو
الهدف المتوقع باستخدام انحدار المربعات الصغرى العادية. لاحظ أن هذه
الصيغة صالحة فقط عندما <code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">&gt;</span> <span class="pre">n_features</span></code>.</p>
<p class="rubric">المراجع</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id21" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id19">12</a><span class="fn-bracket">]</span></span>
<p class="sd-card-text"><a class="reference external" href="https://arxiv.org/abs/0712.0881.pdf">Zou, Hui, Trevor Hastie, and Robert Tibshirani.
&quot;حول درجات حرية lasso.&quot;
The Annals of Statistics 35.5 (2007): 2173-2192.</a></p>
</aside>
<aside class="footnote brackets" id="id22" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id20">13</a><span class="fn-bracket">]</span></span>
<p class="sd-card-text"><a class="reference external" href="https://doi.org/10.1162/089976603321891864">Cherkassky, Vladimir, and Yunqian Ma.
&quot;مقارنة اختيار النموذج للانحدار.&quot;
Neural computation 15.7 (2003): 1691-1714.</a></p>
</aside>
</aside>
</div>
</details></section>
<section id="svm">
<h4><span class="section-number">1.1.3.1.4. </span>مقارنة مع معلمة التنظيم لـ SVM<a class="headerlink" href="#svm" title="Link to this heading">#</a></h4>
<p>التكافؤ بين <code class="docutils literal notranslate"><span class="pre">alpha</span></code> ومعلمة التنظيم لـ SVM،
<code class="docutils literal notranslate"><span class="pre">C</span></code> مُعطى بواسطة <code class="docutils literal notranslate"><span class="pre">alpha</span> <span class="pre">=</span> <span class="pre">1</span> <span class="pre">/</span> <span class="pre">C</span></code> أو <code class="docutils literal notranslate"><span class="pre">alpha</span> <span class="pre">=</span> <span class="pre">1</span> <span class="pre">/</span> <span class="pre">(n_samples</span> <span class="pre">*</span> <span class="pre">C)</span></code>،
اعتمادًا على المُقدِّر ودالة الهدف الدقيقة التي يُحسِّنها
النموذج.</p>
</section>
</section>
</section>
<section id="multi-task-lasso">
<span id="id23"></span><h2><span class="section-number">1.1.4. </span>Lasso متعدد المهام<a class="headerlink" href="#multi-task-lasso" title="Link to this heading">#</a></h2>
<p><a class="reference internal" href="generated/sklearn.linear_model.MultiTaskLasso.html#sklearn.linear_model.MultiTaskLasso" title="sklearn.linear_model.MultiTaskLasso"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiTaskLasso</span></code></a> هو نموذج خطي يُقدِّر المعاملات المتفرقة
لمشاكل الانحدار المتعددة بشكل مُشترك: <code class="docutils literal notranslate"><span class="pre">y</span></code> هي مصفوفة ثنائية الأبعاد،
ذات شكل <code class="docutils literal notranslate"><span class="pre">(n_samples,</span> <span class="pre">n_tasks)</span></code>. القيد هو أن الميزات
المحددة هي نفسها لجميع مشاكل الانحدار، وتسمى أيضًا المهام.</p>
<p>تُقارن الصورة التالية موقع الإدخالات غير الصفرية في
مصفوفة المعاملات W التي تم الحصول عليها باستخدام Lasso بسيط أو MultiTaskLasso.
تُعطي تقديرات Lasso قيمًا غير صفرية مُشتتة بينما القيم غير الصفرية لـ
MultiTaskLasso هي أعمدة كاملة.</p>
<p class="centered">
<strong><a class="reference external" href="../auto_examples/linear_model/plot_multi_task_lasso_support.html"><img alt="multi_task_lasso_1" src="../_images/sphx_glr_plot_multi_task_lasso_support_001.png" style="width: 384.0px; height: 240.0px;" /></a> <a class="reference external" href="../auto_examples/linear_model/plot_multi_task_lasso_support.html"><img alt="multi_task_lasso_2" src="../_images/sphx_glr_plot_multi_task_lasso_support_002.png" style="width: 307.2px; height: 230.39999999999998px;" /></a></strong></p><p class="centered">
<strong>ملاءمة نموذج سلسلة زمنية، بفرض أن تكون أي ميزة نشطة نشطة في جميع الأوقات.</strong></p><p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/linear_model/plot_multi_task_lasso_support.html#sphx-glr-auto-examples-linear-model-plot-multi-task-lasso-support-py"><span class="std std-ref">Joint feature selection with multi-task Lasso</span></a></p></li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="التفاصيل-الرياضية-2">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">التفاصيل الرياضية<a class="headerlink" href="#التفاصيل-الرياضية-2" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">رياضيًا، يتكون من نموذج خطي مُدرَّب بمزيج من
قاعدة <span class="math notranslate nohighlight">\(\ell_1\)</span> <span class="math notranslate nohighlight">\(\ell_2\)</span> لتنظيم.
دالة الهدف التي يجب تقليلها هي:</p>
<div class="math notranslate nohighlight">
\[\min_{W} { \frac{1}{2n_{\text{samples}}} ||X W - Y||_{\text{Fro}} ^ 2 + \alpha ||W||_{21}}\]</div>
<p class="sd-card-text">حيث يُشير <span class="math notranslate nohighlight">\(\text{Fro}\)</span> إلى قاعدة Frobenius</p>
<div class="math notranslate nohighlight">
\[||A||_{\text{Fro}} = \sqrt{\sum_{ij} a_{ij}^2}\]</div>
<p class="sd-card-text">و <span class="math notranslate nohighlight">\(\ell_1\)</span> <span class="math notranslate nohighlight">\(\ell_2\)</span> تقرأ</p>
<div class="math notranslate nohighlight">
\[||A||_{2 1} = \sum_i \sqrt{\sum_j a_{ij}^2}.\]</div>
<p class="sd-card-text">يستخدم التطبيق في الفئة <a class="reference internal" href="generated/sklearn.linear_model.MultiTaskLasso.html#sklearn.linear_model.MultiTaskLasso" title="sklearn.linear_model.MultiTaskLasso"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiTaskLasso</span></code></a>
النزول الإحداثي كخوارزمية لملاءمة المعاملات.</p>
</div>
</details></section>
<section id="elastic-net">
<span id="id24"></span><h2><span class="section-number">1.1.5. </span>Elastic-Net<a class="headerlink" href="#elastic-net" title="Link to this heading">#</a></h2>
<p><a class="reference internal" href="generated/sklearn.linear_model.ElasticNet.html#sklearn.linear_model.ElasticNet" title="sklearn.linear_model.ElasticNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">ElasticNet</span></code></a> هو نموذج انحدار خطي مُدرَّب بكل من
تنظيم <span class="math notranslate nohighlight">\(\ell_1\)</span> و <span class="math notranslate nohighlight">\(\ell_2\)</span> للمعاملات.
يسمح هذا المزيج بتعلم نموذج متفرق حيث يكون عدد قليل من
الأوزان غير صفري مثل <a class="reference internal" href="generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso" title="sklearn.linear_model.Lasso"><code class="xref py py-class docutils literal notranslate"><span class="pre">Lasso</span></code></a>، مع الحفاظ على
خصائص التنظيم لـ <a class="reference internal" href="generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge" title="sklearn.linear_model.Ridge"><code class="xref py py-class docutils literal notranslate"><span class="pre">Ridge</span></code></a>. نتحكم في التركيبة
المُحدبة لـ <span class="math notranslate nohighlight">\(\ell_1\)</span> و <span class="math notranslate nohighlight">\(\ell_2\)</span> باستخدام معلمة <code class="docutils literal notranslate"><span class="pre">l1_ratio</span></code>.</p>
<p>Elastic-net مفيد عندما يكون هناك العديد من الميزات
المُرتبطة ببعضها البعض. من المرجح أن يختار Lasso واحدًا من هذه
بشكل عشوائي، بينما من المرجح أن يختار Elastic-Net كليهما.</p>
<p>ميزة عملية للمُفاضلة بين Lasso و Ridge هي أنه
يسمح لـ Elastic-Net بوراثة بعض استقرار Ridge تحت الدوران.</p>
<p>دالة الهدف التي يجب تقليلها هي في هذه الحالة</p>
<div class="math notranslate nohighlight">
\[\min_{w} { \frac{1}{2n_{\text{samples}}} ||X w - y||_2 ^ 2 + \alpha \rho ||w||_1 +
\frac{\alpha(1-\rho)}{2} ||w||_2 ^ 2}\]</div>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/linear_model/plot_lasso_lasso_lars_elasticnet_path.html"><img alt="../_images/sphx_glr_plot_lasso_lasso_lars_elasticnet_path_002.png" src="../_images/sphx_glr_plot_lasso_lasso_lars_elasticnet_path_002.png" style="width: 320.0px; height: 240.0px;" />
</a>
</figure>
<p>يمكن استخدام الفئة <a class="reference internal" href="generated/sklearn.linear_model.ElasticNetCV.html#sklearn.linear_model.ElasticNetCV" title="sklearn.linear_model.ElasticNetCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">ElasticNetCV</span></code></a> لضبط المعلمات
<code class="docutils literal notranslate"><span class="pre">alpha</span></code> (<span class="math notranslate nohighlight">\(\alpha\)</span>) و <code class="docutils literal notranslate"><span class="pre">l1_ratio</span></code> (<span class="math notranslate nohighlight">\(\rho\)</span>) عن طريق التحقق
المتبادل.</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/linear_model/plot_lasso_and_elasticnet.html#sphx-glr-auto-examples-linear-model-plot-lasso-and-elasticnet-py"><span class="std std-ref">L1-based models for Sparse Signals</span></a></p></li>
<li><p><a class="reference internal" href="../auto_examples/linear_model/plot_lasso_lasso_lars_elasticnet_path.html#sphx-glr-auto-examples-linear-model-plot-lasso-lasso-lars-elasticnet-path-py"><span class="std std-ref">Lasso, Lasso-LARS, and Elastic Net paths</span></a></p></li>
<li><p><a class="reference internal" href="../auto_examples/linear_model/plot_elastic_net_precomputed_gram_matrix_with_weighted_samples.html#sphx-glr-auto-examples-linear-model-plot-elastic-net-precomputed-gram-matrix-with-weighted-samples-py"><span class="std std-ref">Fitting an Elastic Net with a precomputed Gram Matrix and Weighted Samples</span></a></p></li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-3" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">يشرح المرجعان التاليان التكرارات
المُستخدمة في محلل النزول الإحداثي لـ scikit-learn، وكذلك
حساب فجوة الازدواجية المُستخدم للتحكم في التقارب.</p>
<ul class="simple">
<li><p class="sd-card-text">&quot;مسار التنظيم للنماذج الخطية المُعممة عن طريق النزول الإحداثي&quot;,
Friedman, Hastie &amp; Tibshirani, J Stat Softw, 2010 (<a class="reference external" href="https://www.jstatsoft.org/article/view/v033i01/v33i01.pdf">الورقة</a>).</p></li>
<li><p class="sd-card-text">&quot;أسلوب نقطة داخلية للمربعات الصغرى المُنظّمة بـ L1 واسعة النطاق,&quot;
S. J. Kim, K. Koh, M. Lustig, S. Boyd and D. Gorinevsky,
في IEEE Journal of Selected Topics in Signal Processing، 2007
(<a class="reference external" href="https://web.stanford.edu/~boyd/papers/pdf/l1_ls.pdf">الورقة</a>)</p></li>
</ul>
</div>
</details></section>
<section id="multi-task-elastic-net">
<span id="id25"></span><h2><span class="section-number">1.1.6. </span>Elastic-Net متعدد المهام<a class="headerlink" href="#multi-task-elastic-net" title="Link to this heading">#</a></h2>
<p><a class="reference internal" href="generated/sklearn.linear_model.MultiTaskElasticNet.html#sklearn.linear_model.MultiTaskElasticNet" title="sklearn.linear_model.MultiTaskElasticNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiTaskElasticNet</span></code></a> هو نموذج شبكة مرنة يُقدِّر المعاملات
المتفرقة لمشاكل الانحدار المتعددة بشكل مُشترك: <code class="docutils literal notranslate"><span class="pre">Y</span></code> هي مصفوفة ثنائية
الأبعاد ذات شكل <code class="docutils literal notranslate"><span class="pre">(n_samples,</span> <span class="pre">n_tasks)</span></code>. القيد هو أن
الميزات المحددة هي نفسها لجميع مشاكل الانحدار، وتسمى أيضًا
المهام.</p>
<p>رياضيًا، يتكون من نموذج خطي مُدرَّب بمزيج من
قاعدة <span class="math notranslate nohighlight">\(\ell_1\)</span> <span class="math notranslate nohighlight">\(\ell_2\)</span> وقاعدة <span class="math notranslate nohighlight">\(\ell_2\)</span> للتنظيم.
دالة الهدف التي يجب تقليلها هي:</p>
<div class="math notranslate nohighlight">
\[\min_{W} { \frac{1}{2n_{\text{samples}}} ||X W - Y||_{\text{Fro}}^2 + \alpha \rho ||W||_{2 1} +
\frac{\alpha(1-\rho)}{2} ||W||_{\text{Fro}}^2}\]</div>
<p>يستخدم التطبيق في الفئة <a class="reference internal" href="generated/sklearn.linear_model.MultiTaskElasticNet.html#sklearn.linear_model.MultiTaskElasticNet" title="sklearn.linear_model.MultiTaskElasticNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiTaskElasticNet</span></code></a> النزول الإحداثي كـ
خوارزمية لملاءمة المعاملات.</p>
<p>يمكن استخدام الفئة <a class="reference internal" href="generated/sklearn.linear_model.MultiTaskElasticNetCV.html#sklearn.linear_model.MultiTaskElasticNetCV" title="sklearn.linear_model.MultiTaskElasticNetCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiTaskElasticNetCV</span></code></a> لضبط المعلمات
<code class="docutils literal notranslate"><span class="pre">alpha</span></code> (<span class="math notranslate nohighlight">\(\alpha\)</span>) و <code class="docutils literal notranslate"><span class="pre">l1_ratio</span></code> (<span class="math notranslate nohighlight">\(\rho\)</span>) عن طريق التحقق
المتبادل.</p>
</section>
<section id="least-angle-regression">
<span id="id26"></span><h2><span class="section-number">1.1.7. </span>انحدار الزاوية الصغرى<a class="headerlink" href="#least-angle-regression" title="Link to this heading">#</a></h2>
<p>انحدار الزاوية الصغرى (LARS) هو خوارزمية انحدار لـ
البيانات عالية الأبعاد، طورتها برادلي إيفرون، تريفور هاستي، إيان
جونستون وروبرت تيبيشيراني. LARS مُشابه لانحدار
الخطوة الأمامية. في كل خطوة، يجد الميزة الأكثر ارتباطًا بـ
الهدف. عندما يكون هناك العديد من الميزات ذات الارتباط المتساوي، بدلاً من
الاستمرار على طول نفس الميزة، فإنه يتقدم في اتجاه متساوي الزوايا
بين الميزات.</p>
<p>مزايا LARS هي:</p>
<ul class="simple">
<li><p>إنه فعال عدديًا في السياقات التي يكون فيها عدد الميزات
أكبر بكثير من عدد العينات.</p></li>
<li><p>إنه سريع حسابيًا مثل الاختيار الأمامي وله
نفس ترتيب التعقيد مثل المربعات الصغرى العادية.</p></li>
<li><p>إنه يُنتج مسار حل خطي مُتكسر كامل، وهو
مفيد في التحقق المتبادل أو المحاولات المُشابهة لضبط النموذج.</p></li>
<li><p>إذا كانت ميزتان مُرتبطتين تقريبًا بنفس القدر بالهدف،
فإن معاملاتهما يجب أن تزداد بنفس المعدل تقريبًا.
وبالتالي تتصرف الخوارزمية كما يتوقع الحدس، و
هي أيضًا أكثر استقرارًا.</p></li>
<li><p>من السهل تعديله لإنتاج حلول لمُقدِّرات أخرى،
مثل Lasso.</p></li>
</ul>
<p>تشمل عيوب أسلوب LARS ما يلي:</p>
<ul class="simple">
<li><p>لأن LARS يعتمد على إعادة ملاءمة متكررة لـ
البواقي، سيبدو حساسًا بشكل خاص لـ
آثار الضوضاء. تمت مناقشة هذه المشكلة بالتفصيل بواسطة Weisberg
في قسم المناقشة من مقالة Efron وآخرون (2004) Annals of
Statistics.</p></li>
</ul>
<p>يمكن استخدام نموذج LARS عبر المُقدِّر <a class="reference internal" href="generated/sklearn.linear_model.Lars.html#sklearn.linear_model.Lars" title="sklearn.linear_model.Lars"><code class="xref py py-class docutils literal notranslate"><span class="pre">Lars</span></code></a>، أو تطبيقه
منخفض المستوى <a class="reference internal" href="generated/sklearn.linear_model.lars_path.html#sklearn.linear_model.lars_path" title="sklearn.linear_model.lars_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">lars_path</span></code></a> أو <a class="reference internal" href="generated/sklearn.linear_model.lars_path_gram.html#sklearn.linear_model.lars_path_gram" title="sklearn.linear_model.lars_path_gram"><code class="xref py py-func docutils literal notranslate"><span class="pre">lars_path_gram</span></code></a>.</p>
</section>
<section id="lars-lasso">
<h2><span class="section-number">1.1.8. </span>LARS Lasso<a class="headerlink" href="#lars-lasso" title="Link to this heading">#</a></h2>
<p><a class="reference internal" href="generated/sklearn.linear_model.LassoLars.html#sklearn.linear_model.LassoLars" title="sklearn.linear_model.LassoLars"><code class="xref py py-class docutils literal notranslate"><span class="pre">LassoLars</span></code></a> هو نموذج lasso مُطبق باستخدام خوارزمية LARS،
وعلى عكس التطبيق القائم على النزول الإحداثي،
يُعطي هذا الحل الدقيق، وهو خطي متعدد التعريف كـ
دالة لقاعدة معاملاته.</p>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/linear_model/plot_lasso_lasso_lars_elasticnet_path.html"><img alt="../_images/sphx_glr_plot_lasso_lasso_lars_elasticnet_path_001.png" src="../_images/sphx_glr_plot_lasso_lasso_lars_elasticnet_path_001.png" style="width: 320.0px; height: 240.0px;" />
</a>
</figure>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LassoLars</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="go">LassoLars(alpha=0.1)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span><span class="o">.</span><span class="n">coef_</span>
<span class="go">array([0.6..., 0.        ])</span>
</pre></div>
</div>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/linear_model/plot_lasso_lasso_lars_elasticnet_path.html#sphx-glr-auto-examples-linear-model-plot-lasso-lasso-lars-elasticnet-path-py"><span class="std std-ref">Lasso, Lasso-LARS, and Elastic Net paths</span></a></p></li>
</ul>
<p>تُوفر خوارزمية Lars المسار الكامل للمعاملات على طول
معلمة التنظيم مجانًا تقريبًا، وبالتالي فإن العملية الشائعة
هي استرداد المسار باستخدام إحدى الدالتين <a class="reference internal" href="generated/sklearn.linear_model.lars_path.html#sklearn.linear_model.lars_path" title="sklearn.linear_model.lars_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">lars_path</span></code></a>
أو <a class="reference internal" href="generated/sklearn.linear_model.lars_path_gram.html#sklearn.linear_model.lars_path_gram" title="sklearn.linear_model.lars_path_gram"><code class="xref py py-func docutils literal notranslate"><span class="pre">lars_path_gram</span></code></a>.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="الصيغة-الرياضية">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">الصيغة الرياضية<a class="headerlink" href="#الصيغة-الرياضية" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">الخوارزمية مُشابهة لانحدار الخطوة الأمامية، ولكن بدلاً من
تضمين الميزات في كل خطوة، يتم
زيادة المعاملات المُقدَّرة في اتجاه متساوي الزوايا لكل ارتباط واحد
مع الباقي.</p>
<p class="sd-card-text">بدلاً من إعطاء نتيجة متجه، يتكون حل LARS من
منحنى يُشير إلى الحل لكل قيمة لقاعدة <span class="math notranslate nohighlight">\(\ell_1\)</span> لـ
متجه المعلمة. يتم تخزين مسار المعاملات الكامل في المصفوفة
<code class="docutils literal notranslate"><span class="pre">coef_path_</span></code> ذات الشكل <code class="docutils literal notranslate"><span class="pre">(n_features,</span> <span class="pre">max_features</span> <span class="pre">+</span> <span class="pre">1)</span></code>. العمود الأول
دائمًا صفر.</p>
<p class="rubric">المراجع</p>
<ul class="simple">
<li><p class="sd-card-text">تم تفصيل الخوارزمية الأصلية في الورقة <a class="reference external" href="https://www-stat.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf">انحدار الزاوية الصغرى</a>
بواسطة Hastie وآخرون.</p></li>
</ul>
</div>
</details></section>
<section id="omp">
<span id="id28"></span><h2><span class="section-number">1.1.9. </span>مطاردة التطابق المتعامد (OMP)<a class="headerlink" href="#omp" title="Link to this heading">#</a></h2>
<p><a class="reference internal" href="generated/sklearn.linear_model.OrthogonalMatchingPursuit.html#sklearn.linear_model.OrthogonalMatchingPursuit" title="sklearn.linear_model.OrthogonalMatchingPursuit"><code class="xref py py-class docutils literal notranslate"><span class="pre">OrthogonalMatchingPursuit</span></code></a> و <a class="reference internal" href="generated/sklearn.linear_model.orthogonal_mp.html#sklearn.linear_model.orthogonal_mp" title="sklearn.linear_model.orthogonal_mp"><code class="xref py py-func docutils literal notranslate"><span class="pre">orthogonal_mp</span></code></a> يُطبقان
خوارزمية OMP لتقريب ملاءمة نموذج خطي مع قيود مفروضة على
عدد المعاملات غير الصفرية (أي قاعدة <span class="math notranslate nohighlight">\(\ell_0\)</span> الزائفة).</p>
<p>نظرًا لكونه أسلوب اختيار ميزات أمامي مثل <a class="reference internal" href="#least-angle-regression"><span class="std std-ref">انحدار الزاوية الصغرى</span></a>،
يمكن لمطاردة التطابق المتعامد تقريب متجه الحل الأمثل بعدد
ثابت من العناصر غير الصفرية:</p>
<div class="math notranslate nohighlight">
\[\underset{w}{\operatorname{arg\,min\,}}  ||y - Xw||_2^2 \text{ subject to } ||w||_0 \leq n_{\text{nonzero_coefs}}\]</div>
<p>بدلاً من ذلك، يمكن لمطاردة التطابق المتعامد استهداف خطأ مُحدد بدلاً من
عدد مُحدد من المعاملات غير الصفرية. يمكن التعبير عن هذا كـ:</p>
<div class="math notranslate nohighlight">
\[\underset{w}{\operatorname{arg\,min\,}} ||w||_0 \text{ subject to } ||y-Xw||_2^2 \leq \text{tol}\]</div>
<p>يعتمد OMP على خوارزمية جشعة تتضمن في كل خطوة الذرة الأكثر
ارتباطًا بالباقي الحالي. إنه مُشابه لأسلوب
مطاردة التطابق (MP) الأبسط، ولكنه أفضل من حيث أنه في كل تكرار،
يتم إعادة حساب الباقي باستخدام إسقاط متعامد على فضاء
عناصر القاموس المختارة سابقًا.</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/linear_model/plot_omp.html#sphx-glr-auto-examples-linear-model-plot-omp-py"><span class="std std-ref">Orthogonal Matching Pursuit</span></a></p></li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-4">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-4" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text"><a class="reference external" href="https://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf">https://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf</a></p></li>
<li><p class="sd-card-text"><a class="reference external" href="https://www.di.ens.fr/~mallat/papiers/MallatPursuit93.pdf">مطاردات التطابق مع قواميس التردد الزمني</a>،
S. G. Mallat، Z. Zhang،</p></li>
</ul>
</div>
</details></section>
<section id="bayesian-regression">
<span id="id30"></span><h2><span class="section-number">1.1.10. </span>الانحدار البايزي<a class="headerlink" href="#bayesian-regression" title="Link to this heading">#</a></h2>
<p>يمكن استخدام تقنيات الانحدار البايزي لتضمين معلمات التنظيم
في إجراء التقدير: لا يتم تعيين معلمة التنظيم بمعنى صارم
ولكن يتم ضبطها على البيانات الموجودة.</p>
<p>يمكن القيام بذلك عن طريق إدخال <a class="reference external" href="https://en.wikipedia.org/wiki/Non-informative_prior#Uninformative_priors">مُسبقات غير إعلامية</a>
على المعلمات الفائقة للنموذج.
تنظيم <span class="math notranslate nohighlight">\(\ell_{2}\)</span> المُستخدم في <a class="reference internal" href="#ridge-regression"><span class="std std-ref">انحدار ريدج والتصنيف</span></a>
يُعادل إيجاد أقصى تقدير لاحق في ظل مُسبق غاوسي
على المعاملات <span class="math notranslate nohighlight">\(w\)</span> بدقة <span class="math notranslate nohighlight">\(\lambda^{-1}\)</span>.
بدلاً من تعيين <code class="docutils literal notranslate"><span class="pre">lambda</span></code> يدويًا، من الممكن مُعالجتها كمتغير
عشوائي يتم تقديره من البيانات.</p>
<p>للحصول على نموذج احتمالي بالكامل، يُفترض أن يكون الإخراج <span class="math notranslate nohighlight">\(y\)</span>
موزعًا غاوسيًا حول <span class="math notranslate nohighlight">\(X w\)</span>:</p>
<div class="math notranslate nohighlight">
\[p(y|X,w,\alpha) = \mathcal{N}(y|X w,\alpha^{-1})\]</div>
<p>حيث يتم مُعالجة <span class="math notranslate nohighlight">\(\alpha\)</span> مرة أخرى كمتغير عشوائي يتم
تقديره من البيانات.</p>
<p>مزايا الانحدار البايزي هي:</p>
<ul class="simple">
<li><p>يتكيف مع البيانات الموجودة.</p></li>
<li><p>يمكن استخدامه لتضمين معلمات التنظيم في
إجراء التقدير.</p></li>
</ul>
<p>تشمل عيوب الانحدار البايزي ما يلي:</p>
<ul class="simple">
<li><p>يمكن أن يكون استدلال النموذج مُستهلكًا للوقت.</p></li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-5">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-5" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text">تم تقديم مقدمة جيدة للأساليب البايزية في C. Bishop: Pattern
Recognition and Machine learning</p></li>
<li><p class="sd-card-text">تم تفصيل الخوارزمية الأصلية في كتاب <code class="docutils literal notranslate"><span class="pre">التعلم</span> <span class="pre">البايزي</span> <span class="pre">للشبكات</span>
<span class="pre">العصبية</span></code> بواسطة Radford M. Neal</p></li>
</ul>
</div>
</details><section id="bayesian-ridge-regression">
<span id="id31"></span><h3><span class="section-number">1.1.10.1. </span>انحدار ريدج البايزي<a class="headerlink" href="#bayesian-ridge-regression" title="Link to this heading">#</a></h3>
<p><a class="reference internal" href="generated/sklearn.linear_model.BayesianRidge.html#sklearn.linear_model.BayesianRidge" title="sklearn.linear_model.BayesianRidge"><code class="xref py py-class docutils literal notranslate"><span class="pre">BayesianRidge</span></code></a> يُقدِّر نموذجًا احتماليًا لـ
مشكلة الانحدار كما هو موضح أعلاه.
المُسبق للمعامل <span class="math notranslate nohighlight">\(w\)</span> مُعطى بواسطة توزيع غاوسي كروي:</p>
<div class="math notranslate nohighlight">
\[p(w|\lambda) =
\mathcal{N}(w|0,\lambda^{-1}\mathbf{I}_{p})\]</div>
<p>يتم اختيار المُسبقات على <span class="math notranslate nohighlight">\(\alpha\)</span> و <span class="math notranslate nohighlight">\(\lambda\)</span> لتكون <a class="reference external" href="https://en.wikipedia.org/wiki/Gamma_distribution">توزيعات جاما</a>،
المُسبق المُقترن لدقة التوزيع الغاوسي. يُسمى النموذج الناتج
<em>انحدار ريدج البايزي</em>، وهو مُشابه لـ <a class="reference internal" href="generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge" title="sklearn.linear_model.Ridge"><code class="xref py py-class docutils literal notranslate"><span class="pre">Ridge</span></code></a> الكلاسيكي.</p>
<p>يتم تقدير المعلمات <span class="math notranslate nohighlight">\(w\)</span> و <span class="math notranslate nohighlight">\(\alpha\)</span> و <span class="math notranslate nohighlight">\(\lambda\)</span>
بشكل مُشترك أثناء ملاءمة النموذج، مع تقدير معلمات التنظيم
<span class="math notranslate nohighlight">\(\alpha\)</span> و <span class="math notranslate nohighlight">\(\lambda\)</span> عن طريق تعظيم
<em>احتمالية السجل الهامشي</em>. يعتمد تطبيق scikit-learn
على الخوارزمية الموضحة في الملحق أ من (Tipping، 2001)
حيث يتم تحديث المعلمات <span class="math notranslate nohighlight">\(\alpha\)</span> و <span class="math notranslate nohighlight">\(\lambda\)</span> كما هو مُقترح
في (MacKay، 1992). يمكن تعيين القيمة الأولية لإجراء التعظيم
باستخدام المعلمات الفائقة <code class="docutils literal notranslate"><span class="pre">alpha_init</span></code> و <code class="docutils literal notranslate"><span class="pre">lambda_init</span></code>.</p>
<p>هناك أربع معلمات فائقة أخرى، <span class="math notranslate nohighlight">\(\alpha_1\)</span> و <span class="math notranslate nohighlight">\(\alpha_2\)</span>
و <span class="math notranslate nohighlight">\(\lambda_1\)</span> و <span class="math notranslate nohighlight">\(\lambda_2\)</span> لتوزيعات جاما السابقة على
<span class="math notranslate nohighlight">\(\alpha\)</span> و <span class="math notranslate nohighlight">\(\lambda\)</span>. عادةً ما يتم اختيار هذه لتكون
<em>غير إعلامية</em>. افتراضيًا <span class="math notranslate nohighlight">\(\alpha_1 = \alpha_2 =  \lambda_1 = \lambda_2 = 10^{-6}\)</span>.</p>
<p>يُستخدم انحدار ريدج البايزي للانحدار:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Y</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">BayesianRidge</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
<span class="go">BayesianRidge()</span>
</pre></div>
</div>
<p>بعد ملاءمته، يمكن استخدام النموذج للتنبؤ بقيم جديدة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]])</span>
<span class="go">array([0.50000013])</span>
</pre></div>
</div>
<p>يمكن الوصول إلى معاملات <span class="math notranslate nohighlight">\(w\)</span> للنموذج:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span><span class="o">.</span><span class="n">coef_</span>
<span class="go">array([0.49999993, 0.49999993])</span>
</pre></div>
</div>
<p>نظرًا لإطار العمل البايزي، فإن الأوزان التي تم العثور عليها تختلف قليلاً عن
تلك التي تم العثور عليها بواسطة <span class="xref std std-ref">المربعات الصغرى العادية</span>. ومع ذلك، فإن انحدار
ريدج البايزي أكثر قوة للمشاكل سيئة الوضع.</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/linear_model/plot_bayesian_ridge_curvefit.html#sphx-glr-auto-examples-linear-model-plot-bayesian-ridge-curvefit-py"><span class="std std-ref">Curve Fitting with Bayesian Ridge Regression</span></a></p></li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-6">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-6" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text">القسم 3.3 في Christopher M. Bishop: Pattern Recognition and Machine Learning، 2006</p></li>
<li><p class="sd-card-text">David J. C. MacKay، <a class="reference external" href="https://citeseerx.ist.psu.edu/doc_view/pid/b14c7cc3686e82ba40653c6dff178356a33e5e2c">الاستيفاء البايزي</a>، 1992.</p></li>
<li><p class="sd-card-text">Michael E. Tipping، <a class="reference external" href="https://www.jmlr.org/papers/volume1/tipping01a/tipping01a.pdf">التعلم البايزي المتفرق وآلة متجه الصلة</a>، 2001.</p></li>
</ul>
</div>
</details></section>
<section id="ard">
<span id="automatic-relevance-determination"></span><h3><span class="section-number">1.1.10.2. </span>تحديد الصلة التلقائي - ARD<a class="headerlink" href="#ard" title="Link to this heading">#</a></h3>
<p>تحديد الصلة التلقائي (كما هو مُطبق في
<a class="reference internal" href="generated/sklearn.linear_model.ARDRegression.html#sklearn.linear_model.ARDRegression" title="sklearn.linear_model.ARDRegression"><code class="xref py py-class docutils literal notranslate"><span class="pre">ARDRegression</span></code></a>) هو نوع من النماذج الخطية يُشبه جدًا
<a class="reference internal" href="#id31">انحدار ريدج البايزي</a>، ولكنه يؤدي إلى معاملات <span class="math notranslate nohighlight">\(w\)</span> أكثر تفرقًا
<a class="footnote-reference brackets" href="#id38" id="id34" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a> <a class="footnote-reference brackets" href="#id39" id="id35" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a>.</p>
<p><a class="reference internal" href="generated/sklearn.linear_model.ARDRegression.html#sklearn.linear_model.ARDRegression" title="sklearn.linear_model.ARDRegression"><code class="xref py py-class docutils literal notranslate"><span class="pre">ARDRegression</span></code></a> يضع مُسبقًا مُختلفًا على <span class="math notranslate nohighlight">\(w\)</span>: إنه يُسقط
التوزيع الغاوسي الكروي لتوزيع غاوسي بيضاوي مُتمركز. هذا يعني أنه يمكن
رسم كل معامل <span class="math notranslate nohighlight">\(w_{i}\)</span> من
توزيع غاوسي، مُتمركز على الصفر وبدقة
<span class="math notranslate nohighlight">\(\lambda_{i}\)</span>:</p>
<div class="math notranslate nohighlight">
\[p(w|\lambda) = \mathcal{N}(w|0,A^{-1})\]</div>
<p>مع كون <span class="math notranslate nohighlight">\(A\)</span> مصفوفة قطرية موجبة مُحددة و
<span class="math notranslate nohighlight">\(\text{diag}(A) = \lambda = \{\lambda_{1},...,\lambda_{p}\}\)</span>.</p>
<p>على عكس <a class="reference internal" href="#id31">انحدار ريدج البايزي</a>، كل إحداثي من
<span class="math notranslate nohighlight">\(w_{i}\)</span> له انحرافه المعياري الخاص <span class="math notranslate nohighlight">\(\frac{1}{\lambda_i}\)</span>.
يتم اختيار المُسبق على جميع <span class="math notranslate nohighlight">\(\lambda_i\)</span> ليكون نفس توزيع جاما
المُعطى بواسطة المعلمات الفائقة <span class="math notranslate nohighlight">\(\lambda_1\)</span> و <span class="math notranslate nohighlight">\(\lambda_2\)</span>.</p>
<p>يُعرف ARD أيضًا في الأدبيات باسم <em>التعلم البايزي المتفرق</em> و <em>آلة
متجه الصلة</em> <a class="footnote-reference brackets" href="#id41" id="id36" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a> <a class="footnote-reference brackets" href="#id43" id="id37" role="doc-noteref"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></a>. لمقارنة مُفصلة بين ARD و <a class="reference internal" href="#id31">انحدار
ريدج البايزي</a>، انظر المثال أدناه.</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/linear_model/plot_ard.html#sphx-glr-auto-examples-linear-model-plot-ard-py"><span class="std std-ref">Comparing Linear Bayesian Regressors</span></a></p></li>
</ul>
<p class="rubric">المراجع</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id38" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id34">1</a><span class="fn-bracket">]</span></span>
<p>Christopher M. Bishop: Pattern Recognition and Machine Learning, Chapter 7.2.1</p>
</aside>
<aside class="footnote brackets" id="id39" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id35">2</a><span class="fn-bracket">]</span></span>
<p>David Wipf and Srikantan Nagarajan: <a class="reference external" href="https://papers.nips.cc/paper/3372-a-new-view-of-automatic-relevance-determination.pdf">نظرة جديدة على تحديد الصلة التلقائي</a></p>
</aside>
<aside class="footnote brackets" id="id41" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id36">3</a><span class="fn-bracket">]</span></span>
<p>Michael E. Tipping: <a class="reference external" href="https://www.jmlr.org/papers/volume1/tipping01a/tipping01a.pdf">التعلم البايزي المتفرق وآلة متجه الصلة</a></p>
</aside>
<aside class="footnote brackets" id="id43" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id37">4</a><span class="fn-bracket">]</span></span>
<p>Tristan Fletcher: <a class="reference external" href="https://citeseerx.ist.psu.edu/doc_view/pid/3dc9d625404fdfef6eaccc3babddefe4c176abd4">شرح آلات متجه الصلة</a></p>
</aside>
</aside>
</section>
</section>
<section id="logistic-regression">
<span id="id45"></span><h2><span class="section-number">1.1.11. </span>الانحدار اللوجستي<a class="headerlink" href="#logistic-regression" title="Link to this heading">#</a></h2>
<p>يتم تطبيق الانحدار اللوجستي في <a class="reference internal" href="generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="sklearn.linear_model.LogisticRegression"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogisticRegression</span></code></a>. على الرغم من
اسمه، فإنه يتم تطبيقه كنموذج خطي للتصنيف بدلاً من
الانحدار من حيث تسمية scikit-learn / ML. يُعرف الانحدار
اللوجستي أيضًا في الأدبيات باسم انحدار logit،
تصنيف الحد الأقصى للإنتروبيا (MaxEnt) أو المُصنف اللوغاريتمي الخطي. في هذا
النموذج، يتم نمذجة الاحتمالات التي تصف النتائج المُمكنة لتجربة
واحدة باستخدام <a class="reference external" href="https://en.wikipedia.org/wiki/Logistic_function">دالة لوجستية</a>.</p>
<p>يمكن لهذا التطبيق ملاءمة الانحدار اللوجستي الثنائي أو واحد مقابل البقية أو
متعدد الحدود مع تنظيم <span class="math notranslate nohighlight">\(\ell_1\)</span> أو <span class="math notranslate nohighlight">\(\ell_2\)</span> أو Elastic-Net
اختياري.</p>
<div class="admonition note">
<p class="admonition-title">ملاحظة</p>
<p><strong>التنظيم</strong></p>
<p>يتم تطبيق التنظيم افتراضيًا، وهو أمر شائع في التعلم
الآلي ولكن ليس في الإحصاء. ميزة أخرى للتنظيم هي
أنه يُحسِّن الاستقرار العددي. لا يُعادل التنظيم
تعيين C إلى قيمة عالية جدًا.</p>
</div>
<div class="admonition note">
<p class="admonition-title">ملاحظة</p>
<p><strong>الانحدار اللوجستي كحالة خاصة من النماذج الخطية المُعممة (GLM)</strong></p>
<p>الانحدار اللوجستي هو حالة خاصة من
<a class="reference internal" href="#generalized-linear-models"><span class="std std-ref">النماذج الخطية المُعممة</span></a> مع توزيع شرطي ذي حدين / برنولي
وربط Logit. يمكن استخدام الناتج العددي للانحدار
اللوجستي، وهو الاحتمال المُتوقع، كمُصنف
عن طريق تطبيق عتبة (افتراضيًا 0.5) عليه. هذه هي الطريقة التي يتم
تطبيقها في scikit-learn، لذلك يتوقع هدفًا فئويًا، مما
يجعل الانحدار اللوجستي مُصنفًا.</p>
</div>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/linear_model/plot_logistic_l1_l2_sparsity.html#sphx-glr-auto-examples-linear-model-plot-logistic-l1-l2-sparsity-py"><span class="std std-ref">L1 Penalty and Sparsity in Logistic Regression</span></a></p></li>
<li><p><a class="reference internal" href="../auto_examples/linear_model/plot_logistic_path.html#sphx-glr-auto-examples-linear-model-plot-logistic-path-py"><span class="std std-ref">Regularization path of L1- Logistic Regression</span></a></p></li>
<li><p><a class="reference internal" href="../auto_examples/linear_model/plot_logistic_multinomial.html#sphx-glr-auto-examples-linear-model-plot-logistic-multinomial-py"><span class="std std-ref">Decision Boundaries of Multinomial and One-vs-Rest Logistic Regression</span></a></p></li>
<li><p><a class="reference internal" href="../auto_examples/linear_model/plot_sparse_logistic_regression_20newsgroups.html#sphx-glr-auto-examples-linear-model-plot-sparse-logistic-regression-20newsgroups-py"><span class="std std-ref">Multiclass sparse logistic regression on 20newgroups</span></a></p></li>
<li><p><a class="reference internal" href="../auto_examples/linear_model/plot_sparse_logistic_regression_mnist.html#sphx-glr-auto-examples-linear-model-plot-sparse-logistic-regression-mnist-py"><span class="std std-ref">MNIST classification using multinomial logistic + L1</span></a></p></li>
<li><p><a class="reference internal" href="../auto_examples/classification/plot_classification_probability.html#sphx-glr-auto-examples-classification-plot-classification-probability-py"><span class="std std-ref">Plot classification probability</span></a></p></li>
</ul>
<section id="id47">
<h3><span class="section-number">1.1.11.1. </span>الحالة الثنائية<a class="headerlink" href="#id47" title="Link to this heading">#</a></h3>
<p>لتسهيل التدوين، نفترض أن الهدف <span class="math notranslate nohighlight">\(y_i\)</span> يأخذ قيمًا في
المجموعة <span class="math notranslate nohighlight">\(\{0, 1\}\)</span> لنقطة البيانات <span class="math notranslate nohighlight">\(i\)</span>.
بمجرد ملاءمته، أسلوب <a class="reference internal" href="generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict_proba" title="sklearn.linear_model.LogisticRegression.predict_proba"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict_proba</span></code></a>
لـ <a class="reference internal" href="generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="sklearn.linear_model.LogisticRegression"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogisticRegression</span></code></a> يتنبأ
باحتمالية الفئة الإيجابية <span class="math notranslate nohighlight">\(P(y_i=1|X_i)\)</span> كـ</p>
<div class="math notranslate nohighlight">
\[\hat{p}(X_i) = \operatorname{expit}(X_i w + w_0) = \frac{1}{1 + \exp(-X_i w - w_0)}.\]</div>
<p>كمشكلة تحسين، يُقلل الانحدار اللوجستي
الثنائي مع مُصطلح التنظيم <span class="math notranslate nohighlight">\(r(w)\)</span> دالة التكلفة التالية:</p>
<div class="math notranslate nohighlight" id="regularized-logistic-loss">
<span id="equation-regularized-logistic-loss"></span><span class="eqno">(1)<a class="headerlink" href="#regularized-logistic-loss" title="Link to this equation">#</a></span>\[\min_{w} \frac{1}{S}\sum_{i=1}^n s_i
\left(-y_i \log(\hat{p}(X_i)) - (1 - y_i) \log(1 - \hat{p}(X_i))\right)
+ \frac{r(w)}{S C}\,,\]</div>
<p>حيث <span class="math notranslate nohighlight">\({s_i}\)</span> تُقابل الأوزان المُعيَّنة من قبل المستخدم لـ
عينة تدريب مُحددة (يتم تشكيل المتجه <span class="math notranslate nohighlight">\(s\)</span> عن طريق
ضرب أوزان الفئة وأوزان العينة حسب العنصر)،
والمجموع <span class="math notranslate nohighlight">\(S = \sum_{i=1}^n s_i\)</span>.</p>
<p>نُقدم حاليًا أربعة خيارات لمُصطلح التنظيم <span class="math notranslate nohighlight">\(r(w)\)</span> عبر
وسيطة <code class="docutils literal notranslate"><span class="pre">penalty</span></code>:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>penalty</p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(r(w)\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">None</span></code></p></td>
<td><p><span class="math notranslate nohighlight">\(0\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(\ell_1\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\|w\|_1\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(\ell_2\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\frac{1}{2}\|w\|_2^2 = \frac{1}{2}w^T w\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">ElasticNet</span></code></p></td>
<td><p><span class="math notranslate nohighlight">\(\frac{1 - \rho}{2}w^T w + \rho \|w\|_1\)</span></p></td>
</tr>
</tbody>
</table>
</div>
<p>بالنسبة لـ ElasticNet، <span class="math notranslate nohighlight">\(\rho\)</span> (التي تُقابل معلمة <code class="docutils literal notranslate"><span class="pre">l1_ratio</span></code>)
تتحكم في قوة تنظيم <span class="math notranslate nohighlight">\(\ell_1\)</span> مقابل تنظيم
<span class="math notranslate nohighlight">\(\ell_2\)</span>. Elastic-Net يُعادل <span class="math notranslate nohighlight">\(\ell_1\)</span> عندما
<span class="math notranslate nohighlight">\(\rho = 1\)</span> ويُعادل <span class="math notranslate nohighlight">\(\ell_2\)</span> عندما <span class="math notranslate nohighlight">\(\rho=0\)</span>.</p>
<p>لاحظ أن مقياس أوزان الفئة وأوزان العينة سيؤثر على
مشكلة التحسين. على سبيل المثال، ضرب أوزان العينة في
ثابت <span class="math notranslate nohighlight">\(b&gt;0\)</span> يُعادل ضرب قوة التنظيم (العكسية) <code class="docutils literal notranslate"><span class="pre">C</span></code> في
<span class="math notranslate nohighlight">\(b\)</span>.</p>
</section>
<section id="id48">
<h3><span class="section-number">1.1.11.2. </span>حالة متعددة الحدود<a class="headerlink" href="#id48" title="Link to this heading">#</a></h3>
<p>يمكن تمديد الحالة الثنائية إلى <span class="math notranslate nohighlight">\(K\)</span> فئات مما يؤدي إلى
الانحدار اللوجستي متعدد الحدود، انظر أيضًا <a class="reference external" href="https://en.wikipedia.org/wiki/Multinomial_logistic_regression#As_a_log-linear_model">النموذج اللوغاريتمي الخطي</a>.</p>
<div class="admonition note">
<p class="admonition-title">ملاحظة</p>
<p>من الممكن تحديد معلمات نموذج تصنيف <span class="math notranslate nohighlight">\(K\)</span> فئة
باستخدام <span class="math notranslate nohighlight">\(K-1\)</span> متجهات وزن فقط، وترك احتمال فئة واحدة مُحددًا
تمامًا بواسطة احتمالات الفئات الأخرى من خلال الاستفادة من حقيقة أن جميع
احتمالات الفئات يجب أن يصل مجموعها إلى واحد. نختار عمدًا زيادة معلمات
النموذج باستخدام <span class="math notranslate nohighlight">\(K\)</span> متجهات وزن لسهولة التطبيق وللحفاظ على
التحيز الاستقرائي المتماثل فيما يتعلق بترتيب الفئات، انظر <a class="footnote-reference brackets" href="#id66" id="id50" role="doc-noteref"><span class="fn-bracket">[</span>16<span class="fn-bracket">]</span></a>. يصبح هذا التأثير
مهمًا بشكل خاص عند استخدام التنظيم. قد يكون اختيار زيادة المعلمات
ضارًا بالنماذج غير المُعاقبة لأنه قد لا يكون الحل فريدًا، كما هو موضح
في <a class="footnote-reference brackets" href="#id66" id="id51" role="doc-noteref"><span class="fn-bracket">[</span>16<span class="fn-bracket">]</span></a>.</p>
</div>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="التفاصيل-الرياضية-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">التفاصيل الرياضية<a class="headerlink" href="#التفاصيل-الرياضية-3" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">افترض أن <span class="math notranslate nohighlight">\(y_i \in {1, \ldots, K}\)</span> هو متغير الهدف المُرمَّز (ترتيبيًا)
للملاحظة <span class="math notranslate nohighlight">\(i\)</span>.
بدلاً من متجه معاملات واحد، لدينا الآن
مصفوفة من المعاملات <span class="math notranslate nohighlight">\(W\)</span> حيث يتوافق كل متجه صف <span class="math notranslate nohighlight">\(W_k\)</span> مع الفئة
<span class="math notranslate nohighlight">\(k\)</span>. نهدف إلى التنبؤ باحتمالات الفئة <span class="math notranslate nohighlight">\(P(y_i=k|X_i)\)</span> عبر
<a class="reference internal" href="generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict_proba" title="sklearn.linear_model.LogisticRegression.predict_proba"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict_proba</span></code></a> كـ:</p>
<div class="math notranslate nohighlight">
\[\hat{p}_k(X_i) = \frac{\exp(X_i W_k + W_{0, k})}{\sum_{l=0}^{K-1} \exp(X_i W_l + W_{0, l})}.\]</div>
<p class="sd-card-text">يصبح الهدف للتحسين</p>
<div class="math notranslate nohighlight">
\[\min_W -\frac{1}{S}\sum_{i=1}^n \sum_{k=0}^{K-1} s_{ik} [y_i = k] \log(\hat{p}_k(X_i))
+ \frac{r(W)}{S C}\,,\]</div>
<p class="sd-card-text">حيث <span class="math notranslate nohighlight">\([P]\)</span> يُمثل قوس إيفرسون الذي يُقيَّم إلى <span class="math notranslate nohighlight">\(0\)</span>
إذا كان <span class="math notranslate nohighlight">\(P\)</span> خطأ، وإلا فإنه يُقيَّم إلى <span class="math notranslate nohighlight">\(1\)</span>.</p>
<p class="sd-card-text">مرة أخرى، <span class="math notranslate nohighlight">\(s_{ik}\)</span> هي الأوزان التي يُعيِّنها المستخدم (ضرب أوزان
العينة وأوزان الفئة) مع مجموعها <span class="math notranslate nohighlight">\(S = \sum_{i=1}^n \sum_{k=0}^{K-1} s_{ik}\)</span>.</p>
<p class="sd-card-text">نُقدم حاليًا أربعة خيارات
لمُصطلح التنظيم <span class="math notranslate nohighlight">\(r(W)\)</span> عبر وسيطة <code class="docutils literal notranslate"><span class="pre">penalty</span></code>، حيث <span class="math notranslate nohighlight">\(m\)</span>
هو عدد الميزات:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p class="sd-card-text">penalty</p></th>
<th class="head"><p class="sd-card-text"><span class="math notranslate nohighlight">\(r(W)\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p class="sd-card-text"><code class="docutils literal notranslate"><span class="pre">None</span></code></p></td>
<td><p class="sd-card-text"><span class="math notranslate nohighlight">\(0\)</span></p></td>
</tr>
<tr class="row-odd"><td><p class="sd-card-text"><span class="math notranslate nohighlight">\(\ell_1\)</span></p></td>
<td><p class="sd-card-text"><span class="math notranslate nohighlight">\(\|W\|_{1,1} = \sum_{i=1}^m\sum_{j=1}^{K}|W_{i,j}|\)</span></p></td>
</tr>
<tr class="row-even"><td><p class="sd-card-text"><span class="math notranslate nohighlight">\(\ell_2\)</span></p></td>
<td><p class="sd-card-text"><span class="math notranslate nohighlight">\(\frac{1}{2}\|W\|_F^2 = \frac{1}{2}\sum_{i=1}^m\sum_{j=1}^{K} W_{i,j}^2\)</span></p></td>
</tr>
<tr class="row-odd"><td><p class="sd-card-text"><code class="docutils literal notranslate"><span class="pre">ElasticNet</span></code></p></td>
<td><p class="sd-card-text"><span class="math notranslate nohighlight">\(\frac{1 - \rho}{2}\|W\|_F^2 + \rho \|W\|_{1,1}\)</span></p></td>
</tr>
</tbody>
</table>
</div>
</div>
</details></section>
<section id="logistic-regression-solvers">
<span id="id52"></span><h3><span class="section-number">1.1.11.3. </span>المحللات<a class="headerlink" href="#logistic-regression-solvers" title="Link to this heading">#</a></h3>
<p>المحللات المُطبقة في الفئة <a class="reference internal" href="generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="sklearn.linear_model.LogisticRegression"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogisticRegression</span></code></a>
هي &quot;lbfgs&quot; و &quot;liblinear&quot; و &quot;newton-cg&quot; و &quot;newton-cholesky&quot; و &quot;sag&quot; و &quot;saga&quot;:</p>
<p>يُلخص الجدول التالي العقوبات ومتعدد الحدود متعدد الفئات المدعومة
من قِبل كل محلل:</p>
<p>يتم استخدام محلل &quot;lbfgs&quot; افتراضيًا لمتانته. بالنسبة لمجموعات البيانات
الكبيرة، عادةً ما يكون محلل &quot;saga&quot; أسرع.
لمجموعة البيانات الكبيرة، يمكنك أيضًا التفكير في استخدام <a class="reference internal" href="generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier" title="sklearn.linear_model.SGDClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">SGDClassifier</span></code></a>
مع <code class="docutils literal notranslate"><span class="pre">loss=&quot;log_loss&quot;</span></code>، والذي قد يكون أسرع ولكنه يتطلب المزيد من الضبط.</p>
<section id="liblinear-differences">
<span id="id53"></span><h4><span class="section-number">1.1.11.3.1. </span>الاختلافات بين المحللات<a class="headerlink" href="#liblinear-differences" title="Link to this heading">#</a></h4>
<p>قد يكون هناك اختلاف في الدرجات التي تم الحصول عليها بين
<a class="reference internal" href="generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="sklearn.linear_model.LogisticRegression"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogisticRegression</span></code></a> مع <code class="docutils literal notranslate"><span class="pre">solver=liblinear</span></code> أو
<a class="reference internal" href="generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC" title="sklearn.svm.LinearSVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">LinearSVC</span></code></a> ومكتبة liblinear الخارجية
مباشرةً، عندما <code class="docutils literal notranslate"><span class="pre">fit_intercept=False</span></code> و <code class="docutils literal notranslate"><span class="pre">coef_</span></code> المُناسب (أو)
البيانات التي سيتم التنبؤ بها هي أصفار. هذا لأن للعينة (العينات) ذات
<code class="docutils literal notranslate"><span class="pre">decision_function</span></code> صفر، يتنبأ <a class="reference internal" href="generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="sklearn.linear_model.LogisticRegression"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogisticRegression</span></code></a> و
<a class="reference internal" href="generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC" title="sklearn.svm.LinearSVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">LinearSVC</span></code></a> بالفئة
السالبة، بينما يتنبأ liblinear بالفئة الموجبة. لاحظ أن النموذج
مع <code class="docutils literal notranslate"><span class="pre">fit_intercept=False</span></code> ويحتوي على العديد من العينات مع <code class="docutils literal notranslate"><span class="pre">decision_function</span></code>
صفر، من المرجح أن يكون نموذجًا سيئًا مُفرطًا في التعميم، ويُنصح بتعيين
<code class="docutils literal notranslate"><span class="pre">fit_intercept=True</span></code> وزيادة <code class="docutils literal notranslate"><span class="pre">intercept_scaling</span></code>.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="تفاصيل-المحللات">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">تفاصيل المحللات<a class="headerlink" href="#تفاصيل-المحللات" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text">يستخدم محلل &quot;liblinear&quot; خوارزمية النزول الإحداثي (CD)، ويعتمد
على مكتبة C ++ <a class="reference external" href="https://www.csie.ntu.edu.tw/~cjlin/liblinear/">LIBLINEAR الممتازة</a>، التي يتم شحنها مع
scikit-learn. ومع ذلك، لا يمكن لخوارزمية CD المُطبقة في liblinear تعلم
نموذج متعدد الحدود (متعدد الفئات) حقيقي؛ بدلاً من ذلك، يتم
تحليل مشكلة التحسين بطريقة &quot;واحد مقابل البقية&quot; لذلك يتم
تدريب مُصنِّفات ثنائية مُنفصلة لجميع الفئات. يحدث هذا تحت الغطاء،
لذلك تتصرف مثيلات <a class="reference internal" href="generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="sklearn.linear_model.LogisticRegression"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogisticRegression</span></code></a> التي تستخدم هذا المحلل
كمُصنِّفات متعددة الفئات. بالنسبة لتنظيم <span class="math notranslate nohighlight">\(\ell_1\)</span>، يسمح <a class="reference internal" href="generated/sklearn.svm.l1_min_c.html#sklearn.svm.l1_min_c" title="sklearn.svm.l1_min_c"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.svm.l1_min_c</span></code></a>
بحساب الحد الأدنى لـ C من أجل الحصول على نموذج غير &quot;فارغ&quot; (جميع أوزان
الميزات إلى الصفر).</p></li>
<li><p class="sd-card-text">تدعم محللات &quot;lbfgs&quot; و &quot;newton-cg&quot; و &quot;sag&quot; فقط تنظيم <span class="math notranslate nohighlight">\(\ell_2\)</span>
أو عدم التنظيم، ووجد أنها تتقارب بشكل أسرع بالنسبة لبعض
البيانات عالية الأبعاد. يؤدي تعيين <code class="docutils literal notranslate"><span class="pre">multi_class</span></code> إلى &quot;multinomial&quot; مع هذه المحللات
إلى تعلم نموذج انحدار لوجستي متعدد الحدود حقيقي <a class="footnote-reference brackets" href="#id59" id="id54" role="doc-noteref"><span class="fn-bracket">[</span>5<span class="fn-bracket">]</span></a>، مما يعني أن
تقديرات احتماله يجب أن تكون مُعايرة بشكل أفضل من إعداد &quot;واحد مقابل
البقية&quot; الافتراضي.</p></li>
<li><p class="sd-card-text">يستخدم محلل &quot;sag&quot; نزول التدرج العشوائي المتوسط <a class="footnote-reference brackets" href="#id60" id="id55" role="doc-noteref"><span class="fn-bracket">[</span>6<span class="fn-bracket">]</span></a>. إنه أسرع
من المحللات الأخرى لمجموعات البيانات الكبيرة، عندما يكون كل من عدد العينات وعدد
الميزات كبيرًا.</p></li>
<li><p class="sd-card-text">محلل &quot;saga&quot; <a class="footnote-reference brackets" href="#id62" id="id56" role="doc-noteref"><span class="fn-bracket">[</span>7<span class="fn-bracket">]</span></a> هو مُتغير من &quot;sag&quot; يدعم أيضًا
<code class="docutils literal notranslate"><span class="pre">penalty=&quot;l1&quot;</span></code> غير السلس. لذلك هذا هو المحلل المُفضل
للانحدار اللوجستي متعدد الحدود المتفرق. وهو أيضًا المحلل الوحيد الذي يدعم
<code class="docutils literal notranslate"><span class="pre">penalty=&quot;elasticnet&quot;</span></code>.</p></li>
<li><p class="sd-card-text">&quot;lbfgs&quot; هي خوارزمية تحسين تُقارب
خوارزمية Broyden-Fletcher-Goldfarb-Shanno <a class="footnote-reference brackets" href="#id63" id="id57" role="doc-noteref"><span class="fn-bracket">[</span>8<span class="fn-bracket">]</span></a>، التي تنتمي إلى
أساليب شبه نيوتن. على هذا النحو، يمكنها التعامل مع مجموعة واسعة من بيانات
التدريب المُختلفة، وبالتالي فهي المحلل الافتراضي. ومع ذلك، فإن أدائها يُعاني
على مجموعات البيانات ذات المقياس السيئ وعلى مجموعات البيانات ذات الميزات الفئوية
المُرمَّزة أحاديًا مع فئات نادرة.</p></li>
<li><p class="sd-card-text">محلل &quot;newton-cholesky&quot; هو محلل نيوتن دقيق يحسب مصفوفة
هيسيان ويحل النظام الخطي الناتج. إنه خيار جيد جدًا
لـ <code class="docutils literal notranslate"><span class="pre">n_samples</span></code> &gt;&gt; <code class="docutils literal notranslate"><span class="pre">n_features</span></code>، لكن لديه بعض أوجه القصور: يتم دعم
تنظيم <span class="math notranslate nohighlight">\(\ell_2\)</span> فقط. علاوة على ذلك، نظرًا لحساب مصفوفة
هيسيان صراحةً، فإن استخدام الذاكرة له تبعية تربيعية على <code class="docutils literal notranslate"><span class="pre">n_features</span></code>
وكذلك على <code class="docutils literal notranslate"><span class="pre">n_classes</span></code>. ونتيجة لذلك، يتم تطبيق مخطط واحد مقابل البقية فقط
للحالة متعددة الفئات.</p></li>
</ul>
<p class="sd-card-text">لمقارنة بعض هذه المحللات، انظر <a class="footnote-reference brackets" href="#id64" id="id58" role="doc-noteref"><span class="fn-bracket">[</span>9<span class="fn-bracket">]</span></a>.</p>
<p class="rubric">المراجع</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id59" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id54">5</a><span class="fn-bracket">]</span></span>
<p class="sd-card-text">Christopher M. Bishop: Pattern Recognition and Machine Learning، الفصل 4.3.4</p>
</aside>
<aside class="footnote brackets" id="id60" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id55">6</a><span class="fn-bracket">]</span></span>
<p class="sd-card-text">Mark Schmidt, Nicolas Le Roux, and Francis Bach: <a class="reference external" href="https://hal.inria.fr/hal-00860051/document">تقليل المجاميع المحدودة باستخدام متوسط التدرج العشوائي.</a></p>
</aside>
<aside class="footnote brackets" id="id62" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id56">7</a><span class="fn-bracket">]</span></span>
<p class="sd-card-text">Aaron Defazio, Francis Bach, Simon Lacoste-Julien:
<a class="reference external" href="https://arxiv.org/abs/1407.0202">SAGA: أسلوب تدرج تزايدي سريع مع دعم لـ
أهداف مُركبة غير مُحدبة بقوة.</a></p>
</aside>
<aside class="footnote brackets" id="id63" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id57">8</a><span class="fn-bracket">]</span></span>
<p class="sd-card-text"><a class="reference external" href="https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm">https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm</a></p>
</aside>
<aside class="footnote brackets" id="id64" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id58">9</a><span class="fn-bracket">]</span></span>
<p class="sd-card-text">Thomas P. Minka <a class="reference external" href="https://tminka.github.io/papers/logreg/minka-logreg.pdf">&quot;مقارنة بين المُحسِّنات العددية للانحدار اللوجستي&quot;</a></p>
</aside>
<aside class="footnote brackets" id="id66" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>16<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id50">1</a>,<a role="doc-backlink" href="#id51">2</a>)</span>
<p class="sd-card-text"><a class="reference external" href="https://arxiv.org/abs/1311.6529">Simon, Noah, J. Friedman and T. Hastie.
&quot;خوارزمية نزول الكتل للانحدار متعدد الاستجابات
و متعدد الحدود المُعاقب للمجموعة.&quot;</a></p>
</aside>
</aside>
</div>
</details><div class="admonition note">
<p class="admonition-title">ملاحظة</p>
<p><strong>اختيار الميزات مع الانحدار اللوجستي المتفرق</strong></p>
<p>يُعطي الانحدار اللوجستي مع عقوبة <span class="math notranslate nohighlight">\(\ell_1\)</span> نماذج متفرقة، ويمكن
بالتالي استخدامه لإجراء اختيار الميزات، كما هو مُفصل في
<a class="reference internal" href="feature_selection.html#l1-feature-selection"><span class="std std-ref">اختيار الميزات القائم على L1</span></a>.</p>
</div>
<div class="admonition note">
<p class="admonition-title">ملاحظة</p>
<p><strong>تقدير قيمة p</strong></p>
<p>من الممكن الحصول على قيم p وفترات ثقة لـ
المعاملات في حالات الانحدار بدون عقوبة. تدعم حزمة <a class="reference external" href="https://pypi.org/project/statsmodels/">statsmodels</a> هذا أصلاً.
داخل sklearn، يمكن للمرء استخدام التمهيد بدلاً من ذلك أيضًا.</p>
</div>
<p><a class="reference internal" href="generated/sklearn.linear_model.LogisticRegressionCV.html#sklearn.linear_model.LogisticRegressionCV" title="sklearn.linear_model.LogisticRegressionCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogisticRegressionCV</span></code></a> يُطبق الانحدار اللوجستي مع
دعم التحقق المتبادل المُدمج، لإيجاد معلمات <code class="docutils literal notranslate"><span class="pre">C</span></code> و <code class="docutils literal notranslate"><span class="pre">l1_ratio</span></code>
المثلى وفقًا للسمة <code class="docutils literal notranslate"><span class="pre">scoring</span></code>. تم العثور على محللات &quot;newton-cg&quot; و &quot;sag&quot;
و &quot;saga&quot; و &quot;lbfgs&quot; لتكون أسرع للبيانات الكثيفة عالية الأبعاد،
بسبب البدء الدافئ (انظر <a class="reference internal" href="../glossary.html#term-warm_start"><span class="xref std std-term">المُصطلحات</span></a>).</p>
</section>
</section>
</section>
<section id="generalized-linear-models">
<span id="generalized-linear-regression"></span><span id="id67"></span><h2><span class="section-number">1.1.12. </span>النماذج الخطية المُعممة<a class="headerlink" href="#generalized-linear-models" title="Link to this heading">#</a></h2>
<p>تُوسِّع النماذج الخطية المُعممة (GLM) النماذج الخطية بطريقتين
<a class="footnote-reference brackets" href="#id70" id="id68" role="doc-noteref"><span class="fn-bracket">[</span>10<span class="fn-bracket">]</span></a>. أولاً، ترتبط القيم المُتوقعة <span class="math notranslate nohighlight">\(\hat{y}\)</span> بتركيبة
خطية من متغيرات الإدخال <span class="math notranslate nohighlight">\(X\)</span> عبر دالة ربط عكسية
<span class="math notranslate nohighlight">\(h\)</span> كـ</p>
<div class="math notranslate nohighlight">
\[\hat{y}(w, X) = h(Xw).\]</div>
<p>ثانيًا، يتم استبدال دالة الخسارة التربيعية بالانحراف
الوحيد <span class="math notranslate nohighlight">\(d\)</span> لتوزيع في الأسرة الأسية (أو بشكل أكثر دقة،
نموذج تشتت أسي تناسلي (EDM) <a class="footnote-reference brackets" href="#id71" id="id69" role="doc-noteref"><span class="fn-bracket">[</span>11<span class="fn-bracket">]</span></a>).</p>
<p>تصبح مشكلة التصغير:</p>
<div class="math notranslate nohighlight">
\[\min_{w} \frac{1}{2 n_{\text{samples}}} \sum_i d(y_i, \hat{y}_i) + \frac{\alpha}{2} ||w||_2^2,\]</div>
<p>حيث <span class="math notranslate nohighlight">\(\alpha\)</span> هي عقوبة تنظيم L2. عندما يتم توفير أوزان
العينة، يصبح المتوسط متوسطًا موزونًا.</p>
<p>يسرد الجدول التالي بعض EDMs المُحددة وانحرافها الوحيد:</p>
<p>يتم توضيح دوال كثافة الاحتمال (PDF) لهذه التوزيعات
في الشكل التالي،</p>
<figure class="align-center" id="id89">
<a class="reference internal image-reference" href="../_images/poisson_gamma_tweedie_distributions.png"><img alt="../_images/poisson_gamma_tweedie_distributions.png" src="../_images/poisson_gamma_tweedie_distributions.png" style="width: 1200.0px; height: 350.0px;" />
</a>
<figcaption>
<p><span class="caption-text">PDF لمتغير عشوائي Y يتبع توزيعات بواسون وتويدي (القوة = 1.5) وجاما
بقيم متوسطة مختلفة (<span class="math notranslate nohighlight">\(\mu\)</span>). لاحظ كتلة النقطة
عند <span class="math notranslate nohighlight">\(Y=0\)</span> لتوزيع بواسون وتوزيع تويدي (القوة = 1.5)،
ولكن ليس لتوزيع جاما الذي له مجال هدف موجب تمامًا.</span><a class="headerlink" href="#id89" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>توزيع برنولي هو توزيع احتمالي منفصل يُنمذج تجربة
برنولي - حدث له نتيجتان فقط متنافيتان.
التوزيع الفئوي هو تعميم لتوزيع برنولي
لمتغير عشوائي فئوي. بينما يحتوي متغير عشوائي في توزيع برنولي
على نتيجتين مُمكنتين، يمكن لمتغير عشوائي فئوي أن يأخذ
إحدى الفئات K المُمكنة، مع تحديد احتمال كل فئة
بشكل مُنفصل.</p>
<p>يعتمد اختيار التوزيع على المشكلة المطروحة:</p>
<ul class="simple">
<li><p>إذا كانت القيم المستهدفة <span class="math notranslate nohighlight">\(y\)</span> عبارة عن أعداد (ذات قيم صحيحة غير
سالبة) أو ترددات نسبية (غير سالبة)، فقد تستخدم توزيع بواسون
بربط سجل.</p></li>
<li><p>إذا كانت القيم المستهدفة ذات قيم موجبة ومنحرفة، فقد تُجرب توزيع جاما
بربط سجل.</p></li>
<li><p>إذا بدت القيم المستهدفة أثقل من توزيع جاما، فقد
تُجرب توزيع غاوسي عكسي (أو حتى قوى تباين أعلى
لعائلة تويدي).</p></li>
<li><p>إذا كانت القيم المستهدفة <span class="math notranslate nohighlight">\(y\)</span> احتمالات، يمكنك استخدام توزيع
برنولي. يمكن استخدام توزيع برنولي مع ربط logit للتصنيف
الثنائي. يمكن استخدام التوزيع الفئوي مع ربط softmax لـ
التصنيف متعدد الفئات.</p></li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="أمثلة-على-حالات-الاستخدام">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">أمثلة على حالات الاستخدام<a class="headerlink" href="#أمثلة-على-حالات-الاستخدام" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text">نمذجة الزراعة / الطقس: عدد أحداث المطر سنويًا (بويسون)،
كمية هطول الأمطار لكل حدث (جاما)، إجمالي هطول الأمطار سنويًا (تويدي /
مُركب بواسون جاما).</p></li>
<li><p class="sd-card-text">نمذجة المخاطر / تسعير بوليصة التأمين: عدد أحداث المطالبة /
حامل البوليصة سنويًا (بويسون)، التكلفة لكل حدث (جاما)، التكلفة الإجمالية لكل
حامل بوليصة سنويًا (تويدي / مُركب بواسون جاما).</p></li>
<li><p class="sd-card-text">التخلف عن سداد الائتمان: احتمال عدم سداد قرض (برنولي).</p></li>
<li><p class="sd-card-text">الكشف عن الاحتيال: احتمال أن تكون معاملة مالية مثل تحويل نقدي
معاملة احتيالية (برنولي).</p></li>
<li><p class="sd-card-text">الصيانة التنبؤية: عدد أحداث انقطاع الإنتاج سنويًا
(بويسون)، مدة الانقطاع (جاما)، إجمالي وقت الانقطاع سنويًا
(تويدي / مُركب بواسون جاما).</p></li>
<li><p class="sd-card-text">اختبار الأدوية الطبية: احتمال علاج مريض في مجموعة من التجارب أو
احتمال تعرض المريض لآثار جانبية (برنولي).</p></li>
<li><p class="sd-card-text">تصنيف الأخبار: تصنيف المقالات الإخبارية إلى ثلاث فئات
وهي أخبار الأعمال والسياسة وأخبار الترفيه (فئوي).</p></li>
</ul>
</div>
</details><p class="rubric">المراجع</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id70" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id68">10</a><span class="fn-bracket">]</span></span>
<p>McCullagh, Peter; Nelder, John (1989). النماذج الخطية
المُعممة، الطبعة الثانية. Boca Raton: Chapman and Hall/CRC. ISBN 0-412-31760-5.</p>
</aside>
<aside class="footnote brackets" id="id71" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id69">11</a><span class="fn-bracket">]</span></span>
<p>Jørgensen, B. (1992). نظرية نماذج التشتت الأسي
وتحليل الانحراف. Monografias de matemática, no. 51.  انظر أيضًا
<a class="reference external" href="https://en.wikipedia.org/wiki/Exponential_dispersion_model">نموذج التشتت الأسي.</a></p>
</aside>
</aside>
<section id="id73">
<h3><span class="section-number">1.1.12.1. </span>الاستخدام<a class="headerlink" href="#id73" title="Link to this heading">#</a></h3>
<p><a class="reference internal" href="generated/sklearn.linear_model.TweedieRegressor.html#sklearn.linear_model.TweedieRegressor" title="sklearn.linear_model.TweedieRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">TweedieRegressor</span></code></a> يُطبق نموذجًا خطيًا مُعممًا لـ
توزيع تويدي، والذي يسمح بنمذجة أي من التوزيعات المذكورة أعلاه
باستخدام معلمة <code class="docutils literal notranslate"><span class="pre">power</span></code> المناسبة. على وجه الخصوص:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">power</span> <span class="pre">=</span> <span class="pre">0</span></code>: التوزيع العادي. مُقدِّرات مُحددة مثل
<a class="reference internal" href="generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge" title="sklearn.linear_model.Ridge"><code class="xref py py-class docutils literal notranslate"><span class="pre">Ridge</span></code></a>، <a class="reference internal" href="generated/sklearn.linear_model.ElasticNet.html#sklearn.linear_model.ElasticNet" title="sklearn.linear_model.ElasticNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">ElasticNet</span></code></a> تكون أكثر ملاءمة بشكل عام في
هذه الحالة.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">power</span> <span class="pre">=</span> <span class="pre">1</span></code>: توزيع بواسون. <a class="reference internal" href="generated/sklearn.linear_model.PoissonRegressor.html#sklearn.linear_model.PoissonRegressor" title="sklearn.linear_model.PoissonRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">PoissonRegressor</span></code></a> مُعرَّض
للراحة. ومع ذلك، فهو يُعادل تمامًا
<code class="docutils literal notranslate"><span class="pre">TweedieRegressor(power=1,</span> <span class="pre">link='log')</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">power</span> <span class="pre">=</span> <span class="pre">2</span></code>: توزيع جاما. <a class="reference internal" href="generated/sklearn.linear_model.GammaRegressor.html#sklearn.linear_model.GammaRegressor" title="sklearn.linear_model.GammaRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">GammaRegressor</span></code></a> مُعرَّض لـ
الراحة. ومع ذلك، فهو يُعادل تمامًا
<code class="docutils literal notranslate"><span class="pre">TweedieRegressor(power=2,</span> <span class="pre">link='log')</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">power</span> <span class="pre">=</span> <span class="pre">3</span></code>: التوزيع الغاوسي العكسي.</p></li>
</ul>
<p>يتم تحديد دالة الربط بواسطة معلمة <code class="docutils literal notranslate"><span class="pre">link</span></code>.</p>
<p>مثال على الاستخدام:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">TweedieRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span> <span class="o">=</span> <span class="n">TweedieRegressor</span><span class="p">(</span><span class="n">power</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">link</span><span class="o">=</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="go">TweedieRegressor(alpha=0.5, link=&#39;log&#39;, power=1)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span><span class="o">.</span><span class="n">coef_</span>
<span class="go">array([0.2463..., 0.4337...])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span><span class="o">.</span><span class="n">intercept_</span>
<span class="go">-0.7638...</span>
</pre></div>
</div>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/linear_model/plot_poisson_regression_non_normal_loss.html#sphx-glr-auto-examples-linear-model-plot-poisson-regression-non-normal-loss-py"><span class="std std-ref">Poisson regression and non-normal loss</span></a></p></li>
<li><p><a class="reference internal" href="../auto_examples/linear_model/plot_tweedie_regression_insurance_claims.html#sphx-glr-auto-examples-linear-model-plot-tweedie-regression-insurance-claims-py"><span class="std std-ref">Tweedie regression on insurance claims</span></a></p></li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="اعتبارات-عملية">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">اعتبارات عملية<a class="headerlink" href="#اعتبارات-عملية" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">يجب توحيد مصفوفة الميزات <code class="docutils literal notranslate"><span class="pre">X</span></code> قبل الملاءمة. هذا يضمن
أن العقوبة تُعامل الميزات على قدم المساواة.</p>
<p class="sd-card-text">نظرًا لأن المُتنبئ الخطي <span class="math notranslate nohighlight">\(Xw\)</span> يمكن أن يكون سالبًا وبويسون و
جاما والتوزيعات الغاوسية العكسية لا تدعم القيم السالبة، فمن
الضروري تطبيق دالة ربط عكسية تضمن
عدم السلبية. على سبيل المثال، مع <code class="docutils literal notranslate"><span class="pre">link='log'</span></code>، تصبح دالة الربط العكسي
<span class="math notranslate nohighlight">\(h(Xw)=\exp(Xw)\)</span>.</p>
<p class="sd-card-text">إذا كنت تُريد نمذجة تردد نسبي، أي عدد لكل تعرض (وقت،
حجم، ...) يمكنك القيام بذلك عن طريق استخدام توزيع بواسون وتمرير
<span class="math notranslate nohighlight">\(y=\frac{\mathrm{counts}}{\mathrm{exposure}}\)</span> كقيم مستهدفة
مع <span class="math notranslate nohighlight">\(\mathrm{exposure}\)</span> كأوزان عينة. للحصول على مثال
ملموس، انظر على سبيل المثال
<a class="reference internal" href="../auto_examples/linear_model/plot_tweedie_regression_insurance_claims.html#sphx-glr-auto-examples-linear-model-plot-tweedie-regression-insurance-claims-py"><span class="std std-ref">Tweedie regression on insurance claims</span></a>.</p>
<p class="sd-card-text">عند إجراء التحقق المتبادل لمعلمة <code class="docutils literal notranslate"><span class="pre">power</span></code> لـ
<code class="docutils literal notranslate"><span class="pre">TweedieRegressor</span></code>، يُنصح بتحديد دالة <code class="docutils literal notranslate"><span class="pre">scoring</span></code> صريحة،
لأن المُسجل الافتراضي <a class="reference internal" href="generated/sklearn.linear_model.TweedieRegressor.html#sklearn.linear_model.TweedieRegressor.score" title="sklearn.linear_model.TweedieRegressor.score"><code class="xref py py-meth docutils literal notranslate"><span class="pre">TweedieRegressor.score</span></code></a> هو دالة
لـ <code class="docutils literal notranslate"><span class="pre">power</span></code> نفسها.</p>
</div>
</details></section>
</section>
<section id="sgd">
<h2><span class="section-number">1.1.13. </span>نزول التدرج العشوائي - SGD<a class="headerlink" href="#sgd" title="Link to this heading">#</a></h2>
<p>نزول التدرج العشوائي هو نهج بسيط ولكنه فعال للغاية
لملاءمة النماذج الخطية. إنه مفيد بشكل خاص عندما يكون عدد العينات
(وعدد الميزات) كبيرًا جدًا.
يسمح أسلوب <code class="docutils literal notranslate"><span class="pre">partial_fit</span></code> بالتعلم على الإنترنت / خارج النواة.</p>
<p>تُوفر الفئات <a class="reference internal" href="generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier" title="sklearn.linear_model.SGDClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">SGDClassifier</span></code></a> و <a class="reference internal" href="generated/sklearn.linear_model.SGDRegressor.html#sklearn.linear_model.SGDRegressor" title="sklearn.linear_model.SGDRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">SGDRegressor</span></code></a>
وظائف لملاءمة النماذج الخطية للتصنيف والانحدار
باستخدام دوال خسارة (مُحدبة) مُختلفة وعقوبات مُختلفة.
على سبيل المثال، مع <code class="docutils literal notranslate"><span class="pre">loss=&quot;log&quot;</span></code>، <a class="reference internal" href="generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier" title="sklearn.linear_model.SGDClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">SGDClassifier</span></code></a>
يُناسب نموذج انحدار لوجستي،
بينما مع <code class="docutils literal notranslate"><span class="pre">loss=&quot;hinge&quot;</span></code> يُناسب آلة متجه دعم خطية (SVM).</p>
<p>يمكنك الرجوع إلى قسم الوثائق <a class="reference internal" href="sgd.html#sgd"><span class="std std-ref">التحسين التدريجي العشوائي</span></a> المُخصص لمزيد من التفاصيل.</p>
</section>
<section id="perceptron">
<span id="id74"></span><h2><span class="section-number">1.1.14. </span>Perceptron<a class="headerlink" href="#perceptron" title="Link to this heading">#</a></h2>
<p><a class="reference internal" href="generated/sklearn.linear_model.Perceptron.html#sklearn.linear_model.Perceptron" title="sklearn.linear_model.Perceptron"><code class="xref py py-class docutils literal notranslate"><span class="pre">Perceptron</span></code></a> هو خوارزمية تصنيف بسيطة أخرى مُناسبة لـ
التعلم على نطاق واسع. افتراضيًا:</p>
<ul class="simple">
<li><p>لا يتطلب مُعدل تعلم.</p></li>
<li><p>إنه غير مُنظّم (مُعاقب).</p></li>
<li><p>يُحدِّث نموذجه فقط على الأخطاء.</p></li>
</ul>
<p>الخاصية الأخيرة تعني أن Perceptron أسرع قليلاً في
التدريب من SGD مع خسارة المفصلة وأن النماذج الناتجة
متفرقة.</p>
<p>في الواقع، <a class="reference internal" href="generated/sklearn.linear_model.Perceptron.html#sklearn.linear_model.Perceptron" title="sklearn.linear_model.Perceptron"><code class="xref py py-class docutils literal notranslate"><span class="pre">Perceptron</span></code></a> هو غلاف حول فئة <a class="reference internal" href="generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier" title="sklearn.linear_model.SGDClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">SGDClassifier</span></code></a>
باستخدام خسارة perceptron ومُعدل تعلم ثابت. راجع
<span class="xref std std-ref">القسم الرياضي</span> لإجراء SGDلمزيد من التفاصيل.</p>
</section>
<section id="passive-aggressive">
<span id="id75"></span><h2><span class="section-number">1.1.15. </span>خوارزميات عدوانية سلبية<a class="headerlink" href="#passive-aggressive" title="Link to this heading">#</a></h2>
<p>الخوارزميات العدوانية السلبية هي عائلة من الخوارزميات للتعلم
واسع النطاق. إنها تُشبه Perceptron من حيث أنها لا تتطلب
مُعدل تعلم. ومع ذلك، على عكس Perceptron، فإنها تتضمن معلمة
تنظيم <code class="docutils literal notranslate"><span class="pre">C</span></code>.</p>
<p>للتصنيف، يمكن استخدام <a class="reference internal" href="generated/sklearn.linear_model.PassiveAggressiveClassifier.html#sklearn.linear_model.PassiveAggressiveClassifier" title="sklearn.linear_model.PassiveAggressiveClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">PassiveAggressiveClassifier</span></code></a> مع
<code class="docutils literal notranslate"><span class="pre">loss='hinge'</span></code> (PA-I) أو <code class="docutils literal notranslate"><span class="pre">loss='squared_hinge'</span></code> (PA-II). للانحدار،
يمكن استخدام <a class="reference internal" href="generated/sklearn.linear_model.PassiveAggressiveRegressor.html#sklearn.linear_model.PassiveAggressiveRegressor" title="sklearn.linear_model.PassiveAggressiveRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">PassiveAggressiveRegressor</span></code></a> مع
<code class="docutils literal notranslate"><span class="pre">loss='epsilon_insensitive'</span></code> (PA-I) أو
<code class="docutils literal notranslate"><span class="pre">loss='squared_epsilon_insensitive'</span></code> (PA-II).</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-7">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-7" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text"><a class="reference external" href="http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf">&quot;خوارزميات عدوانية سلبية على الإنترنت&quot;</a>
K. Crammer, O. Dekel, J. Keshat, S. Shalev-Shwartz, Y. Singer - JMLR 7 (2006)</p></li>
</ul>
</div>
</details></section>
<section id="id77">
<h2><span class="section-number">1.1.16. </span>انحدار المتانة: القيم المتطرفة وأخطاء النمذجة<a class="headerlink" href="#id77" title="Link to this heading">#</a></h2>
<p>يهدف الانحدار القوي إلى ملاءمة نموذج انحدار في
وجود بيانات تالفة: إما قيم متطرفة، أو خطأ في النموذج.</p>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/linear_model/plot_theilsen.html"><img alt="../_images/sphx_glr_plot_theilsen_001.png" src="../_images/sphx_glr_plot_theilsen_001.png" style="width: 320.0px; height: 240.0px;" />
</a>
</figure>
<section id="id78">
<h3><span class="section-number">1.1.16.1. </span>سيناريوهات مختلفة ومفاهيم مفيدة<a class="headerlink" href="#id78" title="Link to this heading">#</a></h3>
<p>هناك أشياء مختلفة يجب وضعها في الاعتبار عند التعامل مع البيانات
التالفة بواسطة القيم المتطرفة:</p>
<ul>
<li><p><strong>القيم المتطرفة في X أو في y</strong>؟</p></li>
<li><p><strong>جزء القيم المتطرفة مقابل سعة الخطأ</strong></p>
<p>يهم عدد النقاط المتطرفة، ولكن أيضًا مقدار تطرفها.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>القيم المتطرفة الصغيرة</p></th>
<th class="head"><p>القيم المتطرفة الكبيرة</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference external" href="../auto_examples/linear_model/plot_robust_fit.html"><img alt="y_outliers" src="../_images/sphx_glr_plot_robust_fit_003.png" style="width: 300.0px; height: 240.0px;" /></a></p></td>
<td><p><a class="reference external" href="../auto_examples/linear_model/plot_robust_fit.html"><img alt="large_y_outliers" src="../_images/sphx_glr_plot_robust_fit_005.png" style="width: 300.0px; height: 240.0px;" /></a></p></td>
</tr>
</tbody>
</table>
</div>
</li>
</ul>
<p>مفهوم مهم للملاءمة القوية هو نقطة الانهيار: جزء
البيانات التي يمكن أن تكون متطرفة حتى تبدأ الملاءمة في فقدان
البيانات الداخلية.</p>
<p>لاحظ أنه بشكل عام، الملاءمة القوية في الإعداد عالي الأبعاد (كبير
<code class="docutils literal notranslate"><span class="pre">n_features</span></code>) صعبة للغاية. من المحتمل ألا تعمل النماذج القوية هنا
في هذه الإعدادات.</p>
<aside class="topic">
<p class="topic-title">المفاضلات: أي مُقدِّر؟</p>
<p>يُوفر Scikit-learn 3 مُقدِّرات انحدار قوية:
<a class="reference internal" href="#ransac-regression"><span class="std std-ref">RANSAC</span></a>،
<a class="reference internal" href="#theil-sen-regression"><span class="std std-ref">Theil Sen</span></a> و
<a class="reference internal" href="#huber-regression"><span class="std std-ref">HuberRegressor</span></a>.</p>
<ul class="simple">
<li><p>يجب أن يكون <a class="reference internal" href="#huber-regression"><span class="std std-ref">HuberRegressor</span></a> أسرع من
<a class="reference internal" href="#ransac-regression"><span class="std std-ref">RANSAC</span></a> و <a class="reference internal" href="#theil-sen-regression"><span class="std std-ref">Theil Sen</span></a>
إلا إذا كان عدد العينات كبيرًا جدًا، أي <code class="docutils literal notranslate"><span class="pre">n_samples</span></code> &gt;&gt; <code class="docutils literal notranslate"><span class="pre">n_features</span></code>.
هذا لأن <a class="reference internal" href="#ransac-regression"><span class="std std-ref">RANSAC</span></a> و <a class="reference internal" href="#theil-sen-regression"><span class="std std-ref">Theil Sen</span></a>
يُناسبان مجموعات فرعية أصغر من البيانات. ومع ذلك، من غير المُرجح أن يكون
كل من <a class="reference internal" href="#theil-sen-regression"><span class="std std-ref">Theil Sen</span></a>
و <a class="reference internal" href="#ransac-regression"><span class="std std-ref">RANSAC</span></a> بنفس قوة
<a class="reference internal" href="#huber-regression"><span class="std std-ref">HuberRegressor</span></a> للمعلمات الافتراضية.</p></li>
<li><p><a class="reference internal" href="#ransac-regression"><span class="std std-ref">RANSAC</span></a> أسرع من <a class="reference internal" href="#theil-sen-regression"><span class="std std-ref">Theil Sen</span></a>
ويتناسب بشكل أفضل مع عدد العينات.</p></li>
<li><p><a class="reference internal" href="#ransac-regression"><span class="std std-ref">RANSAC</span></a> سيتعامل بشكل أفضل مع
القيم المتطرفة الكبيرة في اتجاه y (الحالة الأكثر شيوعًا).</p></li>
<li><p><a class="reference internal" href="#theil-sen-regression"><span class="std std-ref">Theil Sen</span></a> سيتعامل بشكل أفضل مع
القيم المتطرفة متوسطة الحجم في اتجاه X، لكن هذه الخاصية
ستختفي في الإعدادات عالية الأبعاد.</p></li>
</ul>
<p>عند الشك، استخدم <a class="reference internal" href="#ransac-regression"><span class="std std-ref">RANSAC</span></a>.</p>
</aside>
</section>
<section id="ransac">
<span id="ransac-regression"></span><h3><span class="section-number">1.1.16.2. </span>RANSAC: توافق العينة العشوائي<a class="headerlink" href="#ransac" title="Link to this heading">#</a></h3>
<p>يُناسب RANSAC (RANdom SAmple Consensus) نموذجًا من مجموعات فرعية عشوائية من
القيم الداخلية من مجموعة البيانات الكاملة.</p>
<p>RANSAC هي خوارزمية غير حتمية تُنتج نتيجة معقولة فقط مع
احتمالية مُعينة، والتي تعتمد على عدد التكرارات (انظر
معلمة <code class="docutils literal notranslate"><span class="pre">max_trials</span></code>). يتم استخدامه عادةً لمشاكل الانحدار الخطي وغير الخطي
وهو شائع بشكل خاص في مجال رؤية الكمبيوتر التصويرية.</p>
<p>تقسم الخوارزمية بيانات عينة الإدخال الكاملة إلى مجموعة من القيم
الداخلية، والتي قد تخضع للضوضاء، والقيم المتطرفة، والتي تنتج
على سبيل المثال عن قياسات خاطئة أو فرضيات غير صالحة حول البيانات. ثم
يتم تقدير النموذج الناتج فقط من القيم الداخلية المُحددة.</p>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/linear_model/plot_ransac.html"><img alt="../_images/sphx_glr_plot_ransac_001.png" src="../_images/sphx_glr_plot_ransac_001.png" style="width: 320.0px; height: 240.0px;" />
</a>
</figure>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/linear_model/plot_ransac.html#sphx-glr-auto-examples-linear-model-plot-ransac-py"><span class="std std-ref">Robust linear model estimation using RANSAC</span></a></p></li>
<li><p><a class="reference internal" href="../auto_examples/linear_model/plot_robust_fit.html#sphx-glr-auto-examples-linear-model-plot-robust-fit-py"><span class="std std-ref">Robust linear estimator fitting</span></a></p></li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="تفاصيل-الخوارزمية">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">تفاصيل الخوارزمية<a class="headerlink" href="#تفاصيل-الخوارزمية" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">يُجري كل تكرار الخطوات التالية:</p>
<ol class="arabic simple">
<li><p class="sd-card-text">حدد <code class="docutils literal notranslate"><span class="pre">min_samples</span></code> عينات عشوائية من البيانات الأصلية وتحقق
مما إذا كانت مجموعة البيانات صالحة (انظر <code class="docutils literal notranslate"><span class="pre">is_data_valid</span></code>).</p></li>
<li><p class="sd-card-text">قم بملاءمة نموذج على المجموعة الفرعية العشوائية (<code class="docutils literal notranslate"><span class="pre">estimator.fit</span></code>) وتحقق
مما إذا كان النموذج المُقدَّر صالحًا (انظر <code class="docutils literal notranslate"><span class="pre">is_model_valid</span></code>).</p></li>
<li><p class="sd-card-text">صنف جميع البيانات على أنها قيم داخلية أو قيم متطرفة عن طريق حساب البواقي
إلى النموذج المُقدَّر (<code class="docutils literal notranslate"><span class="pre">estimator.predict(X)</span> <span class="pre">-</span> <span class="pre">y</span></code>) - جميع عينات
البيانات ذات البواقي المُطلقة الأصغر من أو تساوي
<code class="docutils literal notranslate"><span class="pre">residual_threshold</span></code> تُعتبر قيمًا داخلية.</p></li>
<li><p class="sd-card-text">احفظ النموذج المُناسب كأفضل نموذج إذا كان عدد عينات القيم الداخلية
أقصى. في حالة احتواء النموذج المُقدَّر الحالي على نفس عدد
القيم الداخلية، فإنه يُعتبر فقط كأفضل نموذج إذا كان لديه درجة أفضل.</p></li>
</ol>
<p class="sd-card-text">يتم تنفيذ هذه الخطوات إما لعدد أقصى من المرات (<code class="docutils literal notranslate"><span class="pre">max_trials</span></code>) أو
حتى يتم استيفاء أحد معايير الإيقاف الخاصة (انظر <code class="docutils literal notranslate"><span class="pre">stop_n_inliers</span></code> و
<code class="docutils literal notranslate"><span class="pre">stop_score</span></code>). يتم تقدير النموذج النهائي باستخدام جميع عينات القيم الداخلية
(مجموعة التوافق) لأفضل نموذج مُحدد مسبقًا.</p>
<p class="sd-card-text">تسمح الدالتان <code class="docutils literal notranslate"><span class="pre">is_data_valid</span></code> و <code class="docutils literal notranslate"><span class="pre">is_model_valid</span></code> بتحديد ورفض
مجموعات عينات فرعية عشوائية مُتدهورة. إذا لم يكن النموذج المُقدَّر
مطلوبًا لتحديد الحالات المتدهورة، فيجب استخدام <code class="docutils literal notranslate"><span class="pre">is_data_valid</span></code>
حيث يتم استدعاؤه قبل ملاءمة النموذج، مما يؤدي إلى أداء
حسابي أفضل.</p>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-8">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-8" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text"><a class="reference external" href="https://en.wikipedia.org/wiki/RANSAC">https://en.wikipedia.org/wiki/RANSAC</a></p></li>
<li><p class="sd-card-text"><a class="reference external" href="https://www.cs.ait.ac.th/~mdailey/cvreadings/Fischler-RANSAC.pdf">&quot;توافق العينة العشوائي: نموذج للملاءمة مع التطبيقات لـ
تحليل الصور ورسم الخرائط التلقائي&quot;</a>
Martin A. Fischler and Robert C. Bolles - SRI International (1981)</p></li>
<li><p class="sd-card-text"><a class="reference external" href="http://www.bmva.org/bmvc/2009/Papers/Paper355/Paper355.pdf">&quot;تقييم أداء عائلة RANSAC&quot;</a>
Sunglok Choi, Taemin Kim and Wonpil Yu - BMVC (2009)</p></li>
</ul>
</div>
</details></section>
<section id="theil-sen">
<span id="theil-sen-regression"></span><h3><span class="section-number">1.1.16.3. </span>مُقدِّر Theil-Sen: مُقدِّر قائم على الوسيط المُعمم<a class="headerlink" href="#theil-sen" title="Link to this heading">#</a></h3>
<p>يستخدم مُقدِّر <a class="reference internal" href="generated/sklearn.linear_model.TheilSenRegressor.html#sklearn.linear_model.TheilSenRegressor" title="sklearn.linear_model.TheilSenRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">TheilSenRegressor</span></code></a> تعميمًا للوسيط في
أبعاد متعددة. وبالتالي فهو قوي ضد القيم المتطرفة متعددة المتغيرات. لاحظ
ومع ذلك أن قوة المُقدِّر تتناقص بسرعة مع أبعاد
المشكلة. يفقد خصائص المتانة الخاصة به ويصبح ليس
أفضل من المربعات الصغرى العادية في البُعد العالي.</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/linear_model/plot_theilsen.html#sphx-glr-auto-examples-linear-model-plot-theilsen-py"><span class="std std-ref">Theil-Sen Regression</span></a></p></li>
<li><p><a class="reference internal" href="../auto_examples/linear_model/plot_robust_fit.html#sphx-glr-auto-examples-linear-model-plot-robust-fit-py"><span class="std std-ref">Robust linear estimator fitting</span></a></p></li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="اعتبارات-نظرية">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">اعتبارات نظرية<a class="headerlink" href="#اعتبارات-نظرية" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><a class="reference internal" href="generated/sklearn.linear_model.TheilSenRegressor.html#sklearn.linear_model.TheilSenRegressor" title="sklearn.linear_model.TheilSenRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">TheilSenRegressor</span></code></a> مُقارن لـ <a class="reference internal" href="#ordinary-least-squares"><span class="std std-ref">المربعات الصغرى
العادية (OLS)</span></a> من حيث الكفاءة المقاربة وكمُقدِّر
غير مُتحيز. على عكس OLS، فإن Theil-Sen هو أسلوب غير معلمي
مما يعني أنه لا يضع أي افتراض حول التوزيع
الأساسي للبيانات. نظرًا لأن Theil-Sen هو مُقدِّر قائم على الوسيط، فإنه
أكثر قوة ضد البيانات التالفة المعروفة أيضًا باسم القيم المتطرفة. في
إعداد أحادي المتغير، Theil-Sen لديه نقطة انهيار تبلغ حوالي 29.3% في حالة
الانحدار الخطي البسيط مما يعني أنه يمكنه تحمل
بيانات تالفة عشوائية تصل إلى 29.3%.</p>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/linear_model/plot_theilsen.html"><img alt="../_images/sphx_glr_plot_theilsen_001.png" src="../_images/sphx_glr_plot_theilsen_001.png" style="width: 320.0px; height: 240.0px;" />
</a>
</figure>
<p class="sd-card-text">يتبع تطبيق <a class="reference internal" href="generated/sklearn.linear_model.TheilSenRegressor.html#sklearn.linear_model.TheilSenRegressor" title="sklearn.linear_model.TheilSenRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">TheilSenRegressor</span></code></a> في scikit-learn تعميمًا لنموذج
الانحدار الخطي متعدد المتغيرات <a class="footnote-reference brackets" href="#f1" id="id81" role="doc-noteref"><span class="fn-bracket">[</span>14<span class="fn-bracket">]</span></a> باستخدام الوسيط المكاني
وهو تعميم للوسيط لأبعاد متعددة <a class="footnote-reference brackets" href="#f2" id="id82" role="doc-noteref"><span class="fn-bracket">[</span>15<span class="fn-bracket">]</span></a>.</p>
<p class="sd-card-text">من حيث تعقيد الوقت والمساحة، يتناسب Theil-Sen وفقًا لـ</p>
<div class="math notranslate nohighlight">
\[\binom{n_{\text{samples}}}{n_{\text{subsamples}}}\]</div>
<p class="sd-card-text">مما يجعله غير مُجدي للتطبيق بشكل شامل على المشاكل التي تحتوي على
عدد كبير من العينات والميزات. لذلك، يمكن اختيار حجم
مجموعة فرعية لتقييد تعقيد الوقت والمساحة عن طريق
النظر فقط في مجموعة فرعية عشوائية من جميع التوليفات الممكنة.</p>
<p class="rubric">المراجع</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="f1" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id81">14</a><span class="fn-bracket">]</span></span>
<p class="sd-card-text">Xin Dang, Hanxiang Peng, Xueqin Wang and Heping Zhang: <a class="reference external" href="http://home.olemiss.edu/~xdang/papers/MTSE.pdf">مقدرات Theil-Sen في نموذج انحدار خطي متعدد.</a></p>
</aside>
<aside class="footnote brackets" id="f2" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id82">15</a><span class="fn-bracket">]</span></span>
<ol class="upperalpha simple" start="20">
<li><p class="sd-card-text">Kärkkäinen and S. Äyrämö: <a class="reference external" href="http://users.jyu.fi/~samiayr/pdf/ayramo_eurogen05.pdf">حول حساب الوسيط المكاني لتنقيب البيانات القوي.</a></p></li>
</ol>
</aside>
</aside>
<p class="sd-card-text">انظر أيضًا <a class="reference external" href="https://en.wikipedia.org/wiki/Theil%E2%80%93Sen_estimator">صفحة ويكيبيديا</a></p>
</div>
</details></section>
<section id="huber">
<span id="huber-regression"></span><h3><span class="section-number">1.1.16.4. </span>انحدار Huber<a class="headerlink" href="#huber" title="Link to this heading">#</a></h3>
<p>يختلف <a class="reference internal" href="generated/sklearn.linear_model.HuberRegressor.html#sklearn.linear_model.HuberRegressor" title="sklearn.linear_model.HuberRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">HuberRegressor</span></code></a> عن <a class="reference internal" href="generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge" title="sklearn.linear_model.Ridge"><code class="xref py py-class docutils literal notranslate"><span class="pre">Ridge</span></code></a> لأنه يُطبق
خسارة خطية على العينات التي تُصنف على أنها قيم متطرفة.
يتم تصنيف عينة على أنها قيمة داخلية إذا كان الخطأ المُطلق لتلك العينة
أقل من عتبة مُعينة. إنه يختلف عن <a class="reference internal" href="generated/sklearn.linear_model.TheilSenRegressor.html#sklearn.linear_model.TheilSenRegressor" title="sklearn.linear_model.TheilSenRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">TheilSenRegressor</span></code></a>
و <a class="reference internal" href="generated/sklearn.linear_model.RANSACRegressor.html#sklearn.linear_model.RANSACRegressor" title="sklearn.linear_model.RANSACRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">RANSACRegressor</span></code></a> لأنه لا يتجاهل تأثير القيم المتطرفة
ولكنه يُعطي وزنًا أقل لها.</p>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/linear_model/plot_huber_vs_ridge.html"><img alt="../_images/sphx_glr_plot_huber_vs_ridge_001.png" src="../_images/sphx_glr_plot_huber_vs_ridge_001.png" style="width: 320.0px; height: 240.0px;" />
</a>
</figure>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/linear_model/plot_huber_vs_ridge.html#sphx-glr-auto-examples-linear-model-plot-huber-vs-ridge-py"><span class="std std-ref">HuberRegressor vs Ridge on dataset with strong outliers</span></a></p></li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="التفاصيل-الرياضية-4">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">التفاصيل الرياضية<a class="headerlink" href="#التفاصيل-الرياضية-4" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">دالة الخسارة التي يُقللها <a class="reference internal" href="generated/sklearn.linear_model.HuberRegressor.html#sklearn.linear_model.HuberRegressor" title="sklearn.linear_model.HuberRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">HuberRegressor</span></code></a> مُعطاة بواسطة</p>
<div class="math notranslate nohighlight">
\[\min_{w, \sigma} {\sum_{i=1}^n\left(\sigma + H_{\epsilon}\left(\frac{X_{i}w - y_{i}}{\sigma}\right)\sigma\right) + \alpha {||w||_2}^2}\]</div>
<p class="sd-card-text">حيث</p>
<div class="math notranslate nohighlight">
\[\begin{split}H_{\epsilon}(z) = \begin{cases}
      z^2, &amp; \text {if } |z| &lt; \epsilon, \\
      2\epsilon|z| - \epsilon^2, &amp; \text{otherwise}
\end{cases}\end{split}\]</div>
<p class="sd-card-text">يُنصح بتعيين المعلمة <code class="docutils literal notranslate"><span class="pre">epsilon</span></code> إلى 1.35 لتحقيق كفاءة
إحصائية بنسبة 95%.</p>
<p class="rubric">المراجع</p>
<ul class="simple">
<li><p class="sd-card-text">Peter J. Huber, Elvezio M. Ronchetti: Robust Statistics, Concomitant scale
estimates, pg 172</p></li>
</ul>
</div>
</details><p>يختلف <a class="reference internal" href="generated/sklearn.linear_model.HuberRegressor.html#sklearn.linear_model.HuberRegressor" title="sklearn.linear_model.HuberRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">HuberRegressor</span></code></a> عن استخدام <a class="reference internal" href="generated/sklearn.linear_model.SGDRegressor.html#sklearn.linear_model.SGDRegressor" title="sklearn.linear_model.SGDRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">SGDRegressor</span></code></a> مع تعيين الخسارة
إلى <code class="docutils literal notranslate"><span class="pre">huber</span></code> بالطرق التالية.</p>
<ul class="simple">
<li><p><a class="reference internal" href="generated/sklearn.linear_model.HuberRegressor.html#sklearn.linear_model.HuberRegressor" title="sklearn.linear_model.HuberRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">HuberRegressor</span></code></a> ثابت المقياس. بمجرد تعيين <code class="docutils literal notranslate"><span class="pre">epsilon</span></code>، فإن تغيير
مقياس <code class="docutils literal notranslate"><span class="pre">X</span></code> و <code class="docutils literal notranslate"><span class="pre">y</span></code> لأعلى أو لأسفل بقيم مُختلفة سيُنتج نفس المتانة
للقيم المتطرفة كما كان من قبل.
مُقارنةً بـ <a class="reference internal" href="generated/sklearn.linear_model.SGDRegressor.html#sklearn.linear_model.SGDRegressor" title="sklearn.linear_model.SGDRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">SGDRegressor</span></code></a> حيث يجب تعيين <code class="docutils literal notranslate"><span class="pre">epsilon</span></code> مرة أخرى عند
تغيير مقياس <code class="docutils literal notranslate"><span class="pre">X</span></code> و <code class="docutils literal notranslate"><span class="pre">y</span></code>.</p></li>
<li><p>يجب أن يكون <a class="reference internal" href="generated/sklearn.linear_model.HuberRegressor.html#sklearn.linear_model.HuberRegressor" title="sklearn.linear_model.HuberRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">HuberRegressor</span></code></a> أكثر كفاءة في الاستخدام على البيانات ذات
العدد القليل من العينات بينما يحتاج <a class="reference internal" href="generated/sklearn.linear_model.SGDRegressor.html#sklearn.linear_model.SGDRegressor" title="sklearn.linear_model.SGDRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">SGDRegressor</span></code></a> إلى عدد من
التمريرات على بيانات التدريب لـ
إنتاج نفس المتانة.</p></li>
</ul>
<p>لاحظ أن هذا المُقدِّر يختلف عن تطبيق R للانحدار القوي
(<a class="reference external" href="https://stats.oarc.ucla.edu/r/dae/robust-regression/">https://stats.oarc.ucla.edu/r/dae/robust-regression/</a>) لأن تطبيق R يُجري
تطبيقًا للمربعات الصغرى الموزونة بأوزان مُعطاة لكل عينة على أساس
مقدار الباقي أكبر من عتبة مُعينة.</p>
</section>
</section>
<section id="quantile-regression">
<span id="id86"></span><h2><span class="section-number">1.1.17. </span>انحدار المُكمِّم<a class="headerlink" href="#quantile-regression" title="Link to this heading">#</a></h2>
<p>يُقدِّر انحدار المُكمِّم الوسيط أو مُكمِّمات أخرى لـ <span class="math notranslate nohighlight">\(y\)</span>
الشرطية على <span class="math notranslate nohighlight">\(X\)</span>، بينما تُقدِّر المربعات الصغرى العادية (OLS)
المتوسط الشرطي.</p>
<p>قد يكون انحدار المُكمِّم مفيدًا إذا كان المرء مهتمًا بالتنبؤ بـ
فاصل زمني بدلاً من التنبؤ بالنقطة. في بعض الأحيان، يتم
حساب فترات التنبؤ بناءً على افتراض أن خطأ التنبؤ موزع
بشكل طبيعي بمتوسط صفري وتباين ثابت. يُوفر انحدار المُكمِّم
فترات تنبؤ معقولة حتى للأخطاء ذات التباين غير الثابت (ولكن
التنبؤي) أو التوزيع غير العادي.</p>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/linear_model/plot_quantile_regression.html"><img alt="../_images/sphx_glr_plot_quantile_regression_002.png" src="../_images/sphx_glr_plot_quantile_regression_002.png" style="width: 320.0px; height: 240.0px;" />
</a>
</figure>
<p>بناءً على تقليل خسارة الكرة والدبوس، يمكن أيضًا
تقدير المُكمِّمات الشرطية بواسطة نماذج أخرى غير النماذج الخطية. على سبيل المثال،
<a class="reference internal" href="generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor" title="sklearn.ensemble.GradientBoostingRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingRegressor</span></code></a> يمكنه التنبؤ بـ
مُكمِّمات شرطية إذا تم تعيين معلمته <code class="docutils literal notranslate"><span class="pre">loss</span></code> إلى <code class="docutils literal notranslate"><span class="pre">&quot;quantile&quot;</span></code> وتم تعيين
المعلمة <code class="docutils literal notranslate"><span class="pre">alpha</span></code> إلى المُكمِّم الذي يجب التنبؤ به. انظر المثال في
<a class="reference internal" href="../auto_examples/ensemble/plot_gradient_boosting_quantile.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-quantile-py"><span class="std std-ref">Prediction Intervals for Gradient Boosting Regression</span></a>.</p>
<p>تعتمد معظم تطبيقات انحدار المُكمِّم على مشكلة البرمجة
الخطية. يعتمد التطبيق الحالي على
<a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.linprog.html#scipy.optimize.linprog" title="(in SciPy v1.14.1)"><code class="xref py py-func docutils literal notranslate"><span class="pre">scipy.optimize.linprog</span></code></a>.</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/linear_model/plot_quantile_regression.html#sphx-glr-auto-examples-linear-model-plot-quantile-regression-py"><span class="std std-ref">Quantile regression</span></a></p></li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="التفاصيل-الرياضية-5">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">التفاصيل الرياضية<a class="headerlink" href="#التفاصيل-الرياضية-5" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">كنموذج خطي، يُعطي <a class="reference internal" href="generated/sklearn.linear_model.QuantileRegressor.html#sklearn.linear_model.QuantileRegressor" title="sklearn.linear_model.QuantileRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantileRegressor</span></code></a> تنبؤات خطية
<span class="math notranslate nohighlight">\(\hat{y}(w, X) = Xw\)</span> لـ <span class="math notranslate nohighlight">\(q\)</span>-th مُكمِّم، <span class="math notranslate nohighlight">\(q \in (0, 1)\)</span>.
ثم يتم إيجاد الأوزان أو المعاملات <span class="math notranslate nohighlight">\(w\)</span> بواسطة مشكلة
التصغير التالية:</p>
<div class="math notranslate nohighlight">
\[\min_{w} {\frac{1}{n_{\text{samples}}}
\sum_i PB_q(y_i - X_i w) + \alpha ||w||_1}.\]</div>
<p class="sd-card-text">يتكون هذا من خسارة الكرة والدبوس (المعروفة أيضًا باسم الخسارة الخطية)،
انظر أيضًا <a class="reference internal" href="generated/sklearn.metrics.mean_pinball_loss.html#sklearn.metrics.mean_pinball_loss" title="sklearn.metrics.mean_pinball_loss"><code class="xref py py-class docutils literal notranslate"><span class="pre">mean_pinball_loss</span></code></a>،</p>
<div class="math notranslate nohighlight">
\[\begin{split}PB_q(t) = q \max(t, 0) + (1 - q) \max(-t, 0) =
\begin{cases}
    q t, &amp; t &gt; 0, \\
    0,    &amp; t = 0, \\
    (q-1) t, &amp; t &lt; 0
\end{cases}\end{split}\]</div>
<p class="sd-card-text">وعقوبة L1 التي تتحكم فيها المعلمة <code class="docutils literal notranslate"><span class="pre">alpha</span></code>، على غرار
<a class="reference internal" href="generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso" title="sklearn.linear_model.Lasso"><code class="xref py py-class docutils literal notranslate"><span class="pre">Lasso</span></code></a>.</p>
<p class="sd-card-text">نظرًا لأن خسارة الكرة والدبوس خطية فقط في البواقي، فإن انحدار
المُكمِّم أكثر قوة ضد القيم المتطرفة من التقدير القائم على
الخطأ التربيعي للمتوسط.
في مكان ما بينهما هو <a class="reference internal" href="generated/sklearn.linear_model.HuberRegressor.html#sklearn.linear_model.HuberRegressor" title="sklearn.linear_model.HuberRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">HuberRegressor</span></code></a>.</p>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-9">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-9" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text">Koenker, R., &amp; Bassett Jr, G. (1978). <a class="reference external" href="https://gib.people.uic.edu/RQ.pdf">المُكمِّمات الانحدارية.</a>
Econometrica: journal of the Econometric Society, 33-50.</p></li>
<li><p class="sd-card-text">Portnoy, S., &amp; Koenker, R. (1997). <a class="reference external" href="https://doi.org/10.1214/ss/1030037960">الأرنب الغاوسي والسلحفاة
لابلاس: قابلية حساب المُقدِّرات القائمة على الخطأ التربيعي مقابل
المُقدِّرات القائمة على الخطأ المُطلق. Statistical Science، 12، 279-300</a>.</p></li>
<li><p class="sd-card-text">Koenker, R. (2005). <a class="reference external" href="https://doi.org/10.1017/CBO9780511754098">انحدار المُكمِّم</a>.
Cambridge University Press.</p></li>
</ul>
</div>
</details></section>
<section id="polynomial-regression">
<span id="id88"></span><h2><span class="section-number">1.1.18. </span>الانحدار متعدد الحدود: توسيع النماذج الخطية مع دوال الأساس<a class="headerlink" href="#polynomial-regression" title="Link to this heading">#</a></h2>
<p>أحد الأنماط الشائعة في التعلم الآلي هو استخدام النماذج الخطية المُدرَّبة
على دوال غير خطية للبيانات. يحافظ هذا النهج على الأداء
السريع بشكل عام للطرق الخطية، مع السماح لها بملاءمة
نطاق أوسع بكثير من البيانات.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="التفاصيل-الرياضية-6">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">التفاصيل الرياضية<a class="headerlink" href="#التفاصيل-الرياضية-6" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">على سبيل المثال، يمكن تمديد انحدار خطي بسيط عن طريق بناء
<strong>ميزات متعددة الحدود</strong> من المعاملات. في حالة الانحدار
الخطي القياسية، قد يكون لديك نموذج يبدو كالتالي لـ
بيانات ثنائية الأبعاد:</p>
<div class="math notranslate nohighlight">
\[\hat{y}(w, x) = w_0 + w_1 x_1 + w_2 x_2\]</div>
<p class="sd-card-text">إذا أردنا ملاءمة قطع مكافئ للبيانات بدلاً من مستوى، فيمكننا دمج
الميزات في كثيرات حدود من الدرجة الثانية، بحيث يبدو النموذج على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[\hat{y}(w, x) = w_0 + w_1 x_1 + w_2 x_2 + w_3 x_1 x_2 + w_4 x_1^2 + w_5 x_2^2\]</div>
<p class="sd-card-text">الملاحظة (المُفاجئة أحيانًا) هي أن هذا <em>لا يزال نموذجًا خطيًا</em>:
لرؤية ذلك، تخيل إنشاء مجموعة جديدة من الميزات</p>
<div class="math notranslate nohighlight">
\[z = [x_1, x_2, x_1 x_2, x_1^2, x_2^2]\]</div>
<p class="sd-card-text">مع إعادة تسمية البيانات هذه، يمكن كتابة مشكلتنا</p>
<div class="math notranslate nohighlight">
\[\hat{y}(w, z) = w_0 + w_1 z_1 + w_2 z_2 + w_3 z_3 + w_4 z_4 + w_5 z_5\]</div>
<p class="sd-card-text">نرى أن <em>الانحدار متعدد الحدود</em> الناتج في نفس فئة
النماذج الخطية التي نظرنا فيها أعلاه (أي أن النموذج خطي في <span class="math notranslate nohighlight">\(w\)</span>)
ويمكن حله بنفس التقنيات. بالنظر إلى الملاءمات الخطية داخل
فضاء ذي أبعاد أعلى مبني باستخدام دوال الأساس هذه، يتمتع النموذج
بالمرونة لملاءمة نطاق أوسع بكثير من البيانات.</p>
</div>
</details><p>فيما يلي مثال على تطبيق هذه الفكرة على بيانات أحادية البعد، باستخدام
ميزات متعددة الحدود بدرجات مُتفاوتة:</p>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/linear_model/plot_polynomial_interpolation.html"><img alt="../_images/sphx_glr_plot_polynomial_interpolation_001.png" src="../_images/sphx_glr_plot_polynomial_interpolation_001.png" style="width: 320.0px; height: 240.0px;" />
</a>
</figure>
<p>يتم إنشاء هذا الشكل باستخدام مُحوِّل <a class="reference internal" href="generated/sklearn.preprocessing.PolynomialFeatures.html#sklearn.preprocessing.PolynomialFeatures" title="sklearn.preprocessing.PolynomialFeatures"><code class="xref py py-class docutils literal notranslate"><span class="pre">PolynomialFeatures</span></code></a>، الذي
يُحوِّل مصفوفة بيانات الإدخال إلى مصفوفة بيانات جديدة من درجة مُعطاة.
يمكن استخدامه على النحو التالي:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span>
<span class="go">array([[0, 1],</span>
<span class="go">       [2, 3],</span>
<span class="go">       [4, 5]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">poly</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">poly</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">array([[ 1.,  0.,  1.,  0.,  0.,  1.],</span>
<span class="go">       [ 1.,  2.,  3.,  4.,  6.,  9.],</span>
<span class="go">       [ 1.,  4.,  5., 16., 20., 25.]])</span>
</pre></div>
</div>
<p>تم تحويل ميزات <code class="docutils literal notranslate"><span class="pre">X</span></code> من <span class="math notranslate nohighlight">\([x_1, x_2]\)</span> إلى
<span class="math notranslate nohighlight">\([1, x_1, x_2, x_1^2, x_1 x_2, x_2^2]\)</span>، ويمكن الآن استخدامها داخل
أي نموذج خطي.</p>
<p>يمكن تبسيط هذا النوع من المُعالجة المُسبقة باستخدام
أدوات <a class="reference internal" href="compose.html#pipeline"><span class="std std-ref">Pipeline</span></a>. يمكن إنشاء كائن واحد يُمثِّل
انحدارًا متعدد الحدود بسيطًا واستخدامه على النحو التالي:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">3</span><span class="p">)),</span>
<span class="gp">... </span>                  <span class="p">(</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">LinearRegression</span><span class="p">(</span><span class="n">fit_intercept</span><span class="o">=</span><span class="kc">False</span><span class="p">))])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># ملاءمة بيانات متعددة الحدود من الرتبة 3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s1">&#39;linear&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">coef_</span>
<span class="go">array([ 3., -2.,  1., -1.])</span>
</pre></div>
</div>
<p>النموذج الخطي المُدرَّب على الميزات متعددة الحدود قادر على استرداد
معاملات مُتعددة الحدود المدخلة بدقة.</p>
<p>في بعض الحالات، ليس من الضروري تضمين قوى أعلى لأي ميزة
فردية، ولكن فقط ما يُسمى <em>ميزات التفاعل</em>
التي تضرب معًا <span class="math notranslate nohighlight">\(d\)</span> ميزات مُتميزة على الأكثر.
يمكن الحصول على هذه من <a class="reference internal" href="generated/sklearn.preprocessing.PolynomialFeatures.html#sklearn.preprocessing.PolynomialFeatures" title="sklearn.preprocessing.PolynomialFeatures"><code class="xref py py-class docutils literal notranslate"><span class="pre">PolynomialFeatures</span></code></a> مع الإعداد
<code class="docutils literal notranslate"><span class="pre">interaction_only=True</span></code>.</p>
<p>على سبيل المثال، عند التعامل مع ميزات منطقية،
<span class="math notranslate nohighlight">\(x_i^n = x_i\)</span> لجميع <span class="math notranslate nohighlight">\(n\)</span> وبالتالي فهي غير مُجدية؛
لكن <span class="math notranslate nohighlight">\(x_i x_j\)</span> يُمثل اقتران اثنين من القيم المنطقية.
بهذه الطريقة، يمكننا حل مشكلة XOR باستخدام مُصنف خطي:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Perceptron</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">^</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span>
<span class="go">array([0, 1, 1, 0])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">interaction_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span>
<span class="go">array([[1, 0, 0, 0],</span>
<span class="go">       [1, 0, 1, 0],</span>
<span class="go">       [1, 1, 0, 0],</span>
<span class="go">       [1, 1, 1, 1]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">Perceptron</span><span class="p">(</span><span class="n">fit_intercept</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="gp">... </span>                 <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>وتنبؤات المُصنف &quot;مثالية&quot;:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">array([0, 1, 1, 0])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">1.0</span>
</pre></div>
</div>
</section>
</section>


                </article>
              
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="prev-next-area">
    <a class="left-prev"
       href="../supervised_learning.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">السابق</p>
        <p class="prev-next-title"><span class="section-number">1. </span>التعليم الخاضع للإشراف</p>
      </div>
    </a>
    <a class="right-next"
       href="lda_qda.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">التالي</p>
        <p class="prev-next-title"><span class="section-number">1.2. </span>تحليل التمييز الخطي والتربيعي</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>
                </footer>
              
              
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ordinary-least-squares">1.1.1. المربعات الصغرى العادية</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">1.1.1.1. المربعات الصغرى غير السالبة</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">1.1.1.2. تعقيد المربعات الصغرى العادية</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ridge-regression">1.1.2. انحدار ريدج والتصنيف</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">1.1.2.1. الانحدار</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">1.1.2.2. التصنيف</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">1.1.2.3. تعقيد ريدج</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">1.1.2.4. تعيين معلمة التنظيم: التحقق المتبادل لترك واحد</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lasso">1.1.3. Lasso</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id15">1.1.3.1. تعيين معلمة التنظيم</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id16">1.1.3.1.1. استخدام التحقق المتبادل</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#lasso-lars-ic">1.1.3.1.2. اختيار النموذج القائم على معيار المعلومات</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#aic-bic">1.1.3.1.3. معايير AIC و BIC</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#svm">1.1.3.1.4. مقارنة مع معلمة التنظيم لـ SVM</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-task-lasso">1.1.4. Lasso متعدد المهام</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#elastic-net">1.1.5. Elastic-Net</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-task-elastic-net">1.1.6. Elastic-Net متعدد المهام</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#least-angle-regression">1.1.7. انحدار الزاوية الصغرى</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lars-lasso">1.1.8. LARS Lasso</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#omp">1.1.9. مطاردة التطابق المتعامد (OMP)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-regression">1.1.10. الانحدار البايزي</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-ridge-regression">1.1.10.1. انحدار ريدج البايزي</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ard">1.1.10.2. تحديد الصلة التلقائي - ARD</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#logistic-regression">1.1.11. الانحدار اللوجستي</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id47">1.1.11.1. الحالة الثنائية</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id48">1.1.11.2. حالة متعددة الحدود</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#logistic-regression-solvers">1.1.11.3. المحللات</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#liblinear-differences">1.1.11.3.1. الاختلافات بين المحللات</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generalized-linear-models">1.1.12. النماذج الخطية المُعممة</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id73">1.1.12.1. الاستخدام</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sgd">1.1.13. نزول التدرج العشوائي - SGD</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#perceptron">1.1.14. Perceptron</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#passive-aggressive">1.1.15. خوارزميات عدوانية سلبية</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id77">1.1.16. انحدار المتانة: القيم المتطرفة وأخطاء النمذجة</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id78">1.1.16.1. سيناريوهات مختلفة ومفاهيم مفيدة</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ransac">1.1.16.2. RANSAC: توافق العينة العشوائي</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#theil-sen">1.1.16.3. مُقدِّر Theil-Sen: مُقدِّر قائم على الوسيط المُعمم</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#huber">1.1.16.4. انحدار Huber</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quantile-regression">1.1.17. انحدار المُكمِّم</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#polynomial-regression">1.1.18. الانحدار متعدد الحدود: توسيع النماذج الخطية مع دوال الأساس</a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">

  <div class="tocsection sourcelink">
    <a href="../_sources/modules/linear_model.rst.txt">
      <i class="fa-solid fa-file-lines"></i> إظهار المصدر
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2007 - 2024, scikit-learn developers (BSD License)           Translate into Arabic &lt;a href=&#39;https://github.com/AhmmedAlmaghz/scikit-learn&#39;&gt;Eng. Ahmed Almaghz &lt;/a&gt;.
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
</div>

  </footer>
  </body>
</html>