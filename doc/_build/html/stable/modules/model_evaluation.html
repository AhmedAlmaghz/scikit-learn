
<!DOCTYPE html>


<html lang="ar" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="3.4. المقاييس والتهديف: تحديد جودة التنبؤات" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://scikit-learn/stable/modules/model_evaluation.html" />
<meta property="og:site_name" content="scikit-learn" />
<meta property="og:description" content="هناك 3 واجهات برمجة تطبيقات مختلفة لتقييم جودة تنبؤات النموذج: طريقة التهديف للمقدر: للمقدرات طريقة score تُوفر معيار تقييم افتراضي للمشكلة التي تم تصميمها لحلها. لا تتم مناقشة هذا في هذه الصفحة، و..." />
<meta property="og:image" content="https://scikit-learn/stable/_images/sphx_glr_plot_confusion_matrix_001.png" />
<meta property="og:image:alt" content="scikit-learn" />
<meta name="description" content="هناك 3 واجهات برمجة تطبيقات مختلفة لتقييم جودة تنبؤات النموذج: طريقة التهديف للمقدر: للمقدرات طريقة score تُوفر معيار تقييم افتراضي للمشكلة التي تم تصميمها لحلها. لا تتم مناقشة هذا في هذه الصفحة، و..." />

    <title>3.4. المقاييس والتهديف: تحديد جودة التنبؤات &#8212; scikit-learn 1.6.dev0 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css?v=7f9a90b1" />
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Vibur" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyterlite_sphinx.css?v=ca70e7f1" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/colors.css?v=cc94ab7d" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/custom.css?v=85b0813d" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="../_static/documentation_options.js?v=3cd28d06"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=97f0b27d"></script>
    <script src="../_static/jupyterlite_sphinx.js?v=d6bdf5f8"></script>
    <script src="../_static/translations.js?v=87cb2081"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script data-domain="scikit-learn.org" defer="defer" src="https://views.scientific-python.org/js/script.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'modules/model_evaluation';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.0';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://scikit-learn.org/dev/_static/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '1.6.dev0';
        DOCUMENTATION_OPTIONS.show_version_warning_banner = true;
        </script>
    <script src="../_static/scripts/dropdown.js?v=e2048168"></script>
    <script src="../_static/scripts/version-switcher.js?v=a6dd8357"></script>
    <link rel="icon" href="../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="search" title="بحث" href="../search.html" />
    <link rel="next" title="3.5. منحنيات التحقق من الصحة: رسم الدرجات لتقييم النماذج" href="learning_curve.html" />
    <link rel="prev" title="3.3. ضبط عتبة القرار لتنبؤ الفئة" href="classification_threshold.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="ar"/>
  <meta name="docsearch:version" content="1.6" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/scikit-learn-logo-small.png" class="logo__image only-light" alt="scikit-learn homepage"/>
    <img src="../_static/scikit-learn-logo-small.png" class="logo__image only-dark pst-js-only" alt="scikit-learn homepage"/>
  
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../install.html">
    Install
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../user_guide.html">
    دليل المستخدم
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api/index.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../auto_examples/index.html">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://blog.scikit-learn.org/">
    Community
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../getting_started.html">
    البدء
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../whats_new.html">
    Release History
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../glossary.html">
    Glossary
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../developers/index.html">
    Development
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../faq.html">
    FAQ
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../support.html">
    الدعم الفني
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../related_projects.html">
    مشاريع ذات علاقة
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../roadmap.html">
    Roadmap
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../governance.html">
    Governance
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../about.html">
    من نحن
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="بحث" aria-label="بحث" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/scikit-learn/scikit-learn" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
      
        <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="بحث" aria-label="بحث" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../install.html">
    Install
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../user_guide.html">
    دليل المستخدم
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api/index.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../auto_examples/index.html">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://blog.scikit-learn.org/">
    Community
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../getting_started.html">
    البدء
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../whats_new.html">
    Release History
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../glossary.html">
    Glossary
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../developers/index.html">
    Development
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../faq.html">
    FAQ
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../support.html">
    الدعم الفني
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../related_projects.html">
    مشاريع ذات علاقة
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../roadmap.html">
    Roadmap
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../governance.html">
    Governance
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../about.html">
    من نحن
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/scikit-learn/scikit-learn" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
        
          <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../supervised_learning.html">1. التعليم الخاضع للإشراف</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="linear_model.html">1.1. النماذج الخطية</a></li>
<li class="toctree-l2"><a class="reference internal" href="lda_qda.html">1.2. تحليل التمييز الخطي والتربيعي</a></li>
<li class="toctree-l2"><a class="reference internal" href="kernel_ridge.html">1.3. انحدار حافة النواة</a></li>
<li class="toctree-l2"><a class="reference internal" href="svm.html">1.4. آلات الدعم المتجهية (SVM)</a></li>
<li class="toctree-l2"><a class="reference internal" href="sgd.html">1.5. التحسين التدريجي العشوائي</a></li>
<li class="toctree-l2"><a class="reference internal" href="neighbors.html">1.6. أقرب الجيران</a></li>
<li class="toctree-l2"><a class="reference internal" href="gaussian_process.html">1.7. العمليات الغاوسية</a></li>
<li class="toctree-l2"><a class="reference internal" href="cross_decomposition.html">1.8. التحليل المتقاطع</a></li>
<li class="toctree-l2"><a class="reference internal" href="naive_bayes.html">1.9. خوارزميات بايز الساذجة</a></li>
<li class="toctree-l2"><a class="reference internal" href="tree.html">1.10. شجرة القرار</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble.html">1.11. المجموعات: تعزيز التدرج، الغابات العشوائية، التجميع، التصويت، التكديس</a></li>
<li class="toctree-l2"><a class="reference internal" href="multiclass.html">1.12. خوارزميات متعددة التصنيف ومتعددة الإخراج</a></li>
<li class="toctree-l2"><a class="reference internal" href="feature_selection.html">1.13. اختيار الميزات</a></li>
<li class="toctree-l2"><a class="reference internal" href="semi_supervised.html">1.14. التعليم شبه الخاضع للإشراف</a></li>
<li class="toctree-l2"><a class="reference internal" href="isotonic.html">1.15. الانحدار المتساوي التوتر</a></li>
<li class="toctree-l2"><a class="reference internal" href="calibration.html">1.16. معايرة الاحتمال</a></li>
<li class="toctree-l2"><a class="reference internal" href="neural_networks_supervised.html">1.17. نماذج الشبكات العصبية (الخاضعة للإشراف)</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../unsupervised_learning.html">2. التعليم الغير خاضع للإشراف</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="mixture.html">2.1. نماذج خليط غاوسي</a></li>
<li class="toctree-l2"><a class="reference internal" href="manifold.html">2.2. تعلم المشعبات</a></li>
<li class="toctree-l2"><a class="reference internal" href="clustering.html">2.3. التجميع</a></li>
<li class="toctree-l2"><a class="reference internal" href="biclustering.html">2.4. التجميع الثنائي</a></li>
<li class="toctree-l2"><a class="reference internal" href="decomposition.html">2.5. تحليل الإشارات إلى مكونات (مشاكل تحليل المصفوفات)</a></li>
<li class="toctree-l2"><a class="reference internal" href="covariance.html">2.6. تقدير التباين المشترك</a></li>
<li class="toctree-l2"><a class="reference internal" href="outlier_detection.html">2.7. كشف القيم الغريبة والقيم المتطرفة</a></li>
<li class="toctree-l2"><a class="reference internal" href="density.html">2.8. تقدير الكثافة</a></li>
<li class="toctree-l2"><a class="reference internal" href="neural_networks_unsupervised.html">2.9. نماذج الشبكة العصبية (غير خاضعة للإشراف)</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../model_selection.html">3. تقييم وإختيار النموذج</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="cross_validation.html">3.1. التحقق المتبادل: تقييم أداء المقدر</a></li>
<li class="toctree-l2"><a class="reference internal" href="grid_search.html">3.2. ضبط المعلمات الفائقة لمُقدِّر</a></li>
<li class="toctree-l2"><a class="reference internal" href="classification_threshold.html">3.3. ضبط عتبة القرار لتنبؤ الفئة</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">3.4. المقاييس والتهديف: تحديد جودة التنبؤات</a></li>
<li class="toctree-l2"><a class="reference internal" href="learning_curve.html">3.5. منحنيات التحقق من الصحة: رسم الدرجات لتقييم النماذج</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../inspection.html">4. الفحص</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="partial_dependence.html">4.1. مخططات الاعتماد الجزئي والتوقع الشرطي الفردي</a></li>
<li class="toctree-l2"><a class="reference internal" href="permutation_importance.html">4.2. أهمية التبديل</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../visualizations.html">5. التصورات المرئية</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../data_transforms.html">6. تحويلات مجموعات البيانات</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="compose.html">6.1. خطوط الأنابيب والمقدرات المركبة</a></li>
<li class="toctree-l2"><a class="reference internal" href="feature_extraction.html">6.2. استخراج الميزات</a></li>
<li class="toctree-l2"><a class="reference internal" href="preprocessing.html">6.3. المعالجة المسبقة للبيانات</a></li>
<li class="toctree-l2"><a class="reference internal" href="impute.html">6.4. تعويض القيم المفقودة</a></li>
<li class="toctree-l2"><a class="reference internal" href="unsupervised_reduction.html">6.5. تخفيض الأبعاد غير الخاضع للإشراف</a></li>
<li class="toctree-l2"><a class="reference internal" href="random_projection.html">6.6. الإسقاط العشوائي</a></li>
<li class="toctree-l2"><a class="reference internal" href="kernel_approximation.html">6.7. Kernel Approximation</a></li>
<li class="toctree-l2"><a class="reference internal" href="metrics.html">6.8. مقاييس المقارنة الزوجية، والصلات، والنوى (Kernels)</a></li>
<li class="toctree-l2"><a class="reference internal" href="preprocessing_targets.html">6.9. تحويل هدف التنبؤ (<code class="docutils literal notranslate"><span class="pre">y</span></code>)</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets/toy_dataset.html">7. مجموعات بيانات تجريبية</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets/real_world.html">8. مجموعات بيانات العالم الحقيقي</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets/sample_generators.html">9. مجموعات بيانات مولدة</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets/loading_other_datasets.html">10. تحميل مجموعات بيانات أخرى</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../computing.html">11. الحوسبة مع scikit-learn</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../computing/scaling_strategies.html">11.1. استراتيجيات للقياس حسابيًا: بيانات أكبر</a></li>
<li class="toctree-l2"><a class="reference internal" href="../computing/computational_performance.html">11.2. الأداء الحسابي</a></li>
<li class="toctree-l2"><a class="reference internal" href="../computing/parallelism.html">11.3. التوازي وإدارة الموارد والتهيئة</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../model_persistence.html">12. حفظ النموذج</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common_pitfalls.html">13. المزالق الشائعة والممارسات الموصى بها</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../dispatching.html">14. Dispatching</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="array_api.html">14.1. دعم المدخلات المتوافقة مع <code class="docutils literal notranslate"><span class="pre">Array</span> <span class="pre">API</span></code></a></li>

</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../machine_learning_map.html">15. اختيار المقدر المناسب</a></li>
<li class="toctree-l1"><a class="reference internal" href="../presentations.html">16. المصادر الخارجية ومقاطع الفيديو والمحادثات</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../user_guide.html" class="nav-link">دليل المستخدم</a></li>
    
    
    <li class="breadcrumb-item"><a href="../model_selection.html" class="nav-link"><span class="section-number">3. </span>تقييم وإختيار النموذج</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis"><span class="section-number">3.4. </span>المقاييس والتهديف: تحديد جودة التنبؤات</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="model-evaluation">
<span id="id1"></span><h1><span class="section-number">3.4. </span>المقاييس والتهديف: تحديد جودة التنبؤات<a class="headerlink" href="#model-evaluation" title="Link to this heading">#</a></h1>
<p>هناك 3 واجهات برمجة تطبيقات مختلفة لتقييم جودة تنبؤات النموذج:</p>
<ul class="simple">
<li><p><strong>طريقة التهديف للمقدر</strong>: للمقدرات طريقة <code class="docutils literal notranslate"><span class="pre">score</span></code> تُوفر معيار تقييم افتراضي للمشكلة التي تم تصميمها لحلها. لا تتم مناقشة هذا في هذه الصفحة، ولكن في وثائق كل مقدر.</p></li>
<li><p><strong>معلمة التهديف</strong>: تعتمد أدوات تقييم النموذج التي تستخدم <a class="reference internal" href="cross_validation.html#cross-validation"><span class="std std-ref">التحقق المتبادل</span></a> (مثل <a class="reference internal" href="generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score" title="sklearn.model_selection.cross_val_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">model_selection.cross_val_score</span></code></a> و <a class="reference internal" href="generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" title="sklearn.model_selection.GridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">model_selection.GridSearchCV</span></code></a>) على إستراتيجية <em>تهديف</em> داخلية. تمت مناقشة هذا في القسم <a class="reference internal" href="#scoring-parameter"><span class="std std-ref">معلمة scoring: تعريف قواعد تقييم النموذج</span></a>.</p></li>
<li><p><strong>وظائف المقياس</strong>: تُطبق الوحدة <a class="reference internal" href="../api/sklearn.metrics.html#module-sklearn.metrics" title="sklearn.metrics"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></a> وظائف تُقيّم خطأ التنبؤ لأغراض مُحدّدة. هذه المقاييس مُفصلة في الأقسام الخاصة بـ <a class="reference internal" href="#classification-metrics"><span class="std std-ref">مقاييس التصنيف</span></a> و <a class="reference internal" href="#multilabel-ranking-metrics"><span class="std std-ref">مقاييس ترتيب متعددة التسميات</span></a> و <a class="reference internal" href="#regression-metrics"><span class="std std-ref">مقاييس الانحدار</span></a> و <a class="reference internal" href="#clustering-metrics"><span class="std std-ref">مقاييس التجميع</span></a>.</p></li>
</ul>
<p>أخيرًا، تُعد <a class="reference internal" href="#dummy-estimators"><span class="std std-ref">مقدرات وهمية</span></a> مفيدة للحصول على قيمة أساسية لهذه المقاييس للتنبؤات العشوائية.</p>
<div class="admonition seealso">
<p class="admonition-title">شاهد أيضا</p>
<p>للحصول على مقاييس &quot;زوجية&quot;، بين <em>العينات</em> وليس المقدرات أو التنبؤات، انظر قسم <a class="reference internal" href="metrics.html#metrics"><span class="std std-ref">مقاييس المقارنة الزوجية، والصلات، والنوى (Kernels)</span></a>.</p>
</div>
<section id="scoring">
<span id="scoring-parameter"></span><h2><span class="section-number">3.4.1. </span>معلمة <code class="docutils literal notranslate"><span class="pre">scoring</span></code>: تعريف قواعد تقييم النموذج<a class="headerlink" href="#scoring" title="Link to this heading">#</a></h2>
<p>يأخذ اختيار النموذج وتقييمه باستخدام أدوات، مثل <a class="reference internal" href="generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" title="sklearn.model_selection.GridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">model_selection.GridSearchCV</span></code></a> و <a class="reference internal" href="generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score" title="sklearn.model_selection.cross_val_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">model_selection.cross_val_score</span></code></a>، معلمة <code class="docutils literal notranslate"><span class="pre">scoring</span></code> التي تتحكم في المقياس الذي تُطبقه على المقدرات التي تم تقييمها.</p>
<section id="id2">
<h3><span class="section-number">3.4.1.1. </span>الحالات الشائعة: القيم المُعرّفة مسبقًا<a class="headerlink" href="#id2" title="Link to this heading">#</a></h3>
<p>بالنسبة لأكثر حالات الاستخدام شيوعًا، يمكنك تعيين كائن هدّاف باستخدام المعلمة <code class="docutils literal notranslate"><span class="pre">scoring</span></code>؛ يُظهر الجدول أدناه جميع القيم المُمكنة. تتبع جميع كائنات الهدّاف الاتفاقية التي تنص على أن <strong>قيم الإرجاع الأعلى أفضل من قيم الإرجاع الأقل</strong>. وبالتالي، فإن المقاييس التي تقيس المسافة بين النموذج والبيانات، مثل <a class="reference internal" href="generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error" title="sklearn.metrics.mean_squared_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.mean_squared_error</span></code></a>، متاحة كـ neg_mean_squared_error التي تُعيد القيمة السالبة للمقياس.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>التهديف</p></th>
<th class="head"><p>الوظيفة</p></th>
<th class="head"><p>التعليق</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>التصنيف</strong></p></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>'accuracy'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score" title="sklearn.metrics.accuracy_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.accuracy_score</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>'balanced_accuracy'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.balanced_accuracy_score.html#sklearn.metrics.balanced_accuracy_score" title="sklearn.metrics.balanced_accuracy_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.balanced_accuracy_score</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>'top_k_accuracy'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.top_k_accuracy_score.html#sklearn.metrics.top_k_accuracy_score" title="sklearn.metrics.top_k_accuracy_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.top_k_accuracy_score</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>'average_precision'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score" title="sklearn.metrics.average_precision_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.average_precision_score</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>'neg_brier_score'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.brier_score_loss.html#sklearn.metrics.brier_score_loss" title="sklearn.metrics.brier_score_loss"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.brier_score_loss</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>'f1'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score" title="sklearn.metrics.f1_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.f1_score</span></code></a></p></td>
<td><p>للأهداف الثنائية</p></td>
</tr>
<tr class="row-odd"><td><p>'f1_micro'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score" title="sklearn.metrics.f1_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.f1_score</span></code></a></p></td>
<td><p>متوسط دقيق</p></td>
</tr>
<tr class="row-even"><td><p>'f1_macro'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score" title="sklearn.metrics.f1_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.f1_score</span></code></a></p></td>
<td><p>متوسط كلي</p></td>
</tr>
<tr class="row-odd"><td><p>'f1_weighted'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score" title="sklearn.metrics.f1_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.f1_score</span></code></a></p></td>
<td><p>متوسط مرجح</p></td>
</tr>
<tr class="row-even"><td><p>'f1_samples'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score" title="sklearn.metrics.f1_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.f1_score</span></code></a></p></td>
<td><p>حسب عينة متعددة التسميات</p></td>
</tr>
<tr class="row-odd"><td><p>'neg_log_loss'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.log_loss.html#sklearn.metrics.log_loss" title="sklearn.metrics.log_loss"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.log_loss</span></code></a></p></td>
<td><p>يتطلب دعم <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code></p></td>
</tr>
<tr class="row-even"><td><p>'precision' إلخ.</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score" title="sklearn.metrics.precision_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.precision_score</span></code></a></p></td>
<td><p>تنطبق اللواحق كما هو الحال مع 'f1'</p></td>
</tr>
<tr class="row-odd"><td><p>'recall' إلخ.</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score" title="sklearn.metrics.recall_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.recall_score</span></code></a></p></td>
<td><p>تنطبق اللواحق كما هو الحال مع 'f1'</p></td>
</tr>
<tr class="row-even"><td><p>'jaccard' إلخ.</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.jaccard_score.html#sklearn.metrics.jaccard_score" title="sklearn.metrics.jaccard_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.jaccard_score</span></code></a></p></td>
<td><p>تنطبق اللواحق كما هو الحال مع 'f1'</p></td>
</tr>
<tr class="row-odd"><td><p>'roc_auc'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score" title="sklearn.metrics.roc_auc_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.roc_auc_score</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>'roc_auc_ovr'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score" title="sklearn.metrics.roc_auc_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.roc_auc_score</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>'roc_auc_ovo'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score" title="sklearn.metrics.roc_auc_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.roc_auc_score</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>'roc_auc_ovr_weighted'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score" title="sklearn.metrics.roc_auc_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.roc_auc_score</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>'roc_auc_ovo_weighted'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score" title="sklearn.metrics.roc_auc_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.roc_auc_score</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>'d2_log_loss_score'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.d2_log_loss_score.html#sklearn.metrics.d2_log_loss_score" title="sklearn.metrics.d2_log_loss_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.d2_log_loss_score</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>التجميع</strong></p></td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>'adjusted_mutual_info_score'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.adjusted_mutual_info_score.html#sklearn.metrics.adjusted_mutual_info_score" title="sklearn.metrics.adjusted_mutual_info_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.adjusted_mutual_info_score</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>'adjusted_rand_score'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.adjusted_rand_score.html#sklearn.metrics.adjusted_rand_score" title="sklearn.metrics.adjusted_rand_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.adjusted_rand_score</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>'completeness_score'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.completeness_score.html#sklearn.metrics.completeness_score" title="sklearn.metrics.completeness_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.completeness_score</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>'fowlkes_mallows_score'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.fowlkes_mallows_score.html#sklearn.metrics.fowlkes_mallows_score" title="sklearn.metrics.fowlkes_mallows_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.fowlkes_mallows_score</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>'homogeneity_score'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.homogeneity_score.html#sklearn.metrics.homogeneity_score" title="sklearn.metrics.homogeneity_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.homogeneity_score</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>'mutual_info_score'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.mutual_info_score.html#sklearn.metrics.mutual_info_score" title="sklearn.metrics.mutual_info_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.mutual_info_score</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>'normalized_mutual_info_score'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.normalized_mutual_info_score.html#sklearn.metrics.normalized_mutual_info_score" title="sklearn.metrics.normalized_mutual_info_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.normalized_mutual_info_score</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>'rand_score'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.rand_score.html#sklearn.metrics.rand_score" title="sklearn.metrics.rand_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.rand_score</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>'v_measure_score'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.v_measure_score.html#sklearn.metrics.v_measure_score" title="sklearn.metrics.v_measure_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.v_measure_score</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>الانحدار</strong></p></td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>'explained_variance'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.explained_variance_score.html#sklearn.metrics.explained_variance_score" title="sklearn.metrics.explained_variance_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.explained_variance_score</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>'neg_max_error'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.max_error.html#sklearn.metrics.max_error" title="sklearn.metrics.max_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.max_error</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>'neg_mean_absolute_error'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error" title="sklearn.metrics.mean_absolute_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.mean_absolute_error</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>'neg_mean_squared_error'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error" title="sklearn.metrics.mean_squared_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.mean_squared_error</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>'neg_root_mean_squared_error'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.root_mean_squared_error.html#sklearn.metrics.root_mean_squared_error" title="sklearn.metrics.root_mean_squared_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.root_mean_squared_error</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>'neg_mean_squared_log_error'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.mean_squared_log_error.html#sklearn.metrics.mean_squared_log_error" title="sklearn.metrics.mean_squared_log_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.mean_squared_log_error</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>'neg_root_mean_squared_log_error'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.root_mean_squared_log_error.html#sklearn.metrics.root_mean_squared_log_error" title="sklearn.metrics.root_mean_squared_log_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.root_mean_squared_log_error</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>'neg_median_absolute_error'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.median_absolute_error.html#sklearn.metrics.median_absolute_error" title="sklearn.metrics.median_absolute_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.median_absolute_error</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>'r2'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="sklearn.metrics.r2_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.r2_score</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>'neg_mean_poisson_deviance'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.mean_poisson_deviance.html#sklearn.metrics.mean_poisson_deviance" title="sklearn.metrics.mean_poisson_deviance"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.mean_poisson_deviance</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>'neg_mean_gamma_deviance'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.mean_gamma_deviance.html#sklearn.metrics.mean_gamma_deviance" title="sklearn.metrics.mean_gamma_deviance"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.mean_gamma_deviance</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>'neg_mean_absolute_percentage_error'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.mean_absolute_percentage_error.html#sklearn.metrics.mean_absolute_percentage_error" title="sklearn.metrics.mean_absolute_percentage_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.mean_absolute_percentage_error</span></code></a></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>'d2_absolute_error_score'</p></td>
<td><p><a class="reference internal" href="generated/sklearn.metrics.d2_absolute_error_score.html#sklearn.metrics.d2_absolute_error_score" title="sklearn.metrics.d2_absolute_error_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.d2_absolute_error_score</span></code></a></p></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<p>أمثلة الاستخدام:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span><span class="p">,</span> <span class="n">datasets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;recall_macro&#39;</span><span class="p">)</span>
<span class="go">array([0.96..., 0.96..., 0.96..., 0.93..., 1.        ])</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">ملاحظة</p>
<p>إذا تم تمرير اسم تهديف خاطئ، فسيتم طرح <code class="docutils literal notranslate"><span class="pre">InvalidParameterError</span></code>. يمكنك استرداد أسماء جميع الهدّافين المُتاحين عن طريق استدعاء <a class="reference internal" href="generated/sklearn.metrics.get_scorer_names.html#sklearn.metrics.get_scorer_names" title="sklearn.metrics.get_scorer_names"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_scorer_names</span></code></a>.</p>
</div>
</section>
<section id="id3">
<span id="id4"></span><h3><span class="section-number">3.4.1.2. </span>تعريف إستراتيجية التهديف الخاصة بك من وظائف المقياس<a class="headerlink" href="#id3" title="Link to this heading">#</a></h3>
<p>لا يتم تنفيذ وظائف المقاييس التالية كهدّافين مُسمّين، أحيانًا لأنها تتطلب معلمات إضافية، مثل <a class="reference internal" href="generated/sklearn.metrics.fbeta_score.html#sklearn.metrics.fbeta_score" title="sklearn.metrics.fbeta_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">fbeta_score</span></code></a>. لا يمكن تمريرها إلى معلمات <code class="docutils literal notranslate"><span class="pre">scoring</span></code>؛ بدلاً من ذلك، يجب تمرير وظيفتها القابلة للاستدعاء إلى <a class="reference internal" href="generated/sklearn.metrics.make_scorer.html#sklearn.metrics.make_scorer" title="sklearn.metrics.make_scorer"><code class="xref py py-func docutils literal notranslate"><span class="pre">make_scorer</span></code></a> جنبًا إلى جنب مع قيمة المعلمات التي يُمكن للمستخدم ضبطها.</p>
<p>إحدى حالات الاستخدام النموذجية هي تغليف دالة مقياس موجودة من المكتبة بقيم غير افتراضية لمعلماتها، مثل المعلمة <code class="docutils literal notranslate"><span class="pre">beta</span></code> لدالة <a class="reference internal" href="generated/sklearn.metrics.fbeta_score.html#sklearn.metrics.fbeta_score" title="sklearn.metrics.fbeta_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">fbeta_score</span></code></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">fbeta_score</span><span class="p">,</span> <span class="n">make_scorer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ftwo_scorer</span> <span class="o">=</span> <span class="n">make_scorer</span><span class="p">(</span><span class="n">fbeta_score</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">LinearSVC</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">LinearSVC</span><span class="p">(),</span> <span class="n">param_grid</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">]},</span>
<span class="gp">... </span>                    <span class="n">scoring</span><span class="o">=</span><span class="n">ftwo_scorer</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
<p>تكشف الوحدة <a class="reference internal" href="../api/sklearn.metrics.html#module-sklearn.metrics" title="sklearn.metrics"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></a> أيضًا عن مجموعة من الوظائف البسيطة التي تقيس خطأ التنبؤ بالنظر إلى القيمة الحقيقية والتنبؤ:</p>
<ul class="simple">
<li><p>تُعيد الدوال التي تنتهي بـ <code class="docutils literal notranslate"><span class="pre">_score</span></code> قيمة لتعظيمها، فكلما زادت قيمتها كان ذلك أفضل.</p></li>
<li><p>تُعيد الدوال التي تنتهي بـ <code class="docutils literal notranslate"><span class="pre">_error</span></code> أو <code class="docutils literal notranslate"><span class="pre">_loss</span></code> أو <code class="docutils literal notranslate"><span class="pre">_deviance</span></code> قيمة للتقليل منها، فكلما قلت قيمتها كان ذلك أفضل. عند التحويل إلى كائن هدّاف باستخدام <a class="reference internal" href="generated/sklearn.metrics.make_scorer.html#sklearn.metrics.make_scorer" title="sklearn.metrics.make_scorer"><code class="xref py py-func docutils literal notranslate"><span class="pre">make_scorer</span></code></a>، قم بتعيين المعلمة <code class="docutils literal notranslate"><span class="pre">greater_is_better</span></code> إلى <code class="docutils literal notranslate"><span class="pre">False</span></code> (<code class="docutils literal notranslate"><span class="pre">True</span></code> افتراضيًا؛ انظر وصف المعلمة أدناه).</p></li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="كائنات-هدّاف-مخصصة">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">كائنات هدّاف مخصصة<a class="headerlink" href="#كائنات-هدّاف-مخصصة" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">حالة الاستخدام الثانية هي بناء كائن هدّاف مخصص تمامًا من دالة بايثون بسيطة باستخدام <a class="reference internal" href="generated/sklearn.metrics.make_scorer.html#sklearn.metrics.make_scorer" title="sklearn.metrics.make_scorer"><code class="xref py py-func docutils literal notranslate"><span class="pre">make_scorer</span></code></a>، والتي يمكن أن تأخذ عدة معلمات:</p>
<ul class="simple">
<li><p class="sd-card-text">دالة بايثون التي تُريد استخدامها (<code class="docutils literal notranslate"><span class="pre">my_custom_loss_func</span></code> في المثال أدناه)</p></li>
<li><p class="sd-card-text">ما إذا كانت دالة بايثون تُعيد درجة (<code class="docutils literal notranslate"><span class="pre">greater_is_better=True</span></code>، الافتراضي) أو خسارة (<code class="docutils literal notranslate"><span class="pre">greater_is_better=False</span></code>). في حالة الخسارة، يتم عكس ناتج دالة بايثون بواسطة كائن الهدّاف، بما يتوافق مع اتفاقية التحقق المتبادل التي تُعيد الهدّافين قيمًا أعلى للنماذج الأفضل.</p></li>
<li><p class="sd-card-text">لمقاييس التصنيف فقط: ما إذا كانت دالة بايثون التي قدمتها تتطلب يقين قرارات مستمرة. إذا كانت دالة التهديف تقبل فقط تقديرات الاحتمالية (مثل <code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.log_loss</span></code>)، فيجب على المرء تعيين المعلمة <code class="docutils literal notranslate"><span class="pre">response_method</span></code>، وبالتالي في هذه الحالة <code class="docutils literal notranslate"><span class="pre">response_method=&quot;predict_proba&quot;</span></code>. لا تتطلب بعض دوال التهديف بالضرورة تقديرات احتمالية، بل تتطلب قيم قرار غير عتبة (مثل <code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.roc_auc_score</span></code>). في هذه الحالة، يُوفّر المرء قائمة مثل <code class="docutils literal notranslate"><span class="pre">response_method=[&quot;decision_function&quot;,</span> <span class="pre">&quot;predict_proba&quot;]</span></code>. في هذه الحالة، سيستخدم الهدّاف الطريقة الأولى المُتاحة، بالترتيب الوارد في القائمة، لحساب الدرجات.</p></li>
<li><p class="sd-card-text">أي معلمات إضافية، مثل <code class="docutils literal notranslate"><span class="pre">beta</span></code> أو <code class="docutils literal notranslate"><span class="pre">labels</span></code> في <a class="reference internal" href="generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score" title="sklearn.metrics.f1_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">f1_score</span></code></a>.</p></li>
</ul>
<p class="sd-card-text">فيما يلي مثال على بناء هدّافين مخصصين، وعلى استخدام المعلمة <code class="docutils literal notranslate"><span class="pre">greater_is_better</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">my_custom_loss_func</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">diff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y_true</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log1p</span><span class="p">(</span><span class="n">diff</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># ستعكس الدرجة قيمة الإرجاع لـ my_custom_loss_func،</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># والتي ستكون np.log(2)، 0.693، بالنظر إلى القيم لـ X</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># و y المُعرّفة أدناه.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">score</span> <span class="o">=</span> <span class="n">make_scorer</span><span class="p">(</span><span class="n">my_custom_loss_func</span><span class="p">,</span> <span class="n">greater_is_better</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.dummy</span> <span class="kn">import</span> <span class="n">DummyClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">DummyClassifier</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;most_frequent&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">my_custom_loss_func</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="go">0.69...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">-0.69...</span>
</pre></div>
</div>
</div>
</details></section>
<section id="diy-scoring">
<span id="id5"></span><h3><span class="section-number">3.4.1.3. </span>تنفيذ كائن التهديف الخاص بك<a class="headerlink" href="#diy-scoring" title="Link to this heading">#</a></h3>
<p>يمكنك إنشاء هدّافين نماذج أكثر مرونة من خلال إنشاء كائن التهديف الخاص بك من البداية، دون استخدام مصنع <a class="reference internal" href="generated/sklearn.metrics.make_scorer.html#sklearn.metrics.make_scorer" title="sklearn.metrics.make_scorer"><code class="xref py py-func docutils literal notranslate"><span class="pre">make_scorer</span></code></a>.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="كيفية-بناء-هدّاف-من-البداية">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">كيفية بناء هدّاف من البداية<a class="headerlink" href="#كيفية-بناء-هدّاف-من-البداية" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">لكي يكون العنصر القابل للاستدعاء هدّافًا، يجب أن يفي بالبروتوكول المُحدّد بالقاعدتين التاليتين:</p>
<ul class="simple">
<li><p class="sd-card-text">يمكن استدعاؤه بالمعلمات <code class="docutils literal notranslate"><span class="pre">(estimator,</span> <span class="pre">X,</span> <span class="pre">y)</span></code>، حيث <code class="docutils literal notranslate"><span class="pre">estimator</span></code> هو النموذج الذي يجب تقييمه، <code class="docutils literal notranslate"><span class="pre">X</span></code> هي بيانات التحقق من الصحة، و <code class="docutils literal notranslate"><span class="pre">y</span></code> هو الهدف الحقيقي لـ <code class="docutils literal notranslate"><span class="pre">X</span></code> (في الحالة الخاضعة للإشراف) أو <code class="docutils literal notranslate"><span class="pre">None</span></code> (في الحالة غير الخاضعة للإشراف).</p></li>
<li><p class="sd-card-text">يُعيد رقمًا عشريًا يُحدّد جودة تنبؤ <code class="docutils literal notranslate"><span class="pre">estimator</span></code> على <code class="docutils literal notranslate"><span class="pre">X</span></code>، بالرجوع إلى <code class="docutils literal notranslate"><span class="pre">y</span></code>. مرة أخرى، وفقًا للاتفاقية، الأرقام الأعلى أفضل، لذلك إذا أعاد هدّافك خسارة، فيجب عكس تلك القيمة.</p></li>
<li><p class="sd-card-text">متقدم: إذا كان يتطلب تمرير بيانات وصفية إضافية إليه، فيجب أن يكشف عن طريقة <code class="docutils literal notranslate"><span class="pre">get_metadata_routing</span></code> تُعيد البيانات الوصفية المطلوبة. يجب أن يكون المستخدم قادرًا على تعيين البيانات الوصفية المطلوبة عبر طريقة <code class="docutils literal notranslate"><span class="pre">set_score_request</span></code>. يرجى مراجعة <a class="reference internal" href="../metadata_routing.html#metadata-routing"><span class="std std-ref">دليل المستخدم</span></a> و <a class="reference internal" href="../auto_examples/miscellaneous/plot_metadata_routing.html#sphx-glr-auto-examples-miscellaneous-plot-metadata-routing-py"><span class="std std-ref">دليل المطور</span></a> لمزيد من التفاصيل.</p></li>
</ul>
</div>
</details><div class="admonition note">
<p class="admonition-title">ملاحظة</p>
<p><strong>استخدام هدّافين مخصصين في الدوال حيث n_jobs &gt; 1</strong></p>
<p>بينما يجب أن يعمل تعريف دالة التهديف المخصصة جنبًا إلى جنب مع دالة الاستدعاء بشكل افتراضي مع الواجهة الخلفية الافتراضية لـ joblib (loky)، فإن استيرادها من وحدة نمطية أخرى سيكون نهجًا أكثر قوة وسيعمل بشكل مستقل عن الواجهة الخلفية لـ joblib.</p>
<p>على سبيل المثال، لاستخدام <code class="docutils literal notranslate"><span class="pre">n_jobs</span></code> أكبر من 1 في المثال أدناه، يتم حفظ دالة <code class="docutils literal notranslate"><span class="pre">custom_scoring_function</span></code> في وحدة نمطية أنشأها المستخدم (<code class="docutils literal notranslate"><span class="pre">custom_scorer_module.py</span></code>) ويتم استيرادها:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">custom_scorer_module</span> <span class="kn">import</span> <span class="n">custom_scoring_function</span> 
<span class="gp">&gt;&gt;&gt; </span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span>
<span class="gp">... </span> <span class="n">X_train</span><span class="p">,</span>
<span class="gp">... </span> <span class="n">y_train</span><span class="p">,</span>
<span class="gp">... </span> <span class="n">scoring</span><span class="o">=</span><span class="n">make_scorer</span><span class="p">(</span><span class="n">custom_scoring_function</span><span class="p">,</span> <span class="n">greater_is_better</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
<span class="gp">... </span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
<span class="gp">... </span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> 
</pre></div>
</div>
</div>
</section>
<section id="multimetric-scoring">
<span id="id6"></span><h3><span class="section-number">3.4.1.4. </span>استخدام تقييم متعدد المقاييس<a class="headerlink" href="#multimetric-scoring" title="Link to this heading">#</a></h3>
<p>تسمح Scikit-learn أيضًا بتقييم مقاييس متعددة في <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> و <code class="docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code> و <code class="docutils literal notranslate"><span class="pre">cross_validate</span></code>.</p>
<p>هناك ثلاث طرق لتحديد مقاييس تهديف متعددة لمعلمة <code class="docutils literal notranslate"><span class="pre">scoring</span></code>:</p>
<ul>
<li><p>كقيمة قابلة للتكرار لمقاييس السلسلة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">scoring</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;precision&#39;</span><span class="p">]</span>
</pre></div>
</div>
</li>
<li><p>كقاموس <code class="docutils literal notranslate"><span class="pre">dict</span></code> يقوم بتعيين اسم الهدّاف إلى دالة التهديف:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">make_scorer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scoring</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">make_scorer</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">),</span>
<span class="gp">... </span>           <span class="s1">&#39;prec&#39;</span><span class="p">:</span> <span class="s1">&#39;precision&#39;</span><span class="p">}</span>
</pre></div>
</div>
<p>لاحظ أن قيم القاموس يُمكن أن تكون إما دوال هدّاف أو إحدى سلاسل المقاييس المُعرّفة مسبقًا.</p>
</li>
<li><p>كقيمة قابلة للاستدعاء تُعيد قاموسًا من الدرجات:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_validate</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># عينة من مجموعة بيانات تصنيف ثنائية</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">make_classification</span><span class="p">(</span><span class="n">n_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">svm</span> <span class="o">=</span> <span class="n">LinearSVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">confusion_matrix_scorer</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">... </span>     <span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">... </span>     <span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="gp">... </span>     <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;tn&#39;</span><span class="p">:</span> <span class="n">cm</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;fp&#39;</span><span class="p">:</span> <span class="n">cm</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>             <span class="s1">&#39;fn&#39;</span><span class="p">:</span> <span class="n">cm</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;tp&#39;</span><span class="p">:</span> <span class="n">cm</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cv_results</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">scoring</span><span class="o">=</span><span class="n">confusion_matrix_scorer</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># الحصول على درجات الإيجابيات الحقيقية لمجموعة الاختبار</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">cv_results</span><span class="p">[</span><span class="s1">&#39;test_tp&#39;</span><span class="p">])</span>
<span class="go">[10  9  8  7  8]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># الحصول على درجات السلبيات الخاطئة لمجموعة الاختبار</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">cv_results</span><span class="p">[</span><span class="s1">&#39;test_fn&#39;</span><span class="p">])</span>
<span class="go">[0 1 2 3 2]</span>
</pre></div>
</div>
</li>
</ul>
</section>
</section>
<section id="classification-metrics">
<span id="id7"></span><h2><span class="section-number">3.4.2. </span>مقاييس التصنيف<a class="headerlink" href="#classification-metrics" title="Link to this heading">#</a></h2>
<p>تُطبق الوحدة <a class="reference internal" href="../api/sklearn.metrics.html#module-sklearn.metrics" title="sklearn.metrics"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></a> العديد من وظائف الخسارة والتهديف والأداة المساعدة لقياس أداء التصنيف. قد تتطلب بعض المقاييس تقديرات احتمالية للفئة الإيجابية أو قيم الثقة أو قيم القرارات الثنائية. تسمح معظم التطبيقات لكل عينة بتقديم مساهمة مرجحة في الدرجة الإجمالية، من خلال المعلمة <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code>.</p>
<p>بعضها يقتصر على حالة التصنيف الثنائي:</p>
<div class="pst-scrollable-table-container"><table class="autosummary longtable table autosummary">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve" title="sklearn.metrics.precision_recall_curve"><code class="xref py py-obj docutils literal notranslate"><span class="pre">precision_recall_curve</span></code></a>(y_true[, y_score, ...])</p></td>
<td><p>Compute precision-recall pairs for different probability thresholds.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve" title="sklearn.metrics.roc_curve"><code class="xref py py-obj docutils literal notranslate"><span class="pre">roc_curve</span></code></a>(y_true, y_score, *[, pos_label, ...])</p></td>
<td><p>Compute Receiver operating characteristic (ROC).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/sklearn.metrics.class_likelihood_ratios.html#sklearn.metrics.class_likelihood_ratios" title="sklearn.metrics.class_likelihood_ratios"><code class="xref py py-obj docutils literal notranslate"><span class="pre">class_likelihood_ratios</span></code></a>(y_true, y_pred, *[, ...])</p></td>
<td><p>Compute binary classification positive and negative likelihood ratios.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/sklearn.metrics.det_curve.html#sklearn.metrics.det_curve" title="sklearn.metrics.det_curve"><code class="xref py py-obj docutils literal notranslate"><span class="pre">det_curve</span></code></a>(y_true, y_score[, pos_label, ...])</p></td>
<td><p>Compute error rates for different probability thresholds.</p></td>
</tr>
</tbody>
</table>
</div>
<p>يعمل البعض الآخر أيضًا في حالة متعددة الفئات:</p>
<div class="pst-scrollable-table-container"><table class="autosummary longtable table autosummary">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/sklearn.metrics.balanced_accuracy_score.html#sklearn.metrics.balanced_accuracy_score" title="sklearn.metrics.balanced_accuracy_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">balanced_accuracy_score</span></code></a>(y_true, y_pred, *[, ...])</p></td>
<td><p>Compute the balanced accuracy.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/sklearn.metrics.cohen_kappa_score.html#sklearn.metrics.cohen_kappa_score" title="sklearn.metrics.cohen_kappa_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cohen_kappa_score</span></code></a>(y1, y2, *[, labels, ...])</p></td>
<td><p>Compute Cohen's kappa: a statistic that measures inter-annotator agreement.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix" title="sklearn.metrics.confusion_matrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">confusion_matrix</span></code></a>(y_true, y_pred, *[, ...])</p></td>
<td><p>Compute confusion matrix to evaluate the accuracy of a classification.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/sklearn.metrics.hinge_loss.html#sklearn.metrics.hinge_loss" title="sklearn.metrics.hinge_loss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hinge_loss</span></code></a>(y_true, pred_decision, *[, ...])</p></td>
<td><p>Average hinge loss (non-regularized).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/sklearn.metrics.matthews_corrcoef.html#sklearn.metrics.matthews_corrcoef" title="sklearn.metrics.matthews_corrcoef"><code class="xref py py-obj docutils literal notranslate"><span class="pre">matthews_corrcoef</span></code></a>(y_true, y_pred, *[, ...])</p></td>
<td><p>Compute the Matthews correlation coefficient (MCC).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score" title="sklearn.metrics.roc_auc_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">roc_auc_score</span></code></a>(y_true, y_score, *[, average, ...])</p></td>
<td><p>Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC)     from prediction scores.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/sklearn.metrics.top_k_accuracy_score.html#sklearn.metrics.top_k_accuracy_score" title="sklearn.metrics.top_k_accuracy_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">top_k_accuracy_score</span></code></a>(y_true, y_score, *[, ...])</p></td>
<td><p>Top-k Accuracy classification score.</p></td>
</tr>
</tbody>
</table>
</div>
<p>يعمل البعض أيضًا في حالة متعددة التسميات:</p>
<div class="pst-scrollable-table-container"><table class="autosummary longtable table autosummary">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score" title="sklearn.metrics.accuracy_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">accuracy_score</span></code></a>(y_true, y_pred, *[, ...])</p></td>
<td><p>Accuracy classification score.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report" title="sklearn.metrics.classification_report"><code class="xref py py-obj docutils literal notranslate"><span class="pre">classification_report</span></code></a>(y_true, y_pred, *[, ...])</p></td>
<td><p>Build a text report showing the main classification metrics.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score" title="sklearn.metrics.f1_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">f1_score</span></code></a>(y_true, y_pred, *[, labels, ...])</p></td>
<td><p>Compute the F1 score, also known as balanced F-score or F-measure.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/sklearn.metrics.fbeta_score.html#sklearn.metrics.fbeta_score" title="sklearn.metrics.fbeta_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fbeta_score</span></code></a>(y_true, y_pred, *, beta[, ...])</p></td>
<td><p>Compute the F-beta score.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/sklearn.metrics.hamming_loss.html#sklearn.metrics.hamming_loss" title="sklearn.metrics.hamming_loss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hamming_loss</span></code></a>(y_true, y_pred, *[, sample_weight])</p></td>
<td><p>Compute the average Hamming loss.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/sklearn.metrics.jaccard_score.html#sklearn.metrics.jaccard_score" title="sklearn.metrics.jaccard_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">jaccard_score</span></code></a>(y_true, y_pred, *[, labels, ...])</p></td>
<td><p>Jaccard similarity coefficient score.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/sklearn.metrics.log_loss.html#sklearn.metrics.log_loss" title="sklearn.metrics.log_loss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">log_loss</span></code></a>(y_true, y_pred, *[, normalize, ...])</p></td>
<td><p>Log loss, aka logistic loss or cross-entropy loss.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/sklearn.metrics.multilabel_confusion_matrix.html#sklearn.metrics.multilabel_confusion_matrix" title="sklearn.metrics.multilabel_confusion_matrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">multilabel_confusion_matrix</span></code></a>(y_true, y_pred, *)</p></td>
<td><p>Compute a confusion matrix for each class or sample.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/sklearn.metrics.precision_recall_fscore_support.html#sklearn.metrics.precision_recall_fscore_support" title="sklearn.metrics.precision_recall_fscore_support"><code class="xref py py-obj docutils literal notranslate"><span class="pre">precision_recall_fscore_support</span></code></a>(y_true, ...)</p></td>
<td><p>Compute precision, recall, F-measure and support for each class.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score" title="sklearn.metrics.precision_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">precision_score</span></code></a>(y_true, y_pred, *[, labels, ...])</p></td>
<td><p>Compute the precision.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score" title="sklearn.metrics.recall_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">recall_score</span></code></a>(y_true, y_pred, *[, labels, ...])</p></td>
<td><p>Compute the recall.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score" title="sklearn.metrics.roc_auc_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">roc_auc_score</span></code></a>(y_true, y_score, *[, average, ...])</p></td>
<td><p>Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC)     from prediction scores.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/sklearn.metrics.zero_one_loss.html#sklearn.metrics.zero_one_loss" title="sklearn.metrics.zero_one_loss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">zero_one_loss</span></code></a>(y_true, y_pred, *[, ...])</p></td>
<td><p>Zero-one classification loss.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/sklearn.metrics.d2_log_loss_score.html#sklearn.metrics.d2_log_loss_score" title="sklearn.metrics.d2_log_loss_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">d2_log_loss_score</span></code></a>(y_true, y_pred, *[, ...])</p></td>
<td><p><span class="math notranslate nohighlight">\(D^2\)</span> score function, fraction of log loss explained.</p></td>
</tr>
</tbody>
</table>
</div>
<p>وبعضها يعمل مع مشاكل ثنائية ومتعددة التسميات (ولكن ليس متعددة الفئات):</p>
<div class="pst-scrollable-table-container"><table class="autosummary longtable table autosummary">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score" title="sklearn.metrics.average_precision_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">average_precision_score</span></code></a>(y_true, y_score, *)</p></td>
<td><p>Compute average precision (AP) from prediction scores.</p></td>
</tr>
</tbody>
</table>
</div>
<p>في الأقسام الفرعية التالية، سنصف كل دالة من هذه الدوال، مسبوقة ببعض الملاحظات حول واجهة برمجة التطبيقات الشائعة وتعريف المقياس.</p>
<section id="average">
<span id="id8"></span><h3><span class="section-number">3.4.2.1. </span>من ثنائي إلى متعدد الفئات ومتعدد التسميات<a class="headerlink" href="#average" title="Link to this heading">#</a></h3>
<p>يتم تعريف بعض المقاييس بشكل أساسي لمهام التصنيف الثنائي (مثل <a class="reference internal" href="generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score" title="sklearn.metrics.f1_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">f1_score</span></code></a>، <a class="reference internal" href="generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score" title="sklearn.metrics.roc_auc_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">roc_auc_score</span></code></a>). في هذه الحالات، يتم افتراضيًا تقييم التسمية الإيجابية فقط، بافتراض أن الفئة الإيجابية مُعلمة بـ <code class="docutils literal notranslate"><span class="pre">1</span></code> (على الرغم من أن هذا قد يكون قابلاً للتكوين من خلال المعلمة <code class="docutils literal notranslate"><span class="pre">pos_label</span></code>).</p>
<p>عند توسيع مقياس ثنائي لمشاكل متعددة الفئات أو متعددة التسميات، يتم التعامل مع البيانات كمجموعة من المشاكل الثنائية، واحدة لكل فئة. ثم هناك عدد من الطرق لمتوسط حسابات المقياس الثنائي عبر مجموعة الفئات، كل منها قد يكون مفيدًا في بعض السيناريوهات. حيثما أمكن، يجب عليك الاختيار من بينها باستخدام المعلمة <code class="docutils literal notranslate"><span class="pre">average</span></code>.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;macro&quot;</span></code> يحسب ببساطة متوسط المقاييس الثنائية، مع إعطاء وزن متساوٍ لكل فئة. في المشاكل التي تكون فيها الفئات غير المتكررة مهمة مع ذلك، قد يكون المتوسط الكلي وسيلة لتسليط الضوء على أدائها. من ناحية أخرى، غالبًا ما يكون افتراض أن جميع الفئات متساوية الأهمية غير صحيح، بحيث أن المتوسط الكلي سيُبالغ في التأكيد على الأداء المنخفض عادةً على فئة غير متكررة.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;weighted&quot;</span></code> يأخذ في الاعتبار عدم توازن الفئات عن طريق حساب متوسط المقاييس الثنائية حيث يتم ترجيح درجة كل فئة بوجودها في عينة البيانات الحقيقية.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;micro&quot;</span></code> يُعطي كل زوج من فئة العينة مساهمة متساوية في المقياس الإجمالي (باستثناء نتيجة وزن العينة). بدلاً من جمع المقياس لكل فئة، يقوم هذا بجمع الأرباح والقواسم التي تُشكل المقاييس لكل فئة لحساب حاصل قسمة إجمالي. قد يُفضّل المتوسط الدقيق في إعدادات متعددة التسميات، بما في ذلك التصنيف متعدد الفئات حيث سيتم تجاهل فئة الأغلبية.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;samples&quot;</span></code> ينطبق فقط على مشاكل متعددة التسميات. لا يحسب مقياسًا لكل فئة، بل يحسب المقياس على الفئات الحقيقية والمتوقعة لكل عينة في بيانات التقييم، ويُعيد متوسطها (المرجح بـ <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code>).</p></li>
<li><p>سيؤدي تحديد <code class="docutils literal notranslate"><span class="pre">average=None</span></code> إلى إرجاع مصفوفة مع الدرجة لكل فئة.</p></li>
</ul>
<p>بينما يتم توفير بيانات متعددة الفئات للمقياس، مثل الأهداف الثنائية، كمصفوفة من تسميات الفئات، يتم تحديد البيانات متعددة التسميات كمصفوفة مؤشر، حيث تكون الخلية <code class="docutils literal notranslate"><span class="pre">[i,</span> <span class="pre">j]</span></code> بقيمة 1 إذا كانت العينة <code class="docutils literal notranslate"><span class="pre">i</span></code> تحمل التسمية <code class="docutils literal notranslate"><span class="pre">j</span></code> وقيمة 0 بخلاف ذلك.</p>
</section>
<section id="accuracy-score">
<span id="id9"></span><h3><span class="section-number">3.4.2.2. </span>درجة الدقة<a class="headerlink" href="#accuracy-score" title="Link to this heading">#</a></h3>
<p>تحسب الدالة <a class="reference internal" href="generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score" title="sklearn.metrics.accuracy_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">accuracy_score</span></code></a> <a class="reference external" href="https://en.wikipedia.org/wiki/Accuracy_and_precision">الدقة</a>، إما الكسر (افتراضيًا) أو العدد (normalize=False) من التنبؤات الصحيحة.</p>
<p>في التصنيف متعدد التسميات، تُعيد الدالة دقة المجموعة الفرعية. إذا تطابقت مجموعة التسميات المتوقعة لعينة ما تمامًا مع مجموعة التسميات الحقيقية، فإن دقة المجموعة الفرعية هي 1.0؛ بخلاف ذلك، فهي 0.0.</p>
<p>إذا كانت <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> هي القيمة المتوقعة للعينة <span class="math notranslate nohighlight">\(i\)</span> و <span class="math notranslate nohighlight">\(y_i\)</span> هي القيمة الحقيقية المقابلة، فسيتم تعريف كسر التنبؤات الصحيحة على <span class="math notranslate nohighlight">\(n_\text{samples}\)</span> على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[\texttt{accuracy}(y, \hat{y}) = \frac{1}{n_\text{samples}} \sum_{i=0}^{n_\text{samples}-1} 1(\hat{y}_i = y_i)\]</div>
<p>حيث <span class="math notranslate nohighlight">\(1(x)\)</span> هي <a class="reference external" href="https://en.wikipedia.org/wiki/Indicator_function">دالة المؤشر</a>.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">2.0</span>
</pre></div>
</div>
<p>في حالة متعددة التسميات مع مؤشرات تسمية ثنائية:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="go">0.5</span>
</pre></div>
</div>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p>انظر <a class="reference internal" href="../auto_examples/model_selection/plot_permutation_tests_for_classification.html#sphx-glr-auto-examples-model-selection-plot-permutation-tests-for-classification-py"><span class="std std-ref">Test with permutations the significance of a classification score</span></a> للحصول على مثال على استخدام درجة الدقة باستخدام تباديل مجموعة البيانات.</p></li>
</ul>
</section>
<section id="k">
<span id="top-k-accuracy-score"></span><h3><span class="section-number">3.4.2.3. </span>درجة دقة أعلى k<a class="headerlink" href="#k" title="Link to this heading">#</a></h3>
<p>الدالة <a class="reference internal" href="generated/sklearn.metrics.top_k_accuracy_score.html#sklearn.metrics.top_k_accuracy_score" title="sklearn.metrics.top_k_accuracy_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">top_k_accuracy_score</span></code></a> هي تعميم لـ <a class="reference internal" href="generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score" title="sklearn.metrics.accuracy_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">accuracy_score</span></code></a>. الفرق هو أن التنبؤ يُعتبر صحيحًا طالما أن التسمية الحقيقية مرتبطة بواحدة من أعلى <code class="docutils literal notranslate"><span class="pre">k</span></code> درجات متوقعة. <a class="reference internal" href="generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score" title="sklearn.metrics.accuracy_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">accuracy_score</span></code></a> هي الحالة الخاصة لـ k = 1.</p>
<p>تُغطي الدالة حالات التصنيف الثنائي ومتعدد الفئات ولكن ليس حالة متعددة التسميات.</p>
<p>إذا كانت <span class="math notranslate nohighlight">\(\hat{f}_{i,j}\)</span> هي الفئة المتوقعة للعينة <span class="math notranslate nohighlight">\(i\)</span> المقابلة لأكبر درجة متوقعة <span class="math notranslate nohighlight">\(j\)</span> و <span class="math notranslate nohighlight">\(y_i\)</span> هي القيمة الحقيقية المقابلة، فسيتم تعريف كسر التنبؤات الصحيحة على <span class="math notranslate nohighlight">\(n_\text{samples}\)</span> على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[\texttt{top-k accuracy}(y, \hat{f}) = \frac{1}{n_\text{samples}} \sum_{i=0}^{n_\text{samples}-1} \sum_{j=1}^{k} 1(\hat{f}_{i,j} = y_i)\]</div>
<p>حيث <span class="math notranslate nohighlight">\(k\)</span> هو عدد التخمينات المسموح بها و <span class="math notranslate nohighlight">\(1(x)\)</span> هي <a class="reference external" href="https://en.wikipedia.org/wiki/Indicator_function">دالة المؤشر</a>.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">top_k_accuracy_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
<span class="gp">... </span>                    <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
<span class="gp">... </span>                    <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
<span class="gp">... </span>                    <span class="p">[</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">top_k_accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="go">0.75</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># عدم التطبيع يُعطي عدد العينات المصنفة &quot;بشكل صحيح&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">top_k_accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">3</span>
</pre></div>
</div>
</section>
<section id="balanced-accuracy-score">
<span id="id13"></span><h3><span class="section-number">3.4.2.4. </span>درجة الدقة المتوازنة<a class="headerlink" href="#balanced-accuracy-score" title="Link to this heading">#</a></h3>
<p>تحسب الدالة <a class="reference internal" href="generated/sklearn.metrics.balanced_accuracy_score.html#sklearn.metrics.balanced_accuracy_score" title="sklearn.metrics.balanced_accuracy_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">balanced_accuracy_score</span></code></a> <a class="reference external" href="https://en.wikipedia.org/wiki/Accuracy_and_precision">الدقة المتوازنة</a>، والتي تتجنب تقديرات الأداء المُبالغ فيها على مجموعات البيانات غير المتوازنة. وهو المتوسط الكلي لدرجات الاستدعاء لكل فئة أو، على نحو مكافئ، الدقة الأولية حيث يتم ترجيح كل عينة وفقًا للانتشار العكسي لفئتها الحقيقية. وبالتالي، بالنسبة لمجموعات البيانات المتوازنة، فإن الدرجة تساوي الدقة.</p>
<p>في الحالة الثنائية، تساوي الدقة المتوازنة المتوسط الحسابي لـ <a class="reference external" href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity">الحساسية</a> (معدل الإيجابيات الحقيقية) و <a class="reference external" href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity">النوعية</a> (معدل السلبيات الحقيقية)، أو المنطقة الواقعة أسفل منحنى ROC مع تنبؤات ثنائية بدلاً من الدرجات:</p>
<div class="math notranslate nohighlight">
\[\texttt{balanced-accuracy} = \frac{1}{2}\left( \frac{TP}{TP + FN} + \frac{TN}{TN + FP}\right )\]</div>
<p>إذا كان المصنف يؤدي أداءً جيدًا على قدم المساواة في أي من الفئتين، فإن هذا المصطلح ينخفض إلى الدقة التقليدية (أي عدد التنبؤات الصحيحة مقسومًا على إجمالي عدد التنبؤات).</p>
<p>في المقابل، إذا كانت الدقة التقليدية أعلى من الصدفة فقط لأن المصنف يستفيد من مجموعة اختبار غير متوازنة، فإن الدقة المتوازنة، حسب الاقتضاء، ستنخفض إلى <span class="math notranslate nohighlight">\(\frac{1}{n\_classes}\)</span>.</p>
<p>يتراوح النطاق من 0 إلى 1، أو عندما يتم استخدام <code class="docutils literal notranslate"><span class="pre">adjusted=True</span></code>، يتم إعادة قياسه إلى النطاق <span class="math notranslate nohighlight">\(\frac{1}{1 - n\_classes}\)</span> إلى 1، شامل، مع أداء عند التهديف العشوائي 0.</p>
<p>إذا كانت <span class="math notranslate nohighlight">\(y_i\)</span> هي القيمة الحقيقية للعينة <span class="math notranslate nohighlight">\(i\)</span>، و <span class="math notranslate nohighlight">\(w_i\)</span> هو وزن العينة المقابل، فإننا نضبط وزن العينة على:</p>
<div class="math notranslate nohighlight">
\[\hat{w}_i = \frac{w_i}{\sum_j{1(y_j = y_i) w_j}}\]</div>
<p>حيث <span class="math notranslate nohighlight">\(1(x)\)</span> هي <a class="reference external" href="https://en.wikipedia.org/wiki/Indicator_function">دالة المؤشر</a>. بالنظر إلى التنبؤ <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> للعينة <span class="math notranslate nohighlight">\(i\)</span>، يتم تعريف الدقة المتوازنة على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[\texttt{balanced-accuracy}(y, \hat{y}, w) = \frac{1}{\sum{\hat{w}_i}} \sum_i 1(\hat{y}_i = y_i) \hat{w}_i\]</div>
<p>مع <code class="docutils literal notranslate"><span class="pre">adjusted=True</span></code>، تُبلغ الدقة المتوازنة عن الزيادة النسبية من <span class="math notranslate nohighlight">\(\texttt{balanced-accuracy}(y, \mathbf{0}, w) =
\frac{1}{n\_classes}\)</span>. في الحالة الثنائية، يُعرف هذا أيضًا باسم <a class="reference external" href="https://en.wikipedia.org/wiki/Youden%27s_J_statistic">*إحصائية J ليودن*</a>، أو <em>المعلوماتية</em>.</p>
<div class="admonition note">
<p class="admonition-title">ملاحظة</p>
<p>يبدو تعريف متعدد الفئات هنا بمثابة التمديد الأكثر منطقية للمقياس المُستخدم في التصنيف الثنائي، على الرغم من عدم وجود إجماع مُؤكّد في الأدبيات:</p>
<ul class="simple">
<li><p>تعريفنا: <a class="reference internal" href="#mosley2013" id="id18"><span>[Mosley2013]</span></a>، <a class="reference internal" href="#kelleher2015" id="id19"><span>[Kelleher2015]</span></a> و <a class="reference internal" href="#guyon2015" id="id20"><span>[Guyon2015]</span></a>، حيث يتبنى <a class="reference internal" href="#guyon2015" id="id21"><span>[Guyon2015]</span></a> الإصدار المعدل لضمان أن يكون للتنبؤات العشوائية درجة <span class="math notranslate nohighlight">\(0\)</span> وللتنبؤات المثالية درجة <span class="math notranslate nohighlight">\(1\)</span>.</p></li>
<li><p>دقة توازن الفئات كما هو موضح في <a class="reference internal" href="#mosley2013" id="id22"><span>[Mosley2013]</span></a>: يتم حساب الحد الأدنى بين الدقة والاستدعاء لكل فئة. ثم يتم حساب متوسط هذه القيم على إجمالي عدد الفئات للحصول على الدقة المتوازنة.</p></li>
<li><p>الدقة المتوازنة كما هو موضح في <a class="reference internal" href="#urbanowicz2015" id="id23"><span>[Urbanowicz2015]</span></a>: يتم حساب متوسط الحساسية والنوعية لكل فئة ثم حساب متوسطها على إجمالي عدد الفئات.</p></li>
</ul>
</div>
<p class="rubric">المراجع</p>
<div role="list" class="citation-list">
<div class="citation" id="guyon2015" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Guyon2015<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id20">1</a>,<a role="doc-backlink" href="#id21">2</a>)</span>
<p>I. Guyon, K. Bennett, G. Cawley, H.J. Escalante, S. Escalera, T.K. Ho, N. Macià,
B. Ray, M. Saeed, A.R. Statnikov, E. Viegas, <a class="reference external" href="https://ieeexplore.ieee.org/document/7280767">Design of the 2015 ChaLearn AutoML Challenge</a>, IJCNN 2015.</p>
</div>
<div class="citation" id="mosley2013" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Mosley2013<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id18">1</a>,<a role="doc-backlink" href="#id22">2</a>)</span>
<p>L. Mosley, <a class="reference external" href="https://lib.dr.iastate.edu/etd/13537/">A balanced approach to the multi-class imbalance problem</a>, IJCV 2010.</p>
</div>
<div class="citation" id="kelleher2015" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id19">Kelleher2015</a><span class="fn-bracket">]</span></span>
<p>John. D. Kelleher, Brian Mac Namee, Aoife D'Arcy, <a class="reference external" href="https://mitpress.mit.edu/books/fundamentals-machine-learning-predictive-data-analytics">Fundamentals of
Machine Learning for Predictive Data Analytics: Algorithms, Worked Examples,
and Case Studies</a>,
2015.</p>
</div>
<div class="citation" id="urbanowicz2015" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id23">Urbanowicz2015</a><span class="fn-bracket">]</span></span>
<p>Urbanowicz R.J.,  Moore, J.H. <a class="reference external" href="https://doi.org/10.1007/s12065-015-0128-8">ExSTraCS 2.0: description
and evaluation of a scalable learning classifier
system</a>, Evol. Intel. (2015) 8: 89.</p>
</div>
</div>
</section>
<section id="cohen-kappa">
<span id="id24"></span><h3><span class="section-number">3.4.2.5. </span>كابا كوهين<a class="headerlink" href="#cohen-kappa" title="Link to this heading">#</a></h3>
<p>تحسب الدالة <a class="reference internal" href="generated/sklearn.metrics.cohen_kappa_score.html#sklearn.metrics.cohen_kappa_score" title="sklearn.metrics.cohen_kappa_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">cohen_kappa_score</span></code></a> إحصائية <a class="reference external" href="https://en.wikipedia.org/wiki/Cohen%27s_kappa">كابا كوهين</a>. يهدف هذا المقياس إلى مقارنة عمليات التوسيم بواسطة مُعلّمين بشريين مختلفين، وليس مُصنفًا مقابل القيمة الحقيقية.</p>
<p>درجة كابا هي رقم بين -1 و 1. تُعتبر الدرجات التي تزيد عن 0.8 اتفاقًا جيدًا بشكل عام؛ الصفر أو أقل يعني عدم وجود اتفاق يعني عدم وجود اتفاق (تسميات عشوائية عمليًا).</p>
<p>يمكن حساب درجات كابا للمشاكل الثنائية أو متعددة الفئات، ولكن ليس لمشاكل متعددة التسميات (إلا عن طريق حساب درجة لكل تسمية يدويًا) وليس لأكثر من مُعلّمين.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">cohen_kappa_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labeling1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labeling2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cohen_kappa_score</span><span class="p">(</span><span class="n">labeling1</span><span class="p">,</span> <span class="n">labeling2</span><span class="p">)</span>
<span class="go">0.4285714285714286</span>
</pre></div>
</div>
</section>
<section id="confusion-matrix">
<span id="id26"></span><h3><span class="section-number">3.4.2.6. </span>مصفوفة الارتباك<a class="headerlink" href="#confusion-matrix" title="Link to this heading">#</a></h3>
<p>تُقيّم الدالة <a class="reference internal" href="generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix" title="sklearn.metrics.confusion_matrix"><code class="xref py py-func docutils literal notranslate"><span class="pre">confusion_matrix</span></code></a> دقة التصنيف عن طريق حساب <a class="reference external" href="https://en.wikipedia.org/wiki/Confusion_matrix">مصفوفة الارتباك</a> مع كل صف يقابل الفئة الحقيقية (قد تستخدم ويكيبيديا والمراجع الأخرى اصطلاحًا مختلفًا للمحاور).</p>
<p>بحكم التعريف، فإن الإدخال <span class="math notranslate nohighlight">\(i, j\)</span> في مصفوفة الارتباك هو عدد المشاهدات الموجودة فعليًا في المجموعة <span class="math notranslate nohighlight">\(i\)</span>، ولكن تم التنبؤ بأنها في المجموعة <span class="math notranslate nohighlight">\(j\)</span>. هنا مثال:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">array([[2, 0, 0],</span>
<span class="go">       [0, 0, 1],</span>
<span class="go">       [1, 0, 2]])</span>
</pre></div>
</div>
<p>يمكن استخدام <a class="reference internal" href="generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay" title="sklearn.metrics.ConfusionMatrixDisplay"><code class="xref py py-class docutils literal notranslate"><span class="pre">ConfusionMatrixDisplay</span></code></a> لتمثيل مصفوفة الارتباك بصريًا كما هو موضح في مثال <a class="reference internal" href="../auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"><span class="std std-ref">Confusion matrix</span></a>، الذي ينشئ الشكل التالي:</p>
<a class="reference external image-reference" href="../auto_examples/model_selection/plot_confusion_matrix.html"><img alt="../_images/sphx_glr_plot_confusion_matrix_001.png" class="align-center" src="../_images/sphx_glr_plot_confusion_matrix_001.png" style="width: 480.0px; height: 360.0px;" />
</a>
<p>تسمح المعلمة <code class="docutils literal notranslate"><span class="pre">normalize</span></code> بالإبلاغ عن النسب بدلاً من الأعداد. يمكن تطبيع مصفوفة الارتباك بثلاث طرق مختلفة: <code class="docutils literal notranslate"><span class="pre">'pred'</span></code> و <code class="docutils literal notranslate"><span class="pre">'true'</span></code> و <code class="docutils literal notranslate"><span class="pre">'all'</span></code> والتي ستقسم الأعداد على مجموع كل أعمدة أو صفوف أو المصفوفة بأكملها، على التوالي.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">)</span>
<span class="go">array([[0.25 , 0.125],</span>
<span class="go">       [0.25 , 0.375]])</span>
</pre></div>
</div>
<p>بالنسبة للمشاكل الثنائية، يمكننا الحصول على أعداد السلبيات الحقيقية والإيجابيات الخاطئة والسلبيات الخاطئة والإيجابيات الحقيقية على النحو التالي:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">tp</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">tp</span>
<span class="go">(2, 1, 2, 3)</span>
</pre></div>
</div>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p>انظر <a class="reference internal" href="../auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"><span class="std std-ref">Confusion matrix</span></a> للحصول على مثال على استخدام مصفوفة الارتباك لتقييم جودة ناتج المصنف.</p></li>
<li><p>انظر <a class="reference internal" href="../auto_examples/classification/plot_digits_classification.html#sphx-glr-auto-examples-classification-plot-digits-classification-py"><span class="std std-ref">Recognizing hand-written digits</span></a> للحصول على مثال على استخدام مصفوفة الارتباك لتصنيف الأرقام المكتوبة بخط اليد.</p></li>
<li><p>انظر <a class="reference internal" href="../auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py"><span class="std std-ref">Classification of text documents using sparse features</span></a> للحصول على مثال على استخدام مصفوفة الارتباك لتصنيف المستندات النصية.</p></li>
</ul>
</section>
<section id="classification-report">
<span id="id28"></span><h3><span class="section-number">3.4.2.7. </span>تقرير التصنيف<a class="headerlink" href="#classification-report" title="Link to this heading">#</a></h3>
<p>تنشئ الدالة <a class="reference internal" href="generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report" title="sklearn.metrics.classification_report"><code class="xref py py-func docutils literal notranslate"><span class="pre">classification_report</span></code></a> تقريرًا نصيًا يُظهر مقاييس التصنيف الرئيسية. هنا مثال صغير مع <code class="docutils literal notranslate"><span class="pre">target_names</span></code> مخصصة وتسميات مُستنتجة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;class 0&#39;</span><span class="p">,</span> <span class="s1">&#39;class 1&#39;</span><span class="p">,</span> <span class="s1">&#39;class 2&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">target_names</span><span class="p">))</span>
<span class="go">              precision    recall  f1-score   support</span>

<span class="go">     class 0       0.67      1.00      0.80         2</span>
<span class="go">     class 1       0.00      0.00      0.00         1</span>
<span class="go">     class 2       1.00      0.50      0.67         2</span>

<span class="go">    accuracy                           0.60         5</span>
<span class="go">   macro avg       0.56      0.50      0.49         5</span>
<span class="go">weighted avg       0.67      0.60      0.59         5</span>
</pre></div>
</div>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p>انظر <a class="reference internal" href="../auto_examples/classification/plot_digits_classification.html#sphx-glr-auto-examples-classification-plot-digits-classification-py"><span class="std std-ref">Recognizing hand-written digits</span></a> للحصول على مثال على استخدام تقرير التصنيف للأرقام المكتوبة بخط اليد.</p></li>
<li><p>انظر <a class="reference internal" href="../auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py"><span class="std std-ref">Custom refit strategy of a grid search with cross-validation</span></a> للحصول على مثال على استخدام تقرير التصنيف للبحث الشبكي مع التحقق المتبادل المتداخل.</p></li>
</ul>
</section>
<section id="hamming-loss">
<span id="id29"></span><h3><span class="section-number">3.4.2.8. </span>خسارة هامينغ<a class="headerlink" href="#hamming-loss" title="Link to this heading">#</a></h3>
<p>تحسب <a class="reference internal" href="generated/sklearn.metrics.hamming_loss.html#sklearn.metrics.hamming_loss" title="sklearn.metrics.hamming_loss"><code class="xref py py-func docutils literal notranslate"><span class="pre">hamming_loss</span></code></a> متوسط خسارة هامينغ أو <a class="reference external" href="https://en.wikipedia.org/wiki/Hamming_distance">مسافة هامينغ</a> بين مجموعتين من العينات.</p>
<p>إذا كانت <span class="math notranslate nohighlight">\(\hat{y}_{i,j}\)</span> هي القيمة المتوقعة للتسمية <span class="math notranslate nohighlight">\(j\)</span> لعينة مُعطاة <span class="math notranslate nohighlight">\(i\)</span>، <span class="math notranslate nohighlight">\(y_{i,j}\)</span> هي القيمة الحقيقية المقابلة، <span class="math notranslate nohighlight">\(n_\text{samples}\)</span> هو عدد العينات و <span class="math notranslate nohighlight">\(n_\text{labels}\)</span> هو عدد التسميات، فسيتم تعريف خسارة هامينغ <span class="math notranslate nohighlight">\(L_{Hamming}\)</span> على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[L_{Hamming}(y, \hat{y}) = \frac{1}{n_\text{samples} * n_\text{labels}} \sum_{i=0}^{n_\text{samples}-1} \sum_{j=0}^{n_\text{labels} - 1} 1(\hat{y}_{i,j} \not= y_{i,j})\]</div>
<p>حيث <span class="math notranslate nohighlight">\(1(x)\)</span> هي <a class="reference external" href="https://en.wikipedia.org/wiki/Indicator_function">دالة المؤشر</a>.</p>
<p>لا تصح المعادلة أعلاه في حالة التصنيف متعدد الفئات. يرجى الرجوع إلى الملاحظة أدناه لمزيد من المعلومات.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">hamming_loss</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hamming_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.25</span>
</pre></div>
</div>
<p>في حالة متعددة التسميات مع مؤشرات تسمية ثنائية:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">hamming_loss</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="go">0.75</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">ملاحظة</p>
<p>في التصنيف متعدد الفئات، تتوافق خسارة هامينغ مع مسافة هامينغ بين <code class="docutils literal notranslate"><span class="pre">y_true</span></code> و <code class="docutils literal notranslate"><span class="pre">y_pred</span></code> والتي تُشبه دالة <a class="reference internal" href="#zero-one-loss"><span class="std std-ref">خسارة الصفر-واحد</span></a>. ومع ذلك، بينما تُعاقب خسارة الصفر-واحد مجموعات التنبؤ التي لا تتطابق تمامًا مع المجموعات الحقيقية، تُعاقب خسارة هامينغ التسميات الفردية. وبالتالي، فإن خسارة هامينغ، التي يحدها من الأعلى خسارة الصفر-واحد، تكون دائمًا بين الصفر والواحد، شامل؛ والتنبؤ بمجموعة فرعية مناسبة أو مجموعة شاملة من التسميات الحقيقية سيعطي خسارة هامينغ بين الصفر والواحد، باستثناء.</p>
</div>
</section>
<section id="f">
<span id="precision-recall-f-measure-metrics"></span><h3><span class="section-number">3.4.2.9. </span>الدقة والاستدعاء ومقاييس F<a class="headerlink" href="#f" title="Link to this heading">#</a></h3>
<p>بشكل بديهي، <a class="reference external" href="https://en.wikipedia.org/wiki/Precision_and_recall#Precision">الدقة</a> هي قدرة المصنف على عدم تسمية عينة سلبية على أنها إيجابية، و <a class="reference external" href="https://en.wikipedia.org/wiki/Precision_and_recall#Recall">الاستدعاء</a> هو قدرة المصنف على إيجاد جميع العينات الإيجابية.</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/F1_score">مقياس F</a> (<span class="math notranslate nohighlight">\(F_\beta\)</span> و <span class="math notranslate nohighlight">\(F_1\)</span> يقيس) يمكن تفسيره على أنه متوسط توافقي مرجح للدقة والاستدعاء. يصل مقياس <span class="math notranslate nohighlight">\(F_\beta\)</span> إلى أفضل قيمة له عند 1 وأسوأ درجة له عند 0. مع <span class="math notranslate nohighlight">\(\beta = 1\)</span>، يكون <span class="math notranslate nohighlight">\(F_\beta\)</span> و <span class="math notranslate nohighlight">\(F_1\)</span> متكافئين، ويكون الاستدعاء والدقة بنفس القدر من الأهمية.</p>
<p>تحسب <a class="reference internal" href="generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve" title="sklearn.metrics.precision_recall_curve"><code class="xref py py-func docutils literal notranslate"><span class="pre">precision_recall_curve</span></code></a> منحنى دقة-استدعاء من تسمية القيمة الحقيقية ودرجة مُعطاة بواسطة المصنف عن طريق تغيير عتبة القرار.</p>
<p>تحسب الدالة <a class="reference internal" href="generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score" title="sklearn.metrics.average_precision_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">average_precision_score</span></code></a> <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Information_retrieval&amp;oldid=793358396#Average_precision">متوسط الدقة</a> (AP) من درجات التنبؤ. القيمة بين 0 و 1 والأعلى أفضل. يتم تعريف AP على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[\text{AP} = \sum_n (R_n - R_{n-1}) P_n\]</div>
<p>حيث <span class="math notranslate nohighlight">\(P_n\)</span> و <span class="math notranslate nohighlight">\(R_n\)</span> هما الدقة والاستدعاء عند العتبة n. مع التنبؤات العشوائية، فإن AP هو كسر العينات الإيجابية.</p>
<p>تُقدّم المراجع <a class="reference internal" href="#manning2008" id="id36"><span>[Manning2008]</span></a> و <a class="reference internal" href="#everingham2010" id="id37"><span>[Everingham2010]</span></a> متغيرات بديلة لـ AP تُقحم منحنى الدقة-الاستدعاء. حاليًا، لا تُطبّق <a class="reference internal" href="generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score" title="sklearn.metrics.average_precision_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">average_precision_score</span></code></a> أي متغير مُقحم. تصف المراجع <a class="reference internal" href="#davis2006" id="id38"><span>[Davis2006]</span></a> و <a class="reference internal" href="#flach2015" id="id39"><span>[Flach2015]</span></a> سبب توفير الاستيفاء الخطي للنقاط على منحنى الدقة-الاستدعاء مقياسًا مُتفائلًا بشكل مُفرط لأداء المصنف. يتم استخدام هذا الاستيفاء الخطي عند حساب المنطقة الواقعة أسفل المنحنى باستخدام قاعدة شبه المنحرف في <a class="reference internal" href="generated/sklearn.metrics.auc.html#sklearn.metrics.auc" title="sklearn.metrics.auc"><code class="xref py py-func docutils literal notranslate"><span class="pre">auc</span></code></a>.</p>
<p>تسمح لك العديد من الدوال بتحليل درجة الدقة والاستدعاء ومقاييس F:</p>
<div class="pst-scrollable-table-container"><table class="autosummary longtable table autosummary">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score" title="sklearn.metrics.average_precision_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">average_precision_score</span></code></a>(y_true, y_score, *)</p></td>
<td><p>Compute average precision (AP) from prediction scores.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score" title="sklearn.metrics.f1_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">f1_score</span></code></a>(y_true, y_pred, *[, labels, ...])</p></td>
<td><p>Compute the F1 score, also known as balanced F-score or F-measure.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/sklearn.metrics.fbeta_score.html#sklearn.metrics.fbeta_score" title="sklearn.metrics.fbeta_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fbeta_score</span></code></a>(y_true, y_pred, *, beta[, ...])</p></td>
<td><p>Compute the F-beta score.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve" title="sklearn.metrics.precision_recall_curve"><code class="xref py py-obj docutils literal notranslate"><span class="pre">precision_recall_curve</span></code></a>(y_true[, y_score, ...])</p></td>
<td><p>Compute precision-recall pairs for different probability thresholds.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/sklearn.metrics.precision_recall_fscore_support.html#sklearn.metrics.precision_recall_fscore_support" title="sklearn.metrics.precision_recall_fscore_support"><code class="xref py py-obj docutils literal notranslate"><span class="pre">precision_recall_fscore_support</span></code></a>(y_true, ...)</p></td>
<td><p>Compute precision, recall, F-measure and support for each class.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score" title="sklearn.metrics.precision_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">precision_score</span></code></a>(y_true, y_pred, *[, labels, ...])</p></td>
<td><p>Compute the precision.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score" title="sklearn.metrics.recall_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">recall_score</span></code></a>(y_true, y_pred, *[, labels, ...])</p></td>
<td><p>Compute the recall.</p></td>
</tr>
</tbody>
</table>
</div>
<p>لاحظ أن الدالة <a class="reference internal" href="generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve" title="sklearn.metrics.precision_recall_curve"><code class="xref py py-func docutils literal notranslate"><span class="pre">precision_recall_curve</span></code></a> تقتصر على الحالة الثنائية. تدعم الدالة <a class="reference internal" href="generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score" title="sklearn.metrics.average_precision_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">average_precision_score</span></code></a> التنسيقات متعددة الفئات ومتعددة التسميات عن طريق حساب كل درجة فئة بطريقة واحد مقابل البقية (OvR) ومتوسطها أو عدم متوسطها اعتمادًا على قيمة وسيطة <code class="docutils literal notranslate"><span class="pre">average</span></code>.</p>
<p>ستقوم الدالتان <a class="reference internal" href="generated/sklearn.metrics.PrecisionRecallDisplay.html#sklearn.metrics.PrecisionRecallDisplay.from_estimator" title="sklearn.metrics.PrecisionRecallDisplay.from_estimator"><code class="xref py py-func docutils literal notranslate"><span class="pre">PrecisionRecallDisplay.from_estimator</span></code></a> و <a class="reference internal" href="generated/sklearn.metrics.PrecisionRecallDisplay.html#sklearn.metrics.PrecisionRecallDisplay.from_predictions" title="sklearn.metrics.PrecisionRecallDisplay.from_predictions"><code class="xref py py-func docutils literal notranslate"><span class="pre">PrecisionRecallDisplay.from_predictions</span></code></a> برسم منحنى الدقة والاستدعاء كما يلي.</p>
<a class="reference external image-reference" href="../auto_examples/model_selection/plot_precision_recall.html#plot-the-precision-recall-curve"><img alt="../_images/sphx_glr_plot_precision_recall_001.png" class="align-center" src="../_images/sphx_glr_plot_precision_recall_001.png" style="width: 480.0px; height: 360.0px;" />
</a>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p>انظر <a class="reference internal" href="../auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py"><span class="std std-ref">Custom refit strategy of a grid search with cross-validation</span></a> للحصول على مثال على استخدام <a class="reference internal" href="generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score" title="sklearn.metrics.precision_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">precision_score</span></code></a> و <a class="reference internal" href="generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score" title="sklearn.metrics.recall_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">recall_score</span></code></a> لتقدير المعلمات باستخدام البحث الشبكي مع التحقق المتبادل المتداخل.</p></li>
<li><p>انظر <a class="reference internal" href="../auto_examples/model_selection/plot_precision_recall.html#sphx-glr-auto-examples-model-selection-plot-precision-recall-py"><span class="std std-ref">Precision-Recall</span></a> للحصول على مثال على استخدام <a class="reference internal" href="generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve" title="sklearn.metrics.precision_recall_curve"><code class="xref py py-func docutils literal notranslate"><span class="pre">precision_recall_curve</span></code></a> لتقييم جودة ناتج المصنف.</p></li>
</ul>
<p class="rubric">المراجع</p>
<div role="list" class="citation-list">
<div class="citation" id="manning2008" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id36">Manning2008</a><span class="fn-bracket">]</span></span>
<p>C.D. Manning, P. Raghavan, H. Schütze, <a class="reference external" href="https://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-ranked-retrieval-results-1.html">Introduction to Information Retrieval</a>,
2008.</p>
</div>
<div class="citation" id="everingham2010" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id37">Everingham2010</a><span class="fn-bracket">]</span></span>
<p>M. Everingham, L. Van Gool, C.K.I. Williams, J. Winn, A. Zisserman,
<a class="reference external" href="https://citeseerx.ist.psu.edu/doc_view/pid/b6bebfd529b233f00cb854b7d8070319600cf59d">The Pascal Visual Object Classes (VOC) Challenge</a>,
IJCV 2010.</p>
</div>
<div class="citation" id="davis2006" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id38">Davis2006</a><span class="fn-bracket">]</span></span>
<p>J. Davis, M. Goadrich, <a class="reference external" href="https://www.biostat.wisc.edu/~page/rocpr.pdf">The Relationship Between Precision-Recall and ROC Curves</a>,
ICML 2006.</p>
</div>
<div class="citation" id="flach2015" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id39">Flach2015</a><span class="fn-bracket">]</span></span>
<p>P.A. Flach, M. Kull, <a class="reference external" href="https://papers.nips.cc/paper/5867-precision-recall-gain-curves-pr-analysis-done-right.pdf">Precision-Recall-Gain Curves: PR Analysis Done Right</a>,
NIPS 2015.</p>
</div>
</div>
<section id="id40">
<h4><span class="section-number">3.4.2.9.1. </span>التصنيف الثنائي<a class="headerlink" href="#id40" title="Link to this heading">#</a></h4>
<p>في مهمة التصنيف الثنائي، يشير المصطلحان &quot;إيجابي&quot; و &quot;سلبي&quot; إلى تنبؤ المصنف، ويشير المصطلحان &quot;صحيح&quot; و &quot;خاطئ&quot; إلى ما إذا كان هذا التنبؤ يتوافق مع الحكم الخارجي (يُعرف أحيانًا باسم &quot;المشاهدة&quot;). بالنظر إلى هذه التعريفات، يمكننا صياغة الجدول التالي:</p>
<p>في هذا السياق، يمكننا تعريف مفاهيم الدقة والاستدعاء:</p>
<div class="math notranslate nohighlight">
\[\text{precision} = \frac{\text{tp}}{\text{tp} + \text{fp}},\]</div>
<div class="math notranslate nohighlight">
\[\text{recall} = \frac{\text{tp}}{\text{tp} + \text{fn}},\]</div>
<p>(أحيانًا يُطلق على الاستدعاء أيضًا &quot;الحساسية&quot;)</p>
<p>مقياس F هو المتوسط التوافقي المرجح للدقة والاستدعاء، مع مساهمة الدقة في المتوسط المرجح بواسطة معلمة <span class="math notranslate nohighlight">\(\beta\)</span>:</p>
<div class="math notranslate nohighlight">
\[F_\beta = (1 + \beta^2) \frac{\text{precision} \times \text{recall}}{\beta^2 \text{precision} + \text{recall}}\]</div>
<p>لتجنب القسمة على صفر عندما تكون الدقة والاستدعاء صفرًا، تحسب Scikit-Learn مقياس F باستخدام هذه الصيغة المكافئة:</p>
<div class="math notranslate nohighlight">
\[F_\beta = \frac{(1 + \beta^2) \text{tp}}{(1 + \beta^2) \text{tp} + \text{fp} + \beta^2 \text{fn}}\]</div>
<p>لاحظ أن هذه الصيغة لا تزال غير مُعرّفة عندما لا توجد إيجابيات حقيقية أو إيجابيات خاطئة أو سلبيات خاطئة. افتراضيًا، يتم حساب F-1 لمجموعة من السلبيات الحقيقية حصريًا على أنه 0، ولكن يمكن تغيير هذا السلوك باستخدام معلمة <code class="docutils literal notranslate"><span class="pre">zero_division</span></code>.
فيما يلي بعض الأمثلة الصغيرة في التصنيف الثنائي:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.66...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">fbeta_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="go">0.83...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">fbeta_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">0.66...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">fbeta_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="go">0.55...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">precision_recall_fscore_support</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="go">(array([0.66..., 1.        ]), array([1. , 0.5]), array([0.71..., 0.83...]), array([2, 2]))</span>


<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_recall_curve</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">average_precision_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">threshold</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">precision</span>
<span class="go">array([0.5       , 0.66..., 0.5       , 1.        , 1.        ])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">recall</span>
<span class="go">array([1. , 1. , 0.5, 0.5, 0. ])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">threshold</span>
<span class="go">array([0.1 , 0.35, 0.4 , 0.8 ])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">average_precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">)</span>
<span class="go">0.83...</span>
</pre></div>
</div>
</section>
<section id="id41">
<h4><span class="section-number">3.4.2.9.2. </span>التصنيف متعدد الفئات ومتعدد التسميات<a class="headerlink" href="#id41" title="Link to this heading">#</a></h4>
<p>في مهمة التصنيف متعدد الفئات ومتعدد التسميات، يمكن تطبيق مفاهيم الدقة والاستدعاء ومقاييس F على كل تسمية بشكل مستقل. هناك بضعة طرق لدمج النتائج عبر التسميات، مُحدّدة بواسطة وسيطة <code class="docutils literal notranslate"><span class="pre">average</span></code> إلى دوال <a class="reference internal" href="generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score" title="sklearn.metrics.average_precision_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">average_precision_score</span></code></a> و <a class="reference internal" href="generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score" title="sklearn.metrics.f1_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">f1_score</span></code></a> و <a class="reference internal" href="generated/sklearn.metrics.fbeta_score.html#sklearn.metrics.fbeta_score" title="sklearn.metrics.fbeta_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">fbeta_score</span></code></a> و <a class="reference internal" href="generated/sklearn.metrics.precision_recall_fscore_support.html#sklearn.metrics.precision_recall_fscore_support" title="sklearn.metrics.precision_recall_fscore_support"><code class="xref py py-func docutils literal notranslate"><span class="pre">precision_recall_fscore_support</span></code></a> و <a class="reference internal" href="generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score" title="sklearn.metrics.precision_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">precision_score</span></code></a> و <a class="reference internal" href="generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score" title="sklearn.metrics.recall_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">recall_score</span></code></a>، كما هو موضح <a class="reference internal" href="#average"><span class="std std-ref">أعلاه</span></a>.</p>
<p>لاحظ السلوكيات التالية عند حساب المتوسط:</p>
<ul class="simple">
<li><p>إذا تم تضمين جميع التسميات، فإن المتوسط &quot;الدقيق&quot; في إعداد متعدد الفئات سينتج دقة واستدعاء و <span class="math notranslate nohighlight">\(F\)</span> متطابقة جميعها مع الدقة.</p></li>
<li><p>قد ينتج عن المتوسط &quot;المرجح&quot; درجة F ليست بين الدقة والاستدعاء.</p></li>
<li><p>يتم حساب المتوسط &quot;الكلي&quot; لمقاييس F على أنه المتوسط الحسابي على مقاييس F لكل تسمية/فئة، وليس المتوسط التوافقي على المتوسط الحسابي للدقة والاستدعاء. يمكن رؤية كلا الحسابين في الأدبيات ولكنهما غير متكافئين، انظر <a class="reference internal" href="#ob2019" id="id42"><span>[OB2019]</span></a> للتفاصيل.</p></li>
</ul>
<p>لتوضيح هذا بشكل أكبر، ضع في اعتبارك الترميز التالي:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(y\)</span> مجموعة أزواج <span class="math notranslate nohighlight">\((sample, label)\)</span> <em>الحقيقية</em></p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{y}\)</span> مجموعة أزواج <span class="math notranslate nohighlight">\((sample, label)\)</span> <em>المتوقعة</em></p></li>
<li><p><span class="math notranslate nohighlight">\(L\)</span> مجموعة التسميات</p></li>
<li><p><span class="math notranslate nohighlight">\(S\)</span> مجموعة العينات</p></li>
<li><p><span class="math notranslate nohighlight">\(y_s\)</span> المجموعة الفرعية من <span class="math notranslate nohighlight">\(y\)</span> مع العينة <span class="math notranslate nohighlight">\(s\)</span>، أي <span class="math notranslate nohighlight">\(y_s := \left\{(s', l) \in y | s' = s\right\}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(y_l\)</span> المجموعة الفرعية من <span class="math notranslate nohighlight">\(y\)</span> مع التسمية <span class="math notranslate nohighlight">\(l\)</span></p></li>
<li><p>وبالمثل، <span class="math notranslate nohighlight">\(\hat{y}_s\)</span> و <span class="math notranslate nohighlight">\(\hat{y}_l\)</span> هما مجموعتان فرعيتان من <span class="math notranslate nohighlight">\(\hat{y}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(A, B) := \frac{\left| A \cap B \right|}{\left|B\right|}\)</span> لبعض المجموعات <span class="math notranslate nohighlight">\(A\)</span> و <span class="math notranslate nohighlight">\(B\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(R(A, B) := \frac{\left| A \cap B \right|}{\left|A\right|}\)</span> (تختلف الاصطلاحات حول معالجة <span class="math notranslate nohighlight">\(A = \emptyset\)</span>؛ يستخدم هذا التنفيذ <span class="math notranslate nohighlight">\(R(A, B):=0\)</span>، ومثل ذلك بالنسبة لـ <span class="math notranslate nohighlight">\(P\)</span>.)</p></li>
<li><p><span class="math notranslate nohighlight">\(F_\beta(A, B) := \left(1 + \beta^2\right) \frac{P(A, B) \times R(A, B)}{\beta^2 P(A, B) + R(A, B)}\)</span></p></li>
</ul>
<p>ثم يتم تعريف المقاييس على النحو التالي:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="go">0.22...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="go">0.33...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">)</span>
<span class="go">0.26...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">fbeta_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="go">0.23...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">precision_recall_fscore_support</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="go">(array([0.66..., 0.        , 0.        ]), array([1., 0., 0.]), array([0.71..., 0.        , 0.        ]), array([2, 2, 2]...))</span>
</pre></div>
</div>
<p>بالنسبة للتصنيف متعدد الفئات مع &quot;فئة سلبية&quot;، من الممكن استبعاد بعض التسميات:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="gp">... </span><span class="c1"># باستبعاد 0، لم يتم استدعاء أي تسميات بشكل صحيح</span>
<span class="go">0.0</span>
</pre></div>
</div>
<p>وبالمثل، يمكن حساب التسميات غير الموجودة في عينة البيانات في المتوسط الكلي.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="go">0.166...</span>
</pre></div>
</div>
<p class="rubric">المراجع</p>
<div role="list" class="citation-list">
<div class="citation" id="ob2019" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id42">OB2019</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://arxiv.org/abs/1911.03347">Opitz, J., &amp; Burst, S. (2019). &quot;Macro f1 and macro f1.&quot;</a></p>
</div>
</div>
</section>
</section>
<section id="jaccard-similarity-score">
<span id="id43"></span><h3><span class="section-number">3.4.2.10. </span>درجة معامل تشابه جاكارد<a class="headerlink" href="#jaccard-similarity-score" title="Link to this heading">#</a></h3>
<p>تحسب الدالة <a class="reference internal" href="generated/sklearn.metrics.jaccard_score.html#sklearn.metrics.jaccard_score" title="sklearn.metrics.jaccard_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">jaccard_score</span></code></a> متوسط <a class="reference external" href="https://en.wikipedia.org/wiki/Jaccard_index">معاملات تشابه جاكارد</a>، وتسمى أيضًا مؤشر جاكارد، بين أزواج مجموعات التسميات.</p>
<p>يتم تعريف معامل تشابه جاكارد مع مجموعة تسميات القيمة الحقيقية <span class="math notranslate nohighlight">\(y\)</span> ومجموعة التسميات المتوقعة <span class="math notranslate nohighlight">\(\hat{y}\)</span> على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[J(y, \hat{y}) = \frac{|y \cap \hat{y}|}{|y \cup \hat{y}|}.\]</div>
<p>تنطبق <a class="reference internal" href="generated/sklearn.metrics.jaccard_score.html#sklearn.metrics.jaccard_score" title="sklearn.metrics.jaccard_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">jaccard_score</span></code></a> (مثل <a class="reference internal" href="generated/sklearn.metrics.precision_recall_fscore_support.html#sklearn.metrics.precision_recall_fscore_support" title="sklearn.metrics.precision_recall_fscore_support"><code class="xref py py-func docutils literal notranslate"><span class="pre">precision_recall_fscore_support</span></code></a>) بشكل أصلي على الأهداف الثنائية. عن طريق حسابها على أساس المجموعة، يمكن توسيعها لتطبيقها على متعدد التسميات ومتعدد الفئات من خلال استخدام <code class="docutils literal notranslate"><span class="pre">average</span></code> (انظر <a class="reference internal" href="#average"><span class="std std-ref">أعلاه</span></a>).</p>
<p>في الحالة الثنائية:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">jaccard_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>                   <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>                   <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">jaccard_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="go">0.6666...</span>
</pre></div>
</div>
<p>في حالة المقارنة ثنائية الأبعاد (على سبيل المثال، تشابه الصورة):</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">jaccard_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;micro&quot;</span><span class="p">)</span>
<span class="go">0.6</span>
</pre></div>
</div>
<p>في حالة متعددة التسميات مع مؤشرات تسمية ثنائية:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">jaccard_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;samples&#39;</span><span class="p">)</span>
<span class="go">0.5833...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">jaccard_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="go">0.6666...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">jaccard_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="go">array([0.5, 0.5, 1. ])</span>
</pre></div>
</div>
<p>يتم تحويل مشاكل متعددة الفئات إلى ثنائية ومعاملتها مثل مشكلة متعددة التسميات المقابلة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">jaccard_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="go">array([1. , 0. , 0.33...])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">jaccard_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="go">0.44...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">jaccard_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="go">0.33...</span>
</pre></div>
</div>
</section>
<section id="hinge-loss">
<span id="id45"></span><h3><span class="section-number">3.4.2.11. </span>خسارة المفصلة<a class="headerlink" href="#hinge-loss" title="Link to this heading">#</a></h3>
<p>تحسب الدالة <a class="reference internal" href="generated/sklearn.metrics.hinge_loss.html#sklearn.metrics.hinge_loss" title="sklearn.metrics.hinge_loss"><code class="xref py py-func docutils literal notranslate"><span class="pre">hinge_loss</span></code></a> متوسط المسافة بين النموذج والبيانات باستخدام <a class="reference external" href="https://en.wikipedia.org/wiki/Hinge_loss">خسارة المفصلة</a>، وهو مقياس من جانب واحد يأخذ في الاعتبار أخطاء التنبؤ فقط. (تُستخدم خسارة المفصلة في مصنفات الهامش الأقصى مثل آلات متجه الدعم.)</p>
<p>إذا تم ترميز التسمية الحقيقية <span class="math notranslate nohighlight">\(y_i\)</span> لمهمة تصنيف ثنائي على أنها <span class="math notranslate nohighlight">\(y_i=\left\{-1, +1\right\}\)</span> لكل عينة <span class="math notranslate nohighlight">\(i\)</span>؛ و <span class="math notranslate nohighlight">\(w_i\)</span> هو القرار المتوقع المقابل (مصفوفة ذات شكل (<code class="docutils literal notranslate"><span class="pre">n_samples</span></code>,) كما هو ناتج عن طريقة <code class="docutils literal notranslate"><span class="pre">decision_function</span></code>)، فسيتم تعريف خسارة المفصلة على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[L_\text{Hinge}(y, w) = \frac{1}{n_\text{samples}} \sum_{i=0}^{n_\text{samples}-1} \max\left\{1 - w_i y_i, 0\right\}\]</div>
<p>إذا كان هناك أكثر من تسميتين، فإن <a class="reference internal" href="generated/sklearn.metrics.hinge_loss.html#sklearn.metrics.hinge_loss" title="sklearn.metrics.hinge_loss"><code class="xref py py-func docutils literal notranslate"><span class="pre">hinge_loss</span></code></a> تستخدم متغيرًا متعدد الفئات بسبب كرامر وسينغر. <a class="reference external" href="https://jmlr.csail.mit.edu/papers/volume2/crammer01a/crammer01a.pdf">هنا</a> الورقة التي تصفها.</p>
<p>في هذه الحالة، يكون القرار المتوقع مصفوفة ذات شكل (<code class="docutils literal notranslate"><span class="pre">n_samples</span></code>، <code class="docutils literal notranslate"><span class="pre">n_labels</span></code>). إذا كانت <span class="math notranslate nohighlight">\(w_{i, y_i}\)</span> هي القرار المتوقع للتسمية الحقيقية <span class="math notranslate nohighlight">\(y_i\)</span> للعينة <span class="math notranslate nohighlight">\(i\)</span>؛ و <span class="math notranslate nohighlight">\(\hat{w}_{i, y_i} = \max\left\{w_{i, y_j}~|~y_j \ne y_i \right\}\)</span> هو الحد الأقصى للقرارات المتوقعة لجميع التسميات الأخرى، فسيتم تعريف خسارة المفصلة متعددة الفئات على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[L_\text{Hinge}(y, w) = \frac{1}{n_\text{samples}}
\sum_{i=0}^{n_\text{samples}-1} \max\left\{1 + \hat{w}_{i, y_i}
- w_{i, y_i}, 0\right\}\]</div>
<p>فيما يلي مثال صغير يُوضح استخدام دالة <a class="reference internal" href="generated/sklearn.metrics.hinge_loss.html#sklearn.metrics.hinge_loss" title="sklearn.metrics.hinge_loss"><code class="xref py py-func docutils literal notranslate"><span class="pre">hinge_loss</span></code></a> مع مُصنف svm في مشكلة فئة ثنائية:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">hinge_loss</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">est</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">LinearSVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">est</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">LinearSVC(random_state=0)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pred_decision</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">decision_function</span><span class="p">([[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pred_decision</span>
<span class="go">array([-2.18...,  2.36...,  0.09...])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hinge_loss</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pred_decision</span><span class="p">)</span>
<span class="go">0.3...</span>
</pre></div>
</div>
<p>فيما يلي مثال يُوضح استخدام دالة <a class="reference internal" href="generated/sklearn.metrics.hinge_loss.html#sklearn.metrics.hinge_loss" title="sklearn.metrics.hinge_loss"><code class="xref py py-func docutils literal notranslate"><span class="pre">hinge_loss</span></code></a> مع مُصنف svm في مشكلة متعددة الفئات:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>  <span class="o">&gt;&gt;&gt;</span> <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">est</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">LinearSVC</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">est</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
<span class="n">LinearSVC</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">pred_decision</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">decision_function</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">hinge_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">pred_decision</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="mf">0.56</span><span class="o">...</span>
</pre></div>
</div>
</section>
<section id="log-loss">
<span id="id48"></span><h3><span class="section-number">3.4.2.12. </span>خسارة السجل<a class="headerlink" href="#log-loss" title="Link to this heading">#</a></h3>
<p>خسارة السجل، وتسمى أيضًا خسارة الانحدار اللوجستي أو خسارة الانتروبيا المتقاطعة، مُعرّفة على تقديرات الاحتمالية. يتم استخدامه بشكل شائع في الانحدار اللوجستي (متعدد الحدود) والشبكات العصبية، وكذلك في بعض متغيرات التوقع-التعظيم، ويمكن استخدامه لتقييم مخرجات الاحتمالية (<code class="docutils literal notranslate"><span class="pre">predict_proba</span></code>) للمُصنف بدلاً من تنبؤاته المنفصلة.</p>
<p>بالنسبة للتصنيف الثنائي مع تسمية حقيقية <span class="math notranslate nohighlight">\(y \in \{0,1\}\)</span> وتقدير احتمالية <span class="math notranslate nohighlight">\(p = \operatorname{Pr}(y = 1)\)</span>، فإن خسارة السجل لكل عينة هي سجل الاحتمالية السالب للمُصنف بالنظر إلى التسمية الحقيقية:</p>
<div class="math notranslate nohighlight">
\[L_{\log}(y, p) = -\log \operatorname{Pr}(y|p) = -(y \log (p) + (1 - y) \log (1 - p))\]</div>
<p>يمتد هذا إلى حالة متعددة الفئات على النحو التالي. دع التسميات الحقيقية لمجموعة من العينات يتم ترميزها كمصفوفة مؤشر ثنائية 1 من K <span class="math notranslate nohighlight">\(Y\)</span>، أي <span class="math notranslate nohighlight">\(y_{i,k} = 1\)</span> إذا كانت العينة <span class="math notranslate nohighlight">\(i\)</span> تحمل التسمية <span class="math notranslate nohighlight">\(k\)</span> مأخوذة من مجموعة من <span class="math notranslate nohighlight">\(K\)</span> تسميات. دع <span class="math notranslate nohighlight">\(P\)</span> تكون مصفوفة من تقديرات الاحتمالية، مع <span class="math notranslate nohighlight">\(p_{i,k} = \operatorname{Pr}(y_{i,k} = 1)\)</span>. فإن خسارة السجل للمجموعة بأكملها هي</p>
<div class="math notranslate nohighlight">
\[L_{\log}(Y, P) = -\log \operatorname{Pr}(Y|P) = - \frac{1}{N} \sum_{i=0}^{N-1} \sum_{k=0}^{K-1} y_{i,k} \log p_{i,k}\]</div>
<p>لمعرفة كيف يُعمّم هذا خسارة السجل الثنائي المُعطاة أعلاه، لاحظ أنه في الحالة الثنائية، <span class="math notranslate nohighlight">\(p_{i,0} = 1 - p_{i,1}\)</span> و <span class="math notranslate nohighlight">\(y_{i,0} = 1 - y_{i,1}\)</span>، لذا فإن توسيع المجموع الداخلي على <span class="math notranslate nohighlight">\(y_{i,k} \in \{0,1\}\)</span> يُعطي خسارة السجل الثنائي.</p>
<p>تحسب الدالة <a class="reference internal" href="generated/sklearn.metrics.log_loss.html#sklearn.metrics.log_loss" title="sklearn.metrics.log_loss"><code class="xref py py-func docutils literal notranslate"><span class="pre">log_loss</span></code></a> خسارة السجل بالنظر إلى قائمة من تسميات القيمة الحقيقية ومصفوفة احتمالية، كما هو مُعاد بواسطة طريقة <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> للمُقدر.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">log_loss</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">.9</span><span class="p">,</span> <span class="mf">.1</span><span class="p">],</span> <span class="p">[</span><span class="mf">.8</span><span class="p">,</span> <span class="mf">.2</span><span class="p">],</span> <span class="p">[</span><span class="mf">.3</span><span class="p">,</span> <span class="mf">.7</span><span class="p">],</span> <span class="p">[</span><span class="mf">.01</span><span class="p">,</span> <span class="mf">.99</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">log_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.1738...</span>
</pre></div>
</div>
<p>يشير أول <code class="docutils literal notranslate"><span class="pre">[.9,</span> <span class="pre">.1]</span></code> في <code class="docutils literal notranslate"><span class="pre">y_pred</span></code> إلى احتمال 90٪ أن العينة الأولى تحمل التسمية 0. خسارة السجل غير سالبة.</p>
</section>
<section id="matthews-corrcoef">
<span id="id49"></span><h3><span class="section-number">3.4.2.13. </span>معامل ارتباط ماثيوز<a class="headerlink" href="#matthews-corrcoef" title="Link to this heading">#</a></h3>
<p>تحسب الدالة <a class="reference internal" href="generated/sklearn.metrics.matthews_corrcoef.html#sklearn.metrics.matthews_corrcoef" title="sklearn.metrics.matthews_corrcoef"><code class="xref py py-func docutils literal notranslate"><span class="pre">matthews_corrcoef</span></code></a> <a class="reference external" href="https://en.wikipedia.org/wiki/Matthews_correlation_coefficient">معامل ارتباط ماثيوز (MCC)</a> للفئات الثنائية. نقلاً عن ويكيبيديا:</p>
<blockquote>
<div><p>&quot;يُستخدم معامل ارتباط ماثيوز في تعلم الآلة كمقياس لجودة التصنيفات الثنائية (فئتين). يأخذ في الاعتبار الإيجابيات والسلبيات الحقيقية والخاطئة، ويُعتبر بشكل عام مقياسًا متوازنًا يمكن استخدامه حتى إذا كانت الفئات ذات أحجام مختلفة جدًا. MCC هو في جوهره قيمة معامل ارتباط بين -1 و +1. يُمثل المعامل +1 تنبؤًا مثاليًا، 0 تنبؤًا عشوائيًا متوسطًا، و -1 تنبؤًا عكسيًا. تُعرف الإحصائية أيضًا باسم معامل فاي.&quot;</p>
</div></blockquote>
<p>في الحالة الثنائية (فئتين)، <span class="math notranslate nohighlight">\(tp\)</span> و <span class="math notranslate nohighlight">\(tn\)</span> و <span class="math notranslate nohighlight">\(fp\)</span> و <span class="math notranslate nohighlight">\(fn\)</span> هي على التوالي عدد الإيجابيات الحقيقية والسلبيات الحقيقية والإيجابيات الخاطئة والسلبيات الخاطئة، يتم تعريف MCC على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[MCC = \frac{tp \times tn - fp \times fn}{\sqrt{(tp + fp)(tp + fn)(tn + fp)(tn + fn)}}.\]</div>
<p>في حالة متعددة الفئات، يمكن <a class="reference external" href="http://rk.kvl.dk/introduction/index.html">تعريف</a> معامل ارتباط ماثيوز من حيث <a class="reference internal" href="generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix" title="sklearn.metrics.confusion_matrix"><code class="xref py py-func docutils literal notranslate"><span class="pre">confusion_matrix</span></code></a> <span class="math notranslate nohighlight">\(C\)</span> لـ <span class="math notranslate nohighlight">\(K\)</span> فئات. لتبسيط التعريف، ضع في اعتبارك المتغيرات الوسيطة التالية:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(t_k=\sum_{i}^{K} C_{ik}\)</span> عدد المرات التي حدثت فيها الفئة <span class="math notranslate nohighlight">\(k\)</span> حقًا،</p></li>
<li><p><span class="math notranslate nohighlight">\(p_k=\sum_{i}^{K} C_{ki}\)</span> عدد المرات التي تم فيها التنبؤ بالفئة <span class="math notranslate nohighlight">\(k\)</span>،</p></li>
<li><p><span class="math notranslate nohighlight">\(c=\sum_{k}^{K} C_{kk}\)</span> العدد الإجمالي للعينات المتوقعة بشكل صحيح،</p></li>
<li><p><span class="math notranslate nohighlight">\(s=\sum_{i}^{K} \sum_{j}^{K} C_{ij}\)</span> العدد الإجمالي للعينات.</p></li>
</ul>
<p>ثم يتم تعريف MCC متعدد الفئات على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[MCC = \frac{
    c \times s - \sum_{k}^{K} p_k \times t_k
}{\sqrt{
    (s^2 - \sum_{k}^{K} p_k^2) \times
    (s^2 - \sum_{k}^{K} t_k^2)
}}\]</div>
<p>عندما يكون هناك أكثر من تسميتين، لن يتراوح نطاق قيمة MCC بين -1 و +1. بدلاً من ذلك، ستكون القيمة الدنيا في مكان ما بين -1 و 0 اعتمادًا على عدد وتوزيع تسميات القيمة الحقيقية. القيمة القصوى دائمًا +1. لمزيد من المعلومات، انظر <a class="reference internal" href="#wikipediamcc2021" id="id51"><span>[WikipediaMCC2021]</span></a>.</p>
<p>فيما يلي مثال صغير يُوضح استخدام دالة <a class="reference internal" href="generated/sklearn.metrics.matthews_corrcoef.html#sklearn.metrics.matthews_corrcoef" title="sklearn.metrics.matthews_corrcoef"><code class="xref py py-func docutils literal notranslate"><span class="pre">matthews_corrcoef</span></code></a>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">matthews_corrcoef</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="o">+</span><span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">matthews_corrcoef</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">-0.33...</span>
</pre></div>
</div>
<p class="rubric">المراجع</p>
<div role="list" class="citation-list">
<div class="citation" id="wikipediamcc2021" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id51">WikipediaMCC2021</a><span class="fn-bracket">]</span></span>
<p>Wikipedia contributors. Phi coefficient.
Wikipedia, The Free Encyclopedia. April 21, 2021, 12:21 CEST.
Available at: <a class="reference external" href="https://en.wikipedia.org/wiki/Phi_coefficient">https://en.wikipedia.org/wiki/Phi_coefficient</a>
Accessed April 21, 2021.</p>
</div>
</div>
</section>
<section id="multilabel-confusion-matrix">
<span id="id52"></span><h3><span class="section-number">3.4.2.14. </span>مصفوفة الارتباك متعددة التسميات<a class="headerlink" href="#multilabel-confusion-matrix" title="Link to this heading">#</a></h3>
<p>تحسب الدالة <a class="reference internal" href="generated/sklearn.metrics.multilabel_confusion_matrix.html#sklearn.metrics.multilabel_confusion_matrix" title="sklearn.metrics.multilabel_confusion_matrix"><code class="xref py py-func docutils literal notranslate"><span class="pre">multilabel_confusion_matrix</span></code></a> مصفوفة ارتباك متعددة التسميات على أساس كل فئة (افتراضيًا) أو على أساس كل عينة (samplewise=True) لتقييم دقة التصنيف. تُعامل multilabel_confusion_matrix أيضًا بيانات متعددة الفئات كما لو كانت متعددة التسميات، حيث إن هذا تحويل يتم تطبيقه بشكل شائع لتقييم مشاكل متعددة الفئات بمقاييس تصنيف ثنائية (مثل الدقة والاستدعاء وما إلى ذلك).</p>
<p>عند حساب مصفوفة ارتباك متعددة التسميات على أساس كل فئة <span class="math notranslate nohighlight">\(C\)</span>، يكون عدد السلبيات الحقيقية للفئة <span class="math notranslate nohighlight">\(i\)</span> هو <span class="math notranslate nohighlight">\(C_{i,0,0}\)</span>، والسلبيات الخاطئة هو <span class="math notranslate nohighlight">\(C_{i,1,0}\)</span>، والإيجابيات الحقيقية هو <span class="math notranslate nohighlight">\(C_{i,1,1}\)</span>، والإيجابيات الخاطئة هو <span class="math notranslate nohighlight">\(C_{i,0,1}\)</span>.</p>
<p>فيما يلي مثال يُوضح استخدام دالة <a class="reference internal" href="generated/sklearn.metrics.multilabel_confusion_matrix.html#sklearn.metrics.multilabel_confusion_matrix" title="sklearn.metrics.multilabel_confusion_matrix"><code class="xref py py-func docutils literal notranslate"><span class="pre">multilabel_confusion_matrix</span></code></a> مع إدخال <span class="xref std std-term">مصفوفة مؤشر متعددة التسميات</span>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">multilabel_confusion_matrix</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>                   <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>                   <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">multilabel_confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">array([[[1, 0],</span>
<span class="go">        [0, 1]],</span>

<span class="go">       [[1, 0],</span>
<span class="go">        [0, 1]],</span>

<span class="go">       [[0, 1],</span>
<span class="go">        [1, 0]]])</span>
</pre></div>
</div>
<p>أو يمكن إنشاء مصفوفة ارتباك لتسميات كل عينة:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">multilabel_confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">samplewise</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">array([[[1, 0],</span>
<span class="go">        [1, 1]],</span>

<span class="go">       [[1, 1],</span>
<span class="go">        [0, 1]]])</span>
</pre></div>
</div>
<p>فيما يلي مثال يُوضح استخدام دالة <a class="reference internal" href="generated/sklearn.metrics.multilabel_confusion_matrix.html#sklearn.metrics.multilabel_confusion_matrix" title="sklearn.metrics.multilabel_confusion_matrix"><code class="xref py py-func docutils literal notranslate"><span class="pre">multilabel_confusion_matrix</span></code></a> مع إدخال <span class="xref std std-term">متعدد الفئات</span>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;cat&quot;</span><span class="p">,</span> <span class="s2">&quot;ant&quot;</span><span class="p">,</span> <span class="s2">&quot;cat&quot;</span><span class="p">,</span> <span class="s2">&quot;cat&quot;</span><span class="p">,</span> <span class="s2">&quot;ant&quot;</span><span class="p">,</span> <span class="s2">&quot;bird&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;ant&quot;</span><span class="p">,</span> <span class="s2">&quot;ant&quot;</span><span class="p">,</span> <span class="s2">&quot;cat&quot;</span><span class="p">,</span> <span class="s2">&quot;cat&quot;</span><span class="p">,</span> <span class="s2">&quot;ant&quot;</span><span class="p">,</span> <span class="s2">&quot;cat&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">multilabel_confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;ant&quot;</span><span class="p">,</span> <span class="s2">&quot;bird&quot;</span><span class="p">,</span> <span class="s2">&quot;cat&quot;</span><span class="p">])</span>
<span class="go">array([[[3, 1],</span>
<span class="go">        [0, 2]],</span>

<span class="go">       [[5, 0],</span>
<span class="go">        [1, 0]],</span>

<span class="go">       [[2, 1],</span>
<span class="go">        [1, 2]]])</span>
</pre></div>
</div>
<p>فيما يلي بعض الأمثلة التي تُوضح استخدام دالة <a class="reference internal" href="generated/sklearn.metrics.multilabel_confusion_matrix.html#sklearn.metrics.multilabel_confusion_matrix" title="sklearn.metrics.multilabel_confusion_matrix"><code class="xref py py-func docutils literal notranslate"><span class="pre">multilabel_confusion_matrix</span></code></a> لحساب الاستدعاء (أو الحساسية) والنوعية والخسارة ومعدل الفقد لكل فئة في مشكلة مع إدخال مصفوفة مؤشر متعددة التسميات.</p>
<p>حساب <a class="reference external" href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity">الاستدعاء</a> (يُسمى أيضًا معدل الإيجابيات الحقيقية أو الحساسية) لكل فئة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>                   <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>                   <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>                   <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>                   <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mcm</span> <span class="o">=</span> <span class="n">multilabel_confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tn</span> <span class="o">=</span> <span class="n">mcm</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tp</span> <span class="o">=</span> <span class="n">mcm</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fn</span> <span class="o">=</span> <span class="n">mcm</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fp</span> <span class="o">=</span> <span class="n">mcm</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tp</span> <span class="o">/</span> <span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fn</span><span class="p">)</span>
<span class="go">array([1. , 0.5, 0. ])</span>
</pre></div>
</div>
<p>حساب <a class="reference external" href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity">النوعية</a> (يُسمى أيضًا معدل السلبيات الحقيقية) لكل فئة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tn</span> <span class="o">/</span> <span class="p">(</span><span class="n">tn</span> <span class="o">+</span> <span class="n">fp</span><span class="p">)</span>
<span class="go">array([1. , 0. , 0.5])</span>
</pre></div>
</div>
<p>حساب <a class="reference external" href="https://en.wikipedia.org/wiki/False_positive_rate">الخسارة</a> (يُسمى أيضًا معدل الإيجابيات الخاطئة) لكل فئة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">fp</span> <span class="o">/</span> <span class="p">(</span><span class="n">fp</span> <span class="o">+</span> <span class="n">tn</span><span class="p">)</span>
<span class="go">array([0. , 1. , 0.5])</span>
</pre></div>
</div>
<p>حساب <a class="reference external" href="https://en.wikipedia.org/wiki/False_positives_and_false_negatives">معدل الفقد</a> (يُسمى أيضًا معدل السلبيات الخاطئة) لكل فئة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">fn</span> <span class="o">/</span> <span class="p">(</span><span class="n">fn</span> <span class="o">+</span> <span class="n">tp</span><span class="p">)</span>
<span class="go">array([0. , 0.5, 1. ])</span>
</pre></div>
</div>
</section>
<section id="roc">
<span id="roc-metrics"></span><h3><span class="section-number">3.4.2.15. </span>خاصية تشغيل المستقبل (ROC)<a class="headerlink" href="#roc" title="Link to this heading">#</a></h3>
<p>تحسب الدالة <a class="reference internal" href="generated/sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve" title="sklearn.metrics.roc_curve"><code class="xref py py-func docutils literal notranslate"><span class="pre">roc_curve</span></code></a> <a class="reference external" href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic">منحنى خاصية تشغيل المستقبل، أو منحنى ROC</a>. نقلاً عن ويكيبيديا:</p>
<blockquote>
<div><p>&quot;خاصية تشغيل المستقبل (ROC)، أو ببساطة منحنى ROC، هو مخطط بياني يُوضح أداء نظام مُصنف ثنائي حيث تتغير عتبة تمييزه. يتم إنشاؤه عن طريق رسم كسر الإيجابيات الحقيقية من الإيجابيات (TPR = معدل الإيجابيات الحقيقية) مقابل كسر الإيجابيات الخاطئة من السلبيات (FPR = معدل الإيجابيات الخاطئة)، عند إعدادات عتبة مختلفة. يُعرف TPR أيضًا باسم الحساسية، و FPR هو واحد ناقص النوعية أو معدل السلبيات الحقيقية.&quot;</p>
</div></blockquote>
<p>تتطلب هذه الدالة القيمة الثنائية الحقيقية ودرجات الهدف، والتي يمكن أن تكون إما تقديرات احتمالية للفئة الإيجابية أو قيم ثقة أو قرارات ثنائية. فيما يلي مثال صغير حول كيفية استخدام دالة <a class="reference internal" href="generated/sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve" title="sklearn.metrics.roc_curve"><code class="xref py py-func docutils literal notranslate"><span class="pre">roc_curve</span></code></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fpr</span>
<span class="go">array([0. , 0. , 0.5, 0.5, 1. ])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tpr</span>
<span class="go">array([0. , 0.5, 0.5, 1. , 1. ])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">thresholds</span>
<span class="go">array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])</span>
</pre></div>
</div>
<p>بالمقارنة مع المقاييس مثل دقة المجموعة الفرعية أو خسارة هامينغ أو درجة F1، لا يتطلب ROC تحسين عتبة لكل تسمية.</p>
<p>تحسب الدالة <a class="reference internal" href="generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score" title="sklearn.metrics.roc_auc_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">roc_auc_score</span></code></a>، والتي يُشار إليها بـ ROC-AUC أو AUROC، المساحة الواقعة أسفل منحنى ROC. من خلال القيام بذلك، يتم تلخيص معلومات المنحنى في رقم واحد.</p>
<p>يُظهر الشكل التالي منحنى ROC ودرجة ROC-AUC لمُصنف يهدف إلى تمييز زهرة virginica عن باقي الأنواع في <a class="reference internal" href="../datasets/toy_dataset.html#iris-dataset"><span class="std std-ref">Iris plants dataset</span></a>:</p>
<a class="reference external image-reference" href="../auto_examples/model_selection/plot_roc.html"><img alt="../_images/sphx_glr_plot_roc_001.png" class="align-center" src="../_images/sphx_glr_plot_roc_001.png" style="width: 480.0px; height: 360.0px;" />
</a>
<p>لمزيد من المعلومات، انظر <a class="reference external" href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve">مقال ويكيبيديا عن AUC</a>.</p>
<section id="roc-auc-binary">
<span id="id54"></span><h4><span class="section-number">3.4.2.15.1. </span>الحالة الثنائية<a class="headerlink" href="#roc-auc-binary" title="Link to this heading">#</a></h4>
<p>في <strong>الحالة الثنائية</strong>، يمكنك إما توفير تقديرات الاحتمالية، باستخدام طريقة <code class="docutils literal notranslate"><span class="pre">classifier.predict_proba()</span></code>، أو قيم القرار غير العتبة التي تُعطيها طريقة <code class="docutils literal notranslate"><span class="pre">classifier.decision_function()</span></code>. في حالة توفير تقديرات الاحتمالية، يجب توفير احتمال الفئة ذات &quot;التسمية الأكبر&quot;. تتوافق &quot;التسمية الأكبر&quot; مع <code class="docutils literal notranslate"><span class="pre">classifier.classes_[1]</span></code> وبالتالي <code class="docutils literal notranslate"><span class="pre">classifier.predict_proba(X)[:,</span> <span class="pre">1]</span></code>. لذلك، فإن معلمة <code class="docutils literal notranslate"><span class="pre">y_score</span></code> ذات حجم (n_samples,).</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s2">&quot;liblinear&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">classes_</span>
<span class="go">array([0, 1])</span>
</pre></div>
</div>
<p>يمكننا استخدام تقديرات الاحتمالية المقابلة لـ <code class="docutils literal notranslate"><span class="pre">clf.classes_[1]</span></code>.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">y_score</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>
<span class="go">0.99...</span>
</pre></div>
</div>
<p>وإلا، يمكننا استخدام قيم القرار غير العتبة</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="go">0.99...</span>
</pre></div>
</div>
</section>
<section id="roc-auc-multiclass">
<span id="id55"></span><h4><span class="section-number">3.4.2.15.2. </span>حالة متعددة الفئات<a class="headerlink" href="#roc-auc-multiclass" title="Link to this heading">#</a></h4>
<p>يمكن أيضًا استخدام الدالة <a class="reference internal" href="generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score" title="sklearn.metrics.roc_auc_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">roc_auc_score</span></code></a> في <strong>التصنيف متعدد الفئات</strong>. يتم حاليًا دعم إستراتيجيتين للمتوسط: تحسب خوارزمية واحد مقابل واحد متوسط درجات ROC AUC الزوجية، وتحسب خوارزمية واحد مقابل البقية متوسط درجات ROC AUC لكل فئة مقابل جميع الفئات الأخرى. في كلتا الحالتين، يتم توفير التسميات المتوقعة في مصفوفة بقيم من 0 إلى <code class="docutils literal notranslate"><span class="pre">n_classes</span></code>، وتتوافق الدرجات مع تقديرات الاحتمالية التي تنتمي إليها عينة ما إلى فئة معينة. تدعم خوارزميات OvO و OvR الترجيح بشكل منتظم (<code class="docutils literal notranslate"><span class="pre">average='macro'</span></code>) وحسب الانتشار (<code class="docutils literal notranslate"><span class="pre">average='weighted'</span></code>).</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="خوارزمية-واحد-مقابل-واحد">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">خوارزمية واحد مقابل واحد<a class="headerlink" href="#خوارزمية-واحد-مقابل-واحد" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">تحسب متوسط AUC لجميع التوليفات الزوجية الممكنة للفئات. يُعرّف <a class="reference internal" href="#ht2001" id="id56"><span>[HT2001]</span></a> مقياس AUC متعدد الفئات مرجحًا بشكل منتظم:</p>
<div class="math notranslate nohighlight">
\[\frac{1}{c(c-1)}\sum_{j=1}^{c}\sum_{k &gt; j}^c (\text{AUC}(j | k) +
\text{AUC}(k | j))\]</div>
<p class="sd-card-text">حيث <span class="math notranslate nohighlight">\(c\)</span> هو عدد الفئات و <span class="math notranslate nohighlight">\(\text{AUC}(j | k)\)</span> هو AUC مع الفئة <span class="math notranslate nohighlight">\(j\)</span> كفئة إيجابية والفئة <span class="math notranslate nohighlight">\(k\)</span> كفئة سلبية. بشكل عام، <span class="math notranslate nohighlight">\(\text{AUC}(j | k) \neq \text{AUC}(k | j))\)</span> في حالة متعددة الفئات. يتم استخدام هذه الخوارزمية عن طريق تعيين وسيطة الكلمة المفتاحية <code class="docutils literal notranslate"><span class="pre">multiclass</span></code> إلى <code class="docutils literal notranslate"><span class="pre">'ovo'</span></code> و <code class="docutils literal notranslate"><span class="pre">average</span></code> إلى <code class="docutils literal notranslate"><span class="pre">'macro'</span></code>.</p>
<p class="sd-card-text">يمكن توسيع مقياس AUC متعدد الفئات <a class="reference internal" href="#ht2001" id="id57"><span>[HT2001]</span></a> ليتم ترجيحه حسب الانتشار:</p>
<div class="math notranslate nohighlight">
\[\frac{1}{c(c-1)}\sum_{j=1}^{c}\sum_{k &gt; j}^c p(j \cup k)(
\text{AUC}(j | k) + \text{AUC}(k | j))\]</div>
<p class="sd-card-text">حيث <span class="math notranslate nohighlight">\(c\)</span> هو عدد الفئات. يتم استخدام هذه الخوارزمية عن طريق تعيين وسيطة الكلمة المفتاحية <code class="docutils literal notranslate"><span class="pre">multiclass</span></code> إلى <code class="docutils literal notranslate"><span class="pre">'ovo'</span></code> و <code class="docutils literal notranslate"><span class="pre">average</span></code> إلى <code class="docutils literal notranslate"><span class="pre">'weighted'</span></code>. يُعيد الخيار <code class="docutils literal notranslate"><span class="pre">'weighted'</span></code> متوسطًا مرجحًا حسب الانتشار كما هو موضح في <a class="reference internal" href="#fc2009" id="id58"><span>[FC2009]</span></a>.</p>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="خوارزمية-واحد-مقابل-البقية">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">خوارزمية واحد مقابل البقية<a class="headerlink" href="#خوارزمية-واحد-مقابل-البقية" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">تحسب AUC لكل فئة مقابل البقية <a class="reference internal" href="#pd2000" id="id59"><span>[PD2000]</span></a>. الخوارزمية هي نفسها وظيفيًا حالة متعددة التسميات. لتمكين هذه الخوارزمية، قم بتعيين وسيطة الكلمة المفتاحية <code class="docutils literal notranslate"><span class="pre">multiclass</span></code> إلى <code class="docutils literal notranslate"><span class="pre">'ovr'</span></code>. بالإضافة إلى المتوسط <code class="docutils literal notranslate"><span class="pre">'macro'</span></code> <a class="reference internal" href="#f2006" id="id60"><span>[F2006]</span></a> و <code class="docutils literal notranslate"><span class="pre">'weighted'</span></code> <a class="reference internal" href="#f2001" id="id61"><span>[F2001]</span></a>، يدعم OvR المتوسط <code class="docutils literal notranslate"><span class="pre">'micro'</span></code>.</p>
<p class="sd-card-text">في التطبيقات التي لا يُمكن فيها تحمل معدل إيجابيات خاطئة عالي، يمكن استخدام المعلمة <code class="docutils literal notranslate"><span class="pre">max_fpr</span></code> لـ <a class="reference internal" href="generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score" title="sklearn.metrics.roc_auc_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">roc_auc_score</span></code></a> لتلخيص منحنى ROC حتى الحد المُعطى.</p>
<p class="sd-card-text">يُظهر الشكل التالي منحنى ROC بمتوسط دقيق ودرجة ROC-AUC المقابلة له لمُصنف يهدف إلى تمييز الأنواع المختلفة في <a class="reference internal" href="../datasets/toy_dataset.html#iris-dataset"><span class="std std-ref">Iris plants dataset</span></a>:</p>
<a class="reference external image-reference" href="../auto_examples/model_selection/plot_roc.html"><img alt="../_images/sphx_glr_plot_roc_002.png" class="align-center" src="../_images/sphx_glr_plot_roc_002.png" style="width: 480.0px; height: 360.0px;" />
</a>
</div>
</details></section>
<section id="roc-auc-multilabel">
<span id="id62"></span><h4><span class="section-number">3.4.2.15.3. </span>حالة متعددة التسميات<a class="headerlink" href="#roc-auc-multilabel" title="Link to this heading">#</a></h4>
<p>في <strong>التصنيف متعدد التسميات</strong>، يتم توسيع الدالة <a class="reference internal" href="generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score" title="sklearn.metrics.roc_auc_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">roc_auc_score</span></code></a> عن طريق حساب المتوسط على التسميات كما هو موضح <a class="reference internal" href="#average"><span class="std std-ref">أعلاه</span></a>. في هذه الحالة، يجب عليك توفير <code class="docutils literal notranslate"><span class="pre">y_score</span></code> ذات شكل <code class="docutils literal notranslate"><span class="pre">(n_samples,</span> <span class="pre">n_classes)</span></code>. وبالتالي، عند استخدام تقديرات الاحتمالية، يحتاج المرء إلى تحديد احتمال الفئة ذات التسمية الأكبر لكل ناتج.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_multilabel_classification</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.multioutput</span> <span class="kn">import</span> <span class="n">MultiOutputClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_multilabel_classification</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inner_clf</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s2">&quot;liblinear&quot;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">MultiOutputClassifier</span><span class="p">(</span><span class="n">inner_clf</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">([</span><span class="n">y_pred</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">y_pred</span> <span class="ow">in</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="go">array([0.82..., 0.86..., 0.94..., 0.85... , 0.94...])</span>
</pre></div>
</div>
<p>ولا تتطلب قيم القرار مثل هذه المعالجة.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">RidgeClassifierCV</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">RidgeClassifierCV</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_score</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="go">array([0.81..., 0.84... , 0.93..., 0.87..., 0.94...])</span>
</pre></div>
</div>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p>انظر <a class="reference internal" href="../auto_examples/model_selection/plot_roc.html#sphx-glr-auto-examples-model-selection-plot-roc-py"><span class="std std-ref">Multiclass Receiver Operating Characteristic (ROC)</span></a> للحصول على مثال على استخدام ROC لتقييم جودة ناتج المُصنف.</p></li>
<li><p>انظر <a class="reference internal" href="../auto_examples/model_selection/plot_roc_crossval.html#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py"><span class="std std-ref">Receiver Operating Characteristic (ROC) with cross validation</span></a> للحصول على مثال على استخدام ROC لتقييم جودة ناتج المُصنف، باستخدام التحقق المتبادل.</p></li>
<li><p>انظر <a class="reference internal" href="../auto_examples/applications/plot_species_distribution_modeling.html#sphx-glr-auto-examples-applications-plot-species-distribution-modeling-py"><span class="std std-ref">Species distribution modeling</span></a> للحصول على مثال على استخدام ROC لنمذجة توزيع الأنواع.</p></li>
</ul>
<p class="rubric">المراجع</p>
<div role="list" class="citation-list">
<div class="citation" id="ht2001" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>HT2001<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id56">1</a>,<a role="doc-backlink" href="#id57">2</a>)</span>
<p>Hand, D.J. and Till, R.J., (2001). <a class="reference external" href="http://link.springer.com/article/10.1023/A:1010920819831">A simple generalisation
of the area under the ROC curve for multiple class classification problems.</a>
Machine learning, 45(2), pp. 171-186.</p>
</div>
<div class="citation" id="fc2009" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id58">FC2009</a><span class="fn-bracket">]</span></span>
<p>Ferri, Cèsar &amp; Hernandez-Orallo, Jose &amp; Modroiu, R. (2009).
<a class="reference external" href="https://www.math.ucdavis.edu/~saito/data/roc/ferri-class-perf-metrics.pdf">An Experimental Comparison of Performance Measures for Classification.</a>
Pattern Recognition Letters. 30. 27-38.</p>
</div>
<div class="citation" id="pd2000" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id59">PD2000</a><span class="fn-bracket">]</span></span>
<p>Provost, F., Domingos, P. (2000). <a class="reference external" href="https://fosterprovost.com/publication/well-trained-pets-improving-probability-estimation-trees/">Well-trained PETs: Improving
probability estimation trees</a>
(Section 6.2), CeDER Working Paper #IS-00-04, Stern School of Business,
New York University.</p>
</div>
<div class="citation" id="f2006" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id60">F2006</a><span class="fn-bracket">]</span></span>
<p>Fawcett, T., 2006. <a class="reference external" href="http://www.sciencedirect.com/science/article/pii/S016786550500303X">An introduction to ROC analysis.</a>
Pattern Recognition Letters, 27(8), pp. 861-874.</p>
</div>
<div class="citation" id="f2001" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id61">F2001</a><span class="fn-bracket">]</span></span>
<p>Fawcett, T., 2001. <a class="reference external" href="https://ieeexplore.ieee.org/document/989510/">Using rule sets to maximize
ROC performance</a>
In Data Mining, 2001.
Proceedings IEEE International Conference, pp. 131-138.</p>
</div>
</div>
</section>
</section>
<section id="det">
<span id="det-curve"></span><h3><span class="section-number">3.4.2.16. </span>مقايضة خطأ الكشف (DET)<a class="headerlink" href="#det" title="Link to this heading">#</a></h3>
<p>تحسب الدالة <a class="reference internal" href="generated/sklearn.metrics.det_curve.html#sklearn.metrics.det_curve" title="sklearn.metrics.det_curve"><code class="xref py py-func docutils literal notranslate"><span class="pre">det_curve</span></code></a> منحنى مقايضة خطأ الكشف (DET) <a class="reference internal" href="#wikipediadet2017" id="id63"><span>[WikipediaDET2017]</span></a>. نقلاً عن ويكيبيديا:</p>
<blockquote>
<div><p>&quot;مخطط مقايضة خطأ الكشف (DET) هو مخطط بياني لمعدلات الخطأ لأنظمة التصنيف الثنائي، يرسم معدل الرفض الخاطئ مقابل معدل القبول الخاطئ. يتم قياس المحاور x و y بشكل غير خطي بواسطة انحرافاتها المعيارية العادية (أو فقط عن طريق التحويل اللوغاريتمي)، مما ينتج عنه منحنيات مقايضة أكثر خطية من منحنيات ROC، ويستخدم معظم مساحة الصورة لتسليط الضوء على اختلافات الأهمية في منطقة التشغيل الحرجة.&quot;</p>
</div></blockquote>
<p>منحنيات DET هي شكل من أشكال منحنيات خاصية تشغيل المستقبل (ROC) حيث يتم رسم معدل السلبيات الخاطئة على المحور y بدلاً من معدل الإيجابيات الحقيقية. عادةً ما يتم رسم منحنيات DET على مقياس الانحراف العادي عن طريق التحويل باستخدام <span class="math notranslate nohighlight">\(\phi^{-1}\)</span> (مع كون <span class="math notranslate nohighlight">\(\phi\)</span> دالة التوزيع التراكمي). تُصوّر منحنيات الأداء الناتجة بشكل صريح مقايضة أنواع الأخطاء لخوارزميات التصنيف المُعطاة. انظر <a class="reference internal" href="#martin1997" id="id64"><span>[Martin1997]</span></a> للأمثلة والمزيد من الدوافع.</p>
<p>تُقارن هذه الصورة منحنيات ROC و DET لمُصنفين مثال على نفس مهمة التصنيف:</p>
<a class="reference external image-reference" href="../auto_examples/model_selection/plot_det.html"><img alt="../_images/sphx_glr_plot_det_001.png" class="align-center" src="../_images/sphx_glr_plot_det_001.png" style="width: 825.0px; height: 375.0px;" />
</a>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="الخصائص">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">الخصائص<a class="headerlink" href="#الخصائص" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text">تُشكّل منحنيات DET منحنى خطيًا على مقياس الانحراف العادي إذا كانت درجات الكشف موزعة بشكل طبيعي (أو قريبة من التوزيع الطبيعي). أظهر <a class="reference internal" href="#navratil2007" id="id65"><span>[Navratil2007]</span></a> أن العكس ليس صحيحًا بالضرورة، وحتى التوزيعات الأكثر عمومية قادرة على إنتاج منحنيات DET خطية.</p></li>
<li><p class="sd-card-text">يعمل تحويل مقياس الانحراف العادي على توزيع النقاط بحيث يتم احتلال مساحة أكبر نسبيًا من الرسم. لذلك، قد يكون من الأسهل التمييز بين المنحنيات ذات أداء التصنيف المُماثل على مخطط DET.</p></li>
<li><p class="sd-card-text">مع كون معدل السلبيات الخاطئة &quot;معكوسًا&quot; لمعدل الإيجابيات الحقيقية، فإن نقطة الكمال لمنحنيات DET هي الأصل (على عكس الزاوية العلوية اليسرى لمنحنيات ROC).</p></li>
</ul>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="التطبيقات-والقيود">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">التطبيقات والقيود<a class="headerlink" href="#التطبيقات-والقيود" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">منحنيات DET سهلة القراءة، وبالتالي تسمح بالتقييم البصري السريع لأداء المُصنف. بالإضافة إلى ذلك، يمكن الرجوع إلى منحنيات DET لتحليل العتبة واختيار نقطة التشغيل. هذا مفيد بشكل خاص إذا كانت هناك حاجة لمقارنة أنواع الأخطاء.</p>
<p class="sd-card-text">من ناحية أخرى، لا تُوفر منحنيات DET مقياسها كرقم واحد. لذلك، إما للتقييم الآلي أو المقارنة مع مهام التصنيف الأخرى، قد تكون المقاييس مثل المنطقة المُشتقة أسفل منحنى ROC أكثر ملاءمة.</p>
</div>
</details><p class="rubric">أمثلة</p>
<ul class="simple">
<li><p>انظر <a class="reference internal" href="../auto_examples/model_selection/plot_det.html#sphx-glr-auto-examples-model-selection-plot-det-py"><span class="std std-ref">Detection error tradeoff (DET) curve</span></a> لمقارنة مثال بين منحنيات خاصية تشغيل المستقبل (ROC) ومنحنيات مقايضة خطأ الكشف (DET).</p></li>
</ul>
<p class="rubric">المراجع</p>
<div role="list" class="citation-list">
<div class="citation" id="wikipediadet2017" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id63">WikipediaDET2017</a><span class="fn-bracket">]</span></span>
<p>Wikipedia contributors. Detection error tradeoff.
Wikipedia, The Free Encyclopedia. September 4, 2017, 23:33 UTC.
Available at: <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Detection_error_tradeoff&amp;oldid=798982054">https://en.wikipedia.org/w/index.php?title=Detection_error_tradeoff&amp;oldid=798982054</a>.
Accessed February 19, 2018.</p>
</div>
<div class="citation" id="martin1997" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id64">Martin1997</a><span class="fn-bracket">]</span></span>
<p>A. Martin, G. Doddington, T. Kamm, M. Ordowski, and M. Przybocki,
<a class="reference external" href="https://ccc.inaoep.mx/~villasen/bib/martin97det.pdf">The DET Curve in Assessment of Detection Task Performance</a>, NIST 1997.</p>
</div>
<div class="citation" id="navratil2007" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id65">Navratil2007</a><span class="fn-bracket">]</span></span>
<p>J. Navractil and D. Klusacek,
<a class="reference external" href="https://ieeexplore.ieee.org/document/4218079">&quot;On Linear DETs&quot;</a>,
2007 IEEE International Conference on Acoustics,
Speech and Signal Processing - ICASSP '07, Honolulu,
HI, 2007, pp. IV-229-IV-232.</p>
</div>
</div>
</section>
<section id="zero-one-loss">
<span id="id66"></span><h3><span class="section-number">3.4.2.17. </span>خسارة الصفر-واحد<a class="headerlink" href="#zero-one-loss" title="Link to this heading">#</a></h3>
<p>تحسب الدالة <a class="reference internal" href="generated/sklearn.metrics.zero_one_loss.html#sklearn.metrics.zero_one_loss" title="sklearn.metrics.zero_one_loss"><code class="xref py py-func docutils literal notranslate"><span class="pre">zero_one_loss</span></code></a> مجموع أو متوسط خسارة التصنيف 0-1 (<span class="math notranslate nohighlight">\(L_{0-1}\)</span>) على <span class="math notranslate nohighlight">\(n_{\text{samples}}\)</span>. افتراضيًا، تُطبّع الدالة على العينة. للحصول على مجموع <span class="math notranslate nohighlight">\(L_{0-1}\)</span>، قم بتعيين <code class="docutils literal notranslate"><span class="pre">normalize</span></code> إلى <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
<p>في التصنيف متعدد التسميات، تُسجّل <a class="reference internal" href="generated/sklearn.metrics.zero_one_loss.html#sklearn.metrics.zero_one_loss" title="sklearn.metrics.zero_one_loss"><code class="xref py py-func docutils literal notranslate"><span class="pre">zero_one_loss</span></code></a> مجموعة فرعية كواحد إذا تطابقت تسمياتها تمامًا مع التنبؤات، وكصفر إذا كان هناك أي أخطاء. افتراضيًا، تُعيد الدالة النسبة المئوية للمجموعات الفرعية المتوقعة بشكل غير كامل. للحصول على عدد هذه المجموعات الفرعية بدلاً من ذلك، قم بتعيين <code class="docutils literal notranslate"><span class="pre">normalize</span></code> إلى <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
<p>إذا كانت <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> هي القيمة المتوقعة للعينة <span class="math notranslate nohighlight">\(i\)</span> و <span class="math notranslate nohighlight">\(y_i\)</span> هي القيمة الحقيقية المقابلة، فسيتم تعريف خسارة 0-1 <span class="math notranslate nohighlight">\(L_{0-1}\)</span> على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[L_{0-1}(y, \hat{y}) = \frac{1}{n_\text{samples}} \sum_{i=0}^{n_\text{samples}-1} 1(\hat{y}_i \not= y_i)\]</div>
<p>حيث <span class="math notranslate nohighlight">\(1(x)\)</span> هي <a class="reference external" href="https://en.wikipedia.org/wiki/Indicator_function">دالة المؤشر</a>. يمكن أيضًا حساب خسارة الصفر-واحد على أنها <span class="math notranslate nohighlight">\(zero-one loss = 1 - accuracy\)</span>.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">zero_one_loss</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">zero_one_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.25</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">zero_one_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">1.0</span>
</pre></div>
</div>
<p>في حالة متعددة التسميات مع مؤشرات تسمية ثنائية، حيث تحتوي مجموعة التسميات الأولى [0,1] على خطأ:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">zero_one_loss</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="go">0.5</span>


<span class="gp">&gt;&gt;&gt; </span><span class="n">zero_one_loss</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>  <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">1.0</span>
</pre></div>
</div>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p>انظر <a class="reference internal" href="../auto_examples/feature_selection/plot_rfe_with_cross_validation.html#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py"><span class="std std-ref">Recursive feature elimination with cross-validation</span></a> للحصول على مثال على استخدام خسارة الصفر-واحد لإجراء استبعاد الميزات التكراري مع التحقق المتبادل.</p></li>
</ul>
</section>
<section id="brier-score-loss">
<span id="id68"></span><h3><span class="section-number">3.4.2.18. </span>خسارة درجة بريير<a class="headerlink" href="#brier-score-loss" title="Link to this heading">#</a></h3>
<p>تحسب الدالة <a class="reference internal" href="generated/sklearn.metrics.brier_score_loss.html#sklearn.metrics.brier_score_loss" title="sklearn.metrics.brier_score_loss"><code class="xref py py-func docutils literal notranslate"><span class="pre">brier_score_loss</span></code></a> <a class="reference external" href="https://en.wikipedia.org/wiki/Brier_score">درجة بريير</a> للفئات الثنائية <a class="reference internal" href="#brier1950" id="id70"><span>[Brier1950]</span></a>. نقلاً عن ويكيبيديا:</p>
<blockquote>
<div><p>&quot;درجة بريير هي دالة درجة مناسبة تقيس دقة التنبؤات الاحتمالية. وهي قابلة للتطبيق على المهام التي يجب أن تُعيّن فيها التنبؤات احتمالات لمجموعة من النتائج المنفصلة المتبادلة.&quot;</p>
</div></blockquote>
<p>تُعيد هذه الدالة متوسط الخطأ التربيعي للنتيجة الفعلية <span class="math notranslate nohighlight">\(y \in \{0,1\}\)</span> وتقدير الاحتمالية المتوقع <span class="math notranslate nohighlight">\(p = \operatorname{Pr}(y = 1)\)</span> (<a class="reference internal" href="../glossary.html#term-predict_proba"><span class="xref std std-term">predict_proba</span></a>) كما هو مُخرَج بواسطة:</p>
<div class="math notranslate nohighlight">
\[BS = \frac{1}{n_{\text{samples}}} \sum_{i=0}^{n_{\text{samples}} - 1}(y_i - p_i)^2\]</div>
<p>تتراوح خسارة درجة بريير أيضًا بين 0 و 1، وكلما انخفضت القيمة (كان فرق المربع المتوسط أصغر)، زادت دقة التنبؤ.</p>
<p>فيما يلي مثال صغير على استخدام هذه الدالة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">brier_score_loss</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true_categorical</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s2">&quot;spam&quot;</span><span class="p">,</span> <span class="s2">&quot;ham&quot;</span><span class="p">,</span> <span class="s2">&quot;ham&quot;</span><span class="p">,</span> <span class="s2">&quot;spam&quot;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">brier_score_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_prob</span><span class="p">)</span>
<span class="go">0.055</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">brier_score_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">y_prob</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="go">0.055</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">brier_score_loss</span><span class="p">(</span><span class="n">y_true_categorical</span><span class="p">,</span> <span class="n">y_prob</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="s2">&quot;ham&quot;</span><span class="p">)</span>
<span class="go">0.055</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">brier_score_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_prob</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="go">0.0</span>
</pre></div>
</div>
<p>يمكن استخدام درجة بريير لتقييم مدى معايرة المُصنف جيدًا. ومع ذلك، لا تعني خسارة درجة بريير الأقل دائمًا معايرة أفضل. هذا لأنه، قياسًا على تحليل التباين والانحياز لمتوسط الخطأ التربيعي، يمكن تحليل خسارة درجة بريير كمجموع خسارة المعايرة وخسارة التحسين <a class="reference internal" href="#bella2012" id="id71"><span>[Bella2012]</span></a>. تُعرّف خسارة المعايرة على أنها متوسط الانحراف التربيعي عن الاحتمالات التجريبية المُشتقة من ميل مقاطع ROC. يمكن تعريف خسارة التحسين على أنها الخسارة المثلى المتوقعة كما تم قياسها بواسطة المنطقة الواقعة أسفل منحنى التكلفة الأمثل. يمكن أن تتغير خسارة التحسين بشكل مستقل عن خسارة المعايرة، وبالتالي لا تعني خسارة درجة بريير الأقل بالضرورة نموذجًا أفضل معايرة. &quot;فقط عندما تظل خسارة التحسين كما هي، فإن خسارة درجة بريير الأقل تعني دائمًا معايرة أفضل&quot; <a class="reference internal" href="#bella2012" id="id72"><span>[Bella2012]</span></a>، <a class="reference internal" href="#flach2008" id="id73"><span>[Flach2008]</span></a>.</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p>انظر <a class="reference internal" href="../auto_examples/calibration/plot_calibration.html#sphx-glr-auto-examples-calibration-plot-calibration-py"><span class="std std-ref">Probability calibration of classifiers</span></a> للحصول على مثال على استخدام خسارة درجة بريير لإجراء معايرة احتمالية للمُصنفات.</p></li>
</ul>
<p class="rubric">المراجع</p>
<div role="list" class="citation-list">
<div class="citation" id="brier1950" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id70">Brier1950</a><span class="fn-bracket">]</span></span>
<p>G. Brier, <a class="reference external" href="ftp://ftp.library.noaa.gov/docs.lib/htdocs/rescue/mwr/078/mwr-078-01-0001.pdf">Verification of forecasts expressed in terms of probability</a>,
Monthly weather review 78.1 (1950)</p>
</div>
<div class="citation" id="bella2012" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Bella2012<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id71">1</a>,<a role="doc-backlink" href="#id72">2</a>)</span>
<p>Bella, Ferri, Hernández-Orallo, and Ramírez-Quintana
<a class="reference external" href="http://dmip.webs.upv.es/papers/BFHRHandbook2010.pdf">&quot;Calibration of Machine Learning Models&quot;</a>
in Khosrow-Pour, M. &quot;Machine learning: concepts, methodologies, tools
and applications.&quot; Hershey, PA: Information Science Reference (2012).</p>
</div>
<div class="citation" id="flach2008" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id73">Flach2008</a><span class="fn-bracket">]</span></span>
<p>Flach, Peter, and Edson Matsubara. <a class="reference external" href="https://drops.dagstuhl.de/opus/volltexte/2008/1382/">&quot;On classification, ranking,
and probability estimation.&quot;</a>
Dagstuhl Seminar Proceedings. Schloss Dagstuhl-Leibniz-Zentrum fr Informatik (2008).</p>
</div>
</div>
</section>
<section id="class-likelihood-ratios">
<span id="id74"></span><h3><span class="section-number">3.4.2.19. </span>نسب احتمالية الفئة<a class="headerlink" href="#class-likelihood-ratios" title="Link to this heading">#</a></h3>
<p>تحسب الدالة <a class="reference internal" href="generated/sklearn.metrics.class_likelihood_ratios.html#sklearn.metrics.class_likelihood_ratios" title="sklearn.metrics.class_likelihood_ratios"><code class="xref py py-func docutils literal notranslate"><span class="pre">class_likelihood_ratios</span></code></a> <a class="reference external" href="https://en.wikipedia.org/wiki/Likelihood_ratios_in_diagnostic_testing">نسب الاحتمالية الإيجابية والسلبية</a> <span class="math notranslate nohighlight">\(LR_\pm\)</span> للفئات الثنائية، والتي يمكن تفسيرها على أنها نسبة احتمالات ما بعد الاختبار إلى احتمالات ما قبل الاختبار كما هو موضح أدناه. نتيجة لذلك، يكون هذا المقياس ثابتًا بالنسبة لانتشار الفئة (عدد العينات في الفئة الإيجابية مقسومًا على العدد الإجمالي للعينات) و <strong>يمكن استقراءه بين السكان بغض النظر عن أي اختلال محتمل في توازن الفئات.</strong></p>
<p>لذلك، تُعد مقاييس <span class="math notranslate nohighlight">\(LR_\pm\)</span> مفيدة جدًا في الإعدادات التي تكون فيها البيانات المتاحة لتعلم وتقييم المُصنف هي مجموعة دراسة ذات فئات متوازنة تقريبًا، مثل دراسة حالة-شاهد، بينما يكون تطبيق الهدف، أي عامة السكان، لديه انتشار منخفض جدًا.</p>
<p>نسبة الاحتمالية الإيجابية <span class="math notranslate nohighlight">\(LR_+\)</span> هي احتمال أن يتنبأ المُصنف بشكل صحيح بأن عينة ما تنتمي إلى الفئة الإيجابية مقسومًا على احتمال التنبؤ بالفئة الإيجابية لعينة تنتمي إلى الفئة السلبية:</p>
<div class="math notranslate nohighlight">
\[LR_+ = \frac{\text{PR}(P+|T+)}{\text{PR}(P+|T-)}.\]</div>
<p>يشير الترميز هنا إلى التسمية المتوقعة (<span class="math notranslate nohighlight">\(P\)</span>) أو الحقيقية (<span class="math notranslate nohighlight">\(T\)</span>)، وتشير العلامة <span class="math notranslate nohighlight">\(+\)</span> و <span class="math notranslate nohighlight">\(-\)</span> إلى الفئة الإيجابية والسلبية، على التوالي، على سبيل المثال، <span class="math notranslate nohighlight">\(P+\)</span> تعني &quot;متوقع إيجابي&quot;.</p>
<p>وبالمثل، فإن نسبة الاحتمالية السلبية <span class="math notranslate nohighlight">\(LR_-\)</span> هي احتمال تصنيف عينة من الفئة الإيجابية على أنها تنتمي إلى الفئة السلبية مقسومًا على احتمال تصنيف عينة من الفئة السلبية بشكل صحيح:</p>
<div class="math notranslate nohighlight">
\[LR_- = \frac{\text{PR}(P-|T+)}{\text{PR}(P-|T-)}.\]</div>
<p>بالنسبة للمُصنفات أعلى من الصدفة <span class="math notranslate nohighlight">\(LR_+\)</span> أعلى من 1 <strong>الأعلى أفضل</strong>، بينما يتراوح <span class="math notranslate nohighlight">\(LR_-\)</span> من 0 إلى 1 و <strong>الأقل أفضل</strong>. تتوافق قيم <span class="math notranslate nohighlight">\(LR_\pm\approx 1\)</span> مع مستوى الصدفة.</p>
<p>لاحظ أن الاحتمالات تختلف عن الأعداد، على سبيل المثال، <span class="math notranslate nohighlight">\(\operatorname{PR}(P+|T+)\)</span> لا يساوي عدد الإيجابيات الحقيقية <code class="docutils literal notranslate"><span class="pre">tp</span></code> (انظر <a class="reference external" href="https://en.wikipedia.org/wiki/Likelihood_ratios_in_diagnostic_testing">صفحة ويكيبيديا</a> للصيغ الفعلية).</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/model_selection/plot_likelihood_ratios.html#sphx-glr-auto-examples-model-selection-plot-likelihood-ratios-py"><span class="std std-ref">Class Likelihood Ratios to measure classification performance</span></a></p></li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="التفسير-عبر-الانتشار-المتفاوت">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">التفسير عبر الانتشار المتفاوت<a class="headerlink" href="#التفسير-عبر-الانتشار-المتفاوت" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">يمكن تفسير نسب احتمالية الفئة من حيث نسبة الاحتمالات (قبل الاختبار وبعده):</p>
<div class="math notranslate nohighlight">
\[\text{post-test odds} = \text{Likelihood ratio} \times \text{pre-test odds}.\]</div>
<p class="sd-card-text">ترتبط الاحتمالات بشكل عام بالاحتمالات عبر</p>
<div class="math notranslate nohighlight">
\[\text{odds} = \frac{\text{probability}}{1 - \text{probability}},\]</div>
<p class="sd-card-text">أو على نحو مكافئ</p>
<div class="math notranslate nohighlight">
\[\text{probability} = \frac{\text{odds}}{1 + \text{odds}}.\]</div>
<p class="sd-card-text">بالنسبة لسكان مُعينين، يتم إعطاء احتمال ما قبل الاختبار بواسطة الانتشار. عن طريق تحويل الاحتمالات إلى احتمالات، يمكن ترجمة نسب الاحتمالية إلى احتمال الانتماء حقًا إلى أي من الفئتين قبل وبعد تنبؤ المُصنف:</p>
<div class="math notranslate nohighlight">
\[\text{post-test odds} = \text{Likelihood ratio} \times
\frac{\text{pre-test probability}}{1 - \text{pre-test probability}},\]</div>
<div class="math notranslate nohighlight">
\[\text{post-test probability} = \frac{\text{post-test odds}}{1 + \text{post-test odds}}.\]</div>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="الاختلافات-الرياضية">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">الاختلافات الرياضية<a class="headerlink" href="#الاختلافات-الرياضية" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">تكون نسبة الاحتمالية الإيجابية غير مُعرّفة عندما <span class="math notranslate nohighlight">\(fp = 0\)</span>، والتي يمكن تفسيرها على أنها تعريف المُصنف للحالات الإيجابية بشكل مثالي. إذا كان <span class="math notranslate nohighlight">\(fp = 0\)</span> وبالإضافة إلى ذلك <span class="math notranslate nohighlight">\(tp = 0\)</span>، فإن هذا يؤدي إلى قسمة صفر/صفر. يحدث هذا، على سبيل المثال، عند استخدام <code class="docutils literal notranslate"><span class="pre">DummyClassifier</span></code> الذي يتنبأ دائمًا بالفئة السلبية، وبالتالي يتم فقدان التفسير كمُصنف مثالي.</p>
<p class="sd-card-text">تكون نسبة الاحتمالية السلبية غير مُعرّفة عندما <span class="math notranslate nohighlight">\(tn = 0\)</span>. هذا الاختلاف غير صالح، حيث أن <span class="math notranslate nohighlight">\(LR_- &gt; 1\)</span> يشير إلى زيادة في احتمالات انتماء عينة ما إلى الفئة الإيجابية بعد تصنيفها على أنها سلبية، كما لو كان فعل التصنيف قد تسبب في الحالة الإيجابية. يتضمن هذا حالة <code class="docutils literal notranslate"><span class="pre">DummyClassifier</span></code> التي تتنبأ دائمًا بالفئة الإيجابية (أي عندما <span class="math notranslate nohighlight">\(tn=fn=0\)</span>).</p>
<p class="sd-card-text">تكون نسب احتمالية الفئة غير مُعرّفة عندما <span class="math notranslate nohighlight">\(tp=fn=0\)</span>، مما يعني أنه لا توجد عينات من الفئة الإيجابية موجودة في مجموعة الاختبار. يمكن أن يحدث هذا أيضًا عند التحقق المتبادل للبيانات غير المتوازنة للغاية.</p>
<p class="sd-card-text">في جميع الحالات السابقة، تُصدر الدالة <a class="reference internal" href="generated/sklearn.metrics.class_likelihood_ratios.html#sklearn.metrics.class_likelihood_ratios" title="sklearn.metrics.class_likelihood_ratios"><code class="xref py py-func docutils literal notranslate"><span class="pre">class_likelihood_ratios</span></code></a> افتراضيًا رسالة تحذير مناسبة وتُعيد <code class="docutils literal notranslate"><span class="pre">nan</span></code> لتجنب التلوث عند حساب المتوسط على طيات التحقق المتبادل.</p>
<p class="sd-card-text">للحصول على عرض عملي لدالة <a class="reference internal" href="generated/sklearn.metrics.class_likelihood_ratios.html#sklearn.metrics.class_likelihood_ratios" title="sklearn.metrics.class_likelihood_ratios"><code class="xref py py-func docutils literal notranslate"><span class="pre">class_likelihood_ratios</span></code></a>، انظر المثال أدناه.</p>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text"><a class="reference external" href="https://en.wikipedia.org/wiki/Likelihood_ratios_in_diagnostic_testing">إدخال ويكيبيديا لنسب الاحتمالية في الاختبار التشخيصي</a></p></li>
<li><p class="sd-card-text">Brenner, H., &amp; Gefeller, O. (1997).
Variation of sensitivity, specificity, likelihood ratios and predictive
values with disease prevalence.
Statistics in medicine, 16(9), 981-991.</p></li>
</ul>
</div>
</details></section>
<section id="d2">
<span id="d2-score-classification"></span><h3><span class="section-number">3.4.2.20. </span>درجة D² للتصنيف<a class="headerlink" href="#d2" title="Link to this heading">#</a></h3>
<p>تحسب درجة D² جزء الانحراف المُفسّر. وهو تعميم لـ R²، حيث يتم تعميم الخطأ التربيعي واستبداله بانحراف تصنيف مُختار <span class="math notranslate nohighlight">\(\text{dev}(y, \hat{y})\)</span> (على سبيل المثال، خسارة السجل). D² هو شكل من أشكال <em>درجة المهارة</em>. يتم حسابها على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[D^2(y, \hat{y}) = 1 - \frac{\text{dev}(y, \hat{y})}{\text{dev}(y, y_{\text{null}})} \,.\]</div>
<p>حيث <span class="math notranslate nohighlight">\(y_{\text{null}}\)</span> هو التنبؤ الأمثل لنموذج التقاطع فقط (على سبيل المثال، نسبة كل فئة من <code class="docutils literal notranslate"><span class="pre">y_true</span></code> في حالة خسارة السجل).</p>
<p>مثل R²، أفضل درجة ممكنة هي 1.0 ويمكن أن تكون سلبية (لأن النموذج يمكن أن يكون أسوأ بشكل تعسفي). سيحصل النموذج الثابت الذي يتنبأ دائمًا بـ <span class="math notranslate nohighlight">\(y_{\text{null}}\)</span>، بغض النظر عن ميزات الإدخال، على درجة D² تبلغ 0.0.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="درجة-خسارة-السجل-d2">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">درجة خسارة السجل D2<a class="headerlink" href="#درجة-خسارة-السجل-d2" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">تُطبق الدالة <a class="reference internal" href="generated/sklearn.metrics.d2_log_loss_score.html#sklearn.metrics.d2_log_loss_score" title="sklearn.metrics.d2_log_loss_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">d2_log_loss_score</span></code></a> الحالة الخاصة لـ D² مع خسارة السجل، انظر <a class="reference internal" href="#log-loss"><span class="std std-ref">خسارة السجل</span></a>، أي:</p>
<div class="math notranslate nohighlight">
\[\text{dev}(y, \hat{y}) = \text{log_loss}(y, \hat{y}).\]</div>
<p class="sd-card-text">فيما يلي بعض أمثلة الاستخدام لدالة <a class="reference internal" href="generated/sklearn.metrics.d2_log_loss_score.html#sklearn.metrics.d2_log_loss_score" title="sklearn.metrics.d2_log_loss_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">d2_log_loss_score</span></code></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">d2_log_loss_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span>
<span class="gp">... </span>   <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">],</span>
<span class="gp">... </span>   <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">],</span>
<span class="gp">... </span>   <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">],</span>
<span class="gp">... </span>   <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">],</span>
<span class="gp">... </span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d2_log_loss_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span>
<span class="gp">... </span>    <span class="p">[</span><span class="mf">0.98</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">],</span>
<span class="gp">... </span>    <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.98</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">],</span>
<span class="gp">... </span>    <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.98</span><span class="p">],</span>
<span class="gp">... </span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d2_log_loss_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.981...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span>
<span class="gp">... </span>    <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
<span class="gp">... </span>    <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
<span class="gp">... </span>    <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
<span class="gp">... </span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d2_log_loss_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">-0.552...</span>
</pre></div>
</div>
</div>
</details></section>
</section>
<section id="multilabel-ranking-metrics">
<span id="id78"></span><h2><span class="section-number">3.4.3. </span>مقاييس ترتيب متعددة التسميات<a class="headerlink" href="#multilabel-ranking-metrics" title="Link to this heading">#</a></h2>
<p>في التعلم متعدد التسميات، يمكن أن يكون لكل عينة أي عدد من تسميات القيمة الحقيقية المرتبطة بها. الهدف هو إعطاء درجات عالية وترتيب أفضل لتسميات القيمة الحقيقية.</p>
<section id="coverage-error">
<span id="id79"></span><h3><span class="section-number">3.4.3.1. </span>خطأ التغطية<a class="headerlink" href="#coverage-error" title="Link to this heading">#</a></h3>
<p>تحسب الدالة <a class="reference internal" href="generated/sklearn.metrics.coverage_error.html#sklearn.metrics.coverage_error" title="sklearn.metrics.coverage_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">coverage_error</span></code></a> متوسط عدد التسميات التي يجب تضمينها في التنبؤ النهائي بحيث يتم التنبؤ بجميع التسميات الحقيقية. هذا مفيد إذا كنت تُريد معرفة عدد التسميات ذات أعلى الدرجات التي يجب عليك التنبؤ بها في المتوسط دون تفويت أي تسمية حقيقية. أفضل قيمة لهذه المقاييس هي متوسط عدد التسميات الحقيقية.</p>
<div class="admonition note">
<p class="admonition-title">ملاحظة</p>
<p>درجة تطبيقنا أكبر بـ 1 من تلك المُعطاة في Tsoumakas et al.، 2010. يمتد هذا للتعامل مع الحالة المُنحطة التي يكون فيها للمثيل 0 تسميات حقيقية.</p>
</div>
<p>رسميًا، بالنظر إلى مصفوفة مؤشر ثنائية لتسميات القيمة الحقيقية <span class="math notranslate nohighlight">\(y \in \left\{0, 1\right\}^{n_\text{samples} \times n_\text{labels}}\)</span> والدرجة المُرتبطة بكل تسمية <span class="math notranslate nohighlight">\(\hat{f} \in \mathbb{R}^{n_\text{samples} \times n_\text{labels}}\)</span>، يتم تعريف التغطية على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[coverage(y, \hat{f}) = \frac{1}{n_{\text{samples}}}
  \sum_{i=0}^{n_{\text{samples}} - 1} \max_{j:y_{ij} = 1} \text{rank}_{ij}\]</div>
<p>مع <span class="math notranslate nohighlight">\(\text{rank}_{ij} = \left|\left\{k: \hat{f}_{ik} \geq \hat{f}_{ij} \right\}\right|\)</span>. بالنظر إلى تعريف الرتبة، يتم كسر الروابط في <code class="docutils literal notranslate"><span class="pre">y_scores</span></code> عن طريق إعطاء أقصى رتبة كان من الممكن تعيينها لجميع القيم المُرتبطة.</p>
<p>فيما يلي مثال صغير على استخدام هذه الدالة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">coverage_error</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">coverage_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>
<span class="go">2.5</span>
</pre></div>
</div>
</section>
<section id="label-ranking-average-precision">
<span id="id80"></span><h3><span class="section-number">3.4.3.2. </span>متوسط دقة ترتيب التسميات<a class="headerlink" href="#label-ranking-average-precision" title="Link to this heading">#</a></h3>
<p>تُطبق الدالة <a class="reference internal" href="generated/sklearn.metrics.label_ranking_average_precision_score.html#sklearn.metrics.label_ranking_average_precision_score" title="sklearn.metrics.label_ranking_average_precision_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">label_ranking_average_precision_score</span></code></a> متوسط دقة ترتيب التسميات (LRAP). يرتبط هذا المقياس بدالة <a class="reference internal" href="generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score" title="sklearn.metrics.average_precision_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">average_precision_score</span></code></a>، ولكنه يعتمد على فكرة ترتيب التسميات بدلاً من الدقة والاستدعاء.</p>
<p>يحسب متوسط دقة ترتيب التسميات (LRAP) متوسط إجابة السؤال التالي على العينات: لكل تسمية قيمة حقيقية، ما هو جزء التسميات ذات الترتيب الأعلى التي كانت تسميات حقيقية؟ سيكون مقياس الأداء هذا أعلى إذا كنت قادرًا على إعطاء رتبة أفضل للتسميات المُرتبطة بكل عينة. تكون الدرجة التي تم الحصول عليها دائمًا أكبر بدقة من 0، وأفضل قيمة هي 1. إذا كانت هناك تسمية واحدة ذات صلة فقط لكل عينة، فإن متوسط دقة ترتيب التسميات يُكافئ <a class="reference external" href="https://en.wikipedia.org/wiki/Mean_reciprocal_rank">متوسط الرتبة التبادلية</a>.</p>
<p>رسميًا، بالنظر إلى مصفوفة مؤشر ثنائية لتسميات القيمة الحقيقية <span class="math notranslate nohighlight">\(y \in \left\{0, 1\right\}^{n_\text{samples} \times n_\text{labels}}\)</span> والدرجة المُرتبطة بكل تسمية <span class="math notranslate nohighlight">\(\hat{f} \in \mathbb{R}^{n_\text{samples} \times n_\text{labels}}\)</span>، يتم تعريف متوسط الدقة على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[LRAP(y, \hat{f}) = \frac{1}{n_{\text{samples}}}
  \sum_{i=0}^{n_{\text{samples}} - 1} \frac{1}{||y_i||_0}
  \sum_{j:y_{ij} = 1} \frac{|\mathcal{L}_{ij}|}{\text{rank}_{ij}}\]</div>
<p>حيث <span class="math notranslate nohighlight">\(\mathcal{L}_{ij} = \left\{k: y_{ik} = 1, \hat{f}_{ik} \geq \hat{f}_{ij} \right\}\)</span>، <span class="math notranslate nohighlight">\(\text{rank}_{ij} = \left|\left\{k: \hat{f}_{ik} \geq \hat{f}_{ij} \right\}\right|\)</span>، <span class="math notranslate nohighlight">\(|\cdot|\)</span> يحسب عدد عناصر المجموعة (أي عدد العناصر في المجموعة)، و <span class="math notranslate nohighlight">\(||\cdot||_0\)</span> هو <span class="math notranslate nohighlight">\(\ell_0\)</span> &quot;معيار&quot; (الذي يحسب عدد العناصر غير الصفرية في متجه).</p>
<p>فيما يلي مثال صغير على استخدام هذه الدالة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">label_ranking_average_precision_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label_ranking_average_precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>
<span class="go">0.416...</span>
</pre></div>
</div>
</section>
<section id="label-ranking-loss">
<span id="id82"></span><h3><span class="section-number">3.4.3.3. </span>خسارة الترتيب<a class="headerlink" href="#label-ranking-loss" title="Link to this heading">#</a></h3>
<p>تحسب الدالة <a class="reference internal" href="generated/sklearn.metrics.label_ranking_loss.html#sklearn.metrics.label_ranking_loss" title="sklearn.metrics.label_ranking_loss"><code class="xref py py-func docutils literal notranslate"><span class="pre">label_ranking_loss</span></code></a> خسارة الترتيب التي تُحسب متوسط عدد أزواج التسميات التي تم ترتيبها بشكل غير صحيح على العينات، أي أن التسميات الحقيقية لها درجة أقل من التسميات الخاطئة، مرجحة بمعكوس عدد الأزواج المُرتبة من التسميات الخاطئة والحقيقية. أقل خسارة ترتيب يمكن تحقيقها هي صفر.</p>
<p>رسميًا، بالنظر إلى مصفوفة مؤشر ثنائية لتسميات القيمة الحقيقية <span class="math notranslate nohighlight">\(y \in \left\{0, 1\right\}^{n_\text{samples} \times n_\text{labels}}\)</span> والدرجة المُرتبطة بكل تسمية <span class="math notranslate nohighlight">\(\hat{f} \in \mathbb{R}^{n_\text{samples} \times n_\text{labels}}\)</span>، يتم تعريف خسارة الترتيب على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[ranking\_loss(y, \hat{f}) =  \frac{1}{n_{\text{samples}}}
  \sum_{i=0}^{n_{\text{samples}} - 1} \frac{1}{||y_i||_0(n_\text{labels} - ||y_i||_0)}
  \left|\left\{(k, l): \hat{f}_{ik} \leq \hat{f}_{il}, y_{ik} = 1, y_{il} = 0 \right\}\right|\]</div>
<p>حيث <span class="math notranslate nohighlight">\(|\cdot|\)</span> يحسب عدد عناصر المجموعة (أي عدد العناصر في المجموعة) و <span class="math notranslate nohighlight">\(||\cdot||_0\)</span> هو <span class="math notranslate nohighlight">\(\ell_0\)</span> &quot;معيار&quot; (الذي يحسب عدد العناصر غير الصفرية في متجه).</p>
<p>فيما يلي مثال صغير على استخدام هذه الدالة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">label_ranking_loss</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label_ranking_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>
<span class="go">0.75...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># مع التنبؤ التالي، لدينا خسارة مثالية وأقل</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label_ranking_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>
<span class="go">0.0</span>
</pre></div>
</div>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-2">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-2" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text">Tsoumakas, G., Katakis, I., &amp; Vlahavas, I. (2010). Mining multi-label data. In
Data mining and knowledge discovery handbook (pp. 667-685). Springer US.</p></li>
</ul>
</div>
</details></section>
<section id="ndcg">
<span id="id83"></span><h3><span class="section-number">3.4.3.4. </span>مكسب تراكمي مُخصّم مُعياري<a class="headerlink" href="#ndcg" title="Link to this heading">#</a></h3>
<p>مكسب تراكمي مُخصّم (DCG) ومكسب تراكمي مُخصّم مُعياري (NDCG) هي مقاييس ترتيب مُطبقة في <a class="reference internal" href="generated/sklearn.metrics.dcg_score.html#sklearn.metrics.dcg_score" title="sklearn.metrics.dcg_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">dcg_score</span></code></a> و <a class="reference internal" href="generated/sklearn.metrics.ndcg_score.html#sklearn.metrics.ndcg_score" title="sklearn.metrics.ndcg_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">ndcg_score</span></code></a>؛ تُقارن ترتيبًا مُتوقعًا بدرجات القيمة الحقيقية، مثل ملاءمة الإجابات للاستعلام.</p>
<p>من صفحة ويكيبيديا لمكسب التراكمي المُخصّم:</p>
<p>&quot;المكسب التراكمي المُخصّم (DCG) هو مقياس لجودة الترتيب. في استرجاع المعلومات، غالبًا ما يُستخدم لقياس فعالية خوارزميات محرك البحث على الويب أو التطبيقات ذات الصلة. باستخدام مقياس ملاءمة مُدرّج للمستندات في مجموعة نتائج محرك البحث، يقيس DCG فائدة أو مكسب مستند بناءً على موضعه في قائمة النتائج. يتراكم المكسب من أعلى قائمة النتائج إلى أسفل، مع خصم مكسب كل نتيجة في مراتب أقل.&quot;</p>
<p>يرتب DCG الأهداف الحقيقية (على سبيل المثال، ملاءمة إجابات الاستعلام) بالترتيب المتوقع، ثم يضربها في انحلال لوغاريتمي ويجمع النتيجة. يمكن اقتطاع المجموع بعد أول <span class="math notranslate nohighlight">\(K\)</span> نتيجة، وفي هذه الحالة نسميها DCG&#64;K. NDCG، أو NDCG&#64;K هو DCG مقسومًا على DCG الذي تم الحصول عليه بواسطة تنبؤ مثالي، بحيث يكون دائمًا بين 0 و 1. عادةً، يُفضّل NDCG على DCG.</p>
<p>بالمقارنة مع خسارة الترتيب، يمكن لـ NDCG أن يأخذ في الاعتبار درجات الملاءمة، بدلاً من ترتيب القيمة الحقيقية. لذلك، إذا كانت القيمة الحقيقية تتكون فقط من ترتيب، فيجب تفضيل خسارة الترتيب؛ إذا كانت القيمة الحقيقية تتكون من درجات فائدة فعلية (على سبيل المثال، 0 لغير ذي صلة، 1 لذي صلة، 2 لذي صلة جدًا)، فيمكن استخدام NDCG.</p>
<p>بالنسبة لعينة واحدة، بالنظر إلى متجه قيم القيمة الحقيقية المستمرة لكل هدف <span class="math notranslate nohighlight">\(y \in \mathbb{R}^{M}\)</span>، حيث <span class="math notranslate nohighlight">\(M\)</span> هو عدد المخرجات، والتنبؤ <span class="math notranslate nohighlight">\(\hat{y}\)</span>، الذي يستحث دالة الترتيب <span class="math notranslate nohighlight">\(f\)</span>، فإن درجة DCG هي</p>
<div class="math notranslate nohighlight">
\[\sum_{r=1}^{\min(K, M)}\frac{y_{f(r)}}{\log(1 + r)}\]</div>
<p>ودرجة NDCG هي درجة DCG مقسومة على درجة DCG التي تم الحصول عليها لـ <span class="math notranslate nohighlight">\(y\)</span>.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-3" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text"><a class="reference external" href="https://en.wikipedia.org/wiki/Discounted_cumulative_gain">إدخال ويكيبيديا لمكسب التراكمي المُخصّم</a></p></li>
<li><p class="sd-card-text">Jarvelin, K., &amp; Kekalainen, J. (2002).
Cumulated gain-based evaluation of IR techniques. ACM Transactions on
Information Systems (TOIS), 20(4), 422-446.</p></li>
<li><p class="sd-card-text">Wang, Y., Wang, L., Li, Y., He, D., Chen, W., &amp; Liu, T. Y. (2013, May).
A theoretical analysis of NDCG ranking measures. In Proceedings of the 26th
Annual Conference on Learning Theory (COLT 2013)</p></li>
<li><p class="sd-card-text">McSherry, F., &amp; Najork, M. (2008, March). Computing information retrieval
performance measures efficiently in the presence of tied scores. In
European conference on information retrieval (pp. 414-421). Springer,
Berlin, Heidelberg.</p></li>
</ul>
</div>
</details></section>
</section>
<section id="regression-metrics">
<span id="id85"></span><h2><span class="section-number">3.4.4. </span>مقاييس الانحدار<a class="headerlink" href="#regression-metrics" title="Link to this heading">#</a></h2>
<p>تُطبق الوحدة <a class="reference internal" href="../api/sklearn.metrics.html#module-sklearn.metrics" title="sklearn.metrics"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></a> العديد من وظائف الخسارة والتهديف والأداة المساعدة لقياس أداء الانحدار. تم تحسين بعضها للتعامل مع حالة المخرجات المتعددة: <a class="reference internal" href="generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error" title="sklearn.metrics.mean_squared_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">mean_squared_error</span></code></a> و <a class="reference internal" href="generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error" title="sklearn.metrics.mean_absolute_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">mean_absolute_error</span></code></a> و <a class="reference internal" href="generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="sklearn.metrics.r2_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">r2_score</span></code></a> و <a class="reference internal" href="generated/sklearn.metrics.explained_variance_score.html#sklearn.metrics.explained_variance_score" title="sklearn.metrics.explained_variance_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">explained_variance_score</span></code></a> و:func:<code class="docutils literal notranslate"><span class="pre">mean_pinball_loss</span></code> و:func:<code class="docutils literal notranslate"><span class="pre">d2_pinball_score</span></code> و:func:<code class="docutils literal notranslate"><span class="pre">d2_absolute_error_score</span></code>.</p>
<p>تحتوي هذه الدوال على وسيطة كلمة مفتاحية <code class="docutils literal notranslate"><span class="pre">multioutput</span></code> تُحدد الطريقة التي يجب أن يتم بها حساب متوسط الدرجات أو الخسائر لكل هدف فردي. الافتراضي هو <code class="docutils literal notranslate"><span class="pre">'uniform_average'</span></code>، الذي يُحدد متوسطًا مرجحًا بشكل منتظم على المخرجات. إذا تم تمرير <code class="docutils literal notranslate"><span class="pre">ndarray</span></code> ذات شكل <code class="docutils literal notranslate"><span class="pre">(n_outputs,)</span></code>، فسيتم تفسير إدخالاتها على أنها أوزان ويتم إرجاع متوسط مرجح وفقًا لذلك. إذا كان <code class="docutils literal notranslate"><span class="pre">multioutput</span></code> هو <code class="docutils literal notranslate"><span class="pre">'raw_values'</span></code>، فسيتم إرجاع جميع الدرجات أو الخسائر الفردية غير المعدلة في مصفوفة ذات شكل <code class="docutils literal notranslate"><span class="pre">(n_outputs,)</span></code>.</p>
<p>يقبل كل من <a class="reference internal" href="generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="sklearn.metrics.r2_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">r2_score</span></code></a> و <a class="reference internal" href="generated/sklearn.metrics.explained_variance_score.html#sklearn.metrics.explained_variance_score" title="sklearn.metrics.explained_variance_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">explained_variance_score</span></code></a> قيمة إضافية <code class="docutils literal notranslate"><span class="pre">'variance_weighted'</span></code> لمعلمة <code class="docutils literal notranslate"><span class="pre">multioutput</span></code>. يؤدي هذا الخيار إلى ترجيح كل درجة فردية بواسطة تباين المتغير الهدف المقابل. يُحدد هذا الإعداد التباين غير المتدرج الذي تم التقاطه عالميًا. إذا كانت المتغيرات المستهدفة ذات مقياس مختلف، فإن هذه الدرجة تُعطي أهمية أكبر لشرح متغيرات التباين الأعلى.</p>
<section id="r2">
<span id="r2-score"></span><h3><span class="section-number">3.4.4.1. </span>درجة R²، معامل التحديد<a class="headerlink" href="#r2" title="Link to this heading">#</a></h3>
<p>تحسب الدالة <a class="reference internal" href="generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="sklearn.metrics.r2_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">r2_score</span></code></a> <a class="reference external" href="https://en.wikipedia.org/wiki/Coefficient_of_determination">معامل التحديد</a>، والذي يُشار إليه عادةً بـ <span class="math notranslate nohighlight">\(R^2\)</span>.</p>
<p>يُمثل نسبة التباين (لـ y) التي تم تفسيرها بواسطة المتغيرات المستقلة في النموذج. يُوفر مؤشرًا على جودة الملاءمة، وبالتالي مقياسًا لمدى احتمالية تنبؤ النموذج بعينات غير مرئية، من خلال نسبة التباين المُفسّر.</p>
<p>نظرًا لأن هذا التباين يعتمد على مجموعة البيانات، فقد لا يكون <span class="math notranslate nohighlight">\(R^2\)</span> قابلاً للمقارنة بشكل هادف عبر مجموعات البيانات المختلفة. أفضل درجة ممكنة هي 1.0 ويمكن أن تكون سلبية (لأن النموذج يمكن أن يكون أسوأ بشكل تعسفي). سيحصل النموذج الثابت الذي يتنبأ دائمًا بالقيمة المتوقعة (المتوسطة) لـ y، بغض النظر عن ميزات الإدخال، على درجة <span class="math notranslate nohighlight">\(R^2\)</span> تبلغ 0.0.</p>
<p>ملاحظة: عندما يكون لمتبقيات التنبؤ متوسط صفر، فإن درجة <span class="math notranslate nohighlight">\(R^2\)</span> و <a class="reference internal" href="#explained-variance-score"><span class="std std-ref">درجة التباين المُفسّر</span></a> متطابقتان.</p>
<p>إذا كانت <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> هي القيمة المتوقعة للعينة <span class="math notranslate nohighlight">\(i\)</span> و <span class="math notranslate nohighlight">\(y_i\)</span> هي القيمة الحقيقية المقابلة لإجمالي <span class="math notranslate nohighlight">\(n\)</span> عينات، فسيتم تعريف <span class="math notranslate nohighlight">\(R^2\)</span> المُقدّر على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[R^2(y, \hat{y}) = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}\]</div>
<p>حيث <span class="math notranslate nohighlight">\(\bar{y} = \frac{1}{n} \sum_{i=1}^{n} y_i\)</span> و <span class="math notranslate nohighlight">\(\sum_{i=1}^{n} (y_i - \hat{y}_i)^2 = \sum_{i=1}^{n} \epsilon_i^2\)</span>.</p>
<p>لاحظ أن <a class="reference internal" href="generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="sklearn.metrics.r2_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">r2_score</span></code></a> تحسب <span class="math notranslate nohighlight">\(R^2\)</span> غير المعدل دون تصحيح الانحياز في تباين العينة لـ y.</p>
<p>في الحالة الخاصة التي يكون فيها الهدف الحقيقي ثابتًا، فإن درجة <span class="math notranslate nohighlight">\(R^2\)</span> ليست محدودة: إنها إما <code class="docutils literal notranslate"><span class="pre">NaN</span></code> (تنبؤات مثالية) أو <code class="docutils literal notranslate"><span class="pre">-Inf</span></code> (تنبؤات غير مثالية). قد تمنع هذه الدرجات غير المحدودة التحسين الصحيح للنموذج، مثل التحقق المتبادل للبحث الشبكي، من الأداء بشكل صحيح. لهذا السبب، فإن السلوك الافتراضي لـ <a class="reference internal" href="generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="sklearn.metrics.r2_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">r2_score</span></code></a> هو استبدالها بـ 1.0 (تنبؤات مثالية) أو 0.0 (تنبؤات غير مثالية). إذا تم تعيين <code class="docutils literal notranslate"><span class="pre">force_finite</span></code> إلى <code class="docutils literal notranslate"><span class="pre">False</span></code>، فإن هذه الدرجة تعود إلى تعريف <span class="math notranslate nohighlight">\(R^2\)</span> الأصلي.</p>
<p>فيما يلي مثال صغير على استخدام دالة <a class="reference internal" href="generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="sklearn.metrics.r2_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">r2_score</span></code></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.948...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="o">-</span><span class="mi">6</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="s1">&#39;variance_weighted&#39;</span><span class="p">)</span>
<span class="go">0.938...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="o">-</span><span class="mi">6</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="s1">&#39;uniform_average&#39;</span><span class="p">)</span>
<span class="go">0.936...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="s1">&#39;raw_values&#39;</span><span class="p">)</span>
<span class="go">array([0.965..., 0.908...])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">])</span>
<span class="go">0.925...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">force_finite</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">nan</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">force_finite</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">-inf</span>
</pre></div>
</div>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p>انظر <a class="reference internal" href="../auto_examples/linear_model/plot_lasso_and_elasticnet.html#sphx-glr-auto-examples-linear-model-plot-lasso-and-elasticnet-py"><span class="std std-ref">L1-based models for Sparse Signals</span></a> للحصول على مثال على استخدام درجة R² لتقييم Lasso و Elastic Net على الإشارات المتفرقة.</p></li>
</ul>
</section>
<section id="mean-absolute-error">
<span id="id87"></span><h3><span class="section-number">3.4.4.2. </span>متوسط الخطأ المطلق<a class="headerlink" href="#mean-absolute-error" title="Link to this heading">#</a></h3>
<p>تحسب الدالة <a class="reference internal" href="generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error" title="sklearn.metrics.mean_absolute_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">mean_absolute_error</span></code></a> <a class="reference external" href="https://en.wikipedia.org/wiki/Mean_absolute_error">متوسط الخطأ المطلق</a>، وهو مقياس مخاطرة يقابل القيمة المتوقعة لخسارة الخطأ المطلق أو خسارة معيار <span class="math notranslate nohighlight">\(l1\)</span>.</p>
<p>إذا كانت <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> هي القيمة المتوقعة للعينة <span class="math notranslate nohighlight">\(i\)</span>، و <span class="math notranslate nohighlight">\(y_i\)</span> هي القيمة الحقيقية المقابلة، فسيتم تعريف متوسط الخطأ المطلق (MAE) المُقدّر على <span class="math notranslate nohighlight">\(n_{\text{samples}}\)</span> على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[\text{MAE}(y, \hat{y}) = \frac{1}{n_{\text{samples}}} \sum_{i=0}^{n_{\text{samples}}-1} \left| y_i - \hat{y}_i \right|.\]</div>
<p>فيما يلي مثال صغير على استخدام دالة <a class="reference internal" href="generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error" title="sklearn.metrics.mean_absolute_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">mean_absolute_error</span></code></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="go">  &gt;&gt;&gt; mean_absolute_error(y_true, y_pred)</span>
<span class="go">0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="o">-</span><span class="mi">6</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.75</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="s1">&#39;raw_values&#39;</span><span class="p">)</span>
<span class="go">array([0.5, 1. ])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">])</span>
<span class="go">0.85...</span>
</pre></div>
</div>
</section>
<section id="mean-squared-error">
<span id="id89"></span><h3><span class="section-number">3.4.4.3. </span>متوسط الخطأ التربيعي<a class="headerlink" href="#mean-squared-error" title="Link to this heading">#</a></h3>
<p>تحسب الدالة <a class="reference internal" href="generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error" title="sklearn.metrics.mean_squared_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">mean_squared_error</span></code></a> <a class="reference external" href="https://en.wikipedia.org/wiki/Mean_squared_error">متوسط الخطأ التربيعي</a>، وهو مقياس مخاطرة يقابل القيمة المتوقعة للخطأ (التربيعي) أو الخسارة.</p>
<p>إذا كانت <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> هي القيمة المتوقعة للعينة <span class="math notranslate nohighlight">\(i\)</span>، و <span class="math notranslate nohighlight">\(y_i\)</span> هي القيمة الحقيقية المقابلة، فسيتم تعريف متوسط الخطأ التربيعي (MSE) المُقدّر على <span class="math notranslate nohighlight">\(n_{\text{samples}}\)</span> على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[\text{MSE}(y, \hat{y}) = \frac{1}{n_\text{samples}} \sum_{i=0}^{n_\text{samples} - 1} (y_i - \hat{y}_i)^2.\]</div>
<p>فيما يلي مثال صغير على استخدام دالة <a class="reference internal" href="generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error" title="sklearn.metrics.mean_squared_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">mean_squared_error</span></code></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.375</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="o">-</span><span class="mi">6</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.7083...</span>
</pre></div>
</div>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p>انظر <a class="reference internal" href="../auto_examples/ensemble/plot_gradient_boosting_regression.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-regression-py"><span class="std std-ref">Gradient Boosting regression</span></a> للحصول على مثال على استخدام متوسط الخطأ التربيعي لتقييم انحدار التعزيز المتدرج.</p></li>
</ul>
<p>أخذ الجذر التربيعي لـ MSE، ويسمى الجذر التربيعي لمتوسط الخطأ التربيعي (RMSE)، هو مقياس شائع آخر يُوفر قياسًا بنفس وحدات المتغير الهدف. RSME متاح من خلال الدالة <a class="reference internal" href="generated/sklearn.metrics.root_mean_squared_error.html#sklearn.metrics.root_mean_squared_error" title="sklearn.metrics.root_mean_squared_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">root_mean_squared_error</span></code></a>.</p>
</section>
<section id="mean-squared-log-error">
<span id="id91"></span><h3><span class="section-number">3.4.4.4. </span>متوسط الخطأ اللوغاريتمي التربيعي<a class="headerlink" href="#mean-squared-log-error" title="Link to this heading">#</a></h3>
<p>تحسب الدالة <a class="reference internal" href="generated/sklearn.metrics.mean_squared_log_error.html#sklearn.metrics.mean_squared_log_error" title="sklearn.metrics.mean_squared_log_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">mean_squared_log_error</span></code></a> مقياس مخاطرة يقابل القيمة المتوقعة للخطأ (التربيعي) اللوغاريتمي أو الخسارة.</p>
<p>إذا كانت <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> هي القيمة المتوقعة للعينة <span class="math notranslate nohighlight">\(i\)</span>، و <span class="math notranslate nohighlight">\(y_i\)</span> هي القيمة الحقيقية المقابلة، فسيتم تعريف متوسط الخطأ اللوغاريتمي التربيعي (MSLE) المُقدّر على <span class="math notranslate nohighlight">\(n_{\text{samples}}\)</span> على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[\text{MSLE}(y, \hat{y}) = \frac{1}{n_\text{samples}} \sum_{i=0}^{n_\text{samples} - 1} (\log_e (1 + y_i) - \log_e (1 + \hat{y}_i) )^2.\]</div>
<p>حيث <span class="math notranslate nohighlight">\(\log_e (x)\)</span> يعني اللوغاريتم الطبيعي لـ <span class="math notranslate nohighlight">\(x\)</span>. من الأفضل استخدام هذا المقياس عندما يكون للأهداف نمو أسي، مثل أعداد السكان أو متوسط مبيعات سلعة على مدى سنوات، إلخ. لاحظ أن هذا المقياس يُعاقب التقدير الأقل من المتوقع أكثر من التقدير الأكثر من المتوقع.</p>
<p>فيما يلي مثال صغير على استخدام دالة <a class="reference internal" href="generated/sklearn.metrics.mean_squared_log_error.html#sklearn.metrics.mean_squared_log_error" title="sklearn.metrics.mean_squared_log_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">mean_squared_log_error</span></code></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_log_error</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_squared_log_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.039...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">6</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_squared_log_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.044...</span>
</pre></div>
</div>
<p>الجذر التربيعي لمتوسط الخطأ اللوغاريتمي التربيعي (RMSLE) متاح من خلال الدالة <a class="reference internal" href="generated/sklearn.metrics.root_mean_squared_log_error.html#sklearn.metrics.root_mean_squared_log_error" title="sklearn.metrics.root_mean_squared_log_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">root_mean_squared_log_error</span></code></a>.</p>
</section>
<section id="mean-absolute-percentage-error">
<span id="id92"></span><h3><span class="section-number">3.4.4.5. </span>متوسط نسبة الخطأ المطلق<a class="headerlink" href="#mean-absolute-percentage-error" title="Link to this heading">#</a></h3>
<p><a class="reference internal" href="generated/sklearn.metrics.mean_absolute_percentage_error.html#sklearn.metrics.mean_absolute_percentage_error" title="sklearn.metrics.mean_absolute_percentage_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">mean_absolute_percentage_error</span></code></a> (MAPE)، المعروف أيضًا باسم متوسط الانحراف النسبي المطلق (MAPD)، هو مقياس تقييم لمشاكل الانحدار. فكرة هذا المقياس هي أن يكون حساسًا للأخطاء النسبية. على سبيل المثال، لا يتغير عن طريق القياس الشامل للمتغير الهدف.</p>
<p>إذا كانت <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> هي القيمة المتوقعة للعينة <span class="math notranslate nohighlight">\(i\)</span>-th و:math:<code class="docutils literal notranslate"><span class="pre">y_i</span></code> هي القيمة الحقيقية المقابلة، فسيتم تعريف متوسط نسبة الخطأ المطلق (MAPE) المقدر على <span class="math notranslate nohighlight">\(n_\text{samples}\)</span> على النحو التالي</p>
<div class="math notranslate nohighlight">
\[\text{MAPE}(y, \hat{y}) = \frac{1}{n_{\text{samples}}} \sum_{i=0}^{n_{\text{samples}}-1} \frac{{}\left| y_i - \hat{y}_i \right|}{\max(\epsilon, \left| y_i \right|)}\]</div>
<p>حيث <span class="math notranslate nohighlight">\(\epsilon\)</span> هو رقم صغير تعسفي ولكنه موجب تمامًا لتجنب النتائج غير المحددة عندما تكون y صفرًا.</p>
<p>تدعم الدالة <a class="reference internal" href="generated/sklearn.metrics.mean_absolute_percentage_error.html#sklearn.metrics.mean_absolute_percentage_error" title="sklearn.metrics.mean_absolute_percentage_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">mean_absolute_percentage_error</span></code></a> المخرجات المتعددة.</p>
<p>فيما يلي مثال صغير على استخدام الدالة <a class="reference internal" href="generated/sklearn.metrics.mean_absolute_percentage_error.html#sklearn.metrics.mean_absolute_percentage_error" title="sklearn.metrics.mean_absolute_percentage_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">mean_absolute_percentage_error</span></code></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_percentage_error</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">1e6</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mf">1.2e6</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_absolute_percentage_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.2666...</span>
</pre></div>
</div>
<p>في المثال أعلاه، إذا كنا قد استخدمنا <code class="docutils literal notranslate"><span class="pre">mean_absolute_error</span></code>، لكانت قد تجاهلت قيم الحجم الصغير وعكست فقط الخطأ في التنبؤ بقيمة الحجم الأعلى. لكن هذه المشكلة تم حلها في حالة MAPE لأنه يحسب نسبة الخطأ النسبية فيما يتعلق بالإخراج الفعلي.</p>
<div class="admonition note">
<p class="admonition-title">ملاحظة</p>
<p>لا تُمثل صيغة MAPE هنا تعريف &quot;النسبة المئوية&quot; الشائع: يتم تحويل النسبة المئوية في النطاق [0، 100] إلى قيمة نسبية في النطاق [0، 1] بالقسمة على 100. وبالتالي، يتوافق خطأ بنسبة 200٪ مع خطأ نسبي قدره 2. الدافع هنا هو الحصول على نطاق من القيم أكثر اتساقًا مع مقاييس الخطأ الأخرى في scikit-learn، مثل <code class="docutils literal notranslate"><span class="pre">accuracy_score</span></code>.</p>
<p>للحصول على متوسط نسبة الخطأ المطلق وفقًا لصيغة ويكيبيديا، اضرب <code class="docutils literal notranslate"><span class="pre">mean_absolute_percentage_error</span></code> المحسوبة هنا في 100.</p>
</div>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-4">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-4" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text"><a class="reference external" href="https://en.wikipedia.org/wiki/Mean_absolute_percentage_error">إدخال ويكيبيديا لمتوسط نسبة الخطأ المطلق</a></p></li>
</ul>
</div>
</details></section>
<section id="median-absolute-error">
<span id="id94"></span><h3><span class="section-number">3.4.4.6. </span>متوسط الخطأ المطلق للوسيط<a class="headerlink" href="#median-absolute-error" title="Link to this heading">#</a></h3>
<p><a class="reference internal" href="generated/sklearn.metrics.median_absolute_error.html#sklearn.metrics.median_absolute_error" title="sklearn.metrics.median_absolute_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">median_absolute_error</span></code></a> مثير للاهتمام بشكل خاص لأنه قوي ضد القيم المتطرفة. يتم حساب الخسارة عن طريق أخذ وسيط جميع الفروق المطلقة بين الهدف والتنبؤ.</p>
<p>إذا كانت <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> هي القيمة المتوقعة للعينة <span class="math notranslate nohighlight">\(i\)</span> و <span class="math notranslate nohighlight">\(y_i\)</span> هي القيمة الحقيقية المقابلة، فسيتم تعريف متوسط الخطأ المطلق للوسيط (MedAE) المُقدّر على <span class="math notranslate nohighlight">\(n_{\text{samples}}\)</span> على النحو التالي</p>
<div class="math notranslate nohighlight">
\[\text{MedAE}(y, \hat{y}) = \text{median}(\mid y_1 - \hat{y}_1 \mid, \ldots, \mid y_n - \hat{y}_n \mid).\]</div>
<p>لا يدعم <a class="reference internal" href="generated/sklearn.metrics.median_absolute_error.html#sklearn.metrics.median_absolute_error" title="sklearn.metrics.median_absolute_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">median_absolute_error</span></code></a> المخرجات المتعددة.</p>
<p>فيما يلي مثال صغير على استخدام دالة <a class="reference internal" href="generated/sklearn.metrics.median_absolute_error.html#sklearn.metrics.median_absolute_error" title="sklearn.metrics.median_absolute_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">median_absolute_error</span></code></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">median_absolute_error</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">median_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.5</span>
</pre></div>
</div>
</section>
<section id="max-error">
<span id="id95"></span><h3><span class="section-number">3.4.4.7. </span>أقصى خطأ<a class="headerlink" href="#max-error" title="Link to this heading">#</a></h3>
<p>تحسب الدالة <a class="reference internal" href="generated/sklearn.metrics.max_error.html#sklearn.metrics.max_error" title="sklearn.metrics.max_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">max_error</span></code></a> أقصى <a class="reference external" href="https://en.wikipedia.org/wiki/Errors_and_residuals">خطأ مُتبقٍ</a>، وهو مقياس يلتقط أسوأ حالة خطأ بين القيمة المتوقعة والقيمة الحقيقية. في نموذج انحدار ناتج واحد مناسب تمامًا، سيكون <code class="docutils literal notranslate"><span class="pre">max_error</span></code> <code class="docutils literal notranslate"><span class="pre">0</span></code> في مجموعة التدريب، وعلى الرغم من أن هذا من غير المحتمل للغاية في العالم الحقيقي، يُظهر هذا المقياس مدى الخطأ الذي حدث في النموذج عند ملاءمته.</p>
<p>إذا كانت <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> هي القيمة المتوقعة للعينة <span class="math notranslate nohighlight">\(i\)</span>، و <span class="math notranslate nohighlight">\(y_i\)</span> هي القيمة الحقيقية المقابلة، فسيتم تعريف أقصى خطأ على النحو التالي</p>
<div class="math notranslate nohighlight">
\[\text{Max Error}(y, \hat{y}) = \max(| y_i - \hat{y}_i |)\]</div>
<p>فيما يلي مثال صغير على استخدام دالة <a class="reference internal" href="generated/sklearn.metrics.max_error.html#sklearn.metrics.max_error" title="sklearn.metrics.max_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">max_error</span></code></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">max_error</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">max_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">6</span>
</pre></div>
</div>
<p>لا يدعم <a class="reference internal" href="generated/sklearn.metrics.max_error.html#sklearn.metrics.max_error" title="sklearn.metrics.max_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">max_error</span></code></a> المخرجات المتعددة.</p>
</section>
<section id="explained-variance-score">
<span id="id97"></span><h3><span class="section-number">3.4.4.8. </span>درجة التباين المُفسّر<a class="headerlink" href="#explained-variance-score" title="Link to this heading">#</a></h3>
<p>تحسب <a class="reference internal" href="generated/sklearn.metrics.explained_variance_score.html#sklearn.metrics.explained_variance_score" title="sklearn.metrics.explained_variance_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">explained_variance_score</span></code></a> <a class="reference external" href="https://en.wikipedia.org/wiki/Explained_variation">درجة انحدار التباين المُفسّر</a>.</p>
<p>إذا كان <span class="math notranslate nohighlight">\(\hat{y}\)</span> هو ناتج الهدف المُقدّر، <span class="math notranslate nohighlight">\(y\)</span> ناتج الهدف (الصحيح) المقابل، و <span class="math notranslate nohighlight">\(Var\)</span> هو <a class="reference external" href="https://en.wikipedia.org/wiki/Variance">التباين</a>، مربع الانحراف المعياري، فسيتم تقدير التباين المُفسّر على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[explained\_{}variance(y, \hat{y}) = 1 - \frac{Var\{ y - \hat{y}\}}{Var\{y\}}\]</div>
<p>أفضل درجة ممكنة هي 1.0، والقيم الأقل أسوأ.</p>
<aside class="topic">
<p class="topic-title">رابط إلى <a class="reference internal" href="#r2-score"><span class="std std-ref">درجة R²، معامل التحديد</span></a></p>
<p>الفرق بين درجة التباين المُفسّر و <a class="reference internal" href="#r2-score"><span class="std std-ref">درجة R²، معامل التحديد</span></a> هو أن درجة التباين المُفسّر لا تأخذ في الاعتبار الإزاحة المنتظمة في التنبؤ. لهذا السبب، يجب تفضيل <a class="reference internal" href="#r2-score"><span class="std std-ref">درجة R²، معامل التحديد</span></a> بشكل عام.</p>
</aside>
<p>في الحالة الخاصة التي يكون فيها الهدف الحقيقي ثابتًا، فإن درجة التباين المُفسّر ليست محدودة: إنها إما <code class="docutils literal notranslate"><span class="pre">NaN</span></code> (تنبؤات مثالية) أو <code class="docutils literal notranslate"><span class="pre">-Inf</span></code> (تنبؤات غير مثالية). قد تمنع هذه الدرجات غير المحدودة التحسين الصحيح للنموذج، مثل التحقق المتبادل للبحث الشبكي، من الأداء بشكل صحيح. لهذا السبب، فإن السلوك الافتراضي لـ <a class="reference internal" href="generated/sklearn.metrics.explained_variance_score.html#sklearn.metrics.explained_variance_score" title="sklearn.metrics.explained_variance_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">explained_variance_score</span></code></a> هو استبدالها بـ 1.0 (تنبؤات مثالية) أو 0.0 (تنبؤات غير مثالية). يمكنك تعيين معلمة <code class="docutils literal notranslate"><span class="pre">force_finite</span></code> إلى <code class="docutils literal notranslate"><span class="pre">False</span></code> لمنع حدوث هذا الإصلاح والعودة إلى درجة التباين المُفسّر الأصلية.</p>
<p>فيما يلي مثال صغير على استخدام دالة <a class="reference internal" href="generated/sklearn.metrics.explained_variance_score.html#sklearn.metrics.explained_variance_score" title="sklearn.metrics.explained_variance_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">explained_variance_score</span></code></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">explained_variance_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explained_variance_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.957...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="o">-</span><span class="mi">6</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explained_variance_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="s1">&#39;raw_values&#39;</span><span class="p">)</span>
<span class="go">array([0.967..., 1.        ])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explained_variance_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">])</span>
<span class="go">0.990...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explained_variance_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explained_variance_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">force_finite</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">nan</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explained_variance_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explained_variance_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">force_finite</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">-inf</span>
</pre></div>
</div>
</section>
<section id="mean-tweedie-deviance">
<span id="id100"></span><h3><span class="section-number">3.4.4.9. </span>متوسط انحرافات بواسون وغاما وتويد<a class="headerlink" href="#mean-tweedie-deviance" title="Link to this heading">#</a></h3>
<p>تحسب الدالة <a class="reference internal" href="generated/sklearn.metrics.mean_tweedie_deviance.html#sklearn.metrics.mean_tweedie_deviance" title="sklearn.metrics.mean_tweedie_deviance"><code class="xref py py-func docutils literal notranslate"><span class="pre">mean_tweedie_deviance</span></code></a> <a class="reference external" href="https://en.wikipedia.org/wiki/Tweedie_distribution#The_Tweedie_deviance">متوسط خطأ انحراف تويد</a> بمعلمة <code class="docutils literal notranslate"><span class="pre">power</span></code> (<span class="math notranslate nohighlight">\(p\)</span>). هذا مقياس يستخرج قيم التوقع المتوقعة لأهداف الانحدار.</p>
<p>توجد الحالات الخاصة التالية،</p>
<ul class="simple">
<li><p>عندما <code class="docutils literal notranslate"><span class="pre">power=0</span></code> يكون مكافئًا لـ <a class="reference internal" href="generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error" title="sklearn.metrics.mean_squared_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">mean_squared_error</span></code></a>.</p></li>
<li><p>عندما <code class="docutils literal notranslate"><span class="pre">power=1</span></code> يكون مكافئًا لـ <a class="reference internal" href="generated/sklearn.metrics.mean_poisson_deviance.html#sklearn.metrics.mean_poisson_deviance" title="sklearn.metrics.mean_poisson_deviance"><code class="xref py py-func docutils literal notranslate"><span class="pre">mean_poisson_deviance</span></code></a>.</p></li>
<li><p>عندما <code class="docutils literal notranslate"><span class="pre">power=2</span></code> يكون مكافئًا لـ <a class="reference internal" href="generated/sklearn.metrics.mean_gamma_deviance.html#sklearn.metrics.mean_gamma_deviance" title="sklearn.metrics.mean_gamma_deviance"><code class="xref py py-func docutils literal notranslate"><span class="pre">mean_gamma_deviance</span></code></a>.</p></li>
</ul>
<p>إذا كانت <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> هي القيمة المتوقعة للعينة <span class="math notranslate nohighlight">\(i\)</span>، و:math:<code class="docutils literal notranslate"><span class="pre">y_i</span></code> هي القيمة الحقيقية المقابلة، فسيتم تعريف متوسط خطأ انحراف تويد (D) للقوة <span class="math notranslate nohighlight">\(p\)</span>، المُقدّر على <span class="math notranslate nohighlight">\(n_\text{samples}\)</span> على النحو التالي</p>
<div class="math notranslate nohighlight">
\[\begin{split}\text{D}(y, \hat{y}) = \frac{1}{n_\text{samples}}
\sum_{i=0}^{n_\text{samples} - 1}
\begin{cases}
(y_i-\hat{y}_i)^2, &amp; \text{for }p=0\text{ (Normal)}\\
2(y_i \log(y_i/\hat{y}_i) + \hat{y}_i - y_i),  &amp; \text{for }p=1\text{ (Poisson)}\\
2(\log(\hat{y}_i/y_i) + y_i/\hat{y}_i - 1),  &amp; \text{for }p=2\text{ (Gamma)}\\
2\left(\frac{\max(y_i,0)^{2-p}}{(1-p)(2-p)}-
\frac{y_i\,\hat{y}_i^{1-p}}{1-p}+\frac{\hat{y}_i^{2-p}}{2-p}\right),
&amp; \text{otherwise}
\end{cases}\end{split}\]</div>
<p>انحراف تويد هو دالة متجانسة من الدرجة <code class="docutils literal notranslate"><span class="pre">2-power</span></code>. وبالتالي، يعني توزيع جاما مع <code class="docutils literal notranslate"><span class="pre">power=2</span></code> أن قياس <code class="docutils literal notranslate"><span class="pre">y_true</span></code> و <code class="docutils literal notranslate"><span class="pre">y_pred</span></code> في وقت واحد ليس له أي تأثير على الانحراف. بالنسبة لتوزيع بواسون <code class="docutils literal notranslate"><span class="pre">power=1</span></code>، يتدرج الانحراف خطيًا، وبالنسبة للتوزيع الطبيعي (<code class="docutils literal notranslate"><span class="pre">power=0</span></code>)، تربيعيًا. بشكل عام، كلما زادت <code class="docutils literal notranslate"><span class="pre">power</span></code>، قل الوزن المعطى للانحرافات الشديدة بين الأهداف الحقيقية والمتوقعة.</p>
<p>على سبيل المثال، دعونا نقارن التنبؤين 1.5 و 150 اللذين كلاهما أكبر بنسبة 50٪ من قيمتهما الحقيقية المقابلة.</p>
<p>متوسط الخطأ التربيعي (<code class="docutils literal notranslate"><span class="pre">power=0</span></code>) حساس جدًا لاختلاف التنبؤ للنقطة الثانية،:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_tweedie_deviance</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_tweedie_deviance</span><span class="p">([</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.5</span><span class="p">],</span> <span class="n">power</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="go">0.25</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_tweedie_deviance</span><span class="p">([</span><span class="mf">100.</span><span class="p">],</span> <span class="p">[</span><span class="mf">150.</span><span class="p">],</span> <span class="n">power</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="go">2500.0</span>
</pre></div>
</div>
<p>إذا زدنا <code class="docutils literal notranslate"><span class="pre">power</span></code> إلى 1،:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mean_tweedie_deviance</span><span class="p">([</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.5</span><span class="p">],</span> <span class="n">power</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">0.18...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_tweedie_deviance</span><span class="p">([</span><span class="mf">100.</span><span class="p">],</span> <span class="p">[</span><span class="mf">150.</span><span class="p">],</span> <span class="n">power</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">18.9...</span>
</pre></div>
</div>
<p>يقل اختلاف الأخطاء. أخيرًا، عن طريق التعيين، <code class="docutils literal notranslate"><span class="pre">power=2</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mean_tweedie_deviance</span><span class="p">([</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.5</span><span class="p">],</span> <span class="n">power</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="go">0.14...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_tweedie_deviance</span><span class="p">([</span><span class="mf">100.</span><span class="p">],</span> <span class="p">[</span><span class="mf">150.</span><span class="p">],</span> <span class="n">power</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="go">0.14...</span>
</pre></div>
</div>
<p>سنحصل على أخطاء متطابقة. وبالتالي، فإن الانحراف عندما <code class="docutils literal notranslate"><span class="pre">power=2</span></code> حساس فقط للأخطاء النسبية.</p>
</section>
<section id="pinball-loss">
<span id="id102"></span><h3><span class="section-number">3.4.4.10. </span>خسارة الكرة والدبابيس<a class="headerlink" href="#pinball-loss" title="Link to this heading">#</a></h3>
<p>تُستخدم الدالة <a class="reference internal" href="generated/sklearn.metrics.mean_pinball_loss.html#sklearn.metrics.mean_pinball_loss" title="sklearn.metrics.mean_pinball_loss"><code class="xref py py-func docutils literal notranslate"><span class="pre">mean_pinball_loss</span></code></a> لتقييم الأداء التنبؤي لنماذج <a class="reference external" href="https://en.wikipedia.org/wiki/Quantile_regression">انحدار الكميات</a>.</p>
<div class="math notranslate nohighlight">
\[\text{pinball}(y, \hat{y}) = \frac{1}{n_{\text{samples}}} \sum_{i=0}^{n_{\text{samples}}-1}  \alpha \max(y_i - \hat{y}_i, 0) + (1 - \alpha) \max(\hat{y}_i - y_i, 0)\]</div>
<p>تُكافئ قيمة خسارة الكرة والدبابيس نصف <a class="reference internal" href="generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error" title="sklearn.metrics.mean_absolute_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">mean_absolute_error</span></code></a> عندما يتم تعيين معلمة الكمية <code class="docutils literal notranslate"><span class="pre">alpha</span></code> إلى 0.5.</p>
<p>فيما يلي مثال صغير على استخدام دالة <a class="reference internal" href="generated/sklearn.metrics.mean_pinball_loss.html#sklearn.metrics.mean_pinball_loss" title="sklearn.metrics.mean_pinball_loss"><code class="xref py py-func docutils literal notranslate"><span class="pre">mean_pinball_loss</span></code></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_pinball_loss</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_pinball_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="go">0.03...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_pinball_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="go">0.3...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_pinball_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="go">0.3...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_pinball_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="go">0.03...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_pinball_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="go">0.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_pinball_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="go">0.0</span>
</pre></div>
</div>
<p>من الممكن بناء كائن هدّاف مع اختيار مُحدّد لـ <code class="docutils literal notranslate"><span class="pre">alpha</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">make_scorer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_pinball_loss_95p</span> <span class="o">=</span> <span class="n">make_scorer</span><span class="p">(</span><span class="n">mean_pinball_loss</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>
</pre></div>
</div>
<p>يمكن استخدام هذا الهدّاف لتقييم أداء التعميم لمُنحدِر الكميات عبر التحقق المتبادل:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingRegressor</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator</span> <span class="o">=</span> <span class="n">GradientBoostingRegressor</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;quantile&quot;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">mean_pinball_loss_95p</span><span class="p">)</span>
<span class="go">array([13.6..., 9.7..., 23.3..., 9.5..., 10.4...])</span>
</pre></div>
</div>
<p>من الممكن أيضًا بناء كائنات هدّاف لضبط المعلمات الفائقة. يجب تبديل إشارة الخسارة لضمان أن الأكبر يعني الأفضل كما هو موضح في المثال المرتبط أدناه.</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p>انظر <a class="reference internal" href="../auto_examples/ensemble/plot_gradient_boosting_quantile.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-quantile-py"><span class="std std-ref">Prediction Intervals for Gradient Boosting Regression</span></a> للحصول على مثال على استخدام خسارة الكرة والدبابيس لتقييم وضبط المعلمات الفائقة لنماذج انحدار الكميات على البيانات ذات الضوضاء غير المتماثلة والقيم المتطرفة.</p></li>
</ul>
</section>
<section id="d2-score">
<span id="id104"></span><h3><span class="section-number">3.4.4.11. </span>درجة D²<a class="headerlink" href="#d2-score" title="Link to this heading">#</a></h3>
<p>تحسب درجة D² جزء الانحراف المُفسّر. وهو تعميم لـ R²، حيث يتم تعميم الخطأ التربيعي واستبداله بانحراف مُختار <span class="math notranslate nohighlight">\(\text{dev}(y, \hat{y})\)</span> (على سبيل المثال، تويد أو الكرة والدبابيس أو متوسط الخطأ المطلق). D² هو شكل من أشكال <em>درجة المهارة</em>. يتم حسابها على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[D^2(y, \hat{y}) = 1 - \frac{\text{dev}(y, \hat{y})}{\text{dev}(y, y_{\text{null}})} \,.\]</div>
<p>حيث <span class="math notranslate nohighlight">\(y_{\text{null}}\)</span> هو التنبؤ الأمثل لنموذج التقاطع فقط (على سبيل المثال، متوسط <code class="docutils literal notranslate"><span class="pre">y_true</span></code> لحالة تويد، الوسيط للخطأ المطلق، والكمية ألفا لخسارة الكرة والدبابيس).</p>
<p>مثل R²، أفضل درجة ممكنة هي 1.0 ويمكن أن تكون سلبية (لأن النموذج يمكن أن يكون أسوأ بشكل تعسفي). سيحصل النموذج الثابت الذي يتنبأ دائمًا بـ <span class="math notranslate nohighlight">\(y_{\text{null}}\)</span>، بغض النظر عن ميزات الإدخال، على درجة D² تبلغ 0.0.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="درجة-تويد-d²">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">درجة تويد D²<a class="headerlink" href="#درجة-تويد-d²" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">تُطبق الدالة <a class="reference internal" href="generated/sklearn.metrics.d2_tweedie_score.html#sklearn.metrics.d2_tweedie_score" title="sklearn.metrics.d2_tweedie_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">d2_tweedie_score</span></code></a> الحالة الخاصة لـ D² حيث <span class="math notranslate nohighlight">\(\text{dev}(y, \hat{y})\)</span> هو انحراف تويد، انظر <a class="reference internal" href="#mean-tweedie-deviance"><span class="std std-ref">متوسط انحرافات بواسون وغاما وتويد</span></a>. تُعرف أيضًا باسم D² Tweedie وترتبط بمؤشر نسبة احتمالية مكفادين.</p>
<p class="sd-card-text">تُعرّف الوسيطة <code class="docutils literal notranslate"><span class="pre">power</span></code> قوة تويد كما هو الحال بالنسبة لـ <a class="reference internal" href="generated/sklearn.metrics.mean_tweedie_deviance.html#sklearn.metrics.mean_tweedie_deviance" title="sklearn.metrics.mean_tweedie_deviance"><code class="xref py py-func docutils literal notranslate"><span class="pre">mean_tweedie_deviance</span></code></a>. لاحظ أنه بالنسبة لـ <code class="docutils literal notranslate"><span class="pre">power=0</span></code>، تساوي <a class="reference internal" href="generated/sklearn.metrics.d2_tweedie_score.html#sklearn.metrics.d2_tweedie_score" title="sklearn.metrics.d2_tweedie_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">d2_tweedie_score</span></code></a> <a class="reference internal" href="generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="sklearn.metrics.r2_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">r2_score</span></code></a> (للأهداف الفردية).</p>
<p class="sd-card-text">يمكن بناء كائن هدّاف مع اختيار مُحدّد لـ <code class="docutils literal notranslate"><span class="pre">power</span></code> عن طريق:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">d2_tweedie_score</span><span class="p">,</span> <span class="n">make_scorer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d2_tweedie_score_15</span> <span class="o">=</span> <span class="n">make_scorer</span><span class="p">(</span><span class="n">d2_tweedie_score</span><span class="p">,</span> <span class="n">power</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="درجة-الكرة-والدبابيس-d²">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">درجة الكرة والدبابيس D²<a class="headerlink" href="#درجة-الكرة-والدبابيس-d²" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">تُطبق الدالة <a class="reference internal" href="generated/sklearn.metrics.d2_pinball_score.html#sklearn.metrics.d2_pinball_score" title="sklearn.metrics.d2_pinball_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">d2_pinball_score</span></code></a> الحالة الخاصة لـ D² مع خسارة الكرة والدبابيس، انظر <a class="reference internal" href="#pinball-loss"><span class="std std-ref">خسارة الكرة والدبابيس</span></a>، أي:</p>
<div class="math notranslate nohighlight">
\[\text{dev}(y, \hat{y}) = \text{pinball}(y, \hat{y}).\]</div>
<p class="sd-card-text">تُعرّف الوسيطة <code class="docutils literal notranslate"><span class="pre">alpha</span></code> ميل خسارة الكرة والدبابيس كما هو الحال بالنسبة لـ <a class="reference internal" href="generated/sklearn.metrics.mean_pinball_loss.html#sklearn.metrics.mean_pinball_loss" title="sklearn.metrics.mean_pinball_loss"><code class="xref py py-func docutils literal notranslate"><span class="pre">mean_pinball_loss</span></code></a> (<a class="reference internal" href="#pinball-loss"><span class="std std-ref">خسارة الكرة والدبابيس</span></a>). تُحدد مستوى الكمية <code class="docutils literal notranslate"><span class="pre">alpha</span></code> الذي تكون فيه خسارة الكرة والدبابيس وأيضًا D² مثالية. لاحظ أنه بالنسبة لـ <code class="docutils literal notranslate"><span class="pre">alpha=0.5</span></code> (الافتراضي)، تساوي <a class="reference internal" href="generated/sklearn.metrics.d2_pinball_score.html#sklearn.metrics.d2_pinball_score" title="sklearn.metrics.d2_pinball_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">d2_pinball_score</span></code></a> <a class="reference internal" href="generated/sklearn.metrics.d2_absolute_error_score.html#sklearn.metrics.d2_absolute_error_score" title="sklearn.metrics.d2_absolute_error_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">d2_absolute_error_score</span></code></a>.</p>
<p class="sd-card-text">يمكن بناء كائن هدّاف مع اختيار مُحدّد لـ <code class="docutils literal notranslate"><span class="pre">alpha</span></code> عن طريق:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">d2_pinball_score</span><span class="p">,</span> <span class="n">make_scorer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d2_pinball_score_08</span> <span class="o">=</span> <span class="n">make_scorer</span><span class="p">(</span><span class="n">d2_pinball_score</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="درجة-خطأ-مطلق-d²">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">درجة خطأ مطلق D²<a class="headerlink" href="#درجة-خطأ-مطلق-d²" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">تُطبق الدالة <a class="reference internal" href="generated/sklearn.metrics.d2_absolute_error_score.html#sklearn.metrics.d2_absolute_error_score" title="sklearn.metrics.d2_absolute_error_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">d2_absolute_error_score</span></code></a> الحالة الخاصة لـ <a class="reference internal" href="#mean-absolute-error"><span class="std std-ref">متوسط الخطأ المطلق</span></a>:</p>
<div class="math notranslate nohighlight">
\[\text{dev}(y, \hat{y}) = \text{MAE}(y, \hat{y}).\]</div>
<p class="sd-card-text">فيما يلي بعض أمثلة الاستخدام لدالة <a class="reference internal" href="generated/sklearn.metrics.d2_absolute_error_score.html#sklearn.metrics.d2_absolute_error_score" title="sklearn.metrics.d2_absolute_error_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">d2_absolute_error_score</span></code></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">d2_absolute_error_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d2_absolute_error_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.764...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d2_absolute_error_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d2_absolute_error_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.0</span>
</pre></div>
</div>
</div>
</details></section>
<section id="visualization-regression-evaluation">
<span id="id105"></span><h3><span class="section-number">3.4.4.12. </span>التقييم المرئي لنماذج الانحدار<a class="headerlink" href="#visualization-regression-evaluation" title="Link to this heading">#</a></h3>
<p>من بين الطرق لتقييم جودة نماذج الانحدار، تُوفر scikit-learn فئة <a class="reference internal" href="generated/sklearn.metrics.PredictionErrorDisplay.html#sklearn.metrics.PredictionErrorDisplay" title="sklearn.metrics.PredictionErrorDisplay"><code class="xref py py-class docutils literal notranslate"><span class="pre">PredictionErrorDisplay</span></code></a>. تسمح بفحص أخطاء التنبؤ للنموذج بصريًا بطريقتين مختلفتين.</p>
<a class="reference external image-reference" href="../auto_examples/model_selection/plot_cv_predict.html"><img alt="../_images/sphx_glr_plot_cv_predict_001.png" class="align-center" src="../_images/sphx_glr_plot_cv_predict_001.png" style="width: 600.0px; height: 300.0px;" />
</a>
<p>يُظهر الرسم التخطيطي على اليسار القيم الفعلية مقابل القيم المتوقعة. بالنسبة لمهمة انحدار خالية من الضوضاء تهدف إلى التنبؤ بالتوقع (الشرطي) لـ <code class="docutils literal notranslate"><span class="pre">y</span></code>، سيعرض نموذج الانحدار المثالي نقاط البيانات على القطر المُحدّد بواسطة القيم المتوقعة التي تساوي القيم الفعلية. كلما ابتعدنا عن هذا الخط الأمثل، زاد خطأ النموذج. في إعداد أكثر واقعية مع ضوضاء غير قابلة للاختزال، أي عندما لا يمكن تفسير جميع اختلافات <code class="docutils literal notranslate"><span class="pre">y</span></code> بواسطة ميزات في <code class="docutils literal notranslate"><span class="pre">X</span></code>، فإن أفضل نموذج سيؤدي إلى سحابة من النقاط مُرتبة بكثافة حول القطر.</p>
<p>لاحظ أن ما سبق ينطبق فقط عندما تكون القيم المتوقعة هي القيمة المتوقعة لـ <code class="docutils literal notranslate"><span class="pre">y</span></code> بالنظر إلى <code class="docutils literal notranslate"><span class="pre">X</span></code>. هذا هو الحال عادةً بالنسبة لنماذج الانحدار التي تُقلل من دالة الهدف لمتوسط الخطأ التربيعي أو بشكل أكثر عمومية <a class="reference internal" href="#mean-tweedie-deviance"><span class="std std-ref">متوسط انحراف تويد</span></a> لأي قيمة لمعلمة &quot;power&quot;.</p>
<p>عند رسم تنبؤات مقدر يتنبأ بكمية من <code class="docutils literal notranslate"><span class="pre">y</span></code> بالنظر إلى <code class="docutils literal notranslate"><span class="pre">X</span></code>، على سبيل المثال <a class="reference internal" href="generated/sklearn.linear_model.QuantileRegressor.html#sklearn.linear_model.QuantileRegressor" title="sklearn.linear_model.QuantileRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantileRegressor</span></code></a> أو أي نموذج آخر يُقلل من <a class="reference internal" href="#pinball-loss"><span class="std std-ref">خسارة الكرة والدبابيس</span></a>، من المتوقع أن تقع نسبة من النقاط إما فوق أو أسفل القطر اعتمادًا على مستوى الكمية المُقدّر.</p>
<p>إجمالاً، على الرغم من سهولة قراءته، فإن هذا الرسم التخطيطي لا يُخبرنا حقًا بما يجب فعله للحصول على نموذج أفضل.</p>
<p>يُظهر الرسم التخطيطي على الجانب الأيمن المتبقيات (أي الفرق بين القيم الفعلية والمتوقعة) مقابل القيم المتوقعة.</p>
<p>يجعل هذا الرسم التخطيطي من الأسهل تصور ما إذا كانت المتبقيات تتبع توزيعًا <a class="reference external" href="https://en.wikipedia.org/wiki/Homoscedasticity_and_heteroscedasticity">متجانسًا أو غير متجانس</a>.</p>
<p>على وجه الخصوص، إذا كان التوزيع الحقيقي لـ <code class="docutils literal notranslate"><span class="pre">y|X</span></code> هو توزيع بواسون أو جاما، فمن المتوقع أن ينمو تباين المتبقيات للنموذج الأمثل مع القيمة المتوقعة لـ <code class="docutils literal notranslate"><span class="pre">E[y|X]</span></code> (إما خطيًا لبواسون أو تربيعيًا لجاما).</p>
<p>عند ملاءمة نموذج انحدار المربعات الصغرى الخطية (انظر <a class="reference internal" href="generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression" title="sklearn.linear_model.LinearRegression"><code class="xref py py-class docutils literal notranslate"><span class="pre">LinearRegression</span></code></a> و <a class="reference internal" href="generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge" title="sklearn.linear_model.Ridge"><code class="xref py py-class docutils literal notranslate"><span class="pre">Ridge</span></code></a>)، يمكننا استخدام هذا الرسم التخطيطي للتحقق مما إذا كانت بعض <a class="reference external" href="https://en.wikipedia.org/wiki/Ordinary_least_squares#Assumptions">افتراضات النموذج</a> مُستوفاة، على وجه الخصوص أن المتبقيات يجب ألا تكون مُرتبطة، ويجب أن تكون قيمتها المتوقعة خالية، وأن يكون تباينها ثابتًا (تجانس التباين).</p>
<p>إذا لم يكن الأمر كذلك، وعلى وجه الخصوص إذا أظهر مخطط المتبقيات بعض البنية على شكل موزة، فهذا تلميح إلى أن النموذج من المحتمل أن يكون مُحدّدًا بشكل خاطئ وأن هندسة الميزات غير الخطية أو التبديل إلى نموذج انحدار غير خطي قد يكون مفيدًا.</p>
<p>ارجع إلى المثال أدناه للاطلاع على تقييم النموذج الذي يستخدم هذا العرض.</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p>انظر <a class="reference internal" href="../auto_examples/compose/plot_transformed_target.html#sphx-glr-auto-examples-compose-plot-transformed-target-py"><span class="std std-ref">Effect of transforming the targets in regression model</span></a> للحصول على مثال حول كيفية استخدام <a class="reference internal" href="generated/sklearn.metrics.PredictionErrorDisplay.html#sklearn.metrics.PredictionErrorDisplay" title="sklearn.metrics.PredictionErrorDisplay"><code class="xref py py-class docutils literal notranslate"><span class="pre">PredictionErrorDisplay</span></code></a> لتصور تحسين جودة التنبؤ لنموذج الانحدار الذي تم الحصول عليه عن طريق تحويل الهدف قبل التعلم.</p></li>
</ul>
</section>
</section>
<section id="clustering-metrics">
<span id="id108"></span><h2><span class="section-number">3.4.5. </span>مقاييس التجميع<a class="headerlink" href="#clustering-metrics" title="Link to this heading">#</a></h2>
<p>تُطبق الوحدة <a class="reference internal" href="../api/sklearn.metrics.html#module-sklearn.metrics" title="sklearn.metrics"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></a> العديد من وظائف الخسارة والتهديف والأداة المساعدة. لمزيد من المعلومات، انظر قسم <a class="reference internal" href="clustering.html#clustering-evaluation"><span class="std std-ref">تقييم أداء التجميع</span></a> على سبيل المثال التجميع، و <a class="reference internal" href="biclustering.html#biclustering-evaluation"><span class="std std-ref">تقييم التجميع الثنائي</span></a> للتجميع الثنائي.</p>
</section>
<section id="dummy-estimators">
<span id="id109"></span><h2><span class="section-number">3.4.6. </span>مقدرات وهمية<a class="headerlink" href="#dummy-estimators" title="Link to this heading">#</a></h2>
<p>عند القيام بالتعلم الخاضع للإشراف، يتكون فحص السلامة البسيط من مقارنة المُقدر بقواعد عامة بسيطة. تُطبق <a class="reference internal" href="generated/sklearn.dummy.DummyClassifier.html#sklearn.dummy.DummyClassifier" title="sklearn.dummy.DummyClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">DummyClassifier</span></code></a> العديد من هذه الاستراتيجيات البسيطة للتصنيف:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">stratified</span></code> يُولّد تنبؤات عشوائية من خلال احترام توزيع فئة مجموعة التدريب.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">most_frequent</span></code> يتنبأ دائمًا بالتسمية الأكثر شيوعًا في مجموعة التدريب.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">prior</span></code> يتنبأ دائمًا بالفئة التي تُعظّم التوزيع المسبق للفئة (مثل <code class="docutils literal notranslate"><span class="pre">most_frequent</span></code>) و <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> تُعيد التوزيع المسبق للفئة.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">uniform</span></code> يُولّد تنبؤات عشوائية بشكل منتظم.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">constant</span></code> يتنبأ دائمًا بتسمية ثابتة يُوفرها المستخدم. الدافع الرئيسي لهذه الطريقة هو F1-scoring، عندما تكون الفئة الإيجابية أقلية.</p></li>
</ul>
<p>لاحظ أنه مع كل هذه الاستراتيجيات، تتجاهل طريقة <code class="docutils literal notranslate"><span class="pre">predict</span></code> بيانات الإدخال تمامًا!</p>
<p>لتوضيح <a class="reference internal" href="generated/sklearn.dummy.DummyClassifier.html#sklearn.dummy.DummyClassifier" title="sklearn.dummy.DummyClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">DummyClassifier</span></code></a>، دعنا أولاً ننشئ مجموعة بيانات غير متوازنة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="p">[</span><span class="n">y</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>بعد ذلك، دعونا نقارن دقة <code class="docutils literal notranslate"><span class="pre">SVC</span></code> و <code class="docutils literal notranslate"><span class="pre">most_frequent</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.dummy</span> <span class="kn">import</span> <span class="n">DummyClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="go">0.63...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">DummyClassifier</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;most_frequent&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="go">DummyClassifier(random_state=0, strategy=&#39;most_frequent&#39;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="go">0.57...</span>
</pre></div>
</div>
<p>نرى أن <code class="docutils literal notranslate"><span class="pre">SVC</span></code> لا يُقدم أداءً أفضل بكثير من المُصنف الوهمي. الآن، دعونا نُغير النواة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="go">0.94...</span>
</pre></div>
</div>
<p>نرى أن الدقة قد ارتفعت إلى ما يقرب من 100٪. يُوصى بإستراتيجية التحقق المتبادل للحصول على تقدير أفضل للدقة، إذا لم تكن مُكلفة للغاية لوحدة المعالجة المركزية. لمزيد من المعلومات، انظر قسم <a class="reference internal" href="cross_validation.html#cross-validation"><span class="std std-ref">التحقق المتبادل: تقييم أداء المقدر</span></a>. علاوة على ذلك، إذا كنت تُريد التحسين على مساحة المعلمات، فمن المُوصى به بشدة استخدام منهجية مناسبة؛ انظر قسم <a class="reference internal" href="grid_search.html#grid-search"><span class="std std-ref">ضبط المعلمات الفائقة لمُقدِّر</span></a> للتفاصيل.</p>
<p>بشكل عام، عندما تكون دقة المُصنف قريبة جدًا من العشوائية، فمن المحتمل أن يكون هناك خطأ ما: الميزات ليست مفيدة، المعلمة الفائقة غير مضبوطة بشكل صحيح، المُصنف يُعاني من عدم توازن الفئات، إلخ...</p>
<p>تُطبق <a class="reference internal" href="generated/sklearn.dummy.DummyRegressor.html#sklearn.dummy.DummyRegressor" title="sklearn.dummy.DummyRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">DummyRegressor</span></code></a> أيضًا أربع قواعد عامة بسيطة للانحدار:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mean</span></code> يتنبأ دائمًا بمتوسط أهداف التدريب.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">median</span></code> يتنبأ دائمًا بوسيط أهداف التدريب.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">quantile</span></code> يتنبأ دائمًا بكمية مُحدّدة من قبل المستخدم من أهداف التدريب.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">constant</span></code> يتنبأ دائمًا بقيمة ثابتة يُوفرها المستخدم.</p></li>
</ul>
<p>في كل هذه الاستراتيجيات، تتجاهل طريقة <code class="docutils literal notranslate"><span class="pre">predict</span></code> بيانات الإدخال تمامًا.</p>
</section>
</section>


                </article>
              
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="prev-next-area">
    <a class="left-prev"
       href="classification_threshold.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">السابق</p>
        <p class="prev-next-title"><span class="section-number">3.3. </span>ضبط عتبة القرار لتنبؤ الفئة</p>
      </div>
    </a>
    <a class="right-next"
       href="learning_curve.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">التالي</p>
        <p class="prev-next-title"><span class="section-number">3.5. </span>منحنيات التحقق من الصحة: رسم الدرجات لتقييم النماذج</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>
                </footer>
              
              
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#scoring">3.4.1. معلمة <code class="docutils literal notranslate"><span class="pre">scoring</span></code>: تعريف قواعد تقييم النموذج</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">3.4.1.1. الحالات الشائعة: القيم المُعرّفة مسبقًا</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">3.4.1.2. تعريف إستراتيجية التهديف الخاصة بك من وظائف المقياس</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#diy-scoring">3.4.1.3. تنفيذ كائن التهديف الخاص بك</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multimetric-scoring">3.4.1.4. استخدام تقييم متعدد المقاييس</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-metrics">3.4.2. مقاييس التصنيف</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#average">3.4.2.1. من ثنائي إلى متعدد الفئات ومتعدد التسميات</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#accuracy-score">3.4.2.2. درجة الدقة</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#k">3.4.2.3. درجة دقة أعلى k</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#balanced-accuracy-score">3.4.2.4. درجة الدقة المتوازنة</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cohen-kappa">3.4.2.5. كابا كوهين</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#confusion-matrix">3.4.2.6. مصفوفة الارتباك</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-report">3.4.2.7. تقرير التصنيف</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hamming-loss">3.4.2.8. خسارة هامينغ</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#f">3.4.2.9. الدقة والاستدعاء ومقاييس F</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id40">3.4.2.9.1. التصنيف الثنائي</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id41">3.4.2.9.2. التصنيف متعدد الفئات ومتعدد التسميات</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#jaccard-similarity-score">3.4.2.10. درجة معامل تشابه جاكارد</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hinge-loss">3.4.2.11. خسارة المفصلة</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#log-loss">3.4.2.12. خسارة السجل</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#matthews-corrcoef">3.4.2.13. معامل ارتباط ماثيوز</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multilabel-confusion-matrix">3.4.2.14. مصفوفة الارتباك متعددة التسميات</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#roc">3.4.2.15. خاصية تشغيل المستقبل (ROC)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#roc-auc-binary">3.4.2.15.1. الحالة الثنائية</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#roc-auc-multiclass">3.4.2.15.2. حالة متعددة الفئات</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#roc-auc-multilabel">3.4.2.15.3. حالة متعددة التسميات</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#det">3.4.2.16. مقايضة خطأ الكشف (DET)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#zero-one-loss">3.4.2.17. خسارة الصفر-واحد</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#brier-score-loss">3.4.2.18. خسارة درجة بريير</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#class-likelihood-ratios">3.4.2.19. نسب احتمالية الفئة</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#d2">3.4.2.20. درجة D² للتصنيف</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multilabel-ranking-metrics">3.4.3. مقاييس ترتيب متعددة التسميات</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#coverage-error">3.4.3.1. خطأ التغطية</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#label-ranking-average-precision">3.4.3.2. متوسط دقة ترتيب التسميات</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#label-ranking-loss">3.4.3.3. خسارة الترتيب</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ndcg">3.4.3.4. مكسب تراكمي مُخصّم مُعياري</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regression-metrics">3.4.4. مقاييس الانحدار</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#r2">3.4.4.1. درجة R²، معامل التحديد</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mean-absolute-error">3.4.4.2. متوسط الخطأ المطلق</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mean-squared-error">3.4.4.3. متوسط الخطأ التربيعي</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mean-squared-log-error">3.4.4.4. متوسط الخطأ اللوغاريتمي التربيعي</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mean-absolute-percentage-error">3.4.4.5. متوسط نسبة الخطأ المطلق</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#median-absolute-error">3.4.4.6. متوسط الخطأ المطلق للوسيط</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#max-error">3.4.4.7. أقصى خطأ</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#explained-variance-score">3.4.4.8. درجة التباين المُفسّر</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mean-tweedie-deviance">3.4.4.9. متوسط انحرافات بواسون وغاما وتويد</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pinball-loss">3.4.4.10. خسارة الكرة والدبابيس</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#d2-score">3.4.4.11. درجة D²</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualization-regression-evaluation">3.4.4.12. التقييم المرئي لنماذج الانحدار</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering-metrics">3.4.5. مقاييس التجميع</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dummy-estimators">3.4.6. مقدرات وهمية</a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">

  <div class="tocsection sourcelink">
    <a href="../_sources/modules/model_evaluation.rst.txt">
      <i class="fa-solid fa-file-lines"></i> إظهار المصدر
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2007 - 2024, scikit-learn developers (BSD License) ### Translate into Arabic Eng. Ahmed Almaghz - 2024.
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
</div>

  </footer>
  </body>
</html>