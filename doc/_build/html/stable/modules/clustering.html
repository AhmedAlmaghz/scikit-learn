
<!DOCTYPE html>


<html lang="ar" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="2.3. التجميع" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://scikit-learn/stable/modules/clustering.html" />
<meta property="og:site_name" content="scikit-learn" />
<meta property="og:description" content="يمكن إجراء التجميع لـ البيانات غير المُصنّفة مع الوحدة sklearn.cluster. تأتي كل خوارزمية تجميع في نوعين مختلفين: فئة، تنفذ طريقة fit لتعلم المجموعات على بيانات التدريب، ودالة، تُرجع، بالنظر إلى بيا..." />
<meta property="og:image" content="https://scikit-learn/stable/_images/sphx_glr_plot_cluster_comparison_001.png" />
<meta property="og:image:alt" content="scikit-learn" />
<meta name="description" content="يمكن إجراء التجميع لـ البيانات غير المُصنّفة مع الوحدة sklearn.cluster. تأتي كل خوارزمية تجميع في نوعين مختلفين: فئة، تنفذ طريقة fit لتعلم المجموعات على بيانات التدريب، ودالة، تُرجع، بالنظر إلى بيا..." />

    <title>2.3. التجميع &#8212; scikit-learn 1.6.dev0 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css?v=7f9a90b1" />
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Vibur" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyterlite_sphinx.css?v=ca70e7f1" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/colors.css?v=cc94ab7d" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/custom.css?v=85b0813d" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="../_static/documentation_options.js?v=3cd28d06"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=97f0b27d"></script>
    <script src="../_static/jupyterlite_sphinx.js?v=d6bdf5f8"></script>
    <script src="../_static/translations.js?v=87cb2081"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script data-domain="scikit-learn.org" defer="defer" src="https://views.scientific-python.org/js/script.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'modules/clustering';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.0';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://scikit-learn.org/dev/_static/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '1.6.dev0';
        DOCUMENTATION_OPTIONS.show_version_warning_banner = true;
        </script>
    <script src="../_static/scripts/dropdown.js?v=e2048168"></script>
    <script src="../_static/scripts/version-switcher.js?v=a6dd8357"></script>
    <link rel="icon" href="../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="search" title="بحث" href="../search.html" />
    <link rel="next" title="2.4. التجميع الثنائي" href="biclustering.html" />
    <link rel="prev" title="2.2. تعلم المشعبات" href="manifold.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="ar"/>
  <meta name="docsearch:version" content="1.6" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/scikit-learn-logo-small.png" class="logo__image only-light" alt="scikit-learn homepage"/>
    <img src="../_static/scikit-learn-logo-small.png" class="logo__image only-dark pst-js-only" alt="scikit-learn homepage"/>
  
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../install.html">
    Install
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../user_guide.html">
    دليل المستخدم
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api/index.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../auto_examples/index.html">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://blog.scikit-learn.org/">
    Community
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../getting_started.html">
    البدء
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../whats_new.html">
    Release History
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../glossary.html">
    Glossary
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../developers/index.html">
    Development
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../faq.html">
    FAQ
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../support.html">
    الدعم الفني
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../related_projects.html">
    مشاريع ذات علاقة
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../roadmap.html">
    Roadmap
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../governance.html">
    Governance
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../about.html">
    من نحن
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="بحث" aria-label="بحث" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/scikit-learn/scikit-learn" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
      
        <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="بحث" aria-label="بحث" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../install.html">
    Install
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../user_guide.html">
    دليل المستخدم
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api/index.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../auto_examples/index.html">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://blog.scikit-learn.org/">
    Community
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../getting_started.html">
    البدء
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../whats_new.html">
    Release History
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../glossary.html">
    Glossary
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../developers/index.html">
    Development
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../faq.html">
    FAQ
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../support.html">
    الدعم الفني
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../related_projects.html">
    مشاريع ذات علاقة
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../roadmap.html">
    Roadmap
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../governance.html">
    Governance
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../about.html">
    من نحن
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/scikit-learn/scikit-learn" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
        
          <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../supervised_learning.html">1. التعليم الخاضع للإشراف</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="linear_model.html">1.1. النماذج الخطية</a></li>
<li class="toctree-l2"><a class="reference internal" href="lda_qda.html">1.2. تحليل التمييز الخطي والتربيعي</a></li>
<li class="toctree-l2"><a class="reference internal" href="kernel_ridge.html">1.3. انحدار حافة النواة</a></li>
<li class="toctree-l2"><a class="reference internal" href="svm.html">1.4. آلات الدعم المتجهية (SVM)</a></li>
<li class="toctree-l2"><a class="reference internal" href="sgd.html">1.5. التحسين التدريجي العشوائي</a></li>
<li class="toctree-l2"><a class="reference internal" href="neighbors.html">1.6. أقرب الجيران</a></li>
<li class="toctree-l2"><a class="reference internal" href="gaussian_process.html">1.7. العمليات الغاوسية</a></li>
<li class="toctree-l2"><a class="reference internal" href="cross_decomposition.html">1.8. التحليل المتقاطع</a></li>
<li class="toctree-l2"><a class="reference internal" href="naive_bayes.html">1.9. خوارزميات بايز الساذجة</a></li>
<li class="toctree-l2"><a class="reference internal" href="tree.html">1.10. شجرة القرار</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble.html">1.11. المجموعات: تعزيز التدرج، الغابات العشوائية، التجميع، التصويت، التكديس</a></li>
<li class="toctree-l2"><a class="reference internal" href="multiclass.html">1.12. خوارزميات متعددة التصنيف ومتعددة الإخراج</a></li>
<li class="toctree-l2"><a class="reference internal" href="feature_selection.html">1.13. اختيار الميزات</a></li>
<li class="toctree-l2"><a class="reference internal" href="semi_supervised.html">1.14. التعليم شبه الخاضع للإشراف</a></li>
<li class="toctree-l2"><a class="reference internal" href="isotonic.html">1.15. الانحدار المتساوي التوتر</a></li>
<li class="toctree-l2"><a class="reference internal" href="calibration.html">1.16. معايرة الاحتمال</a></li>
<li class="toctree-l2"><a class="reference internal" href="neural_networks_supervised.html">1.17. نماذج الشبكات العصبية (الخاضعة للإشراف)</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../unsupervised_learning.html">2. التعليم الغير خاضع للإشراف</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="mixture.html">2.1. نماذج خليط غاوسي</a></li>
<li class="toctree-l2"><a class="reference internal" href="manifold.html">2.2. تعلم المشعبات</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">2.3. التجميع</a></li>
<li class="toctree-l2"><a class="reference internal" href="biclustering.html">2.4. التجميع الثنائي</a></li>
<li class="toctree-l2"><a class="reference internal" href="decomposition.html">2.5. تحليل الإشارات إلى مكونات (مشاكل تحليل المصفوفات)</a></li>
<li class="toctree-l2"><a class="reference internal" href="covariance.html">2.6. تقدير التباين المشترك</a></li>
<li class="toctree-l2"><a class="reference internal" href="outlier_detection.html">2.7. كشف القيم الغريبة والقيم المتطرفة</a></li>
<li class="toctree-l2"><a class="reference internal" href="density.html">2.8. تقدير الكثافة</a></li>
<li class="toctree-l2"><a class="reference internal" href="neural_networks_unsupervised.html">2.9. نماذج الشبكة العصبية (غير خاضعة للإشراف)</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../model_selection.html">3. تقييم وإختيار النموذج</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="cross_validation.html">3.1. التحقق المتبادل: تقييم أداء المقدر</a></li>
<li class="toctree-l2"><a class="reference internal" href="grid_search.html">3.2. ضبط المعلمات الفائقة لمُقدِّر</a></li>
<li class="toctree-l2"><a class="reference internal" href="classification_threshold.html">3.3. ضبط عتبة القرار لتنبؤ الفئة</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_evaluation.html">3.4. المقاييس والتهديف: تحديد جودة التنبؤات</a></li>
<li class="toctree-l2"><a class="reference internal" href="learning_curve.html">3.5. منحنيات التحقق من الصحة: رسم الدرجات لتقييم النماذج</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../inspection.html">4. الفحص</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="partial_dependence.html">4.1. مخططات الاعتماد الجزئي والتوقع الشرطي الفردي</a></li>
<li class="toctree-l2"><a class="reference internal" href="permutation_importance.html">4.2. أهمية التبديل</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../visualizations.html">5. التصورات المرئية</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../data_transforms.html">6. تحويلات مجموعات البيانات</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="compose.html">6.1. خطوط الأنابيب والمقدرات المركبة</a></li>
<li class="toctree-l2"><a class="reference internal" href="feature_extraction.html">6.2. استخراج الميزات</a></li>
<li class="toctree-l2"><a class="reference internal" href="preprocessing.html">6.3. المعالجة المسبقة للبيانات</a></li>
<li class="toctree-l2"><a class="reference internal" href="impute.html">6.4. تعويض القيم المفقودة</a></li>
<li class="toctree-l2"><a class="reference internal" href="unsupervised_reduction.html">6.5. تخفيض الأبعاد غير الخاضع للإشراف</a></li>
<li class="toctree-l2"><a class="reference internal" href="random_projection.html">6.6. الإسقاط العشوائي</a></li>
<li class="toctree-l2"><a class="reference internal" href="kernel_approximation.html">6.7. Kernel Approximation</a></li>
<li class="toctree-l2"><a class="reference internal" href="metrics.html">6.8. مقاييس المقارنة الزوجية، والصلات، والنوى (Kernels)</a></li>
<li class="toctree-l2"><a class="reference internal" href="preprocessing_targets.html">6.9. تحويل هدف التنبؤ (<code class="docutils literal notranslate"><span class="pre">y</span></code>)</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets/toy_dataset.html">7. مجموعات البيانات التجريبية</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets/real_world.html">8. مجموعات بيانات العالم الحقيقي</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets/sample_generators.html">9. مجموعات البيانات المُولَّدة</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets/loading_other_datasets.html">10. تحميل مجموعات بيانات أخرى</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../computing.html">11. الحوسبة مع scikit-learn</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../computing/scaling_strategies.html">11.1. استراتيجيات للقياس حسابيًا: بيانات أكبر</a></li>
<li class="toctree-l2"><a class="reference internal" href="../computing/computational_performance.html">11.2. الأداء الحسابي</a></li>
<li class="toctree-l2"><a class="reference internal" href="../computing/parallelism.html">11.3. التوازي وإدارة الموارد والتهيئة</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../model_persistence.html">12. حفظ النموذج</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common_pitfalls.html">13. المزالق الشائعة والممارسات الموصى بها</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../dispatching.html">14. Dispatching</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="array_api.html">14.1. دعم المدخلات المتوافقة مع <code class="docutils literal notranslate"><span class="pre">Array</span> <span class="pre">API</span></code></a></li>

</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../machine_learning_map.html">15. اختيار المقدر المناسب</a></li>
<li class="toctree-l1"><a class="reference internal" href="../presentations.html">16. المصادر الخارجية ومقاطع الفيديو والمحادثات</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../user_guide.html" class="nav-link">دليل المستخدم</a></li>
    
    
    <li class="breadcrumb-item"><a href="../unsupervised_learning.html" class="nav-link"><span class="section-number">2. </span>التعليم الغير خاضع للإشراف</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis"><span class="section-number">2.3. </span>التجميع</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="clustering">
<span id="id1"></span><h1><span class="section-number">2.3. </span>التجميع<a class="headerlink" href="#clustering" title="Link to this heading">#</a></h1>
<p>يمكن إجراء <a class="reference external" href="https://en.wikipedia.org/wiki/Cluster_analysis">التجميع</a> لـ
البيانات غير المُصنّفة مع الوحدة <a class="reference internal" href="../api/sklearn.cluster.html#module-sklearn.cluster" title="sklearn.cluster"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.cluster</span></code></a>.</p>
<p>تأتي كل خوارزمية تجميع في نوعين مختلفين: فئة، تنفذ طريقة <code class="docutils literal notranslate"><span class="pre">fit</span></code> لتعلم المجموعات على بيانات التدريب، ودالة، تُرجع، بالنظر إلى بيانات التدريب، مصفوفة من تسميات الأعداد الصحيحة المقابلة للمجموعات المختلفة.
بالنسبة للفئة، يمكن العثور على التسميات على بيانات التدريب في سمة <code class="docutils literal notranslate"><span class="pre">labels_</span></code>.</p>
<aside class="topic">
<p class="topic-title">بيانات الإدخال</p>
<p>أحد الأشياء المهمة التي يجب ملاحظتها هو أن الخوارزميات المطبقة في هذه الوحدة يمكن أن تأخذ أنواعًا مختلفة من المصفوفات كمدخلات.
تقبل جميع الطرق مصفوفات البيانات القياسية ذات الشكل <code class="docutils literal notranslate"><span class="pre">(n_samples,</span> <span class="pre">n_features)</span></code>.
يمكن الحصول على هذه من الفئات في الوحدة <a class="reference internal" href="../api/sklearn.feature_extraction.html#module-sklearn.feature_extraction" title="sklearn.feature_extraction"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.feature_extraction</span></code></a>.
بالنسبة لـ <a class="reference internal" href="generated/sklearn.cluster.AffinityPropagation.html#sklearn.cluster.AffinityPropagation" title="sklearn.cluster.AffinityPropagation"><code class="xref py py-class docutils literal notranslate"><span class="pre">AffinityPropagation</span></code></a> و <a class="reference internal" href="generated/sklearn.cluster.SpectralClustering.html#sklearn.cluster.SpectralClustering" title="sklearn.cluster.SpectralClustering"><code class="xref py py-class docutils literal notranslate"><span class="pre">SpectralClustering</span></code></a> و <a class="reference internal" href="generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN" title="sklearn.cluster.DBSCAN"><code class="xref py py-class docutils literal notranslate"><span class="pre">DBSCAN</span></code></a>، يمكن للمرء أيضًا إدخال مصفوفات التشابه ذات الشكل <code class="docutils literal notranslate"><span class="pre">(n_samples,</span> <span class="pre">n_samples)</span></code>.
يمكن الحصول على هذه من الدوال في الوحدة <a class="reference internal" href="../api/sklearn.metrics.html#module-sklearn.metrics.pairwise" title="sklearn.metrics.pairwise"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics.pairwise</span></code></a>.</p>
</aside>
<section id="id2">
<h2><span class="section-number">2.3.1. </span>نظرة عامة على طرق التجميع<a class="headerlink" href="#id2" title="Link to this heading">#</a></h2>
<figure class="align-center" id="id41">
<a class="reference external image-reference" href="../auto_examples/cluster/plot_cluster_comparison.html"><img alt="../_images/sphx_glr_plot_cluster_comparison_001.png" src="../_images/sphx_glr_plot_cluster_comparison_001.png" style="width: 1050.0px; height: 650.0px;" />
</a>
<figcaption>
<p><span class="caption-text">مقارنة خوارزميات التجميع في scikit-learn</span><a class="headerlink" href="#id41" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="pst-scrollable-table-container"><table class="table">
<colgroup>
<col style="width: 15.1%" />
<col style="width: 16.1%" />
<col style="width: 20.4%" />
<col style="width: 26.9%" />
<col style="width: 21.5%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>اسم الطريقة</p></th>
<th class="head"><p>المعلمات</p></th>
<th class="head"><p>قابلية التوسع</p></th>
<th class="head"><p>حالة الاستخدام</p></th>
<th class="head"><p>الهندسة (المقياس المستخدم)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference internal" href="#k-means"><span class="std std-ref">K-Means</span></a></p></td>
<td><p>عدد المجموعات</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">n_samples</span></code> كبير جدًا، <code class="docutils literal notranslate"><span class="pre">n_clusters</span></code> متوسط مع
<a class="reference internal" href="#mini-batch-kmeans"><span class="std std-ref">كود MiniBatch</span></a></p></td>
<td><p>للأغراض العامة، حتى حجم الكتلة، هندسة مسطحة،
ليس عددًا كبيرًا جدًا من المجموعات، استقرائي</p></td>
<td><p>المسافات بين النقاط</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#affinity-propagation"><span class="std std-ref">انتشار التقارب</span></a></p></td>
<td><p>التخميد، تفضيل العينة</p></td>
<td><p>غير قابل للتطوير مع n_samples</p></td>
<td><p>العديد من المجموعات، حجم الكتلة غير المتكافئ، الهندسة غير المسطحة، استقرائي</p></td>
<td><p>مسافة الرسم البياني (على سبيل المثال، رسم بياني لأقرب جار)</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mean-shift"><span class="std std-ref">Mean-shift</span></a></p></td>
<td><p>عرض النطاق الترددي</p></td>
<td><p>غير قابل للتطوير مع <code class="docutils literal notranslate"><span class="pre">n_samples</span></code></p></td>
<td><p>العديد من المجموعات، حجم الكتلة غير المتكافئ، الهندسة غير المسطحة، استقرائي</p></td>
<td><p>المسافات بين النقاط</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#spectral-clustering"><span class="std std-ref">التجميع الطيفي</span></a></p></td>
<td><p>عدد المجموعات</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">n_samples</span></code> متوسط، <code class="docutils literal notranslate"><span class="pre">n_clusters</span></code> صغير</p></td>
<td><p>عدد قليل من المجموعات، حتى حجم الكتلة، هندسة غير مسطحة، استنتاجي</p></td>
<td><p>مسافة الرسم البياني (على سبيل المثال، رسم بياني لأقرب جار)</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hierarchical-clustering"><span class="std std-ref">تجميع Ward الهرمي</span></a></p></td>
<td><p>عدد المجموعات أو عتبة المسافة</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">n_samples</span></code> و <code class="docutils literal notranslate"><span class="pre">n_clusters</span></code> كبير</p></td>
<td><p>العديد من المجموعات، وربما قيود الاتصال، استنتاجي</p></td>
<td><p>المسافات بين النقاط</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hierarchical-clustering"><span class="std std-ref">التجميع التكتلي</span></a></p></td>
<td><p>عدد المجموعات أو عتبة المسافة، نوع الارتباط، المسافة</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">n_samples</span></code> و <code class="docutils literal notranslate"><span class="pre">n_clusters</span></code> كبير</p></td>
<td><p>العديد من المجموعات، وربما قيود الاتصال، غير الإقليدية
المسافات، استنتاجي</p></td>
<td><p>أي مسافة زوجية</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dbscan"><span class="std std-ref">DBSCAN</span></a></p></td>
<td><p>حجم الحي</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">n_samples</span></code> كبير جدًا، <code class="docutils literal notranslate"><span class="pre">n_clusters</span></code> متوسط</p></td>
<td><p>هندسة غير مسطحة، أحجام مجموعات غير متساوية، إزالة القيم المتطرفة،
استنتاجي</p></td>
<td><p>المسافات بين أقرب النقاط</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hdbscan"><span class="std std-ref">HDBSCAN</span></a></p></td>
<td><p>الحد الأدنى لعضوية الكتلة، الحد الأدنى لجيران النقطة</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">n_samples</span></code> كبير، <code class="docutils literal notranslate"><span class="pre">n_clusters</span></code> متوسط</p></td>
<td><p>هندسة غير مسطحة، أحجام مجموعات غير متساوية، إزالة القيم المتطرفة،
استنتاجي، هرمي، كثافة كتلة متغيرة</p></td>
<td><p>المسافات بين أقرب النقاط</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#optics"><span class="std std-ref">OPTICS</span></a></p></td>
<td><p>الحد الأدنى لعضوية الكتلة</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">n_samples</span></code> كبير جدًا، <code class="docutils literal notranslate"><span class="pre">n_clusters</span></code> كبير</p></td>
<td><p>هندسة غير مسطحة، أحجام مجموعات غير متساوية، كثافة كتلة متغيرة،
إزالة القيم المتطرفة، استنتاجي</p></td>
<td><p>المسافات بين النقاط</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="mixture.html#mixture"><span class="std std-ref">خلائط غاوسية</span></a></p></td>
<td><p>كثير</p></td>
<td><p>غير قابل للتطوير</p></td>
<td><p>هندسة مسطحة، جيدة لتقدير الكثافة، استقرائي</p></td>
<td><p>مسافات Mahalanobis إلى المراكز</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#birch"><span class="std std-ref">BIRCH</span></a></p></td>
<td><p>عامل التفرع، العتبة، التجميع العالمي الاختياري.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">n_clusters</span></code> و <code class="docutils literal notranslate"><span class="pre">n_samples</span></code> كبير</p></td>
<td><p>مجموعة بيانات كبيرة، إزالة القيم المتطرفة، تقليل البيانات، استقرائي</p></td>
<td><p>المسافة الإقليدية بين النقاط</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bisect-k-means"><span class="std std-ref">Bisecting K-Means</span></a></p></td>
<td><p>عدد المجموعات</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">n_samples</span></code> كبير جدًا، <code class="docutils literal notranslate"><span class="pre">n_clusters</span></code> متوسط</p></td>
<td><p>للأغراض العامة، حتى حجم الكتلة، هندسة مسطحة،
لا توجد مجموعات فارغة، استقرائي، هرمي</p></td>
<td><p>المسافات بين النقاط</p></td>
</tr>
</tbody>
</table>
</div>
<p>يكون تجميع الهندسة غير المسطحة مفيدًا عندما يكون للمجموعات شكل محدد، أي مشعب غير مسطح، والمسافة الإقليدية القياسية ليست هي المقياس الصحيح.
تنشأ هذه الحالة في الصفين العلويين من الشكل أعلاه.</p>
<p>يتم وصف نماذج خليط غاوسية، المفيدة للتجميع، في <a class="reference internal" href="mixture.html#mixture"><span class="std std-ref">فصل آخر من الوثائق</span></a> مخصص لنماذج الخليط.
يمكن اعتبار KMeans حالة خاصة من نموذج خليط غاوسي مع التباين المتساوي لكل مكون.</p>
<p>طرق التجميع <span class="xref std std-term">Transductive</span> (على عكس طرق التجميع <span class="xref std std-term">inductive</span>) ليست مصممة لتطبيقها على بيانات جديدة غير مرئية.</p>
</section>
<section id="k-means">
<span id="id3"></span><h2><span class="section-number">2.3.2. </span>K-means<a class="headerlink" href="#k-means" title="Link to this heading">#</a></h2>
<p>تقوم خوارزمية <a class="reference internal" href="generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans" title="sklearn.cluster.KMeans"><code class="xref py py-class docutils literal notranslate"><span class="pre">KMeans</span></code></a> بتجميع البيانات من خلال محاولة فصل العينات في n مجموعات ذات تباين متساوٍ، مما يقلل من معيار يُعرف باسم <em>القصور الذاتي</em> أو مجموع المربعات داخل الكتلة (انظر أدناه).
تتطلب هذه الخوارزمية تحديد عدد المجموعات.
إنه قابل للتطوير بشكل جيد لعدد كبير من العينات وقد تم استخدامه عبر مجموعة كبيرة من مجالات التطبيق في العديد من المجالات المختلفة.</p>
<p>تقسم خوارزمية k-means مجموعة من <span class="math notranslate nohighlight">\(N\)</span> عينات <span class="math notranslate nohighlight">\(X\)</span> إلى <span class="math notranslate nohighlight">\(K\)</span> مجموعات منفصلة <span class="math notranslate nohighlight">\(C\)</span>، يتم وصف كل منها بالمتوسط <span class="math notranslate nohighlight">\(\mu_j\)</span> للعينات في المجموعة.
يُطلق على الوسائل عادةً &quot;مراكز&quot; الكتلة؛ لاحظ أنها ليست، بشكل عام، نقاطًا من <span class="math notranslate nohighlight">\(X\)</span>، على الرغم من أنها تعيش في نفس المساحة.</p>
<p>تهدف خوارزمية K-means إلى اختيار مراكز تقلل من <strong>القصور الذاتي</strong>، أو <strong>معيار مجموع المربعات داخل الكتلة</strong>:</p>
<div class="math notranslate nohighlight">
\[\sum_{i=0}^{n}\min_{\mu_j \in C}(||x_i - \mu_j||^2)\]</div>
<p>يمكن التعرف على القصور الذاتي كمقياس لمدى تماسك المجموعات داخليًا.
إنه يعاني من عيوب مختلفة:</p>
<ul class="simple">
<li><p>يفترض القصور الذاتي أن المجموعات محدبة ومتجانسة الخواص، وهو ليس الحال دائمًا. يستجيب بشكل سيئ للمجموعات الممدودة، أو المشعبات ذات الأشكال غير المنتظمة.</p></li>
<li><p>القصور الذاتي ليس مقياسًا طبيعيًا: نحن نعلم فقط أن القيم المنخفضة أفضل وأن الصفر هو الأمثل.
ولكن في المساحات عالية الأبعاد للغاية، تميل المسافات الإقليدية إلى أن تصبح متضخمة (هذه حالة لما يسمى &quot;لعنة الأبعاد&quot;).
يمكن أن يؤدي تشغيل خوارزمية تقليل الأبعاد مثل <a class="reference internal" href="decomposition.html#pca"><span class="std std-ref">تحليل المكونات الرئيسية (PCA)</span></a> قبل تجميع k-means إلى تخفيف هذه المشكلة وتسريع العمليات الحسابية.</p></li>
</ul>
<a class="reference external image-reference" href="../auto_examples/cluster/plot_kmeans_assumptions.html"><img alt="../_images/sphx_glr_plot_kmeans_assumptions_002.png" class="align-center" src="../_images/sphx_glr_plot_kmeans_assumptions_002.png" style="width: 600.0px; height: 600.0px;" />
</a>
<p>للحصول على أوصاف أكثر تفصيلاً للمشكلات الموضحة أعلاه وكيفية معالجتها، ارجع إلى الأمثلة <span class="xref std std-ref">sphx_glr_auto_examples_cluster/plot_kmeans_assumptions.py</span> و <span class="xref std std-ref">sphx_glr_auto_examples_cluster/plot_kmeans_silhouette_analysis.py</span>.</p>
<p>غالبًا ما يشار إلى K-means باسم خوارزمية لويد. بعبارات أساسية، تتكون الخوارزمية من ثلاث خطوات.
تختار الخطوة الأولى المراكز الأولية، مع كون الطريقة الأساسية هي اختيار <span class="math notranslate nohighlight">\(k\)</span> عينات من مجموعة البيانات <span class="math notranslate nohighlight">\(X\)</span>.
بعد التهيئة، يتكون K-means من التكرار بين الخطوتين الأخريين. تقوم الخطوة الأولى بتعيين كل عينة إلى أقرب مركز لها.
تقوم الخطوة الثانية بإنشاء مراكز جديدة عن طريق أخذ القيمة المتوسطة لجميع العينات المعينة لكل مركز سابق.
يتم حساب الفرق بين المراكز القديمة والجديدة وتكرر الخوارزمية هاتين الخطوتين الأخيرتين حتى تصبح هذه القيمة أقل من عتبة.
بمعنى آخر، يتكرر حتى لا تتحرك المراكز بشكل ملحوظ.</p>
<a class="reference external image-reference" href="../auto_examples/cluster/plot_kmeans_digits.html"><img alt="../_images/sphx_glr_plot_kmeans_digits_001.png" class="align-right" src="../_images/sphx_glr_plot_kmeans_digits_001.png" style="width: 224.0px; height: 168.0px;" />
</a>
<p>K-means مكافئ لخوارزمية تعظيم التوقع مع مصفوفة تباين قطرية صغيرة ومتساوية.</p>
<p>يمكن أيضًا فهم الخوارزمية من خلال مفهوم <a class="reference external" href="https://en.wikipedia.org/wiki/Voronoi_diagram">مخططات فورونوي</a>.
أولاً، يتم حساب مخطط فورونوي للنقاط باستخدام المراكز الحالية.
يصبح كل جزء في مخطط فورونوي مجموعة منفصلة.
ثانيًا، يتم تحديث المراكز إلى متوسط كل جزء.
ثم تكرر الخوارزمية هذا حتى يتم استيفاء معيار التوقف.
عادةً، تتوقف الخوارزمية عندما يكون الانخفاض النسبي في دالة الهدف بين التكرارات أقل من قيمة التسامح المعطاة.
هذا ليس هو الحال في هذا التنفيذ: يتوقف التكرار عندما تتحرك المراكز أقل من التسامح.</p>
<p>مع إعطاء الوقت الكافي، سيتقارب K-means دائمًا، ومع ذلك قد يكون هذا إلى حد أدنى محلي.
هذا يعتمد بشكل كبير على تهيئة المراكز.
ونتيجة لذلك، غالبًا ما يتم إجراء الحساب عدة مرات، مع تهيئة مختلفة للمراكز.
إحدى الطرق للمساعدة في معالجة هذه المشكلة هي مخطط التهيئة k-means ++، والذي تم تنفيذه في scikit-learn (استخدم معلمة <code class="docutils literal notranslate"><span class="pre">init='k-means++'</span></code>).
يقوم هذا بتهيئة المراكز لتكون (بشكل عام) بعيدة عن بعضها البعض، مما يؤدي إلى نتائج أفضل على الأرجح من التهيئة العشوائية، كما هو موضح في المرجع.
للحصول على مثال مفصل لمقارنة مخططات التهيئة المختلفة، ارجع إلى
<span class="xref std std-ref">sphx_glr_auto_examples_cluster/plot_kmeans_digits.py</span>.</p>
<p>يمكن أيضًا استدعاء K-means ++ بشكل مستقل لتحديد البذور لخوارزميات التجميع الأخرى، انظر <a class="reference internal" href="generated/sklearn.cluster.kmeans_plusplus.html#sklearn.cluster.kmeans_plusplus" title="sklearn.cluster.kmeans_plusplus"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.cluster.kmeans_plusplus</span></code></a> للحصول على التفاصيل واستخدام المثال.</p>
<p>تدعم الخوارزمية أوزان العينة، والتي يمكن إعطاؤها بواسطة معلمة <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code>.
يسمح هذا بتعيين وزن أكبر لبعض العينات عند حساب مراكز الكتلة وقيم القصور الذاتي.
على سبيل المثال، فإن تعيين وزن 2 لعينة يعادل إضافة نسخة مكررة من تلك العينة إلى مجموعة البيانات <span class="math notranslate nohighlight">\(X\)</span>.</p>
<p>يمكن استخدام K-means لتقدير المتجه. يتم تحقيق ذلك باستخدام طريقة <code class="docutils literal notranslate"><span class="pre">transform</span></code> لنموذج مدرب من <a class="reference internal" href="generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans" title="sklearn.cluster.KMeans"><code class="xref py py-class docutils literal notranslate"><span class="pre">KMeans</span></code></a>.
للحصول على مثال على إجراء تقدير المتجه على صورة، ارجع إلى <span class="xref std std-ref">sphx_glr_auto_examples_cluster/plot_color_quantization.py</span>.</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><span class="xref std std-ref">sphx_glr_auto_examples_cluster/plot_cluster_iris.py</span>: مثال على استخدام
<a class="reference internal" href="generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans" title="sklearn.cluster.KMeans"><code class="xref py py-class docutils literal notranslate"><span class="pre">KMeans</span></code></a> باستخدام مجموعة بيانات iris</p></li>
<li><p><span class="xref std std-ref">sphx_glr_auto_examples_text/plot_document_clustering.py</span>: تجميع المستندات
باستخدام <a class="reference internal" href="generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans" title="sklearn.cluster.KMeans"><code class="xref py py-class docutils literal notranslate"><span class="pre">KMeans</span></code></a> و <a class="reference internal" href="generated/sklearn.cluster.MiniBatchKMeans.html#sklearn.cluster.MiniBatchKMeans" title="sklearn.cluster.MiniBatchKMeans"><code class="xref py py-class docutils literal notranslate"><span class="pre">MiniBatchKMeans</span></code></a> بناءً على البيانات المتفرقة</p></li>
</ul>
<section id="id5">
<h3><span class="section-number">2.3.2.1. </span>التوازي منخفض المستوى<a class="headerlink" href="#id5" title="Link to this heading">#</a></h3>
<p>يستفيد <a class="reference internal" href="generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans" title="sklearn.cluster.KMeans"><code class="xref py py-class docutils literal notranslate"><span class="pre">KMeans</span></code></a> من التوازي القائم على OpenMP من خلال Cython.
يتم معالجة أجزاء صغيرة من البيانات (256 عينة) بالتوازي، مما ينتج عنه أيضًا انخفاض في حجم الذاكرة.
لمزيد من التفاصيل حول كيفية التحكم في عدد سلاسل الرسائل، يرجى الرجوع إلى ملاحظات <a class="reference internal" href="../computing/parallelism.html#parallelism"><span class="std std-ref">التوازي</span></a>.</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><span class="xref std std-ref">sphx_glr_auto_examples_cluster/plot_kmeans_assumptions.py</span>: إظهار متى يؤدي k-means بشكل حدسي ومتى لا يؤدي</p></li>
<li><p><span class="xref std std-ref">sphx_glr_auto_examples_cluster/plot_kmeans_digits.py</span>: تجميع الأرقام المكتوبة بخط اليد</p></li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text"><a class="reference external" href="http://ilpubs.stanford.edu:8090/778/1/2006-13.pdf">&quot;k-means++: The advantages of careful seeding&quot;</a>
Arthur، David، و Sergei Vassilvitskii،
<em>Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms</em>، Society for Industrial and Applied Mathematics (2007)</p></li>
</ul>
</div>
</details></section>
<section id="mini-batch-k-means">
<span id="mini-batch-kmeans"></span><h3><span class="section-number">2.3.2.2. </span>Mini Batch K-Means<a class="headerlink" href="#mini-batch-k-means" title="Link to this heading">#</a></h3>
<p><a class="reference internal" href="generated/sklearn.cluster.MiniBatchKMeans.html#sklearn.cluster.MiniBatchKMeans" title="sklearn.cluster.MiniBatchKMeans"><code class="xref py py-class docutils literal notranslate"><span class="pre">MiniBatchKMeans</span></code></a> هو نوع مختلف من خوارزمية <a class="reference internal" href="generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans" title="sklearn.cluster.KMeans"><code class="xref py py-class docutils literal notranslate"><span class="pre">KMeans</span></code></a> التي تستخدم مجموعات صغيرة لتقليل وقت الحساب، مع الاستمرار في محاولة تحسين نفس دالة الهدف.
المجموعات الصغيرة هي مجموعات فرعية من بيانات الإدخال، يتم أخذ عينات منها عشوائيًا في كل تكرار تدريب.
تقلل هذه المجموعات الصغيرة بشكل كبير من مقدار الحساب المطلوب للتقارب إلى حل محلي.
على عكس الخوارزميات الأخرى التي تقلل من وقت تقارب k-means، فإن k-means المصغرة تنتج نتائج أسوأ بشكل عام قليلاً من الخوارزمية القياسية.</p>
<p>تتكرر الخوارزمية بين خطوتين رئيسيتين، على غرار k-means الفانيليا.
في الخطوة الأولى، يتم رسم <span class="math notranslate nohighlight">\(b\)</span> عينات عشوائيًا من مجموعة البيانات، لتشكيل مجموعة صغيرة.
ثم يتم تعيينها إلى أقرب مركز.
في الخطوة الثانية، يتم تحديث المراكز.
على عكس k-means، يتم ذلك على أساس كل عينة.
لكل عينة في المجموعة المصغرة، يتم تحديث المركز المعين عن طريق أخذ المتوسط المتدفق للعينة وجميع العينات السابقة المعينة إلى هذا المركز.
هذا له تأثير تقليل معدل التغيير لمركز بمرور الوقت.
يتم تنفيذ هذه الخطوات حتى التقارب أو الوصول إلى عدد محدد مسبقًا من التكرارات.</p>
<p>يتقارب <a class="reference internal" href="generated/sklearn.cluster.MiniBatchKMeans.html#sklearn.cluster.MiniBatchKMeans" title="sklearn.cluster.MiniBatchKMeans"><code class="xref py py-class docutils literal notranslate"><span class="pre">MiniBatchKMeans</span></code></a> بشكل أسرع من <a class="reference internal" href="generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans" title="sklearn.cluster.KMeans"><code class="xref py py-class docutils literal notranslate"><span class="pre">KMeans</span></code></a>، ولكن يتم تقليل جودة النتائج.
من الناحية العملية، يمكن أن يكون هذا الاختلاف في الجودة صغيرًا جدًا، كما هو موضح في المثال والمرجع المذكور.</p>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/cluster/plot_mini_batch_kmeans.html"><img alt="../_images/sphx_glr_plot_mini_batch_kmeans_001.png" src="../_images/sphx_glr_plot_mini_batch_kmeans_001.png" style="width: 800.0px; height: 300.0px;" />
</a>
</figure>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><span class="xref std std-ref">sphx_glr_auto_examples_cluster/plot_mini_batch_kmeans.py</span>: مقارنة
<a class="reference internal" href="generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans" title="sklearn.cluster.KMeans"><code class="xref py py-class docutils literal notranslate"><span class="pre">KMeans</span></code></a> و <a class="reference internal" href="generated/sklearn.cluster.MiniBatchKMeans.html#sklearn.cluster.MiniBatchKMeans" title="sklearn.cluster.MiniBatchKMeans"><code class="xref py py-class docutils literal notranslate"><span class="pre">MiniBatchKMeans</span></code></a></p></li>
<li><p><span class="xref std std-ref">sphx_glr_auto_examples_text/plot_document_clustering.py</span>: تجميع المستندات
باستخدام <a class="reference internal" href="generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans" title="sklearn.cluster.KMeans"><code class="xref py py-class docutils literal notranslate"><span class="pre">KMeans</span></code></a> و <a class="reference internal" href="generated/sklearn.cluster.MiniBatchKMeans.html#sklearn.cluster.MiniBatchKMeans" title="sklearn.cluster.MiniBatchKMeans"><code class="xref py py-class docutils literal notranslate"><span class="pre">MiniBatchKMeans</span></code></a> بناءً على البيانات المتفرقة</p></li>
<li><p><span class="xref std std-ref">sphx_glr_auto_examples_cluster/plot_dict_face_patches.py</span></p></li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-2">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-2" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text"><a class="reference external" href="https://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf">&quot;Web Scale K-Means clustering&quot;</a>
D. Sculley، <em>Proceedings of the 19th international conference on World wide web</em> (2010)</p></li>
</ul>
</div>
</details></section>
</section>
<section id="affinity-propagation">
<span id="id6"></span><h2><span class="section-number">2.3.3. </span>انتشار التقارب<a class="headerlink" href="#affinity-propagation" title="Link to this heading">#</a></h2>
<p>ينشئ <a class="reference internal" href="generated/sklearn.cluster.AffinityPropagation.html#sklearn.cluster.AffinityPropagation" title="sklearn.cluster.AffinityPropagation"><code class="xref py py-class docutils literal notranslate"><span class="pre">AffinityPropagation</span></code></a> مجموعات عن طريق إرسال رسائل بين أزواج من العينات حتى التقارب.
ثم يتم وصف مجموعة البيانات باستخدام عدد صغير من النماذج، والتي يتم تحديدها على أنها الأكثر تمثيلاً لعينات أخرى.
تمثل الرسائل المرسلة بين الأزواج مدى ملاءمة عينة واحدة لتكون نموذجًا للأخرى، والتي يتم تحديثها استجابةً للقيم من الأزواج الأخرى.
يحدث هذا التحديث بشكل متكرر حتى التقارب، وعند هذه النقطة يتم اختيار النماذج النهائية، وبالتالي يتم إعطاء التجميع النهائي.</p>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/cluster/plot_affinity_propagation.html"><img alt="../_images/sphx_glr_plot_affinity_propagation_001.png" src="../_images/sphx_glr_plot_affinity_propagation_001.png" style="width: 320.0px; height: 240.0px;" />
</a>
</figure>
<p>يمكن أن يكون انتشار التقارب مثيرًا للاهتمام لأنه يختار عدد المجموعات بناءً على البيانات المقدمة.
لهذا الغرض، فإن المعلمتين المهمتين هما <em>التفضيل</em>، الذي يتحكم في عدد النماذج المستخدمة، و <em>عامل التخميد</em> الذي يخمد رسائل المسؤولية والتوافر لتجنب التذبذبات العددية عند تحديث هذه الرسائل.</p>
<p>العيب الرئيسي لانتشار التقارب هو تعقيده.
تبلغ تعقيد الخوارزمية الزمني من الرتبة <span class="math notranslate nohighlight">\(O(N^2 T)\)</span>، حيث <span class="math notranslate nohighlight">\(N\)</span> هو عدد العينات و <span class="math notranslate nohighlight">\(T\)</span> هو عدد التكرارات حتى التقارب.
علاوة على ذلك، فإن تعقيد الذاكرة هو من الرتبة <span class="math notranslate nohighlight">\(O(N^2)\)</span> إذا تم استخدام مصفوفة تشابه كثيفة، ولكن يمكن اختزالها إذا تم استخدام مصفوفة تشابه متفرقة. هذا يجعل انتشار التقارب هو الأنسب لمجموعات البيانات الصغيرة والمتوسطة الحجم.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="وصف-الخوارزمية">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">وصف الخوارزمية<a class="headerlink" href="#وصف-الخوارزمية" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">تنتمي الرسائل المرسلة بين النقاط إلى إحدى فئتين.
الأولى هي المسؤولية <span class="math notranslate nohighlight">\(r(i, k)\)</span>، وهي الدليل المتراكم على أن العينة <span class="math notranslate nohighlight">\(k\)</span> يجب أن تكون نموذجًا للعينة <span class="math notranslate nohighlight">\(i\)</span>.
الثاني هو التوافر <span class="math notranslate nohighlight">\(a(i, k)\)</span> وهو الدليل المتراكم على أن العينة <span class="math notranslate nohighlight">\(i\)</span> يجب أن تختار العينة <span class="math notranslate nohighlight">\(k\)</span> لتكون نموذجًا لها، وتأخذ في الاعتبار القيم لجميع العينات الأخرى التي يجب أن تكون <span class="math notranslate nohighlight">\(k\)</span> نموذجًا.
بهذه الطريقة، يتم اختيار النماذج بواسطة العينات إذا كانت (1) متشابهة بدرجة كافية مع العديد من العينات و (2) تم اختيارها من قبل العديد من العينات لتكون ممثلة لنفسها.</p>
<p class="sd-card-text">بشكل أكثر رسمية، تُعطى مسؤولية عينة <span class="math notranslate nohighlight">\(k\)</span> لتكون نموذجًا للعينة <span class="math notranslate nohighlight">\(i\)</span> من خلال:</p>
<div class="math notranslate nohighlight">
\[r(i, k) \leftarrow s(i, k) - max [ a(i, k') + s(i, k') \forall k' \neq k ]\]</div>
<p class="sd-card-text">حيث <span class="math notranslate nohighlight">\(s(i, k)\)</span> هو التشابه بين العينات <span class="math notranslate nohighlight">\(i\)</span> و <span class="math notranslate nohighlight">\(k\)</span>.
توافر العينة <span class="math notranslate nohighlight">\(k\)</span> ليكون نموذجًا للعينة <span class="math notranslate nohighlight">\(i\)</span> هو
معطى بواسطة:</p>
<div class="math notranslate nohighlight">
\[a(i, k) \leftarrow min [0, r(k, k) + \sum_{i'~s.t.~i' \notin \{i, k\}}{r(i',
k)}]\]</div>
<p class="sd-card-text">في البداية، يتم تعيين جميع القيم لـ <span class="math notranslate nohighlight">\(r\)</span> و <span class="math notranslate nohighlight">\(a\)</span> على صفر، ويتم حساب كل تكرار حتى التقارب.
كما نوقش أعلاه، من أجل تجنب التذبذبات العددية عند تحديث الرسائل، يتم إدخال عامل التخميد <span class="math notranslate nohighlight">\(\lambda\)</span> إلى عملية التكرار:</p>
<div class="math notranslate nohighlight">
\[r_{t+1}(i, k) = \lambda\cdot r_{t}(i, k) + (1-\lambda)\cdot r_{t+1}(i, k)\]</div>
<div class="math notranslate nohighlight">
\[a_{t+1}(i, k) = \lambda\cdot a_{t}(i, k) + (1-\lambda)\cdot a_{t+1}(i, k)\]</div>
<p class="sd-card-text">حيث <span class="math notranslate nohighlight">\(t\)</span> يشير إلى أوقات التكرار.</p>
</div>
</details><p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><span class="xref std std-ref">sphx_glr_auto_examples_cluster/plot_affinity_propagation.py</span>: انتشار التقارب على مجموعات بيانات ثنائية الأبعاد اصطناعية مع 3 فئات</p></li>
<li><p><span class="xref std std-ref">sphx_glr_auto_examples_applications/plot_stock_market.py</span> انتشار التقارب على السلاسل الزمنية المالية للعثور على مجموعات من الشركات</p></li>
</ul>
</section>
<section id="mean-shift">
<span id="id7"></span><h2><span class="section-number">2.3.4. </span>Mean Shift<a class="headerlink" href="#mean-shift" title="Link to this heading">#</a></h2>
<p>يهدف تجميع <a class="reference internal" href="generated/sklearn.cluster.MeanShift.html#sklearn.cluster.MeanShift" title="sklearn.cluster.MeanShift"><code class="xref py py-class docutils literal notranslate"><span class="pre">MeanShift</span></code></a> إلى اكتشاف <em>النقاط</em> في كثافة سلسة للعينات.
إنها خوارزمية تعتمد على النقطه المركزية، والتي تعمل عن طريق تحديث المرشحين للمراكز ليكونوا متوسط النقاط داخل منطقة معينة.
ثم يتم تصفية هؤلاء المرشحين في مرحلة ما بعد المعالجة للقضاء على التكرارات القريبة لتشكيل المجموعة النهائية من المراكز.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="التفاصيل-الرياضية">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">التفاصيل الرياضية<a class="headerlink" href="#التفاصيل-الرياضية" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">يتم تعديل موضع المرشحين للنقطه المركزية بشكل متكرر باستخدام تقنية تسمى تسلق التل، والتي تجد الحدود القصوى المحلية لكثافة الاحتمال المقدرة.
بالنظر إلى النقطه المركزية المرشحة <span class="math notranslate nohighlight">\(x\)</span> للتكرار <span class="math notranslate nohighlight">\(t\)</span>، يتم تحديث المرشح وفقًا للمعادلة التالية:</p>
<div class="math notranslate nohighlight">
\[x^{t+1} = x^t + m(x^t)\]</div>
<p class="sd-card-text">حيث <span class="math notranslate nohighlight">\(m\)</span> هو متجه <em>إزاحة المتوسط</em> الذي يتم حسابه لكل نقطة مركزية تشير نحو منطقة الزيادة القصوى في كثافة النقاط.
لحساب <span class="math notranslate nohighlight">\(m\)</span>، نحدد <span class="math notranslate nohighlight">\(N(x)\)</span> على أنها جوار العينات ضمن مسافة معينة حول <span class="math notranslate nohighlight">\(x\)</span>.
ثم يتم حساب <span class="math notranslate nohighlight">\(m\)</span> باستخدام المعادلة التالية، مما يؤدي إلى تحديث النقطه المركزية بشكل فعال لتكون متوسط العينات داخل جوارها:</p>
<div class="math notranslate nohighlight">
\[m(x) = \frac{1}{|N(x)|} \sum_{x_j \in N(x)}x_j - x\]</div>
<p class="sd-card-text">بشكل عام، تعتمد معادلة <span class="math notranslate nohighlight">\(m\)</span> على نواة تستخدم لتقدير الكثافة. الصيغة العامة هي:</p>
<div class="math notranslate nohighlight">
\[m(x) = \frac{\sum_{x_j \in N(x)}K(x_j - x)x_j}{\sum_{x_j \in N(x)}K(x_j -
x)} - x\]</div>
<p class="sd-card-text">في تطبيقنا، <span class="math notranslate nohighlight">\(K(x)\)</span> يساوي 1 إذا كان <span class="math notranslate nohighlight">\(x\)</span> صغيرًا بما يكفي ويساوي 0 بخلاف ذلك.
يشير <span class="math notranslate nohighlight">\(K(y - x)\)</span> بشكل فعال إلى ما إذا كان <span class="math notranslate nohighlight">\(y\)</span> في جوار <span class="math notranslate nohighlight">\(x\)</span>.</p>
</div>
</details><p>تحدد الخوارزمية تلقائيًا عدد المجموعات، بدلاً من الاعتماد على معلمة <code class="docutils literal notranslate"><span class="pre">bandwidth</span></code>، التي تملي حجم المنطقة للبحث من خلالها.
يمكن تعيين هذه المعلمة يدويًا، ولكن يمكن تقديرها باستخدام دالة <code class="docutils literal notranslate"><span class="pre">estimate_bandwidth</span></code> المقدمة، والتي يتم استدعاؤها إذا لم يتم تعيين عرض النطاق الترددي.</p>
<p>الخوارزمية ليست قابلة للتطوير بدرجة عالية، لأنها تتطلب بحثًا متعددًا عن أقرب جار أثناء تنفيذ الخوارزمية.
من المضمون أن تتقارب الخوارزمية، ومع ذلك ستتوقف الخوارزمية عن التكرار عندما يكون التغيير في المراكز صغيرًا.</p>
<p>يتم إجراء تسمية عينة جديدة عن طريق إيجاد أقرب مركز لعينة معينة.</p>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/cluster/plot_mean_shift.html"><img alt="../_images/sphx_glr_plot_mean_shift_001.png" src="../_images/sphx_glr_plot_mean_shift_001.png" style="width: 320.0px; height: 240.0px;" />
</a>
</figure>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><span class="xref std std-ref">sphx_glr_auto_examples_cluster/plot_mean_shift.py</span>: تجميع Mean Shift على مجموعات بيانات ثنائية الأبعاد اصطناعية مع 3 فئات.</p></li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-3" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text"><a class="reference external" href="https://doi.org/10.1109/34.1000236">&quot;Mean shift: A robust approach toward feature space analysis&quot;</a> D. Comaniciu and P. Meer، <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> (2002)</p></li>
</ul>
</div>
</details></section>
<section id="spectral-clustering">
<span id="id8"></span><h2><span class="section-number">2.3.5. </span>التجميع الطيفي<a class="headerlink" href="#spectral-clustering" title="Link to this heading">#</a></h2>
<p>يقوم <a class="reference internal" href="generated/sklearn.cluster.SpectralClustering.html#sklearn.cluster.SpectralClustering" title="sklearn.cluster.SpectralClustering"><code class="xref py py-class docutils literal notranslate"><span class="pre">SpectralClustering</span></code></a> بتضمين منخفض الأبعاد لمصفوفة التقارب بين العينات، متبوعًا بالتجميع، على سبيل المثال، بواسطة KMeans، لمكونات المتجهات الذاتية في الفضاء منخفض الأبعاد.
إنه فعال من الناحية الحسابية خاصةً إذا كانت مصفوفة التقارب متفرقة وتم استخدام أداة الحل <code class="docutils literal notranslate"><span class="pre">amg</span></code> لمشكلة القيمة الذاتية (ملاحظة، تتطلب أداة الحل <code class="docutils literal notranslate"><span class="pre">amg</span></code> تثبيت الوحدة <a class="reference external" href="https://github.com/pyamg/pyamg">pyamg</a>.)</p>
<p>يتطلب الإصدار الحالي من SpectralClustering تحديد عدد المجموعات مسبقًا. إنه يعمل بشكل جيد لعدد صغير من المجموعات، لكن لا ينصح به للعديد من المجموعات.</p>
<p>بالنسبة لمجموعتين، يحل SpectralClustering استرخاء محدب لمشكلة <a class="reference external" href="https://people.eecs.berkeley.edu/~malik/papers/SM-ncut.pdf">القطع الطبيعية</a> على الرسم البياني للتشابه: قطع الرسم البياني إلى قسمين بحيث يكون وزن الحواف المقطوعة صغيرًا مقارنة بأوزان الحواف داخل كل مجموعة.
يكون هذا المعيار مثيرًا للاهتمام بشكل خاص عند العمل على الصور، حيث تكون رؤوس الرسم البياني هي وحدات البكسل، ويتم حساب أوزان حواف الرسم البياني للتشابه باستخدام دالة لتدرج الصورة.</p>
<p class="centered">
<strong><a class="reference external" href="../auto_examples/cluster/plot_segmentation_toy.html"><img alt="noisy_img" src="../_images/sphx_glr_plot_segmentation_toy_001.png" style="width: 500.0px; height: 250.0px;" /></a> <a class="reference external" href="../auto_examples/cluster/plot_segmentation_toy.html"><img alt="segmented_img" src="../_images/sphx_glr_plot_segmentation_toy_002.png" style="width: 500.0px; height: 250.0px;" /></a></strong></p><div class="admonition warning">
<p class="admonition-title">تحذير</p>
<p>تحويل المسافة إلى أوجه تشابه جيدة التصرف</p>
<p>لاحظ أنه إذا لم يتم توزيع قيم مصفوفة التشابه الخاصة بك بشكل جيد، على سبيل المثال مع قيم سالبة أو مع مصفوفة مسافة بدلاً من التشابه، فستكون المشكلة الطيفية مفردة والمشكلة غير قابلة للحل.
في هذه الحالة، يُنصح بتطبيق تحويل على إدخالات المصفوفة.
على سبيل المثال، في حالة مصفوفة المسافة الموقعة، من الشائع تطبيق نواة حرارية:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">similarity</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">beta</span> <span class="o">*</span> <span class="n">distance</span> <span class="o">/</span> <span class="n">distance</span><span class="o">.</span><span class="n">std</span><span class="p">())</span>
</pre></div>
</div>
<p>انظر الأمثلة لمثل هذا التطبيق.</p>
</div>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><span class="xref std std-ref">sphx_glr_auto_examples_cluster/plot_segmentation_toy.py</span>: تجزئة الكائنات من خلفية صاخبة باستخدام التجميع الطيفي.</p></li>
<li><p><span class="xref std std-ref">sphx_glr_auto_examples_cluster/plot_coin_segmentation.py</span>: التجميع الطيفي لتقسيم صورة العملات المعدنية في المناطق.</p></li>
</ul>
<section id="id10">
<h3><span class="section-number">2.3.5.1. </span>استراتيجيات تعيين التسميات المختلفة<a class="headerlink" href="#id10" title="Link to this heading">#</a></h3>
<p>يمكن استخدام استراتيجيات تعيين التسميات المختلفة، المقابلة لمعلمة <code class="docutils literal notranslate"><span class="pre">assign_labels</span></code> لـ <a class="reference internal" href="generated/sklearn.cluster.SpectralClustering.html#sklearn.cluster.SpectralClustering" title="sklearn.cluster.SpectralClustering"><code class="xref py py-class docutils literal notranslate"><span class="pre">SpectralClustering</span></code></a>.
يمكن لاستراتيجية <code class="docutils literal notranslate"><span class="pre">&quot;kmeans&quot;</span></code> مطابقة التفاصيل الدقيقة، ولكن يمكن أن تكون غير مستقرة.
على وجه الخصوص، ما لم تتحكم في <code class="docutils literal notranslate"><span class="pre">random_state</span></code>، فقد لا تكون قابلة للتكرار من تشغيل إلى تشغيل، لأنها تعتمد على التهيئة العشوائية.
استراتيجية <code class="docutils literal notranslate"><span class="pre">&quot;discretize&quot;</span></code> البديلة قابلة للتكرار بنسبة 100٪، ولكنها تميل إلى إنشاء قطع ذات شكل هندسي ومتساوي إلى حد ما.
يعد خيار <code class="docutils literal notranslate"><span class="pre">&quot;cluster_qr&quot;</span></code> المضاف مؤخرًا بديلاً حتميًا يميل إلى إنشاء أفضل تقسيم مرئيًا على تطبيق المثال أدناه.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p><code class="docutils literal notranslate"><span class="pre">assign_labels=&quot;kmeans&quot;</span></code></p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">assign_labels=&quot;discretize&quot;</span></code></p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">assign_labels=&quot;cluster_qr&quot;</span></code></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference external" href="../auto_examples/cluster/plot_coin_segmentation.html"><img alt="coin_kmeans" src="../_images/sphx_glr_plot_coin_segmentation_001.png" style="width: 175.0px; height: 175.0px;" /></a></p></td>
<td><p><a class="reference external" href="../auto_examples/cluster/plot_coin_segmentation.html"><img alt="coin_discretize" src="../_images/sphx_glr_plot_coin_segmentation_002.png" style="width: 175.0px; height: 175.0px;" /></a></p></td>
<td><p><a class="reference external" href="../auto_examples/cluster/plot_coin_segmentation.html"><img alt="coin_cluster_qr" src="../_images/sphx_glr_plot_coin_segmentation_003.png" style="width: 175.0px; height: 175.0px;" /></a></p></td>
</tr>
</tbody>
</table>
</div>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-4">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-4" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text"><a class="reference external" href="https://people.eecs.berkeley.edu/~jordan/courses/281B-spring04/readings/yu-shi.pdf">&quot;Multiclass spectral clustering&quot;</a> Stella X. Yu، Jianbo Shi، 2003</p></li>
<li><p class="sd-card-text"><a class="reference external" href="https://doi.org/10.1093/imaiai/iay008">&quot;Simple, direct, and efficient multi-way spectral clustering&quot;</a> Anil Damle، Victor Minden، Lexing Ying، 2019</p></li>
</ul>
</div>
</details></section>
<section id="spectral-clustering-graph">
<span id="id11"></span><h3><span class="section-number">2.3.5.2. </span>الرسوم البيانية للتجميع الطيفي<a class="headerlink" href="#spectral-clustering-graph" title="Link to this heading">#</a></h3>
<p>يمكن أيضًا استخدام التجميع الطيفي لتقسيم الرسوم البيانية عبر تضميناتها الطيفية.
في هذه الحالة، تكون مصفوفة التقارب هي مصفوفة التجاور للرسم البياني، ويتم تهيئة SpectralClustering باستخدام <code class="docutils literal notranslate"><span class="pre">affinity='precomputed'</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">SpectralClustering</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sc</span> <span class="o">=</span> <span class="n">SpectralClustering</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">affinity</span><span class="o">=</span><span class="s1">&#39;precomputed&#39;</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
<span class="gp">... </span>                        <span class="n">assign_labels</span><span class="o">=</span><span class="s1">&#39;discretize&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sc</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">adjacency_matrix</span><span class="p">)</span>  
</pre></div>
</div>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-5">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-5" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text"><a class="reference external" href="https://doi.org/10.1007/s11222-007-9033-z">&quot;A Tutorial on Spectral Clustering&quot;</a> Ulrike von Luxburg، 2007</p></li>
<li><p class="sd-card-text"><a class="reference external" href="https://doi.org/10.1109/34.868688">&quot;Normalized cuts and image segmentation&quot;</a> Jianbo Shi، Jitendra Malik، 2000</p></li>
<li><p class="sd-card-text"><a class="reference external" href="https://citeseerx.ist.psu.edu/doc_view/pid/84a86a69315e994cfd1e0c7debb86d62d7bd1f44">&quot;A Random Walks View of Spectral Segmentation&quot;</a> Marina Meila، Jianbo Shi، 2001</p></li>
<li><p class="sd-card-text"><a class="reference external" href="https://citeseerx.ist.psu.edu/doc_view/pid/796c5d6336fc52aa84db575fb821c78918b65f58">&quot;On Spectral Clustering: Analysis and an algorithm&quot;</a> Andrew Y. Ng، Michael I. Jordan، Yair Weiss، 2001</p></li>
<li><p class="sd-card-text"><a class="reference external" href="https://arxiv.org/abs/1708.07481">&quot;Preconditioned Spectral Clustering for Stochastic Block Partition Streaming Graph Challenge&quot;</a> David Zhuzhunashvili، Andrew Knyazev</p></li>
</ul>
</div>
</details></section>
</section>
<section id="hierarchical-clustering">
<span id="id12"></span><h2><span class="section-number">2.3.6. </span>التجميع الهرمي<a class="headerlink" href="#hierarchical-clustering" title="Link to this heading">#</a></h2>
<p>التجميع الهرمي هو عائلة عامة من خوارزميات التجميع التي تبني مجموعات متداخلة عن طريق دمجها أو تقسيمها على التوالي.
يتم تمثيل هذا التسلسل الهرمي للمجموعات كشجرة (أو مخطط شجري).
جذر الشجرة هو المجموعة الفريدة التي تجمع كل العينات، والأوراق هي المجموعات التي تحتوي على عينة واحدة فقط.
انظر <a class="reference external" href="https://en.wikipedia.org/wiki/Hierarchical_clustering">صفحة ويكيبيديا</a> لمزيد من التفاصيل.</p>
<p>يقوم الكائن <a class="reference internal" href="generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering" title="sklearn.cluster.AgglomerativeClustering"><code class="xref py py-class docutils literal notranslate"><span class="pre">AgglomerativeClustering</span></code></a> بإجراء تجميع هرمي باستخدام نهج من أسفل إلى أعلى: تبدأ كل ملاحظة في مجموعتها الخاصة، ويتم دمج المجموعات معًا على التوالي. تحدد معايير الارتباط المقياس المستخدم لاستراتيجية الدمج:</p>
<ul class="simple">
<li><p><strong>Ward</strong> يقلل من مجموع الفروق التربيعية داخل جميع المجموعات.
إنه نهج يقلل من التباين وبهذا المعنى يشبه دالة الهدف k-means ولكن يتم معالجتها باستخدام نهج هرمي تكتلي.</p></li>
<li><p><strong>الحد الأقصى</strong> أو <strong>الارتباط الكامل</strong> يقلل من المسافة القصوى بين ملاحظات أزواج المجموعات.</p></li>
<li><p><strong>الارتباط المتوسط</strong> يقلل من متوسط المسافات بين جميع ملاحظات أزواج المجموعات.</p></li>
<li><p><strong>الارتباط الفردي</strong> يقلل من المسافة بين أقرب ملاحظات أزواج المجموعات.</p></li>
</ul>
<p>يمكن أيضًا قياس <a class="reference internal" href="generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering" title="sklearn.cluster.AgglomerativeClustering"><code class="xref py py-class docutils literal notranslate"><span class="pre">AgglomerativeClustering</span></code></a> لعدد كبير من العينات عند استخدامه بشكل مشترك مع مصفوفة اتصال، ولكنه مكلف من الناحية الحسابية عند عدم إضافة قيود اتصال بين العينات: فهو يأخذ في الاعتبار جميع عمليات الدمج الممكنة في كل خطوة.</p>
<aside class="topic">
<p class="topic-title"><a class="reference internal" href="generated/sklearn.cluster.FeatureAgglomeration.html#sklearn.cluster.FeatureAgglomeration" title="sklearn.cluster.FeatureAgglomeration"><code class="xref py py-class docutils literal notranslate"><span class="pre">FeatureAgglomeration</span></code></a></p>
<p>يستخدم <a class="reference internal" href="generated/sklearn.cluster.FeatureAgglomeration.html#sklearn.cluster.FeatureAgglomeration" title="sklearn.cluster.FeatureAgglomeration"><code class="xref py py-class docutils literal notranslate"><span class="pre">FeatureAgglomeration</span></code></a> التجميع التكتلي لتجميع الميزات التي تبدو متشابهة جدًا معًا، مما يقلل من عدد الميزات.
إنها أداة لتقليل الأبعاد، انظر <a class="reference internal" href="unsupervised_reduction.html#data-reduction"><span class="std std-ref">تخفيض الأبعاد غير الخاضع للإشراف</span></a>.</p>
</aside>
<section id="ward">
<h3><span class="section-number">2.3.6.1. </span>نوع الارتباط المختلف: ارتباط Ward، كامل، متوسط، وفردي<a class="headerlink" href="#ward" title="Link to this heading">#</a></h3>
<p>يدعم <a class="reference internal" href="generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering" title="sklearn.cluster.AgglomerativeClustering"><code class="xref py py-class docutils literal notranslate"><span class="pre">AgglomerativeClustering</span></code></a> استراتيجيات ارتباط Ward، فردي، متوسط، وكامل.</p>
<a class="reference external image-reference" href="../auto_examples/cluster/plot_linkage_comparison.html"><img alt="../_images/sphx_glr_plot_linkage_comparison_001.png" src="../_images/sphx_glr_plot_linkage_comparison_001.png" style="width: 589.1px; height: 623.5px;" />
</a>
<p>تتمتع الكتلة التكتلية بسلوك &quot;الغني يزداد ثراءً&quot; مما يؤدي إلى أحجام مجموعات غير متساوية.
في هذا الصدد، يعد الارتباط الفردي هو أسوأ استراتيجية، ويمنح Ward الأحجام الأكثر انتظامًا.
ومع ذلك، لا يمكن تغيير التقارب (أو المسافة المستخدمة في التجميع) مع Ward، وبالتالي بالنسبة للمقاييس غير الإقليدية، فإن الارتباط المتوسط هو بديل جيد.
يمكن حساب الارتباط الفردي، على الرغم من أنه ليس قويًا للبيانات الصاخبة، بكفاءة عالية وبالتالي يمكن أن يكون مفيدًا لتوفير تجميع هرمي لمجموعات البيانات الأكبر.
يمكن أن يؤدي الارتباط الفردي أيضًا أداءً جيدًا على البيانات غير الكروية.</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><span class="xref std std-ref">sphx_glr_auto_examples_cluster/plot_digits_linkage.py</span>: استكشاف
استراتيجيات الارتباط المختلفة في مجموعة بيانات حقيقية.</p>
<ul>
<li><p><span class="xref std std-ref">sphx_glr_auto_examples_cluster/plot_linkage_comparison.py</span>: استكشاف استراتيجيات الارتباط المختلفة في مجموعات بيانات اللعبة.</p></li>
</ul>
</li>
</ul>
</section>
<section id="id14">
<h3><span class="section-number">2.3.6.2. </span>تصور التسلسل الهرمي للكتلة<a class="headerlink" href="#id14" title="Link to this heading">#</a></h3>
<p>من الممكن تصور الشجرة التي تمثل الدمج الهرمي للمجموعات كمخطط شجري.
يمكن أن يكون الفحص البصري مفيدًا غالبًا لفهم بنية البيانات، على الرغم من أنه أكثر من ذلك في حالة أحجام العينات الصغيرة.</p>
<a class="reference external image-reference" href="../auto_examples/cluster/plot_agglomerative_dendrogram.html"><img alt="../_images/sphx_glr_plot_agglomerative_dendrogram_001.png" src="../_images/sphx_glr_plot_agglomerative_dendrogram_001.png" style="width: 268.8px; height: 201.6px;" />
</a>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><span class="xref std std-ref">sphx_glr_auto_examples_cluster/plot_agglomerative_dendrogram.py</span></p></li>
</ul>
</section>
<section id="id15">
<h3><span class="section-number">2.3.6.3. </span>إضافة قيود الاتصال<a class="headerlink" href="#id15" title="Link to this heading">#</a></h3>
<p>أحد الجوانب المثيرة للاهتمام لـ <a class="reference internal" href="generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering" title="sklearn.cluster.AgglomerativeClustering"><code class="xref py py-class docutils literal notranslate"><span class="pre">AgglomerativeClustering</span></code></a> هو أنه يمكن إضافة قيود الاتصال إلى هذه الخوارزمية (يمكن دمج المجموعات المجاورة فقط معًا)، من خلال مصفوفة اتصال تحدد لكل عينة العينات المجاورة التي تتبع بنية معينة للبيانات.
على سبيل المثال، في مثال swiss-roll أدناه، تحظر قيود الاتصال دمج النقاط التي لا تجاور على swiss roll، وبالتالي تتجنب تشكيل مجموعات تمتد عبر طيات متداخلة للفة.</p>
<p class="centered">
<strong><a class="reference external" href="../auto_examples/cluster/plot_ward_structured_vs_unstructured.html"><img alt="unstructured" src="../_images/sphx_glr_plot_ward_structured_vs_unstructured_001.png" style="width: 313.6px; height: 235.2px;" /></a> <a class="reference external" href="../auto_examples/cluster/plot_ward_structured_vs_unstructured.html"><img alt="structured" src="../_images/sphx_glr_plot_ward_structured_vs_unstructured_002.png" style="width: 313.6px; height: 235.2px;" /></a></strong></p><p>تكون هذه القيود مفيدة لفرض بنية محلية معينة، لكنها تجعل الخوارزمية أسرع أيضًا، خاصةً عندما يكون عدد العينات مرتفعًا.</p>
<p>يتم فرض قيود الاتصال عبر مصفوفة الاتصال: مصفوفة scipy متفرقة تحتوي على عناصر فقط عند تقاطع صف وعمود مع مؤشرات مجموعة البيانات التي يجب توصيلها.
يمكن إنشاء هذه المصفوفة من معلومات مسبقة: على سبيل المثال، قد ترغب في تجميع صفحات الويب عن طريق دمج الصفحات التي تحتوي على رابط يشير من واحدة إلى أخرى فقط.
يمكن أيضًا تعلمه من البيانات، على سبيل المثال باستخدام <a class="reference internal" href="generated/sklearn.neighbors.kneighbors_graph.html#sklearn.neighbors.kneighbors_graph" title="sklearn.neighbors.kneighbors_graph"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.neighbors.kneighbors_graph</span></code></a> لتقييد الدمج لأقرب الجيران كما هو الحال في <span class="xref std std-ref">هذا المثال</span>، أو باستخدام <a class="reference internal" href="generated/sklearn.feature_extraction.image.grid_to_graph.html#sklearn.feature_extraction.image.grid_to_graph" title="sklearn.feature_extraction.image.grid_to_graph"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.feature_extraction.image.grid_to_graph</span></code></a> لتمكين دمج وحدات البكسل المجاورة فقط على صورة، كما في <span class="xref std std-ref">مثال العملة</span>.</p>
<div class="admonition warning">
<p class="admonition-title">تحذير</p>
<p><strong>قيود الاتصال مع الارتباط الفردي والمتوسط والكلي</strong></p>
<p>يمكن أن تعزز قيود الاتصال والارتباط الفردي أو الكامل أو المتوسط جانب &quot;الغني يزداد ثراءً&quot; للتجميع التكتلي، لا سيما إذا تم بناؤها باستخدام <a class="reference internal" href="generated/sklearn.neighbors.kneighbors_graph.html#sklearn.neighbors.kneighbors_graph" title="sklearn.neighbors.kneighbors_graph"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.neighbors.kneighbors_graph</span></code></a>.
في حدود عدد صغير من المجموعات، تميل إلى إعطاء عدد قليل من المجموعات المشغولة بشكل مجهري وتلك الفارغة تقريبًا.
(انظر المناقشة في <span class="xref std std-ref">sphx_glr_auto_examples_cluster/plot_agglomerative_clustering.py</span>).
الارتباط الفردي هو خيار الارتباط الأكثر هشاشة فيما يتعلق بهذه المشكلة.</p>
</div>
<a class="reference external image-reference" href="../auto_examples/cluster/plot_agglomerative_clustering.html"><img alt="../_images/sphx_glr_plot_agglomerative_clustering_001.png" src="../_images/sphx_glr_plot_agglomerative_clustering_001.png" style="width: 380.0px; height: 152.0px;" />
</a>
<a class="reference external image-reference" href="../auto_examples/cluster/plot_agglomerative_clustering.html"><img alt="../_images/sphx_glr_plot_agglomerative_clustering_002.png" src="../_images/sphx_glr_plot_agglomerative_clustering_002.png" style="width: 380.0px; height: 152.0px;" />
</a>
<a class="reference external image-reference" href="../auto_examples/cluster/plot_agglomerative_clustering.html"><img alt="../_images/sphx_glr_plot_agglomerative_clustering_003.png" src="../_images/sphx_glr_plot_agglomerative_clustering_003.png" style="width: 380.0px; height: 152.0px;" />
</a>
<a class="reference external image-reference" href="../auto_examples/cluster/plot_agglomerative_clustering.html"><img alt="../_images/sphx_glr_plot_agglomerative_clustering_004.png" src="../_images/sphx_glr_plot_agglomerative_clustering_004.png" style="width: 380.0px; height: 152.0px;" />
</a>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><span class="xref std std-ref">sphx_glr_auto_examples_cluster/plot_coin_ward_segmentation.py</span>: تجميع Ward لتقسيم صورة العملات المعدنية في المناطق.</p></li>
<li><p><span class="xref std std-ref">sphx_glr_auto_examples_cluster/plot_ward_structured_vs_unstructured.py</span>: مثال على خوارزمية Ward على swiss-roll، مقارنة بين الأساليب المنظمة مقابل الأساليب غير المنظمة.</p></li>
<li><p><span class="xref std std-ref">sphx_glr_auto_examples_cluster/plot_feature_agglomeration_vs_univariate_selection.py</span>: مثال على تقليل الأبعاد مع تجميع الميزات بناءً على تجميع Ward الهرمي.</p></li>
<li><p><span class="xref std std-ref">sphx_glr_auto_examples_cluster/plot_agglomerative_clustering.py</span></p></li>
</ul>
</section>
<section id="id16">
<h3><span class="section-number">2.3.6.4. </span>تغيير المقياس<a class="headerlink" href="#id16" title="Link to this heading">#</a></h3>
<p>يمكن استخدام الارتباط الفردي والمتوسط والكلي مع مجموعة متنوعة من المسافات (أو التقاربات)، لا سيما المسافة الإقليدية (<em>l2</em>)، ومسافة مانهاتن (أو Cityblock، أو <em>l1</em>)، ومسافة جيب التمام، أو أي مصفوفة تقارب محسوبة مسبقًا.</p>
<ul class="simple">
<li><p>غالبًا ما تكون مسافة <em>l1</em> جيدة للميزات المتفرقة، أو الضوضاء المتفرقة: أي أن العديد من الميزات تساوي صفرًا، كما هو الحال في استخراج النص باستخدام تكرارات الكلمات النادرة.</p></li>
<li><p>مسافة <em>جيب التمام</em> مثيرة للاهتمام لأنها ثابتة بالنسبة للتدرجات العالمية للإشارة.</p></li>
</ul>
<p>الإرشادات لاختيار مقياس هي استخدام مقياس يزيد المسافة بين العينات في فئات مختلفة، ويقلل ذلك داخل كل فئة.</p>
<a class="reference external image-reference" href="../auto_examples/cluster/plot_agglomerative_clustering_metrics.html"><img alt="../_images/sphx_glr_plot_agglomerative_clustering_metrics_005.png" src="../_images/sphx_glr_plot_agglomerative_clustering_metrics_005.png" style="width: 204.8px; height: 153.6px;" />
</a>
<a class="reference external image-reference" href="../auto_examples/cluster/plot_agglomerative_clustering_metrics.html"><img alt="../_images/sphx_glr_plot_agglomerative_clustering_metrics_006.png" src="../_images/sphx_glr_plot_agglomerative_clustering_metrics_006.png" style="width: 204.8px; height: 153.6px;" />
</a>
<a class="reference external image-reference" href="../auto_examples/cluster/plot_agglomerative_clustering_metrics.html"><img alt="../_images/sphx_glr_plot_agglomerative_clustering_metrics_007.png" src="../_images/sphx_glr_plot_agglomerative_clustering_metrics_007.png" style="width: 204.8px; height: 153.6px;" />
</a>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><span class="xref std std-ref">sphx_glr_auto_examples_cluster/plot_agglomerative_clustering_metrics.py</span></p></li>
</ul>
</section>
<section id="bisecting-k-means">
<h3><span class="section-number">2.3.6.5. </span>Bisecting K-Means<a class="headerlink" href="#bisecting-k-means" title="Link to this heading">#</a></h3>
<p id="bisect-k-means"><a class="reference internal" href="generated/sklearn.cluster.BisectingKMeans.html#sklearn.cluster.BisectingKMeans" title="sklearn.cluster.BisectingKMeans"><code class="xref py py-class docutils literal notranslate"><span class="pre">BisectingKMeans</span></code></a> هو متغير تكراري لـ <a class="reference internal" href="generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans" title="sklearn.cluster.KMeans"><code class="xref py py-class docutils literal notranslate"><span class="pre">KMeans</span></code></a>، باستخدام التجميع الهرمي المقسم.
بدلاً من إنشاء جميع المراكز في وقت واحد، يتم اختيار المراكز بشكل تدريجي بناءً على تجميع سابق: يتم تقسيم الكتلة إلى مجموعتين جديدتين بشكل متكرر حتى يتم الوصول إلى العدد المستهدف من المجموعات.</p>
<p><a class="reference internal" href="generated/sklearn.cluster.BisectingKMeans.html#sklearn.cluster.BisectingKMeans" title="sklearn.cluster.BisectingKMeans"><code class="xref py py-class docutils literal notranslate"><span class="pre">BisectingKMeans</span></code></a> أكثر كفاءة من <a class="reference internal" href="generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans" title="sklearn.cluster.KMeans"><code class="xref py py-class docutils literal notranslate"><span class="pre">KMeans</span></code></a> عندما يكون عدد المجموعات كبيرًا لأنه يعمل فقط على مجموعة فرعية من البيانات في كل قسم بينما يعمل <a class="reference internal" href="generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans" title="sklearn.cluster.KMeans"><code class="xref py py-class docutils literal notranslate"><span class="pre">KMeans</span></code></a> دائمًا على مجموعة البيانات بأكملها.</p>
<p>على الرغم من أن <a class="reference internal" href="generated/sklearn.cluster.BisectingKMeans.html#sklearn.cluster.BisectingKMeans" title="sklearn.cluster.BisectingKMeans"><code class="xref py py-class docutils literal notranslate"><span class="pre">BisectingKMeans</span></code></a> لا يمكنه الاستفادة من مزايا تهيئة <code class="docutils literal notranslate"><span class="pre">&quot;k-means++&quot;</span></code> عن طريق التصميم، إلا أنه سيظل ينتج نتائج قابلة للمقارنة مع <code class="docutils literal notranslate"><span class="pre">KMeans(init=&quot;k-means++&quot;)</span></code> من حيث القصور الذاتي بتكاليف حسابية أرخص، ومن المحتمل أن ينتج نتائج أفضل من <code class="docutils literal notranslate"><span class="pre">KMeans</span></code> مع التهيئة العشوائية.</p>
<p>هذا المتغير أكثر كفاءة للتجميع التكتلي إذا كان عدد المجموعات صغيرًا مقارنة بعدد نقاط البيانات.</p>
<p>لا ينتج هذا المتغير أيضًا مجموعات فارغة.</p>
<dl class="simple">
<dt>توجد استراتيجيتان لاختيار الكتلة لتقسيمها:</dt><dd><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">bisecting_strategy=&quot;largest_cluster&quot;</span></code>  يختار الكتلة التي تحتوي على معظم النقاط</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bisecting_strategy=&quot;biggest_inertia&quot;</span></code>  يختار الكتلة ذات أكبر قصور ذاتي
(الكتلة ذات أكبر مجموع أخطاء مربعة داخل)</p></li>
</ul>
</dd>
</dl>
<p>ينتج عن الاختيار حسب أكبر قدر من نقاط البيانات في معظم الحالات نتيجة دقيقة مثل الاختيار حسب القصور الذاتي وهو أسرع (خاصة بالنسبة لكمية أكبر من نقاط البيانات، حيث قد يكون حساب الخطأ مكلفًا).</p>
<p>من المرجح أيضًا أن ينتج عن الاختيار حسب أكبر قدر من نقاط البيانات مجموعات ذات أحجام متشابهة بينما من المعروف أن <code class="docutils literal notranslate"><span class="pre">KMeans</span></code> ينتج مجموعات ذات أحجام مختلفة.</p>
<p>يمكن رؤية الفرق بين Bisecting K-Means و K-Means العادي في المثال
<span class="xref std std-ref">sphx_glr_auto_examples_cluster/plot_bisect_kmeans.py</span>.
بينما تميل خوارزمية K-Means العادية إلى إنشاء مجموعات غير ذات صلة،
يتم ترتيب المجموعات من Bisecting K-Means بشكل جيد وإنشاء تسلسل هرمي مرئي تمامًا.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-6">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-6" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text"><a class="reference external" href="http://www.philippe-fournier-viger.com/spmf/bisectingkmeans.pdf">&quot;A Comparison of Document Clustering Techniques&quot;</a> Michael Steinbach، George Karypis and Vipin Kumar، Department of Computer Science and Egineering، University of Minnesota (June 2000)</p></li>
<li><p class="sd-card-text"><a class="reference external" href="https://ijeter.everscience.org/Manuscripts/Volume-4/Issue-8/Vol-4-issue-8-M-23.pdf">&quot;Performance Analysis of K-Means and Bisecting K-Means Algorithms in Weblog Data&quot;</a> K.Abirami and Dr.P.Mayilvahanan، International Journal of Emerging Technologies in Engineering Research (IJETER) Volume 4، Issue 8، (August 2016)</p></li>
<li><p class="sd-card-text"><a class="reference external" href="http://www.jcomputers.us/vol13/jcp1306-01.pdf">&quot;Bisecting K-means Algorithm Based on K-valued Self-determining and Clustering Center Optimization&quot;</a> Jian Di، Xinyue Gou School of Control and Computer Engineering، North China Electric Power University، Baoding، Hebei، China (August 2017)</p></li>
</ul>
</div>
</details></section>
</section>
<section id="dbscan">
<span id="id17"></span><h2><span class="section-number">2.3.7. </span>DBSCAN<a class="headerlink" href="#dbscan" title="Link to this heading">#</a></h2>
<p>ترى خوارزمية <a class="reference internal" href="generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN" title="sklearn.cluster.DBSCAN"><code class="xref py py-class docutils literal notranslate"><span class="pre">DBSCAN</span></code></a> المجموعات على أنها مناطق ذات كثافة عالية مفصولة بمناطق ذات كثافة منخفضة.
نظرًا لهذه الرؤية العامة إلى حد ما، يمكن أن تكون المجموعات التي تم العثور عليها بواسطة DBSCAN بأي شكل، على عكس k-means التي تفترض أن المجموعات محدبة الشكل.
المكون المركزي لـ DBSCAN هو مفهوم <em>العينات الأساسية</em>، وهي عينات موجودة في مناطق ذات كثافة عالية.
لذلك، فإن الكتلة عبارة عن مجموعة من العينات الأساسية، كل منها قريب من بعضها البعض (يقاس ببعض مقياس المسافة) ومجموعة من العينات غير الأساسية القريبة من عينة أساسية (لكنها ليست عينات أساسية).
هناك معلمتان للخوارزمية، <code class="docutils literal notranslate"><span class="pre">min_samples</span></code> و <code class="docutils literal notranslate"><span class="pre">eps</span></code>، اللتان تحددان رسميًا ما نعنيه عندما نقول <em>كثيف</em>.
يشير <code class="docutils literal notranslate"><span class="pre">min_samples</span></code> الأعلى أو <code class="docutils literal notranslate"><span class="pre">eps</span></code> الأقل إلى كثافة أعلى ضرورية لتشكيل مجموعة.</p>
<p>بشكل أكثر رسمية، نحدد عينة أساسية على أنها عينة في مجموعة البيانات بحيث توجد <code class="docutils literal notranslate"><span class="pre">min_samples</span></code> عينات أخرى على مسافة <code class="docutils literal notranslate"><span class="pre">eps</span></code>، والتي تُعرّف على أنها <em>جيران</em> للعينة الأساسية.
يخبرنا هذا أن العينة الأساسية موجودة في منطقة كثيفة من فضاء المتجه.
الكتلة هي مجموعة من العينات الأساسية التي يمكن بناؤها عن طريق أخذ عينة أساسية بشكل متكرر، والعثور على جميع جيرانها من العينات الأساسية، والعثور على جميع جيرانها <em>من</em> العينات الأساسية، وهكذا.
تحتوي الكتلة أيضًا على مجموعة من العينات غير الأساسية، وهي عينات مجاورة لعينة أساسية في الكتلة ولكنها ليست عينات أساسية.
بشكل حدسي، توجد هذه العينات على أطراف الكتلة.</p>
<p>أي عينة أساسية هي جزء من مجموعة، بحكم التعريف.
أي عينة ليست عينة أساسية، وتكون على مسافة <code class="docutils literal notranslate"><span class="pre">eps</span></code> على الأقل من أي عينة أساسية، تعتبر قيمة متطرفة بواسطة الخوارزمية.</p>
<p>بينما تتحكم معلمة <code class="docutils literal notranslate"><span class="pre">min_samples</span></code> بشكل أساسي في مدى تسامح الخوارزمية تجاه الضوضاء (في مجموعات البيانات الصاخبة والكبيرة، قد يكون من المستحسن زيادة هذه المعلمة)، فإن معلمة <code class="docutils literal notranslate"><span class="pre">eps</span></code> <em>ضرورية للاختيار بشكل مناسب</em> لمجموعة البيانات ودالة المسافة وعادةً لا يمكن تركها عند القيمة الافتراضية. يتحكم في الحي المحلي للنقاط.
عند اختيارها صغيرة جدًا، لن يتم تجميع معظم البيانات على الإطلاق (وتم تصنيفها على أنها <code class="docutils literal notranslate"><span class="pre">-1</span></code> لـ &quot;الضوضاء&quot;).
عند اختيارها كبيرة جدًا، فإنها تتسبب في دمج المجموعات القريبة في مجموعة واحدة، وفي النهاية يتم إرجاع مجموعة البيانات بأكملها كمجموعة واحدة.
تمت مناقشة بعض الاستدلالات لاختيار هذه المعلمة في الأدبيات، على سبيل المثال بناءً على ركبة في مخطط مسافات أقرب جار (كما هو موضح في المراجع أدناه).</p>
<p>في الشكل أدناه، يشير اللون إلى عضوية الكتلة، مع الإشارة إلى الدوائر الكبيرة للعينات الأساسية التي تم العثور عليها بواسطة الخوارزمية.
الدوائر الأصغر هي عينات غير أساسية لا تزال جزءًا من مجموعة.
علاوة على ذلك، يشار إلى القيم المتطرفة بالنقاط السوداء أدناه.</p>
<p class="centered">
<strong><a class="reference external" href="../auto_examples/cluster/plot_dbscan.html"><img alt="dbscan_results" src="../_images/sphx_glr_plot_dbscan_002.png" style="width: 320.0px; height: 240.0px;" /></a></strong></p><p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><span class="xref std std-ref">sphx_glr_auto_examples_cluster/plot_dbscan.py</span></p></li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="التنفيذ">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">التنفيذ<a class="headerlink" href="#التنفيذ" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">خوارزمية DBSCAN حتمية، وتولد دائمًا نفس المجموعات عند إعطاء نفس البيانات بنفس الترتيب.
ومع ذلك، يمكن أن تختلف النتائج عند توفير البيانات بترتيب مختلف.
أولاً، على الرغم من أنه سيتم دائمًا تعيين العينات الأساسية لنفس المجموعات، إلا أن تسميات تلك المجموعات ستعتمد على الترتيب الذي تصادف فيه تلك العينات في البيانات.
ثانيًا والأهم من ذلك، أن المجموعات التي يتم تعيين العينات غير الأساسية إليها يمكن أن تختلف اعتمادًا على ترتيب البيانات.
سيحدث هذا عندما يكون لعينة غير أساسية مسافة أقل من <code class="docutils literal notranslate"><span class="pre">eps</span></code> إلى عينتين أساسيتين في مجموعات مختلفة.
من خلال عدم المساواة المثلثية، يجب أن تكون هاتان العينتان الأساسيتان بعيدتان عن بعضهما البعض أكثر من <code class="docutils literal notranslate"><span class="pre">eps</span></code>، وإلا فستكونان في نفس المجموعة.
يتم تعيين العينة غير الأساسية إلى أي مجموعة يتم إنشاؤها أولاً في تمريرة عبر البيانات، وبالتالي ستعتمد النتائج على ترتيب البيانات.</p>
<p class="sd-card-text">يستخدم التنفيذ الحالي أشجار الكرة وأشجار kd لتحديد جوار النقاط، مما يتجنب حساب مصفوفة المسافة الكاملة (كما تم في إصدارات scikit-learn قبل 0.14).
يتم الاحتفاظ بإمكانية استخدام المقاييس المخصصة؛ للحصول على التفاصيل، انظر <code class="xref py py-class docutils literal notranslate"><span class="pre">NearestNeighbors</span></code>.</p>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="استهلاك-الذاكرة-لأحجام-العينات-الكبيرة">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">استهلاك الذاكرة لأحجام العينات الكبيرة<a class="headerlink" href="#استهلاك-الذاكرة-لأحجام-العينات-الكبيرة" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">هذا التنفيذ ليس فعالاً من حيث الذاكرة افتراضيًا لأنه يبني مصفوفة تشابه زوجية كاملة في حالة عدم إمكانية استخدام أشجار kd أو أشجار الكرة (على سبيل المثال، مع المصفوفات المتفرقة).
ستستهلك هذه المصفوفة <span class="math notranslate nohighlight">\(n^2\)</span> عوامات. فيما يلي بعض الآليات للتغلب على هذا:</p>
<ul class="simple">
<li><p class="sd-card-text">استخدم تجميع <a class="reference internal" href="#optics"><span class="std std-ref">OPTICS</span></a> بالاقتران مع طريقة <code class="docutils literal notranslate"><span class="pre">extract_dbscan</span></code>.
يحسب تجميع OPTICS أيضًا المصفوفة الزوجية الكاملة، لكنه يحتفظ بصف واحد فقط في الذاكرة في كل مرة (تعقيد الذاكرة n).</p></li>
<li><p class="sd-card-text">يمكن حساب رسم بياني متفرق لجوار نصف القطر (حيث يُفترض أن تكون الإدخالات المفقودة خارج eps) مسبقًا بطريقة فعالة من حيث الذاكرة ويمكن تشغيل dbscan على هذا باستخدام <code class="docutils literal notranslate"><span class="pre">metric='precomputed'</span></code>.
انظر <a class="reference internal" href="generated/sklearn.neighbors.NearestNeighbors.html#sklearn.neighbors.NearestNeighbors.radius_neighbors_graph" title="sklearn.neighbors.NearestNeighbors.radius_neighbors_graph"><code class="xref py py-meth docutils literal notranslate"><span class="pre">sklearn.neighbors.NearestNeighbors.radius_neighbors_graph</span></code></a>.</p></li>
<li><p class="sd-card-text">يمكن ضغط مجموعة البيانات، إما عن طريق إزالة التكرارات الدقيقة إذا حدثت هذه في بياناتك، أو باستخدام BIRCH.
عندها يكون لديك فقط عدد صغير نسبيًا من الممثلين لعدد كبير من النقاط.
يمكنك بعد ذلك توفير <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code> عند ملاءمة DBSCAN.</p></li>
</ul>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-7">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-7" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
</div>
</details><ul class="simple">
<li><p><a class="reference external" href="https://www.aaai.org/Papers/KDD/1996/KDD96-037.pdf">A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise</a>
Ester، M.، H. P. Kriegel، J. Sander، و X. Xu، في وقائع المؤتمر الدولي الثاني حول اكتشاف المعرفة واستخراج البيانات، بورتلاند، أو آر،
AAAI Press، ص 226-231. 1996</p></li>
<li><p><a class="reference external" href="https://doi.org/10.1145/3068335">DBSCAN revisited, revisited: why and how you should (still) use DBSCAN.</a> Schubert، E.، Sander، J.، Ester، M.، Kriegel، H. P.، &amp; Xu،
X. (2017). في معاملات ACM على أنظمة قواعد البيانات (TODS)، 42 (3)، 19.</p></li>
</ul>
</section>
<section id="hdbscan">
<span id="id18"></span><h2><span class="section-number">2.3.8. </span>HDBSCAN<a class="headerlink" href="#hdbscan" title="Link to this heading">#</a></h2>
<p>يمكن اعتبار خوارزمية <a class="reference internal" href="generated/sklearn.cluster.HDBSCAN.html#sklearn.cluster.HDBSCAN" title="sklearn.cluster.HDBSCAN"><code class="xref py py-class docutils literal notranslate"><span class="pre">HDBSCAN</span></code></a> امتدادًا لـ <a class="reference internal" href="generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN" title="sklearn.cluster.DBSCAN"><code class="xref py py-class docutils literal notranslate"><span class="pre">DBSCAN</span></code></a> و <a class="reference internal" href="generated/sklearn.cluster.OPTICS.html#sklearn.cluster.OPTICS" title="sklearn.cluster.OPTICS"><code class="xref py py-class docutils literal notranslate"><span class="pre">OPTICS</span></code></a>.
على وجه التحديد، يفترض <a class="reference internal" href="generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN" title="sklearn.cluster.DBSCAN"><code class="xref py py-class docutils literal notranslate"><span class="pre">DBSCAN</span></code></a> أن معيار التجميع (أي متطلبات الكثافة) <em>متجانس عالميًا</em>.
بمعنى آخر، قد يكافح <a class="reference internal" href="generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN" title="sklearn.cluster.DBSCAN"><code class="xref py py-class docutils literal notranslate"><span class="pre">DBSCAN</span></code></a> لالتقاط المجموعات بكثافات مختلفة بنجاح.
يخفف <a class="reference internal" href="generated/sklearn.cluster.HDBSCAN.html#sklearn.cluster.HDBSCAN" title="sklearn.cluster.HDBSCAN"><code class="xref py py-class docutils literal notranslate"><span class="pre">HDBSCAN</span></code></a> من هذا الافتراض ويستكشف جميع مقاييس الكثافة الممكنة من خلال بناء تمثيل بديل لمشكلة التجميع.</p>
<div class="admonition note">
<p class="admonition-title">ملاحظة</p>
<p>تم تكييف هذا التنفيذ من التنفيذ الأصلي لـ HDBSCAN، <a class="reference external" href="https://github.com/scikit-learn-contrib/hdbscan">scikit-learn-contrib/hdbscan</a> بناءً على <a class="reference internal" href="#lj2017" id="id19"><span>[LJ2017]</span></a>.</p>
</div>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><span class="xref std std-ref">sphx_glr_auto_examples_cluster/plot_hdbscan.py</span></p></li>
</ul>
<section id="id20">
<h3><span class="section-number">2.3.8.1. </span>رسم بياني للوصول المتبادل<a class="headerlink" href="#id20" title="Link to this heading">#</a></h3>
<p>يحدد HDBSCAN أولاً <span class="math notranslate nohighlight">\(d_c(x_p)\)</span>، <em>مسافة النواة</em> للعينة <span class="math notranslate nohighlight">\(x_p\)</span>، على أنها المسافة إلى أقرب جار لها <code class="docutils literal notranslate"><span class="pre">min_samples</span></code>، مع حساب نفسها.
على سبيل المثال، إذا كان <code class="docutils literal notranslate"><span class="pre">min_samples=5</span></code> و <span class="math notranslate nohighlight">\(x_*\)</span> هو أقرب جار 5 لـ <span class="math notranslate nohighlight">\(x_p\)</span>، فإن مسافة النواة هي:</p>
<div class="math notranslate nohighlight">
\[d_c(x_p)=d(x_p, x_*).\]</div>
<p>بعد ذلك يحدد <span class="math notranslate nohighlight">\(d_m(x_p, x_q)\)</span>، <em>مسافة الوصول المتبادل</em> لنقطتين <span class="math notranslate nohighlight">\(x_p, x_q\)</span>، على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[d_m(x_p, x_q) = \max\{d_c(x_p), d_c(x_q), d(x_p, x_q)\}\]</div>
<p>تسمح لنا هاتان الفكرتان ببناء <em>رسم بياني للوصول المتبادل</em> <span class="math notranslate nohighlight">\(G_{ms}\)</span> محدد لاختيار ثابت لـ <code class="docutils literal notranslate"><span class="pre">min_samples</span></code> من خلال ربط كل عينة <span class="math notranslate nohighlight">\(x_p\)</span> برأس الرسم البياني، وبالتالي فإن الحواف بين النقاط <span class="math notranslate nohighlight">\(x_p, x_q\)</span> هي مسافة الوصول المتبادل <span class="math notranslate nohighlight">\(d_m(x_p, x_q)\)</span> بينهما.
قد نبني مجموعات فرعية من هذا الرسم البياني، يُشار إليها باسم <span class="math notranslate nohighlight">\(G_{ms,\varepsilon}\)</span>، عن طريق إزالة أي حواف ذات قيمة أكبر من <span class="math notranslate nohighlight">\(\varepsilon\)</span>: من الرسم البياني الأصلي.
أي نقاط تكون مسافة نواتها أقل من <span class="math notranslate nohighlight">\(\varepsilon\)</span>: يتم تمييزها في هذه المرحلة على أنها ضوضاء.
ثم يتم تجميع النقاط المتبقية عن طريق إيجاد المكونات المتصلة لهذا الرسم البياني المقتطع.</p>
<div class="admonition note">
<p class="admonition-title">ملاحظة</p>
<p>إن أخذ المكونات المتصلة للرسم البياني المقتطع <span class="math notranslate nohighlight">\(G_{ms,\varepsilon}\)</span> يعادل تشغيل DBSCAN* مع <code class="docutils literal notranslate"><span class="pre">min_samples</span></code> و <span class="math notranslate nohighlight">\(\varepsilon\)</span>.
DBSCAN* هو إصدار معدل قليلاً من DBSCAN مذكور في <a class="reference internal" href="#cm2013" id="id21"><span>[CM2013]</span></a>.</p>
</div>
</section>
<section id="id22">
<h3><span class="section-number">2.3.8.2. </span>التجميع الهرمي<a class="headerlink" href="#id22" title="Link to this heading">#</a></h3>
<p>يمكن اعتبار HDBSCAN خوارزمية تقوم بتجميع DBSCAN* عبر جميع قيم <span class="math notranslate nohighlight">\(\varepsilon\)</span>.
كما ذكرنا سابقًا، هذا يعادل إيجاد المكونات المتصلة لرسوم بيانية للوصول المتبادل لجميع قيم <span class="math notranslate nohighlight">\(\varepsilon\)</span>.
للقيام بذلك بكفاءة، يستخرج HDBSCAN أولاً شجرة تمتد بحد أدنى (MST) من رسم بياني للوصول المتبادل متصل بالكامل، ثم يقطع بشكل جشع الحواف ذات الوزن الأعلى.
يرد أدناه مخطط لخوارزمية HDBSCAN:</p>
<ol class="arabic simple">
<li><p>استخرج MST من <span class="math notranslate nohighlight">\(G_{ms}\)</span>.</p></li>
<li><p>قم بتمديد MST عن طريق إضافة &quot;حافة ذاتية&quot; لكل رأس، مع وزن يساوي مسافة النواة للعينة الأساسية.</p></li>
<li><p>قم بتهيئة مجموعة واحدة وتسمية لـ MST.</p></li>
<li><p>قم بإزالة الحافة ذات الوزن الأكبر من MST (يتم إزالة الروابط في وقت واحد).</p></li>
<li><p>قم بتعيين تسميات الكتلة للمكونات المتصلة التي تحتوي على نقاط نهاية الحافة التي تمت إزالتها الآن. إذا لم يكن للمكون حافة واحدة على الأقل، فسيتم تعيين تسمية &quot;فارغة&quot; له بدلاً من ذلك، مما يميزه على أنه ضوضاء.</p></li>
<li><p>كرر 4-5 حتى لا توجد مكونات متصلة.</p></li>
</ol>
<p>لذلك، فإن HDBSCAN قادر على الحصول على جميع الأقسام الممكنة التي يمكن تحقيقها بواسطة DBSCAN* لاختيار ثابت لـ <code class="docutils literal notranslate"><span class="pre">min_samples</span></code> بطريقة هرمية.
في الواقع، يسمح هذا لـ HDBSCAN بإجراء التجميع عبر كثافات متعددة، وعلى هذا النحو لم يعد بحاجة إلى إعطاء <span class="math notranslate nohighlight">\(\varepsilon\)</span> كمعامل فائق.
بدلاً من ذلك، يعتمد فقط على اختيار <code class="docutils literal notranslate"><span class="pre">min_samples</span></code>، والذي يميل إلى أن يكون معاملًا فائقًا أكثر قوة.</p>
<p class="centered">
<strong><a class="reference external" href="../auto_examples/cluster/plot_hdbscan.html"><img alt="hdbscan_ground_truth" src="../_images/sphx_glr_plot_hdbscan_005.png" style="width: 750.0px; height: 300.0px;" /></a></strong></p><p class="centered">
<strong><a class="reference external" href="../auto_examples/cluster/plot_hdbscan.html"><img alt="hdbscan_results" src="../_images/sphx_glr_plot_hdbscan_007.png" style="width: 750.0px; height: 300.0px;" /></a></strong></p><p>يمكن تنعيم HDBSCAN باستخدام معامل فائق إضافي <code class="docutils literal notranslate"><span class="pre">min_cluster_size</span></code> الذي يحدد أنه أثناء التجميع الهرمي، تعتبر المكونات التي تحتوي على أقل من <code class="docutils literal notranslate"><span class="pre">minimum_cluster_size</span></code> العديد من العينات ضوضاء.
من الناحية العملية، يمكن للمرء تعيين <code class="docutils literal notranslate"><span class="pre">minimum_cluster_size</span> <span class="pre">=</span> <span class="pre">min_samples</span></code> لربط المعلمات وتبسيط مساحة المعاملات الفائقة.</p>
<p class="rubric">المراجع</p>
<div role="list" class="citation-list">
<div class="citation" id="cm2013" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id21">CM2013</a><span class="fn-bracket">]</span></span>
<p>Campello، R.J.G.B.، Moulavi، D.، Sander، J. (2013). Density-Based
Clustering Based on Hierarchical Density Estimates. In: Pei، J.، Tseng، V.S.،
Cao، L.، Motoda، H.، Xu، G. (eds) Advances in Knowledge Discovery and Data
Mining. PAKDD 2013. Lecture Notes in Computer Science()، vol 7819. Springer،
Berlin، Heidelberg. <a class="reference external" href="https://doi.org/10.1007/978-3-642-37456-2_14">Density-Based Clustering Based on Hierarchical
Density Estimates</a></p>
</div>
<div class="citation" id="lj2017" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id19">LJ2017</a><span class="fn-bracket">]</span></span>
<p>L. McInnes and J. Healy، (2017). Accelerated Hierarchical Density
Based Clustering. In: IEEE International Conference on Data Mining Workshops
(ICDMW)، 2017، pp. 33-42. <a class="reference external" href="https://doi.org/10.1109/ICDMW.2017.12">Accelerated Hierarchical Density Based
Clustering</a></p>
</div>
</div>
</section>
</section>
<section id="optics">
<span id="id23"></span><h2><span class="section-number">2.3.9. </span>OPTICS<a class="headerlink" href="#optics" title="Link to this heading">#</a></h2>
<p>تشترك خوارزمية <a class="reference internal" href="generated/sklearn.cluster.OPTICS.html#sklearn.cluster.OPTICS" title="sklearn.cluster.OPTICS"><code class="xref py py-class docutils literal notranslate"><span class="pre">OPTICS</span></code></a> في العديد من أوجه التشابه مع خوارزمية <a class="reference internal" href="generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN" title="sklearn.cluster.DBSCAN"><code class="xref py py-class docutils literal notranslate"><span class="pre">DBSCAN</span></code></a>، ويمكن اعتبارها تعميمًا لـ DBSCAN التي تخفف متطلبات <code class="docutils literal notranslate"><span class="pre">eps</span></code> من قيمة واحدة إلى نطاق قيمة.
الفرق الرئيسي بين DBSCAN و OPTICS هو أن خوارزمية OPTICS تبني رسمًا بيانيًا <em>للوصول</em>، والذي يعين لكل عينة مسافة <code class="docutils literal notranslate"><span class="pre">reachability_</span></code>، ونقطة داخل سمة <code class="docutils literal notranslate"><span class="pre">ordering_</span></code> للكتلة؛ يتم تعيين هاتين السمتين عند ملاءمة النموذج، ويتم استخدامهما لتحديد عضوية الكتلة.
إذا تم تشغيل OPTICS بالقيمة الافتراضية <em>inf</em> المحددة لـ <code class="docutils literal notranslate"><span class="pre">max_eps</span></code>، فيمكن إجراء استخراج الكتلة على غرار DBSCAN بشكل متكرر في وقت خطي لأي قيمة <code class="docutils literal notranslate"><span class="pre">eps</span></code> معينة باستخدام طريقة <code class="docutils literal notranslate"><span class="pre">cluster_optics_dbscan</span></code>.
سيؤدي تعيين <code class="docutils literal notranslate"><span class="pre">max_eps</span></code> إلى قيمة أقل إلى أوقات تشغيل أقصر، ويمكن اعتباره كحد أقصى لنصف قطر الحي من كل نقطة للعثور على نقاط أخرى يمكن الوصول إليها.</p>
<p class="centered">
<strong><a class="reference external" href="../auto_examples/cluster/plot_optics.html"><img alt="optics_results" src="../_images/sphx_glr_plot_optics_001.png" style="width: 500.0px; height: 350.0px;" /></a></strong></p><p>تسمح مسافات <em>الوصول</em> التي تم إنشاؤها بواسطة OPTICS باستخراج كثافة متغيرة للمجموعات داخل مجموعة بيانات واحدة.
كما هو موضح في الرسم البياني أعلاه، فإن الجمع بين مسافات <em>الوصول</em> و <code class="docutils literal notranslate"><span class="pre">ordering_</span></code> لمجموعة البيانات ينتج عنه <em>مخطط وصول</em>، حيث يتم تمثيل كثافة النقطة على المحور ص، ويتم ترتيب النقاط بحيث تكون النقاط القريبة متجاورة.
ينتج عن &quot;قطع&quot; مخطط الوصول عند قيمة واحدة نتائج تشبه DBSCAN؛ يتم تصنيف جميع النقاط فوق &quot;القطع&quot; على أنها ضوضاء، وفي كل مرة يكون هناك فاصل عند القراءة من اليسار إلى اليمين يدل على مجموعة جديدة.
ينظر استخراج الكتلة الافتراضي مع OPTICS إلى المنحدرات الحادة داخل الرسم البياني للعثور على مجموعات، ويمكن للمستخدم تحديد ما يعتبر منحدرًا حادًا باستخدام المعلمة <code class="docutils literal notranslate"><span class="pre">xi</span></code>.
هناك أيضًا إمكانيات أخرى للتحليل على الرسم البياني نفسه، مثل إنشاء تمثيلات هرمية للبيانات من خلال مخططات شجرية لمخطط الوصول، ويمكن الوصول إلى التسلسل الهرمي للمجموعات التي تم اكتشافها بواسطة الخوارزمية من خلال معلمة <code class="docutils literal notranslate"><span class="pre">cluster_hierarchy_</span></code>.
تم ترميز الرسم البياني أعلاه بالألوان بحيث تتطابق ألوان الكتلة في الفضاء المستوي مع مجموعات القطعة الخطية لمخطط الوصول.
لاحظ أن المجموعات الزرقاء والحمراء متجاورة في مخطط الوصول، ويمكن تمثيلها بشكل هرمي كأطفال لمجموعة أصل أكبر.</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><span class="xref std std-ref">sphx_glr_auto_examples_cluster/plot_optics.py</span></p></li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="مقارنة-مع-dbscan">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">مقارنة مع DBSCAN<a class="headerlink" href="#مقارنة-مع-dbscan" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">تتشابه النتائج من طريقة OPTICS <code class="docutils literal notranslate"><span class="pre">cluster_optics_dbscan</span></code> و DBSCAN إلى حد كبير، ولكنها ليست متطابقة دائمًا؛ على وجه التحديد، تسمية نقاط المحيط والضوضاء.
ويرجع ذلك جزئيًا إلى أن العينات الأولى من كل منطقة كثيفة تتم معالجتها بواسطة OPTICS لها قيمة وصول كبيرة بينما تكون قريبة من نقاط أخرى في منطقتها، وبالتالي سيتم تمييزها أحيانًا على أنها ضوضاء بدلاً من المحيط.
يؤثر هذا على النقاط المجاورة عندما يتم اعتبارها مرشحة ليتم تمييزها إما على أنها محيطية أو ضوضاء.</p>
<p class="sd-card-text">لاحظ أنه بالنسبة لأي قيمة مفردة لـ <code class="docutils literal notranslate"><span class="pre">eps</span></code>، فإن DBSCAN يميل إلى أن يكون له وقت تشغيل أقصر من OPTICS؛ ومع ذلك، بالنسبة للتشغيلات المتكررة عند قيم <code class="docutils literal notranslate"><span class="pre">eps</span></code> المتغيرة، قد يتطلب تشغيل OPTICS واحد وقت تشغيل تراكمي أقل من DBSCAN.
من المهم أيضًا ملاحظة أن ناتجOPTICS قريب من DBSCAN فقط إذا كان <code class="docutils literal notranslate"><span class="pre">eps</span></code> و <code class="docutils literal notranslate"><span class="pre">max_eps</span></code> قريبين.</p>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="التعقيد-الحسابي">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">التعقيد الحسابي<a class="headerlink" href="#التعقيد-الحسابي" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">يتم استخدام أشجار الفهرسة المكانية لتجنب حساب مصفوفة المسافة الكاملة، والسماح باستخدام الذاكرة بكفاءة على مجموعات كبيرة من العينات.
يمكن توفير مقاييس مسافة مختلفة عبر الكلمة الرئيسية <code class="docutils literal notranslate"><span class="pre">metric</span></code>.</p>
<p class="sd-card-text">بالنسبة لمجموعات البيانات الكبيرة، يمكن الحصول على نتائج مماثلة (ولكن ليست متطابقة) عبر <a class="reference internal" href="generated/sklearn.cluster.HDBSCAN.html#sklearn.cluster.HDBSCAN" title="sklearn.cluster.HDBSCAN"><code class="xref py py-class docutils literal notranslate"><span class="pre">HDBSCAN</span></code></a>.
يكون تنفيذ HDBSCAN متعدد الخيوط، وله تعقيد وقت تشغيل خوارزمي أفضل من OPTICS، على حساب تحجيم ذاكرة أسوأ.
بالنسبة لمجموعات البيانات الكبيرة للغاية التي تستنفد ذاكرة النظام باستخدام HDBSCAN، سيحافظ OPTICS على تحجيم الذاكرة <span class="math notranslate nohighlight">\(n\)</span> (بدلاً من <span class="math notranslate nohighlight">\(n^2\)</span>)؛ ومع ذلك، من المحتمل أن يكون ضبط معلمة <code class="docutils literal notranslate"><span class="pre">max_eps</span></code> ضروريًا لإعطاء حل في قدر معقول من وقت الجدار.</p>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-8">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-8" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text">&quot;OPTICS: ترتيب النقاط لتحديد بنية التجميع.&quot; Ankerst،
Mihael، Markus M. Breunig، Hans-Peter Kriegel، و Jörg Sander. في سجل ACM Sigmod،
المجلد. 28، لا. 2، ص 49-60. ACM، 1999.</p></li>
</ul>
</div>
</details></section>
<section id="birch">
<span id="id24"></span><h2><span class="section-number">2.3.10. </span>BIRCH<a class="headerlink" href="#birch" title="Link to this heading">#</a></h2>
<p>يبني <a class="reference internal" href="generated/sklearn.cluster.Birch.html#sklearn.cluster.Birch" title="sklearn.cluster.Birch"><code class="xref py py-class docutils literal notranslate"><span class="pre">Birch</span></code></a> شجرة تسمى شجرة ميزات التجميع (CFT) للبيانات المحددة.
يتم ضغط البيانات بشكل أساسي مع فقدان إلى مجموعة من عقد ميزات التجميع (عقد CF).
تحتوي عقد CF على عدد من المجموعات الفرعية تسمى المجموعات الفرعية لميزات التجميع (المجموعات الفرعية CF) ويمكن أن تحتوي هذه المجموعات الفرعية CF الموجودة في عقد CF غير الطرفية على عقد CF كأطفال.</p>
<p>تحتوي المجموعات الفرعية CF على المعلومات الضرورية للتجميع مما يمنع الحاجة إلى الاحتفاظ ببيانات الإدخال بأكملها في الذاكرة.
تشمل هذه المعلومات:</p>
<ul class="simple">
<li><p>عدد العينات في مجموعة فرعية.</p></li>
<li><p>المجموع الخطي - متجه n-الأبعاد يحتوي على مجموع جميع العينات</p></li>
<li><p>المجموع التربيعي - مجموع القاعدة التربيعية L2 لجميع العينات.</p></li>
<li><p>النقاط المركزية - لتجنب إعادة حساب المجموع الخطي / n_samples.</p></li>
<li><p>القاعدة التربيعية للنقاط المركزية.</p></li>
</ul>
<p>تحتوي خوارزمية BIRCH على معلمتين، العتبة وعامل التفرع.
يحد عامل التفرع من عدد المجموعات الفرعية في عقدة وتحدد العتبة المسافة بين العينة الداخلة والمجموعات الفرعية الموجودة.</p>
<p>يمكن اعتبار هذه الخوارزمية مثيلًا أو طريقة لتقليل البيانات، لأنها تقلل بيانات الإدخال إلى مجموعة من المجموعات الفرعية التي يتم الحصول عليها مباشرةً من أوراق CFT.
يمكن معالجة هذه البيانات المخفضة بشكل أكبر عن طريق تغذيتها في مجمع عالمي.
يمكن تعيين هذا المجمع العالمي بواسطة <code class="docutils literal notranslate"><span class="pre">n_clusters</span></code>.
إذا تم تعيين <code class="docutils literal notranslate"><span class="pre">n_clusters</span></code> على لا شيء، فسيتم قراءة المجموعات الفرعية من الأوراق مباشرةً، وإلا فإن خطوة التجميع العالمية تصنف هذه المجموعات الفرعية إلى مجموعات عالمية (تسميات) ويتم تعيين العينات إلى التسمية العالمية لأقرب مجموعة فرعية.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="وصف-الخوارزمية-2">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">وصف الخوارزمية<a class="headerlink" href="#وصف-الخوارزمية-2" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text">يتم إدخال عينة جديدة في جذر شجرة CF وهي عقدة CF.
ثم يتم دمجها مع المجموعة الفرعية للجذر، التي لها أصغر نصف قطر بعد الدمج، مقيدة بشروط العتبة وعامل التفرع.
إذا كانت المجموعة الفرعية تحتوي على أي عقدة فرعية، فسيتم ذلك بشكل متكرر حتى تصل إلى ورقة.
بعد العثور على أقرب مجموعة فرعية في الورقة، يتم تحديث خصائص هذه المجموعة الفرعية والمجموعات الفرعية الأصل بشكل متكرر.</p></li>
<li><p class="sd-card-text">إذا كان نصف قطر المجموعة الفرعية التي تم الحصول عليها عن طريق دمج العينة الجديدة وأقرب مجموعة فرعية أكبر من مربع العتبة وإذا كان عدد المجموعات الفرعية أكبر من عامل التفرع، فسيتم تخصيص مساحة مؤقتًا لهذه العينة الجديدة.
يتم أخذ أبعد مجموعتين فرعيتين ويتم تقسيم المجموعات الفرعية إلى مجموعتين على أساس المسافة بين هاتين المجموعتين الفرعيتين.</p></li>
<li><p class="sd-card-text">إذا كانت عقدة التقسيم هذه تحتوي على مجموعة فرعية أصلية وكان هناك مساحة لمجموعة فرعية جديدة، فسيتم تقسيم الأصل إلى قسمين.
إذا لم تكن هناك مساحة، فسيتم تقسيم هذه العقدة مرة أخرى إلى قسمين وتستمر العملية بشكل متكرر، حتى تصل إلى الجذر.</p></li>
</ul>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="birch-أو-minibatchkmeans؟">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">BIRCH أو MiniBatchKMeans؟<a class="headerlink" href="#birch-أو-minibatchkmeans؟" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text">BIRCH لا يتناسب بشكل جيد مع البيانات عالية الأبعاد.
كقاعدة عامة، إذا كان <code class="docutils literal notranslate"><span class="pre">n_features</span></code> أكبر من عشرين، فمن الأفضل عمومًا استخدام MiniBatchKMeans.</p></li>
<li><p class="sd-card-text">إذا كان عدد مثيلات البيانات بحاجة إلى تقليل، أو إذا أراد المرء عددًا كبيرًا من المجموعات الفرعية إما كخطوة معالجة مسبقة أو غير ذلك، فإن BIRCH يكون أكثر فائدة من MiniBatchKMeans.</p></li>
</ul>
<a class="reference external image-reference" href="../auto_examples/cluster/plot_birch_vs_minibatchkmeans.html"><img alt="../_images/sphx_glr_plot_birch_vs_minibatchkmeans_001.png" src="../_images/sphx_glr_plot_birch_vs_minibatchkmeans_001.png" />
</a>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="كيفية-استخدام-partial_fit؟">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">كيفية استخدام partial_fit؟<a class="headerlink" href="#كيفية-استخدام-partial_fit؟" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">لتجنب حساب التجميع العالمي، لكل استدعاء لـ <code class="docutils literal notranslate"><span class="pre">partial_fit</span></code>، يُنصح المستخدم بما يلي:</p>
<ol class="arabic simple">
<li><p class="sd-card-text">لتعيين <code class="docutils literal notranslate"><span class="pre">n_clusters=None</span></code> في البداية.</p></li>
<li><p class="sd-card-text">تدريب جميع البيانات عن طريق استدعاءات متعددة لـ partial_fit.</p></li>
<li><p class="sd-card-text">قم بتعيين <code class="docutils literal notranslate"><span class="pre">n_clusters</span></code> إلى القيمة المطلوبة باستخدام <code class="docutils literal notranslate"><span class="pre">brc.set_params(n_clusters=n_clusters)</span></code>.</p></li>
<li><p class="sd-card-text">اتصل بـ <code class="docutils literal notranslate"><span class="pre">partial_fit</span></code> أخيرًا بدون وسيطات، أي <code class="docutils literal notranslate"><span class="pre">brc.partial_fit()</span></code> الذي يقوم بإجراء التجميع العالمي.</p></li>
</ol>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-9">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-9" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text">Tian Zhang، Raghu Ramakrishnan، Maron Livny BIRCH: طريقة فعالة لتجميع البيانات لقواعد البيانات الكبيرة.
<a class="reference external" href="https://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf">https://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf</a></p></li>
<li><p class="sd-card-text">Roberto Perdisci JBirch - تنفيذ Java لخوارزمية تجميع BIRCH
<a class="reference external" href="https://code.google.com/archive/p/jbirch">https://code.google.com/archive/p/jbirch</a></p></li>
</ul>
</div>
</details></section>
<section id="clustering-evaluation">
<span id="id25"></span><h2><span class="section-number">2.3.11. </span>تقييم أداء التجميع<a class="headerlink" href="#clustering-evaluation" title="Link to this heading">#</a></h2>
<p>إن تقييم أداء خوارزمية التجميع ليس بالأمر السهل مثل حساب عدد الأخطاء أو دقة واستدعاء خوارزمية تصنيف خاضعة للإشراف.
على وجه الخصوص، يجب ألا يأخذ أي مقياس تقييم القيم المطلقة لتسميات الكتلة في الاعتبار، بل بالأحرى ما إذا كان هذا التجميع يحدد فواصل للبيانات مشابهة لمجموعة بيانات الحقيقة الأساسية لبعض الفئات أو يلبي بعض الافتراضات مثل أن الأعضاء الذين ينتمون إلى نفس الفئة أكثر تشابهًا من أعضاء من فئات مختلفة وفقًا لبعض مقياس التشابه.</p>
<section id="adjusted-rand-score">
<span id="rand-score"></span><span id="id26"></span><h3><span class="section-number">2.3.11.1. </span>مؤشر راند<a class="headerlink" href="#adjusted-rand-score" title="Link to this heading">#</a></h3>
<p>بالنظر إلى معرفة تعيينات فئة الحقيقة الأساسية <code class="docutils literal notranslate"><span class="pre">labels_true</span></code> وتعيينات خوارزمية التجميع الخاصة بنا لنفس العينات <code class="docutils literal notranslate"><span class="pre">labels_pred</span></code>، فإن <strong>مؤشر راند (المعدل أو غير المعدل)</strong> هو دالة تقيس <strong>تشابه</strong> التعيينين، مع تجاهل التباديل:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">rand_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">0.66...</span>
</pre></div>
</div>
<p>لا يضمن مؤشر راند الحصول على قيمة قريبة من 0.0 لوضع العلامات العشوائية.
يصحح مؤشر راند المعدل <strong>للصدفة</strong> وسيعطي مثل هذا الأساس.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">adjusted_rand_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">0.24...</span>
</pre></div>
</div>
<p>كما هو الحال مع جميع مقاييس التجميع، يمكن للمرء تبديل 0 و 1 في التسميات المتوقعة، وإعادة تسمية 2 إلى 3، والحصول على نفس النتيجة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">labels_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">rand_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">0.66...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">adjusted_rand_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">0.24...</span>
</pre></div>
</div>
<p>علاوة على ذلك، فإن كل من <a class="reference internal" href="generated/sklearn.metrics.rand_score.html#sklearn.metrics.rand_score" title="sklearn.metrics.rand_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">rand_score</span></code></a> <a class="reference internal" href="generated/sklearn.metrics.adjusted_rand_score.html#sklearn.metrics.adjusted_rand_score" title="sklearn.metrics.adjusted_rand_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">adjusted_rand_score</span></code></a> <strong>متماثلان</strong>: لا يؤدي تبديل الوسيطة إلى تغيير الدرجات.
وبالتالي يمكن استخدامها كمقاييس <strong>توافق</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">rand_score</span><span class="p">(</span><span class="n">labels_pred</span><span class="p">,</span> <span class="n">labels_true</span><span class="p">)</span>
<span class="go">0.66...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">adjusted_rand_score</span><span class="p">(</span><span class="n">labels_pred</span><span class="p">,</span> <span class="n">labels_true</span><span class="p">)</span>
<span class="go">0.24...</span>
</pre></div>
</div>
<p>يتم تسجيل التسمية المثالية 1.0:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">labels_pred</span> <span class="o">=</span> <span class="n">labels_true</span><span class="p">[:]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">rand_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">adjusted_rand_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">1.0</span>
</pre></div>
</div>
<p>التسميات المتوافقة بشكل سيئ (على سبيل المثال، التسميات المستقلة) لها درجات أقل، وبالنسبة لمؤشر راند المعدل، ستكون النتيجة سلبية أو قريبة من الصفر. ومع ذلك، بالنسبة لمؤشر راند غير المعدل، فإن النتيجة، على الرغم من انخفاضها، لن تكون بالضرورة قريبة من الصفر.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">labels_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">rand_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">0.39...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">adjusted_rand_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">-0.07...</span>
</pre></div>
</div>
<aside class="topic">
<p class="topic-title">المزايا:</p>
<ul class="simple">
<li><p><strong>قابلية التفسير</strong>: يتناسب مؤشر راند غير المعدل مع عدد أزواج العينات التي تكون تسمياتها متماثلة في كل من <code class="docutils literal notranslate"><span class="pre">labels_pred</span></code> و <code class="docutils literal notranslate"><span class="pre">labels_true</span></code>، أو مختلفة في كليهما.</p></li>
<li><p><strong>تعيينات التسميات العشوائية (الموحدة) لها درجة مؤشر راند معدلة قريبة من 0.0</strong> لأي قيمة لـ <code class="docutils literal notranslate"><span class="pre">n_clusters</span></code> و <code class="docutils literal notranslate"><span class="pre">n_samples</span></code> (وهو ليس هو الحال بالنسبة لمؤشر راند غير المعدل أو مقياس V على سبيل المثال).</p></li>
<li><p><strong>النطاق المحدود</strong>: تشير القيم المنخفضة إلى تسميات مختلفة، والتجمعات المتشابهة لها مؤشر راند مرتفع (معدل أو غير معدل)، 1.0 هي درجة التطابق المثالية. نطاق النتيجة هو [0، 1] لمؤشر راند غير المعدل و [-0.5، 1] لمؤشر راند المعدل.</p></li>
<li><p><strong>لا يوجد افتراض على بنية الكتلة</strong>: يمكن استخدام مؤشر راند (المعدل أو غير المعدل) لمقارنة جميع أنواع خوارزميات التجميع، ويمكن استخدامه لمقارنة خوارزميات التجميع مثل k-means التي تفترض أشكالًا متجانسة الخواص مع نتائج خوارزميات التجميع الطيفي التي يمكنها العثور على مجموعات ذات أشكال &quot;مطوية&quot;.</p></li>
</ul>
</aside>
<aside class="topic">
<p class="topic-title">العيوب:</p>
<ul>
<li><p>على عكس القصور الذاتي، <strong>يتطلب مؤشر راند (المعدل أو غير المعدل) معرفة فئات الحقيقة الأساسية</strong> والتي لا تتوفر تقريبًا في الممارسة العملية أو تتطلب تعيينًا يدويًا بواسطة التعليقات التوضيحية البشرية (كما هو الحال في إعداد التعلم الخاضع للإشراف).</p>
<p>ومع ذلك، يمكن أن يكون مؤشر راند (المعدل أو غير المعدل) مفيدًا أيضًا في إعداد غير خاضع للإشراف تمامًا كحجر بناء لمؤشر توافق يمكن استخدامه لاختيار نموذج التجميع (TODO).</p>
</li>
<li><p><strong>غالبًا ما يكون مؤشر راند غير المعدل قريبًا من 1.0</strong> حتى لو اختلفت التجمعات نفسها بشكل كبير.
يمكن فهم ذلك عند تفسير مؤشر راند على أنه دقة تسمية زوج العناصر الناتجة عن التجميعات:
في الممارسة العملية، غالبًا ما تكون هناك غالبية من أزواج العناصر التي يتم تعيين تسمية الزوج <code class="docutils literal notranslate"><span class="pre">different</span></code>  لها تحت كل من التجميع المتوقع والحقيقة الأساسية مما ينتج عنه نسبة عالية من تسميات الأزواج التي تتفق، مما يؤدي لاحقًا إلى درجة عالية.</p></li>
</ul>
</aside>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><span class="xref std std-ref">sphx_glr_auto_examples_cluster/plot_adjusted_for_chance_measures.py</span>:
تحليل تأثير حجم مجموعة البيانات على قيمة مقاييس التجميع للتعيينات العشوائية.</p></li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="الصيغة-الرياضية">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">الصيغة الرياضية<a class="headerlink" href="#الصيغة-الرياضية" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">إذا كان C هو تعيين فئة الحقيقة الأساسية و K هو التجميع، فلنحدد
<span class="math notranslate nohighlight">\(a\)</span> و <span class="math notranslate nohighlight">\(b\)</span> على النحو التالي:</p>
<ul class="simple">
<li><p class="sd-card-text"><span class="math notranslate nohighlight">\(a\)</span>، عدد أزواج العناصر الموجودة في نفس المجموعة في C وفي نفس المجموعة في K</p></li>
<li><p class="sd-card-text"><span class="math notranslate nohighlight">\(b\)</span>، عدد أزواج العناصر الموجودة في مجموعات مختلفة في C وفي مجموعات مختلفة في K
ثم يتم إعطاء مؤشر راند غير المعدل بواسطة:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\text{RI} = \frac{a + b}{C_2^{n_{samples}}}\]</div>
<p class="sd-card-text">حيث <span class="math notranslate nohighlight">\(C_2^{n_{samples}}\)</span> هو إجمالي عدد الأزواج الممكنة في مجموعة البيانات.
لا يهم ما إذا كان الحساب يتم على أزواج مرتبة أو أزواج غير مرتبة طالما يتم إجراء الحساب بشكل متسق.</p>
<p class="sd-card-text">ومع ذلك، لا يضمن مؤشر راند أن تعيينات التسميات العشوائية ستحصل على قيمة قريبة من الصفر (خاصة إذا كان عدد المجموعات من نفس حجم عدد العينات).</p>
<p class="sd-card-text">لمواجهة هذا التأثير، يمكننا خصم RI المتوقع <span class="math notranslate nohighlight">\(E[\text{RI}]\)</span> لوضع العلامات العشوائية عن طريق تحديد مؤشر راند المعدل على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[\text{ARI} = \frac{\text{RI} - E[\text{RI}]}{\max(\text{RI}) - E[\text{RI}]}\]</div>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-10">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-10" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text"><a class="reference external" href="https://link.springer.com/article/10.1007%2FBF01908075">مقارنة الأقسام</a> L. Hubert and P.
Arabie، Journal of Classification 1985</p></li>
<li><p class="sd-card-text"><a class="reference external" href="https://psycnet.apa.org/record/2004-17801-007">خصائص مؤشر راند المعدل لـ Hubert-Arabie</a> D. Steinley، Psychological
Methods 2004</p></li>
<li><p class="sd-card-text"><a class="reference external" href="https://en.wikipedia.org/wiki/Rand_index#Adjusted_Rand_index">إدخال ويكيبيديا لمؤشر راند</a></p></li>
<li><p class="sd-card-text"><a class="reference external" href="https://doi.org/10.1007/s11634-022-00491-w">Minimum adjusted Rand index for two clusterings of a given size, 2022, J. E. Chacón and A. I. Rastrojo</a></p></li>
</ul>
</div>
</details></section>
<section id="mutual-info-score">
<span id="id29"></span><h3><span class="section-number">2.3.11.2. </span>درجات المعلومات المتبادلة<a class="headerlink" href="#mutual-info-score" title="Link to this heading">#</a></h3>
<p>بالنظر إلى معرفة تعيينات فئة الحقيقة الأساسية <code class="docutils literal notranslate"><span class="pre">labels_true</span></code> وتعيينات خوارزمية التجميع الخاصة بنا لنفس العينات <code class="docutils literal notranslate"><span class="pre">labels_pred</span></code>، فإن <strong>المعلومات المتبادلة</strong> هي دالة تقيس <strong>اتفاق</strong> التعيينين، مع تجاهل التباديل.
يتوفر إصداران مختلفان معياريان من هذا المقياس، <strong>المعلومات المتبادلة المعيارية (NMI)</strong> و <strong>المعلومات المتبادلة المعدلة (AMI)</strong>.
غالبًا ما يتم استخدام NMI في الأدبيات، بينما تم اقتراح AMI مؤخرًا و <strong>يتم تطبيعه مقابل الصدفة</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">adjusted_mutual_info_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>  
<span class="go">0.22504...</span>
</pre></div>
</div>
<p>يمكن للمرء تبديل 0 و 1 في التسميات المتوقعة، وإعادة تسمية 2 إلى 3 والحصول على نفس النتيجة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">labels_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">adjusted_mutual_info_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>  
<span class="go">0.22504...</span>
</pre></div>
</div>
<p>كل، <a class="reference internal" href="generated/sklearn.metrics.mutual_info_score.html#sklearn.metrics.mutual_info_score" title="sklearn.metrics.mutual_info_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">mutual_info_score</span></code></a>، <a class="reference internal" href="generated/sklearn.metrics.adjusted_mutual_info_score.html#sklearn.metrics.adjusted_mutual_info_score" title="sklearn.metrics.adjusted_mutual_info_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">adjusted_mutual_info_score</span></code></a> و <a class="reference internal" href="generated/sklearn.metrics.normalized_mutual_info_score.html#sklearn.metrics.normalized_mutual_info_score" title="sklearn.metrics.normalized_mutual_info_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">normalized_mutual_info_score</span></code></a> متماثلة: لا يؤدي تبديل الوسيطة إلى تغيير النتيجة.
وبالتالي يمكن استخدامها كمقياس <strong>توافق</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">adjusted_mutual_info_score</span><span class="p">(</span><span class="n">labels_pred</span><span class="p">,</span> <span class="n">labels_true</span><span class="p">)</span>  
<span class="go">0.22504...</span>
</pre></div>
</div>
<p>يتم تسجيل التسمية المثالية 1.0:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">labels_pred</span> <span class="o">=</span> <span class="n">labels_true</span><span class="p">[:]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">adjusted_mutual_info_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>  
<span class="go">1.0</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">normalized_mutual_info_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>  
<span class="go">1.0</span>
</pre></div>
</div>
<p>هذا ليس صحيحًا بالنسبة لـ <code class="docutils literal notranslate"><span class="pre">mutual_info_score</span></code>، وبالتالي يصعب الحكم عليه:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">mutual_info_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>  
<span class="go">0.69...</span>
</pre></div>
</div>
<p>التسميات السيئة (على سبيل المثال، التسميات المستقلة) لها درجات غير موجبة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">labels_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">adjusted_mutual_info_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>  
<span class="go">-0.10526...</span>
</pre></div>
</div>
<aside class="topic">
<p class="topic-title">المزايا:</p>
<ul class="simple">
<li><p><strong>تعيينات التسميات العشوائية (الموحدة) لها درجة AMI قريبة من 0.0</strong> لأي قيمة لـ <code class="docutils literal notranslate"><span class="pre">n_clusters</span></code> و <code class="docutils literal notranslate"><span class="pre">n_samples</span></code> (وهو ليس هو الحال بالنسبة للمعلومات المتبادلة الأولية أو مقياس V على سبيل المثال).</p></li>
<li><p><strong>الحد الأعلى 1</strong>: تشير القيم القريبة من الصفر إلى تعيينين للتسميات مستقلان إلى حد كبير، بينما تشير القيم القريبة من واحد إلى اتفاق كبير.
علاوة على ذلك، يشير AMI من 1 بالضبط إلى أن تعيينات التسمية متساوية (مع أو بدون تبديل).</p></li>
</ul>
</aside>
<aside class="topic">
<p class="topic-title">العيوب:</p>
<ul>
<li><p>على عكس القصور الذاتي، <strong>تتطلب المقاييس المستندة إلى MI معرفة فئات الحقيقة الأساسية</strong> بينما لا تتوفر تقريبًا في الممارسة العملية أو تتطلب تعيينًا يدويًا بواسطة التعليقات التوضيحية البشرية (كما هو الحال في إعداد التعلم الخاضع للإشراف).</p>
<p>ومع ذلك، يمكن أن تكون المقاييس المستندة إلى MI مفيدة أيضًا في إعداد غير خاضع للإشراف تمامًا كحجر بناء لمؤشر توافق يمكن استخدامه لاختيار نموذج التجميع.</p>
</li>
<li><p>NMI و MI غير معدلين ضد الصدفة.</p></li>
</ul>
</aside>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><span class="xref std std-ref">sphx_glr_auto_examples_cluster/plot_adjusted_for_chance_measures.py</span>:
تحليل تأثير حجم مجموعة البيانات على قيمة مقاييس التجميع للتعيينات العشوائية.
يتضمن هذا المثال أيضًا مؤشر راند المعدل.</p></li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="الصيغة-الرياضية-2">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">الصيغة الرياضية<a class="headerlink" href="#الصيغة-الرياضية-2" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">افترض تعيينين للتسميات (لنفس الكائنات N)، <span class="math notranslate nohighlight">\(U\)</span> و <span class="math notranslate nohighlight">\(V\)</span>.
إنتروبياهم هو مقدار عدم اليقين لمجموعة قسم، محددة بواسطة:</p>
<div class="math notranslate nohighlight">
\[H(U) = - \sum_{i=1}^{|U|}P(i)\log(P(i))\]</div>
<p class="sd-card-text">حيث <span class="math notranslate nohighlight">\(P(i) = |U_i| / N\)</span> هو احتمال أن يكون الكائن الذي تم اختياره عشوائيًا من <span class="math notranslate nohighlight">\(U\)</span> يقع في الفئة <span class="math notranslate nohighlight">\(U_i\)</span>. وبالمثل بالنسبة لـ <span class="math notranslate nohighlight">\(V\)</span>:</p>
<div class="math notranslate nohighlight">
\[H(V) = - \sum_{j=1}^{|V|}P'(j)\log(P'(j))\]</div>
<p class="sd-card-text">مع <span class="math notranslate nohighlight">\(P'(j) = |V_j| / N\)</span>. يتم حساب المعلومات المتبادلة (MI) بين <span class="math notranslate nohighlight">\(U\)</span> و <span class="math notranslate nohighlight">\(V\)</span> بواسطة:</p>
<div class="math notranslate nohighlight">
\[\text{MI}(U, V) = \sum_{i=1}^{|U|}\sum_{j=1}^{|V|}P(i, j)\log\left(\frac{P(i,j)}{P(i)P'(j)}\right)\]</div>
<p class="sd-card-text">حيث <span class="math notranslate nohighlight">\(P(i, j) = |U_i \cap V_j| / N\)</span> هو احتمال أن يكون الكائن الذي تم اختياره عشوائيًا يقع في كل من الفئتين <span class="math notranslate nohighlight">\(U_i\)</span> و <span class="math notranslate nohighlight">\(V_j\)</span>.</p>
<p class="sd-card-text">يمكن أيضًا التعبير عنها في صيغة أصلية للمجموعة:</p>
<div class="math notranslate nohighlight">
\[\text{MI}(U, V) = \sum_{i=1}^{|U|} \sum_{j=1}^{|V|} \frac{|U_i \cap V_j|}{N}\log\left(\frac{N|U_i \cap V_j|}{|U_i||V_j|}\right)\]</div>
<p class="sd-card-text">يتم تعريف المعلومات المتبادلة المعيارية على أنها</p>
<div class="math notranslate nohighlight">
\[\text{NMI}(U, V) = \frac{\text{MI}(U, V)}{\text{mean}(H(U), H(V))}\]</div>
<p class="sd-card-text">لا يتم تعديل قيمة المعلومات المتبادلة هذه وكذلك المتغير المعياري للصدفة وستميل إلى الزيادة مع زيادة عدد التسميات (المجموعات) المختلفة، بغض النظر عن المقدار الفعلي &quot;للمعلومات المتبادلة&quot; بين تعيينات التسميات.</p>
<p class="sd-card-text">يمكن حساب القيمة المتوقعة للمعلومات المتبادلة باستخدام المعادلة التالية <a class="reference internal" href="#veb2009" id="id30"><span>[VEB2009]</span></a>.
في هذه المعادلة، <span class="math notranslate nohighlight">\(a_i = |U_i|\)</span> (عدد العناصر في <span class="math notranslate nohighlight">\(U_i\)</span>) و <span class="math notranslate nohighlight">\(b_j = |V_j|\)</span> (عدد العناصر في <span class="math notranslate nohighlight">\(V_j\)</span>).</p>
<div class="math notranslate nohighlight">
\[E[\text{MI}(U,V)]=\sum_{i=1}^{|U|} \sum_{j=1}^{|V|} \sum_{n_{ij}=(a_i+b_j-N)^+
}^{\min(a_i, b_j)} \frac{n_{ij}}{N}\log \left( \frac{ N.n_{ij}}{a_i b_j}\right)
\frac{a_i!b_j!(N-a_i)!(N-b_j)!}{N!n_{ij}!(a_i-n_{ij})!(b_j-n_{ij})!
(N-a_i-b_j+n_{ij})!}\]</div>
<p class="sd-card-text">باستخدام القيمة المتوقعة، يمكن بعد ذلك حساب المعلومات المتبادلة المعدلة باستخدام نموذج مشابه لنموذج مؤشر راند المعدل:</p>
<div class="math notranslate nohighlight">
\[\text{AMI} = \frac{\text{MI} - E[\text{MI}]}{\text{mean}(H(U), H(V)) - E[\text{MI}]}\]</div>
<p class="sd-card-text">بالنسبة للمعلومات المتبادلة المعيارية والمعلومات المتبادلة المعدلة، تكون قيمة التطبيع عادةً بعض المتوسط <em>المعمم</em> لإنتروبيا كل تجميع.
توجد وسائل معممة مختلفة، ولا توجد قواعد ثابتة لتفضيل واحد على الآخر.
القرار إلى حد كبير على أساس كل مجال على حدة؛ على سبيل المثال، في اكتشاف المجتمع، يكون المتوسط الحسابي هو الأكثر شيوعًا.
توفر كل طريقة تطبيع &quot;سلوكيات متشابهة نوعياً&quot; <a class="reference internal" href="#yat2016" id="id31"><span>[YAT2016]</span></a>.
في تطبيقنا، يتم التحكم في ذلك بواسطة معلمة <code class="docutils literal notranslate"><span class="pre">average_method</span></code>.</p>
<p class="sd-card-text">أطلق فينه وآخرون (2010) على متغيرات NMI و AMI من خلال طريقة حساب المتوسط <a class="reference internal" href="#veb2010" id="id32"><span>[VEB2010]</span></a>.
متوسطات 'sqrt' و 'sum' هي الوسائل الهندسية والحسابية؛ نستخدم هذه الأسماء الأكثر شيوعًا.</p>
<p class="rubric">المراجع</p>
<ul class="simple">
<li><p class="sd-card-text">Strehl، Alexander، and Joydeep Ghosh (2002).
&quot;Cluster ensembles - a knowledge reuse framework for combining multiple partitions&quot;.
Journal of Machine Learning Research 3: 583-617. <a class="reference external" href="http://strehl.com/download/strehl-jmlr02.pdf">doi:10.1162/153244303321897735</a>.</p></li>
<li><p class="sd-card-text"><a class="reference external" href="https://en.wikipedia.org/wiki/Mutual_Information">إدخال ويكيبيديا للمعلومات المتبادلة (المعيارية)</a></p></li>
<li><p class="sd-card-text"><a class="reference external" href="https://en.wikipedia.org/wiki/Adjusted_Mutual_Information">إدخال ويكيبيديا للمعلومات المتبادلة المعدلة</a></p></li>
</ul>
<div role="list" class="citation-list">
<div class="citation" id="veb2009" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id30">VEB2009</a><span class="fn-bracket">]</span></span>
<p class="sd-card-text">Vinh، Epps، and Bailey، (2009).
&quot;Information theoretic measures for clusterings comparison&quot;.
Proceedings of the 26th Annual International Conference on Machine Learning - ICML '09. <a class="reference external" href="https://dl.acm.org/citation.cfm?doid=1553374.1553511">doi:10.1145/1553374.1553511</a>. ISBN 9781605585161.</p>
</div>
<div class="citation" id="veb2010" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id32">VEB2010</a><span class="fn-bracket">]</span></span>
<p class="sd-card-text">Vinh، Epps، and Bailey، (2010).
&quot;Information Theoretic Measures for Clusterings Comparison: Variants, Properties, Normalization and Correction for Chance&quot;. JMLR
&lt;<a class="reference external" href="https://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf">https://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf</a>&gt;</p>
</div>
<div class="citation" id="yat2016" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id31">YAT2016</a><span class="fn-bracket">]</span></span>
<p class="sd-card-text">Yang، Algesheimer، and Tessone، (2016).
&quot;A comparative analysis of community detection algorithms on artificial networks&quot;.
Scientific Reports 6: 30750. <a class="reference external" href="https://www.nature.com/articles/srep30750">doi:10.1038/srep30750</a>.</p>
</div>
</div>
</div>
</details></section>
<section id="v">
<span id="homogeneity-completeness"></span><h3><span class="section-number">2.3.11.3. </span>التجانس والاكتمال ومقياس V<a class="headerlink" href="#v" title="Link to this heading">#</a></h3>
<p>بالنظر إلى معرفة تعيينات فئة الحقيقة الأساسية للعينات، من الممكن تحديد بعض المقاييس البديهية باستخدام تحليل الانتروبيا الشرطي.</p>
<p>على وجه الخصوص، حدد روزنبرغ وهيرشبيرج (2007) الهدفين المرغوب فيهما التاليين لأي تعيين كتلة:</p>
<ul class="simple">
<li><p><strong>التجانس</strong>: تحتوي كل مجموعة على أعضاء من فئة واحدة فقط.</p></li>
<li><p><strong>الاكتمال</strong>: يتم تعيين جميع أعضاء فئة معينة إلى نفس المجموعة.</p></li>
</ul>
<p>يمكننا تحويل هذه المفاهيم إلى درجات <a class="reference internal" href="generated/sklearn.metrics.homogeneity_score.html#sklearn.metrics.homogeneity_score" title="sklearn.metrics.homogeneity_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">homogeneity_score</span></code></a> و <a class="reference internal" href="generated/sklearn.metrics.completeness_score.html#sklearn.metrics.completeness_score" title="sklearn.metrics.completeness_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">completeness_score</span></code></a>.
كلاهما محدد أدناه بـ 0.0 وفوق بـ 1.0 (الأعلى أفضل):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">homogeneity_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">0.66...</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">completeness_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">0.42...</span>
</pre></div>
</div>
<p>يتم حساب متوسطها التوافقي المسمى <strong>مقياس V</strong> بواسطة <a class="reference internal" href="generated/sklearn.metrics.v_measure_score.html#sklearn.metrics.v_measure_score" title="sklearn.metrics.v_measure_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">v_measure_score</span></code></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">v_measure_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">0.51...</span>
</pre></div>
</div>
<p>صيغة هذه الدالة هي كما يلي:</p>
<div class="math notranslate nohighlight">
\[v = \frac{(1 + \beta) \times \text{homogeneity} \times \text{completeness}}{(\beta \times \text{homogeneity} + \text{completeness})}\]</div>
<p><code class="docutils literal notranslate"><span class="pre">beta</span></code>  افتراضيًا إلى قيمة 1.0، ولكن لاستخدام قيمة أقل من 1 لـ beta:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">v_measure_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="go">0.54...</span>
</pre></div>
</div>
<p>سيتم عزو المزيد من الوزن إلى التجانس، واستخدام قيمة أكبر من 1:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">v_measure_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.8</span><span class="p">)</span>
<span class="go">0.48...</span>
</pre></div>
</div>
<p>سيتم عزو المزيد من الوزن إلى الاكتمال.</p>
<p>مقياس V مكافئ في الواقع للمعلومات المتبادلة (NMI)
تمت مناقشته أعلاه، مع كون دالة التجميع هي المتوسط الحسابي <a class="reference internal" href="#b2011" id="id35"><span>[B2011]</span></a>.</p>
<p>يمكن حساب التجانس والاكتمال ومقياس V في وقت واحد باستخدام <a class="reference internal" href="generated/sklearn.metrics.homogeneity_completeness_v_measure.html#sklearn.metrics.homogeneity_completeness_v_measure" title="sklearn.metrics.homogeneity_completeness_v_measure"><code class="xref py py-func docutils literal notranslate"><span class="pre">homogeneity_completeness_v_measure</span></code></a> على النحو التالي:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">homogeneity_completeness_v_measure</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">(0.66..., 0.42..., 0.51...)</span>
</pre></div>
</div>
<p>تعيين التجميع التالي أفضل قليلاً، لأنه متجانس ولكنه غير مكتمل:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">labels_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">homogeneity_completeness_v_measure</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">(1.0, 0.68..., 0.81...)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">ملاحظة</p>
<p><a class="reference internal" href="generated/sklearn.metrics.v_measure_score.html#sklearn.metrics.v_measure_score" title="sklearn.metrics.v_measure_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">v_measure_score</span></code></a> <strong>متماثل</strong>: يمكن استخدامه لتقييم <strong>اتفاق</strong> تعيينين مستقلين على نفس مجموعة البيانات.</p>
<p>هذا ليس هو الحال بالنسبة لـ <a class="reference internal" href="generated/sklearn.metrics.completeness_score.html#sklearn.metrics.completeness_score" title="sklearn.metrics.completeness_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">completeness_score</span></code></a> و <a class="reference internal" href="generated/sklearn.metrics.homogeneity_score.html#sklearn.metrics.homogeneity_score" title="sklearn.metrics.homogeneity_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">homogeneity_score</span></code></a>: كلاهما مرتبط بالعلاقة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">homogeneity_score</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span> <span class="o">==</span> <span class="n">completeness_score</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
</pre></div>
</div>
</div>
<aside class="topic">
<p class="topic-title">المزايا:</p>
<ul class="simple">
<li><p><strong>الدرجات المحدودة</strong>: 0.0 سيئة بقدر الإمكان، 1.0 هي درجة مثالية.</p></li>
<li><p>التفسير البديهي: يمكن <strong>تحليل</strong> التجميع مع مقياس V السيئ <strong>نوعياً من حيث التجانس والاكتمال</strong> للشعور بشكل أفضل بنوع &quot;الأخطاء&quot; التي يتم ارتكابها بواسطة التعيين.</p></li>
<li><p><strong>لا يوجد افتراض على بنية الكتلة</strong>: يمكن استخدامه لمقارنة خوارزميات التجميع مثل k-means التي تفترض أشكالًا متجانسة الخواص مع نتائج خوارزميات التجميع الطيفي التي يمكنها العثور على مجموعات ذات أشكال &quot;مطوية&quot;.</p></li>
</ul>
</aside>
<aside class="topic">
<p class="topic-title">العيوب:</p>
<ul>
<li><p><strong>لم يتم تطبيع</strong> المقاييس التي تم تقديمها مسبقًا <strong>فيما يتعلق بالتسمية العشوائية</strong>: هذا يعني أنه اعتمادًا على عدد العينات والمجموعات وفئات الحقيقة الأساسية، لن ينتج عن التسمية العشوائية تمامًا دائمًا نفس القيم للتجانس والاكتمال وبالتالي مقياس v.
على وجه الخصوص، <strong>لن تؤدي التسمية العشوائية إلى درجات صفرية خاصةً عندما يكون عدد المجموعات كبيرًا</strong>.</p>
<p>يمكن تجاهل هذه المشكلة بأمان عندما يكون عدد العينات أكثر من ألف ويكون عدد المجموعات أقل من 10.
<strong>بالنسبة لأحجام العينات الأصغر أو عدد أكبر من المجموعات، يكون من الآمن استخدام فهرس معدل مثل مؤشر راند المعدل (ARI)</strong>.</p>
</li>
</ul>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/cluster/plot_adjusted_for_chance_measures.html"><img alt="../_images/sphx_glr_plot_adjusted_for_chance_measures_001.png" src="../_images/sphx_glr_plot_adjusted_for_chance_measures_001.png" style="width: 640.0px; height: 480.0px;" />
</a>
</figure>
<ul class="simple">
<li><p><strong>تتطلب هذه المقاييس معرفة فئات الحقيقة الأساسية</strong> بينما لا تتوفر تقريبًا في الممارسة العملية أو تتطلب تعيينًا يدويًا بواسطة التعليقات التوضيحية البشرية (كما هو الحال في إعداد التعلم الخاضع للإشراف).</p></li>
</ul>
</aside>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><span class="xref std std-ref">sphx_glr_auto_examples_cluster/plot_adjusted_for_chance_measures.py</span>: تحليل تأثير حجم مجموعة البيانات على قيمة مقاييس التجميع للتعيينات العشوائية.</p></li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="الصيغة-الرياضية-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">الصيغة الرياضية<a class="headerlink" href="#الصيغة-الرياضية-3" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">يتم إعطاء درجات التجانس والاكتمال رسميًا بواسطة:</p>
<div class="math notranslate nohighlight">
\[h = 1 - \frac{H(C|K)}{H(C)}\]</div>
<div class="math notranslate nohighlight">
\[c = 1 - \frac{H(K|C)}{H(K)}\]</div>
<p class="sd-card-text">حيث <span class="math notranslate nohighlight">\(H(C|K)\)</span> هو <strong>الانتروبيا الشرطية للفئات بالنظر إلى تعيينات الكتلة</strong> ويتم إعطاؤها بواسطة:</p>
<div class="math notranslate nohighlight">
\[H(C|K) = - \sum_{c=1}^{|C|} \sum_{k=1}^{|K|} \frac{n_{c,k}}{n}
\cdot \log\left(\frac{n_{c,k}}{n_k}\right)\]</div>
<p class="sd-card-text">و <span class="math notranslate nohighlight">\(H(C)\)</span> هو <strong>إنتروبيا الفئات</strong> ويتم إعطاؤها بواسطة:</p>
<div class="math notranslate nohighlight">
\[H(C) = - \sum_{c=1}^{|C|} \frac{n_c}{n} \cdot \log\left(\frac{n_c}{n}\right)\]</div>
<p class="sd-card-text">مع <span class="math notranslate nohighlight">\(n\)</span> إجمالي عدد العينات، <span class="math notranslate nohighlight">\(n_c\)</span> و <span class="math notranslate nohighlight">\(n_k\)</span> عدد العينات التي تنتمي على التوالي إلى الفئة <span class="math notranslate nohighlight">\(c\)</span> والكتلة <span class="math notranslate nohighlight">\(k\)</span>، وأخيرًا <span class="math notranslate nohighlight">\(n_{c,k}\)</span> عدد العينات من الفئة <span class="math notranslate nohighlight">\(c\)</span> المعينة إلى الكتلة <span class="math notranslate nohighlight">\(k\)</span>.</p>
<p class="sd-card-text">يتم تعريف <strong>الانتروبيا الشرطية للمجموعات بالنظر إلى الفئة</strong> <span class="math notranslate nohighlight">\(H(K|C)\)</span> و <strong>إنتروبيا المجموعات</strong> <span class="math notranslate nohighlight">\(H(K)\)</span> بطريقة متماثلة.</p>
<p class="sd-card-text">يحدد روزنبرغ وهيرشبيرج كذلك <strong>مقياس V</strong> على أنه <strong>المتوسط التوافقي للتجانس والاكتمال</strong>:</p>
<div class="math notranslate nohighlight">
\[v = 2 \cdot \frac{h \cdot c}{h + c}\]</div>
</div>
</details><p class="rubric">المراجع</p>
<ul class="simple">
<li><p><a class="reference external" href="https://aclweb.org/anthology/D/D07/D07-1043.pdf">V-Measure: A conditional entropy-based external cluster evaluation measure</a> Andrew Rosenberg and Julia Hirschberg، 2007</p></li>
</ul>
<div role="list" class="citation-list">
<div class="citation" id="b2011" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id35">B2011</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="http://www.cs.columbia.edu/~hila/hila-thesis-distributed.pdf">Identification and Characterization of Events in Social Media</a>، Hila Becker، PhD Thesis.</p>
</div>
</div>
</section>
<section id="fowlkes-mallows">
<span id="fowlkes-mallows-scores"></span><h3><span class="section-number">2.3.11.4. </span>درجات Fowlkes-Mallows<a class="headerlink" href="#fowlkes-mallows" title="Link to this heading">#</a></h3>
<p>يمكن استخدام مؤشر Fowlkes-Mallows (<a class="reference internal" href="generated/sklearn.metrics.fowlkes_mallows_score.html#sklearn.metrics.fowlkes_mallows_score" title="sklearn.metrics.fowlkes_mallows_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.fowlkes_mallows_score</span></code></a>) عندما تكون تعيينات فئة الحقيقة الأساسية للعينات معروفة.
يتم تعريف درجة Fowlkes-Mallows FMI على أنها المتوسط الهندسي للدقة والاستدعاء الزوجي:</p>
<div class="math notranslate nohighlight">
\[\text{FMI} = \frac{\text{TP}}{\sqrt{(\text{TP} + \text{FP}) (\text{TP} + \text{FN})}}\]</div>
<p>حيث <code class="docutils literal notranslate"><span class="pre">TP</span></code> هو عدد <strong>الإيجابيات الحقيقية</strong> (أي عدد أزواج النقاط التي تنتمي إلى نفس المجموعات في كل من التسميات الحقيقية والتسميات المتوقعة)، <code class="docutils literal notranslate"><span class="pre">FP</span></code> هو عدد <strong>الإيجابيات الكاذبة</strong> (أي عدد أزواج النقاط التي تنتمي إلى نفس المجموعات في التسميات الحقيقية وليس في التسميات المتوقعة) و <code class="docutils literal notranslate"><span class="pre">FN</span></code> هو عدد <strong>السلبيات الكاذبة</strong> (أي عدد أزواج النقاط التي تنتمي إلى نفس المجموعات في التسميات المتوقعة وليس في التسميات الحقيقية).</p>
<p>يتراوح النطاق من 0 إلى 1. تشير القيمة العالية إلى تشابه جيد بين مجموعتين.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">fowlkes_mallows_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">0.47140...</span>
</pre></div>
</div>
<p>يمكن للمرء تبديل 0 و 1 في التسميات المتوقعة، وإعادة تسمية 2 إلى 3 والحصول على نفس النتيجة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">labels_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">fowlkes_mallows_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">0.47140...</span>
</pre></div>
</div>
<p>يتم تسجيل التسمية المثالية 1.0:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">labels_pred</span> <span class="o">=</span> <span class="n">labels_true</span><span class="p">[:]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">fowlkes_mallows_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">1.0</span>
</pre></div>
</div>
<p>التسميات السيئة (على سبيل المثال، التسميات المستقلة) لها درجات صفرية:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">labels_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">fowlkes_mallows_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">0.0</span>
</pre></div>
</div>
<aside class="topic">
<p class="topic-title">المزايا:</p>
<ul class="simple">
<li><p><strong>تعيينات التسميات العشوائية (الموحدة) لها درجة FMI قريبة من 0.0</strong> لأي قيمة لـ <code class="docutils literal notranslate"><span class="pre">n_clusters</span></code> و <code class="docutils literal notranslate"><span class="pre">n_samples</span></code> (وهو ليس هو الحال بالنسبة للمعلومات المتبادلة الأولية أو مقياس V على سبيل المثال).</p></li>
<li><p><strong>الحد الأعلى عند 1</strong>: تشير القيم القريبة من الصفر إلى تعيينين للتسميات مستقلان إلى حد كبير، بينما تشير القيم القريبة من واحد إلى اتفاق كبير.
علاوة على ذلك، تشير قيم 0 بالضبط إلى تعيينات تسميات مستقلة <strong>بشكل خالص</strong> ويشير FMI من 1 بالضبط إلى أن تعيينات التسمية متساوية (مع أو بدون تبديل).</p></li>
<li><p><strong>لا يوجد افتراض على بنية الكتلة</strong>: يمكن استخدامه لمقارنة خوارزميات التجميع مثل k-means التي تفترض أشكالًا متجانسة الخواص مع نتائج خوارزميات التجميع الطيفي التي يمكنها العثور على مجموعات ذات أشكال &quot;مطوية&quot;.</p></li>
</ul>
</aside>
<aside class="topic">
<p class="topic-title">العيوب:</p>
<ul class="simple">
<li><p>على عكس القصور الذاتي، <strong>تتطلب المقاييس المستندة إلى FMI معرفة فئات الحقيقة الأساسية</strong> بينما لا تتوفر تقريبًا في الممارسة العملية أو تتطلب تعيينًا يدويًا بواسطة التعليقات التوضيحية البشرية (كما هو الحال في إعداد التعلم الخاضع للإشراف).</p></li>
</ul>
</aside>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-11">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-11" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text">E. B. Fowkles and C. L. Mallows، 1983. &quot;A method for comparing two hierarchical clusterings&quot;. Journal of the American Statistical Association.
<a class="reference external" href="https://www.tandfonline.com/doi/abs/10.1080/01621459.1983.10478008">https://www.tandfonline.com/doi/abs/10.1080/01621459.1983.10478008</a></p></li>
<li><p class="sd-card-text"><a class="reference external" href="https://en.wikipedia.org/wiki/Fowlkes-Mallows_index">إدخال ويكيبيديا لمؤشر Fowlkes-Mallows</a></p></li>
</ul>
</div>
</details></section>
<section id="silhouette">
<span id="silhouette-coefficient"></span><h3><span class="section-number">2.3.11.5. </span>معامل silhouette<a class="headerlink" href="#silhouette" title="Link to this heading">#</a></h3>
<p>إذا لم تكن تسميات الحقيقة الأساسية معروفة، فيجب إجراء التقييم باستخدام النموذج نفسه.
معامل silhouette (<a class="reference internal" href="generated/sklearn.metrics.silhouette_score.html#sklearn.metrics.silhouette_score" title="sklearn.metrics.silhouette_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.silhouette_score</span></code></a>) هو مثال على هذا التقييم، حيث ترتبط درجة معامل silhouette الأعلى بنموذج بمجموعات محددة بشكل أفضل.
يتم تعريف معامل silhouette لكل عينة ويتكون من درجتين:</p>
<ul class="simple">
<li><p><strong>a</strong>: متوسط المسافة بين عينة وجميع النقاط الأخرى في نفس الفئة.</p></li>
<li><p><strong>b</strong>: متوسط المسافة بين عينة وجميع النقاط الأخرى في <em>أقرب مجموعة تالية</em>.</p></li>
</ul>
<p>ثم يتم إعطاء معامل silhouette <em>s</em> لعينة واحدة على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[s = \frac{b - a}{max(a, b)}\]</div>
<p>يتم إعطاء معامل silhouette لمجموعة من العينات على أنه متوسط معامل silhouette لكل عينة.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">pairwise_distances</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>في الاستخدام العادي، يتم تطبيق معامل silhouette على نتائج تحليل الكتلة.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kmeans_model</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">kmeans_model</span><span class="o">.</span><span class="n">labels_</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">silhouette_score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="go">0.55...</span>
</pre></div>
</div>
<aside class="topic">
<p class="topic-title">المزايا:</p>
<ul class="simple">
<li><p>النتيجة محدودة بين -1 للتجميع غير الصحيح و +1 للتجميع عالي الكثافة.
تشير الدرجات حول الصفر إلى مجموعات متداخلة.</p></li>
<li><p>تكون النتيجة أعلى عندما تكون المجموعات كثيفة ومفصولة جيدًا، مما يتعلق بمفهوم قياسي للكتلة.</p></li>
</ul>
</aside>
<aside class="topic">
<p class="topic-title">العيوب:</p>
<ul class="simple">
<li><p>يكون معامل silhouette أعلى بشكل عام للمجموعات المحدبة من مفاهيم المجموعات الأخرى، مثل المجموعات القائمة على الكثافة مثل تلك التي تم الحصول عليها من خلال DBSCAN.</p></li>
</ul>
</aside>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><span class="xref std std-ref">sphx_glr_auto_examples_cluster/plot_kmeans_silhouette_analysis.py</span>: في هذا المثال، يتم استخدام تحليل silhouette لاختيار قيمة مثالية لـ n_clusters.</p></li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-12">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-12" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text">Peter J. Rousseeuw (1987). <a class="reference external" href="https://doi.org/10.1016/0377-0427(87)90125-7">&quot;Silhouettes: a Graphical Aid to the Interpretation and Validation of Cluster Analysis&quot;</a>.
Computational and Applied Mathematics 20: 53-65.</p></li>
</ul>
</div>
</details></section>
<section id="calinski-harabasz">
<span id="calinski-harabasz-index"></span><h3><span class="section-number">2.3.11.6. </span>مؤشر Calinski-Harabasz<a class="headerlink" href="#calinski-harabasz" title="Link to this heading">#</a></h3>
<p>إذا لم تكن تسميات الحقيقة الأساسية معروفة، فيمكن استخدام مؤشر Calinski-Harabasz (<a class="reference internal" href="generated/sklearn.metrics.calinski_harabasz_score.html#sklearn.metrics.calinski_harabasz_score" title="sklearn.metrics.calinski_harabasz_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.calinski_harabasz_score</span></code></a>) - المعروف أيضًا باسم معيار نسبة التباين - لتقييم النموذج، حيث ترتبط درجة Calinski-Harabasz الأعلى بنموذج بمجموعات محددة بشكل أفضل.</p>
<p>المؤشر هو نسبة مجموع تشتت بين المجموعات وتشتت داخل المجموعات لجميع المجموعات (حيث يتم تعريف التشتت على أنه مجموع المسافات المربعة):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">pairwise_distances</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>في الاستخدام العادي، يتم تطبيق مؤشر Calinski-Harabasz على نتائج تحليل الكتلة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kmeans_model</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">kmeans_model</span><span class="o">.</span><span class="n">labels_</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">calinski_harabasz_score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
<span class="go">561.59...</span>
</pre></div>
</div>
<aside class="topic">
<p class="topic-title">المزايا:</p>
<ul class="simple">
<li><p>تكون النتيجة أعلى عندما تكون المجموعات كثيفة ومفصولة جيدًا، مما يتعلق بمفهوم قياسي للكتلة.</p></li>
<li><p>النتيجة سريعة الحساب.</p></li>
</ul>
</aside>
<aside class="topic">
<p class="topic-title">العيوب:</p>
<ul class="simple">
<li><p>يكون مؤشر Calinski-Harabasz أعلى بشكل عام للمجموعات المحدبة من مفاهيم المجموعات الأخرى، مثل المجموعات القائمة على الكثافة مثل تلك التي تم الحصول عليها من خلال DBSCAN.</p></li>
</ul>
</aside>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="الصيغة-الرياضية-4">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">الصيغة الرياضية<a class="headerlink" href="#الصيغة-الرياضية-4" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">بالنسبة لمجموعة من البيانات <span class="math notranslate nohighlight">\(E\)</span> ذات الحجم <span class="math notranslate nohighlight">\(n_E\)</span> التي تم تجميعها في <span class="math notranslate nohighlight">\(k\)</span> مجموعات، يتم تعريف درجة Calinski-Harabasz <span class="math notranslate nohighlight">\(s\)</span> على أنها نسبة متوسط تشتت بين المجموعات وتشتت داخل الكتلة:</p>
<div class="math notranslate nohighlight">
\[s = \frac{\mathrm{tr}(B_k)}{\mathrm{tr}(W_k)} \times \frac{n_E - k}{k - 1}\]</div>
<p class="sd-card-text">حيث <span class="math notranslate nohighlight">\(\mathrm{tr}(B_k)\)</span> هو تتبع مصفوفة التشتت بين المجموعات و <span class="math notranslate nohighlight">\(\mathrm{tr}(W_k)\)</span> هو تتبع مصفوفة التشتت داخل الكتلة المحددة بواسطة:</p>
<div class="math notranslate nohighlight">
\[W_k = \sum_{q=1}^k \sum_{x \in C_q} (x - c_q) (x - c_q)^T\]</div>
<div class="math notranslate nohighlight">
\[B_k = \sum_{q=1}^k n_q (c_q - c_E) (c_q - c_E)^T\]</div>
<p class="sd-card-text">مع <span class="math notranslate nohighlight">\(C_q\)</span> مجموعة النقاط في الكتلة <span class="math notranslate nohighlight">\(q\)</span>، <span class="math notranslate nohighlight">\(c_q\)</span> مركز الكتلة <span class="math notranslate nohighlight">\(q\)</span>، <span class="math notranslate nohighlight">\(c_E\)</span> مركز <span class="math notranslate nohighlight">\(E\)</span>، و <span class="math notranslate nohighlight">\(n_q\)</span> عدد النقاط في الكتلة <span class="math notranslate nohighlight">\(q\)</span>.</p>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-13">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-13" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text">Caliński، T.، &amp; Harabasz، J. (1974). <a class="reference external" href="https://www.researchgate.net/publication/233096619_A_Dendrite_Method_for_Cluster_Analysis">&quot;A Dendrite Method for Cluster Analysis&quot;</a>.
<a class="reference external" href="https://doi.org/10.1080/03610927408827101">Communications in Statistics-theory and Methods 3: 1-27</a>.</p></li>
</ul>
</div>
</details></section>
<section id="davies-bouldin">
<span id="davies-bouldin-index"></span><h3><span class="section-number">2.3.11.7. </span>مؤشر Davies-Bouldin<a class="headerlink" href="#davies-bouldin" title="Link to this heading">#</a></h3>
<p>إذا لم تكن تسميات الحقيقة الأساسية معروفة، فيمكن استخدام مؤشر Davies-Bouldin (<a class="reference internal" href="generated/sklearn.metrics.davies_bouldin_score.html#sklearn.metrics.davies_bouldin_score" title="sklearn.metrics.davies_bouldin_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.davies_bouldin_score</span></code></a>) لتقييم النموذج، حيث يرتبط مؤشر Davies-Bouldin الأقل بنموذج مع فصل أفضل بين المجموعات.</p>
<p>يشير هذا المؤشر إلى متوسط &quot;التشابه&quot; بين المجموعات، حيث يكون التشابه مقياسًا يقارن المسافة بين المجموعات بحجم المجموعات نفسها.</p>
<p>الصفر هو أدنى درجة ممكنة. تشير القيم الأقرب إلى الصفر إلى قسم أفضل.</p>
<p>في الاستخدام العادي، يتم تطبيق مؤشر Davies-Bouldin على نتائج تحليل الكتلة على النحو التالي:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">davies_bouldin_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">davies_bouldin_score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
<span class="go">0.666...</span>
</pre></div>
</div>
<aside class="topic">
<p class="topic-title">المزايا:</p>
<ul class="simple">
<li><p>حساب Davies-Bouldin أبسط من حساب درجات silhouette.</p></li>
<li><p>يعتمد المؤشر فقط على الكميات والميزات المتأصلة في مجموعة البيانات حيث لا يستخدم حسابه سوى المسافات النقطية.</p></li>
</ul>
</aside>
<aside class="topic">
<p class="topic-title">العيوب:</p>
<ul class="simple">
<li><p>يكون مؤشر Davies-Boulding أعلى بشكل عام للمجموعات المحدبة من مفاهيم المجموعات الأخرى، مثل المجموعات القائمة على الكثافة مثل تلك التي تم الحصول عليها من DBSCAN.</p></li>
<li><p>استخدام مسافة النقطه المركزية يحد من مقياس المسافة إلى الفضاء الإقليدي.</p></li>
</ul>
</aside>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="الصيغة-الرياضية-5">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">الصيغة الرياضية<a class="headerlink" href="#الصيغة-الرياضية-5" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">يتم تعريف المؤشر على أنه متوسط التشابه بين كل مجموعة <span class="math notranslate nohighlight">\(C_i\)</span> لـ <span class="math notranslate nohighlight">\(i=1, ..., k\)</span> وأكثرها تشابهًا <span class="math notranslate nohighlight">\(C_j\)</span>.
في سياق هذا المؤشر، يتم تعريف التشابه على أنه مقياس <span class="math notranslate nohighlight">\(R_{ij}\)</span> الذي يتداول:</p>
<ul class="simple">
<li><p class="sd-card-text"><span class="math notranslate nohighlight">\(s_i\)</span>، متوسط المسافة بين كل نقطة من الكتلة <span class="math notranslate nohighlight">\(i\)</span> والنقطه المركزية لتلك الكتلة - تُعرف أيضًا باسم قطر الكتلة.</p></li>
<li><p class="sd-card-text"><span class="math notranslate nohighlight">\(d_{ij}\)</span>، المسافة بين مراكز الكتلة <span class="math notranslate nohighlight">\(i\)</span> و <span class="math notranslate nohighlight">\(j\)</span>.</p></li>
</ul>
<p class="sd-card-text">اختيار بسيط لبناء <span class="math notranslate nohighlight">\(R_{ij}\)</span> بحيث يكون غير سالب ومتماثل هو:</p>
<div class="math notranslate nohighlight">
\[R_{ij} = \frac{s_i + s_j}{d_{ij}}\]</div>
<p class="sd-card-text">ثم يتم تعريف مؤشر Davies-Bouldin على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[DB = \frac{1}{k} \sum_{i=1}^k \max_{i \neq j} R_{ij}\]</div>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-14">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-14" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text">Davies، David L.؛ Bouldin، Donald W. (1979). <a class="reference external" href="https://doi.org/10.1109/TPAMI.1979.4766909">&quot;A Cluster Separation
Measure&quot;</a> IEEE Transactions on Pattern Analysis
and Machine Intelligence. PAMI-1 (2): 224-227.</p></li>
<li><p class="sd-card-text">Halkidi، Maria؛ Batistakis، Yannis؛ Vazirgiannis، Michalis (2001). <a class="reference external" href="https://doi.org/10.1023/A:1012801612483">&quot;On
Clustering Validation Techniques&quot;</a> Journal of
Intelligent Information Systems، 17 (2-3)، 107-145.</p></li>
<li><p class="sd-card-text"><a class="reference external" href="https://en.wikipedia.org/wiki/Davies-Bouldin_index">إدخال ويكيبيديا لمؤشر Davies-Bouldin</a>.</p></li>
</ul>
</div>
</details></section>
<section id="contingency-matrix">
<span id="id38"></span><h3><span class="section-number">2.3.11.8. </span>مصفوفة الطوارئ<a class="headerlink" href="#contingency-matrix" title="Link to this heading">#</a></h3>
<p>تُبلغ مصفوفة الطوارئ (<a class="reference internal" href="generated/sklearn.metrics.cluster.contingency_matrix.html#sklearn.metrics.cluster.contingency_matrix" title="sklearn.metrics.cluster.contingency_matrix"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.cluster.contingency_matrix</span></code></a>) عن أصل التقاطع لكل زوج من المجموعات الحقيقية / المتوقعة.
توفر مصفوفة الطوارئ إحصائيات كافية لجميع مقاييس التجميع حيث تكون العينات مستقلة وموزعة بشكل متماثل ولا يحتاج المرء إلى مراعاة عدم تجميع بعض المثيلات.</p>
<p>فيما يلي مثال:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics.cluster</span> <span class="kn">import</span> <span class="n">contingency_matrix</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">contingency_matrix</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">array([[2, 1, 0],</span>
<span class="go">       [0, 1, 2]])</span>
</pre></div>
</div>
<p>يشير الصف الأول من مصفوفة الإخراج إلى وجود ثلاث عينات تكون مجموعتها الحقيقية هي &quot;a&quot;.
من بينها، اثنان في الكتلة المتوقعة 0، وواحد في 1، ولا يوجد أي منها في 2.
ويشير الصف الثاني إلى وجود ثلاث عينات تكون مجموعتها الحقيقية هي &quot;b&quot;.
من بينها، لا يوجد أي منها في الكتلة المتوقعة 0، وواحد في 1 واثنان في 2.</p>
<p><a class="reference internal" href="model_evaluation.html#confusion-matrix"><span class="std std-ref">مصفوفة الارتباك</span></a> للتصنيف هي مصفوفة طوارئ مربعة حيث يتوافق ترتيب الصفوف والأعمدة مع قائمة الفئات.</p>
<aside class="topic">
<p class="topic-title">المزايا:</p>
<ul class="simple">
<li><p>يسمح بفحص انتشار كل مجموعة حقيقية عبر المجموعات المتوقعة والعكس صحيح.</p></li>
<li><p>يتم استخدام جدول الطوارئ المحسوب عادةً في حساب إحصائية التشابه (مثل الإحصائيات الأخرى المدرجة في هذه الوثيقة) بين التجميعين.</p></li>
</ul>
</aside>
<aside class="topic">
<p class="topic-title">العيوب:</p>
<ul class="simple">
<li><p>من السهل تفسير مصفوفة الطوارئ لعدد صغير من المجموعات، ولكن يصعب تفسيرها لعدد كبير من المجموعات.</p></li>
<li><p>لا يعطي مقياسًا واحدًا لاستخدامه كهدف لتحسين التجميع.</p></li>
</ul>
</aside>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-15">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-15" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text"><a class="reference external" href="https://en.wikipedia.org/wiki/Contingency_table">إدخال ويكيبيديا لمصفوفة الطوارئ</a></p></li>
</ul>
</div>
</details></section>
<section id="pair-confusion-matrix">
<span id="id40"></span><h3><span class="section-number">2.3.11.9. </span>مصفوفة ارتباك الزوج<a class="headerlink" href="#pair-confusion-matrix" title="Link to this heading">#</a></h3>
<p>مصفوفة ارتباك الزوج (<a class="reference internal" href="generated/sklearn.metrics.cluster.pair_confusion_matrix.html#sklearn.metrics.cluster.pair_confusion_matrix" title="sklearn.metrics.cluster.pair_confusion_matrix"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.cluster.pair_confusion_matrix</span></code></a>) هي مصفوفة تشابه 2x2</p>
<div class="math notranslate nohighlight">
\[\begin{split}C = \left[\begin{matrix}
C_{00} &amp; C_{01} \\
C_{10} &amp; C_{11}
\end{matrix}\right]\end{split}\]</div>
<p>بين تجميعين محسوبين من خلال النظر في جميع أزواج العينات وعد أزواج يتم تعيينها في نفس المجموعات أو في مجموعات مختلفة تحت التجميعات الحقيقية والمتوقعة.</p>
<p>لديها الإدخالات التالية:</p>
<p><span class="math notranslate nohighlight">\(C_{00}\)</span> : عدد الأزواج مع كلا التجميعين اللذين لا تحتوي عيناتهما على مجموعات معًا</p>
<p><span class="math notranslate nohighlight">\(C_{10}\)</span> : عدد الأزواج مع تجميع التسمية الحقيقية التي تحتوي على عينات مجمعة معًا ولكن التجميع الآخر لا يحتوي على عينات مجمعة معًا</p>
<p><span class="math notranslate nohighlight">\(C_{01}\)</span> : عدد الأزواج مع تجميع التسمية الحقيقية التي لا تحتوي على عينات مجمعة معًا ولكن التجميع الآخر يحتوي على عينات مجمعة معًا</p>
<p><span class="math notranslate nohighlight">\(C_{11}\)</span> : عدد الأزواج مع كلا التجميعين اللذين يحتويان على عينات مجمعة معًا</p>
<p>بالنظر إلى زوج من العينات التي تم تجميعها معًا كزوج إيجابي، كما هو الحال في التصنيف الثنائي، فإن عدد السلبيات الحقيقية هو <span class="math notranslate nohighlight">\(C_{00}\)</span>، والسلبيات الكاذبة هي <span class="math notranslate nohighlight">\(C_{10}\)</span>، والإيجابيات الحقيقية هي <span class="math notranslate nohighlight">\(C_{11}\)</span> والإيجابيات الكاذبة هي <span class="math notranslate nohighlight">\(C_{01}\)</span>.</p>
<p>تحتوي التسميات المتطابقة تمامًا على جميع الإدخالات غير الصفرية على القطر بغض النظر عن قيم التسمية الفعلية:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics.cluster</span> <span class="kn">import</span> <span class="n">pair_confusion_matrix</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pair_confusion_matrix</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="go">array([[8, 0],</span>
<span class="go">       [0, 4]])</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">pair_confusion_matrix</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="go">array([[8, 0],</span>
<span class="go">       [0, 4]])</span>
</pre></div>
</div>
<p>التسميات التي تعين جميع أعضاء الفئات إلى نفس المجموعات كاملة ولكنها قد لا تكون نقية دائمًا، وبالتالي يتم معاقبتها، ولديها بعض الإدخالات غير الصفرية خارج القطر:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">pair_confusion_matrix</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="go">array([[8, 2],</span>
<span class="go">       [0, 2]])</span>
</pre></div>
</div>
<p>المصفوفة ليست متماثلة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">pair_confusion_matrix</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="go">array([[8, 0],</span>
<span class="go">       [2, 2]])</span>
</pre></div>
</div>
<p>إذا تم تقسيم أعضاء الفئات تمامًا عبر مجموعات مختلفة، فإن التعيين غير مكتمل تمامًا، وبالتالي تحتوي المصفوفة على جميع إدخالات القطر الصفرية:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">pair_confusion_matrix</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="go">array([[ 0,  0],</span>
<span class="go">       [12,  0]])</span>
</pre></div>
</div>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-16">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-16" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text"><a class="reference external" href="https://doi.org/10.1007/BF01908075">&quot;Comparing Partitions&quot;</a> L. Hubert and P. Arabie،
Journal of Classification 1985</p></li>
</ul>
</div>
</details></section>
</section>
</section>


                </article>
              
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="prev-next-area">
    <a class="left-prev"
       href="manifold.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">السابق</p>
        <p class="prev-next-title"><span class="section-number">2.2. </span>تعلم المشعبات</p>
      </div>
    </a>
    <a class="right-next"
       href="biclustering.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">التالي</p>
        <p class="prev-next-title"><span class="section-number">2.4. </span>التجميع الثنائي</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>
                </footer>
              
              
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">2.3.1. نظرة عامة على طرق التجميع</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#k-means">2.3.2. K-means</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">2.3.2.1. التوازي منخفض المستوى</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mini-batch-k-means">2.3.2.2. Mini Batch K-Means</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#affinity-propagation">2.3.3. انتشار التقارب</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mean-shift">2.3.4. Mean Shift</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spectral-clustering">2.3.5. التجميع الطيفي</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">2.3.5.1. استراتيجيات تعيين التسميات المختلفة</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#spectral-clustering-graph">2.3.5.2. الرسوم البيانية للتجميع الطيفي</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hierarchical-clustering">2.3.6. التجميع الهرمي</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ward">2.3.6.1. نوع الارتباط المختلف: ارتباط Ward، كامل، متوسط، وفردي</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id14">2.3.6.2. تصور التسلسل الهرمي للكتلة</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id15">2.3.6.3. إضافة قيود الاتصال</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id16">2.3.6.4. تغيير المقياس</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bisecting-k-means">2.3.6.5. Bisecting K-Means</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dbscan">2.3.7. DBSCAN</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hdbscan">2.3.8. HDBSCAN</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id20">2.3.8.1. رسم بياني للوصول المتبادل</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id22">2.3.8.2. التجميع الهرمي</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optics">2.3.9. OPTICS</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#birch">2.3.10. BIRCH</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering-evaluation">2.3.11. تقييم أداء التجميع</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#adjusted-rand-score">2.3.11.1. مؤشر راند</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mutual-info-score">2.3.11.2. درجات المعلومات المتبادلة</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#v">2.3.11.3. التجانس والاكتمال ومقياس V</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fowlkes-mallows">2.3.11.4. درجات Fowlkes-Mallows</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#silhouette">2.3.11.5. معامل silhouette</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#calinski-harabasz">2.3.11.6. مؤشر Calinski-Harabasz</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#davies-bouldin">2.3.11.7. مؤشر Davies-Bouldin</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#contingency-matrix">2.3.11.8. مصفوفة الطوارئ</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pair-confusion-matrix">2.3.11.9. مصفوفة ارتباك الزوج</a></li>
</ul>
</li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">

  <div class="tocsection sourcelink">
    <a href="../_sources/modules/clustering.rst.txt">
      <i class="fa-solid fa-file-lines"></i> إظهار المصدر
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2007 - 2024, scikit-learn developers (BSD License) ### Translate into Arabic Eng. Ahmed Almaghz - 2024.
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
</div>

  </footer>
  </body>
</html>