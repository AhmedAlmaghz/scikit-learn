{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class='alert alert-warning'>\n\n# JupyterLite warning\n\nRunning the scikit-learn examples in JupyterLite is experimental and you may encounter some unexpected behavior.\n\nThe main difference is that imports will take a lot longer than usual, for example the first `import sklearn` can take roughly 10-20s.\n\nIf you notice problems, feel free to open an [issue](https://github.com/scikit-learn/scikit-learn/issues/new/choose) about it.\n</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# JupyterLite-specific code\nimport matplotlib\nimport pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# \u0631\u0633\u0645 \u0627\u062d\u062a\u0645\u0627\u0644\u064a\u0629 \u0627\u0644\u062a\u0635\u0646\u064a\u0641\n\n\u0627\u0631\u0633\u0645 \u0627\u062d\u062a\u0645\u0627\u0644\u064a\u0629 \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0644\u0645\u0635\u0646\u0641\u0627\u062a \u0645\u062e\u062a\u0644\u0641\u0629. \u0646\u0633\u062a\u062e\u062f\u0645 \u0645\u062c\u0645\u0648\u0639\u0629 \u0628\u064a\u0627\u0646\u0627\u062a \u0645\u0646 3 \u0641\u0626\u0627\u062a\u060c \u0648\u0646\u0635\u0646\u0641\u0647\u0627 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u0645\u0635\u0646\u0641 \u0627\u0644\u062f\u0639\u0645 \u0627\u0644\u0645\u0648\u062c\u0647\u060c \u0648\u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0644\u0648\u062c\u0633\u062a\u064a \u0627\u0644\u0645\u0639\u0627\u0642\u0628 L1 \u0648L2 (\u0645\u062a\u0639\u062f\u062f \u0627\u0644\u062d\u062f\u0648\u062f \u0645\u062a\u0639\u062f\u062f \u0627\u0644\u0641\u0626\u0627\u062a)\u060c \u0648\u0625\u0635\u062f\u0627\u0631 One-Vs-Rest \u0645\u0639 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0644\u0648\u062c\u0633\u062a\u064a\u060c \u0648\u062a\u0635\u0646\u064a\u0641 \u0639\u0645\u0644\u064a\u0629 \u062c\u0627\u0648\u0633.\n\nSVC \u0627\u0644\u062e\u0637\u064a \u0644\u064a\u0633 \u0645\u0635\u0646\u0641 \u0627\u062d\u062a\u0645\u0627\u0644\u064a \u0628\u0634\u0643\u0644 \u0627\u0641\u062a\u0631\u0627\u0636\u064a\u060c \u0648\u0644\u0643\u0646\u0647 \u064a\u062d\u062a\u0648\u064a \u0639\u0644\u0649 \u062e\u064a\u0627\u0631 \u0645\u0639\u0627\u064a\u0631\u0629 \u0645\u062f\u0645\u062c \u0645\u064f\u0645\u0643\u0651\u0646 \u0641\u064a \u0647\u0630\u0627 \u0627\u0644\u0645\u062b\u0627\u0644 (`probability=True`).\n\n\u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0644\u0648\u062c\u0633\u062a\u064a \u0645\u0639 One-Vs-Rest \u0644\u064a\u0633 \u0645\u0635\u0646\u0641 \u0645\u062a\u0639\u062f\u062f \u0627\u0644\u0641\u0626\u0627\u062a \u0628\u0634\u0643\u0644 \u0627\u0641\u062a\u0631\u0627\u0636\u064a. \u0648\u0646\u062a\u064a\u062c\u0629 \u0644\u0630\u0644\u0643\u060c \u064a\u0648\u0627\u062c\u0647 \u0635\u0639\u0648\u0628\u0629 \u0623\u0643\u0628\u0631 \u0641\u064a \u0641\u0635\u0644 \u0627\u0644\u0641\u0626\u0629 2 \u06483 \u0639\u0646 \u0627\u0644\u0645\u0635\u0646\u0641\u0627\u062a \u0627\u0644\u0623\u062e\u0631\u0649.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \u0627\u0644\u0645\u0624\u0644\u0641\u0648\u0646: \u0645\u0637\u0648\u0631\u064a \u0633\u0643\u0627\u064a\u062a-\u0644\u064a\u0631\u0646\n# \u0645\u0639\u0631\u0641-\u062a\u0631\u062e\u064a\u0635-SPDX: BSD-3-Clause\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib import cm\n\nfrom sklearn import datasets\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.inspection import DecisionBoundaryDisplay\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import SVC\n\niris = datasets.load_iris()\nX = iris.data[:, 0:2]  # \u0646\u0623\u062e\u0630 \u0641\u0642\u0637 \u0627\u0644\u062e\u0627\u0635\u064a\u062a\u064a\u0646 \u0627\u0644\u0623\u0648\u0644\u064a\u064a\u0646 \u0644\u0644\u062a\u0635\u0648\u0631\ny = iris.target\n\nn_features = X.shape[1]\n\nC = 10\nkernel = 1.0 * RBF([1.0, 1.0])  # \u0644\u062a\u0635\u0646\u064a\u0641 GPC\n\n# \u0625\u0646\u0634\u0627\u0621 \u0645\u0635\u0646\u0641\u0627\u062a \u0645\u062e\u062a\u0644\u0641\u0629.\nclassifiers = {\n    \"L1 logistic\": LogisticRegression(C=C, penalty=\"l1\", solver=\"saga\", max_iter=10000),\n    \"L2 logistic (Multinomial)\": LogisticRegression(\n        C=C, penalty=\"l2\", solver=\"saga\", max_iter=10000\n    ),\n    \"L2 logistic (OvR)\": OneVsRestClassifier(\n        LogisticRegression(C=C, penalty=\"l2\", solver=\"saga\", max_iter=10000)\n    ),\n    \"Linear SVC\": SVC(kernel=\"linear\", C=C, probability=True, random_state=0),\n    \"GPC\": GaussianProcessClassifier(kernel),\n}\n\nn_classifiers = len(classifiers)\n\nfig, axes = plt.subplots(\n    nrows=n_classifiers,\n    ncols=len(iris.target_names),\n    figsize=(3 * 2, n_classifiers * 2),\n)\nfor classifier_idx, (name, classifier) in enumerate(classifiers.items()):\n    y_pred = classifier.fit(X, y).predict(X)\n    accuracy = accuracy_score(y, y_pred)\n    print(f\"Accuracy (train) for {name}: {accuracy:0.1%}\")\n    for label in np.unique(y):\n        # \u0627\u0631\u0633\u0645 \u062a\u0642\u062f\u064a\u0631 \u0627\u0644\u0627\u062d\u062a\u0645\u0627\u0644\u064a\u0629 \u0627\u0644\u0645\u0642\u062f\u0645 \u0645\u0646 \u0627\u0644\u0645\u0635\u0646\u0641\n        disp = DecisionBoundaryDisplay.from_estimator(\n            classifier,\n            X,\n            response_method=\"predict_proba\",\n            class_of_interest=label,\n            ax=axes[classifier_idx, label],\n            vmin=0,\n            vmax=1,\n        )\n        axes[classifier_idx, label].set_title(f\"Class {label}\")\n        # \u0627\u0631\u0633\u0645 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u0645\u062a\u0648\u0642\u0639\u0629 \u0644\u0644\u0627\u0646\u062a\u0645\u0627\u0621 \u0625\u0644\u0649 \u0627\u0644\u0641\u0626\u0629 \u0627\u0644\u0645\u0639\u0637\u0627\u0629\n        mask_y_pred = y_pred == label\n        axes[classifier_idx, label].scatter(\n            X[mask_y_pred, 0], X[mask_y_pred, 1], marker=\"o\", c=\"w\", edgecolor=\"k\"\n        )\n        axes[classifier_idx, label].set(xticks=(), yticks=())\n    axes[classifier_idx, 0].set_ylabel(name)\n\nax = plt.axes([0.15, 0.04, 0.7, 0.02])\nplt.title(\"Probability\")\n_ = plt.colorbar(\n    cm.ScalarMappable(norm=None, cmap=\"viridis\"), cax=ax, orientation=\"horizontal\"\n)\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}