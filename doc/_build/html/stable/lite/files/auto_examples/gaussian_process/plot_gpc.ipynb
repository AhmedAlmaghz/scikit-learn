{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class='alert alert-warning'>\n\n# JupyterLite warning\n\nRunning the scikit-learn examples in JupyterLite is experimental and you may encounter some unexpected behavior.\n\nThe main difference is that imports will take a lot longer than usual, for example the first `import sklearn` can take roughly 10-20s.\n\nIf you notice problems, feel free to open an [issue](https://github.com/scikit-learn/scikit-learn/issues/new/choose) about it.\n</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# JupyterLite-specific code\nimport matplotlib\nimport pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# \u0627\u0644\u062a\u0646\u0628\u0624\u0627\u062a \u0627\u0644\u0627\u062d\u062a\u0645\u0627\u0644\u064a\u0629 \u0645\u0639 \u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0639\u0645\u0644\u064a\u0629 \u0627\u0644\u063a\u0627\u0648\u0633\u064a\u0629 (GPC)\n\n\u064a\u0648\u0636\u062d \u0647\u0630\u0627 \u0627\u0644\u0645\u062b\u0627\u0644 \u0627\u0644\u0627\u062d\u062a\u0645\u0627\u0644 \u0627\u0644\u0645\u062a\u0648\u0642\u0639 \u0644\u0640 GPC \u0644\u0646\u0648\u0627\u0629 RBF\n\u0645\u0639 \u062e\u064a\u0627\u0631\u0627\u062a \u0645\u062e\u062a\u0644\u0641\u0629 \u0644\u0644\u0645\u0639\u0644\u0645\u0627\u062a \u0627\u0644\u0641\u0627\u0626\u0642\u0629. \u064a\u064f\u0638\u0647\u0631 \u0627\u0644\u0634\u0643\u0644 \u0627\u0644\u0623\u0648\u0644 \u0627\u0644\u0627\u062d\u062a\u0645\u0627\u0644 \u0627\u0644\u0645\u062a\u0648\u0642\u0639 \u0644\u0640 GPC \u0645\u0639 \u0645\u0639\u0644\u0645\u0627\u062a \u0641\u0627\u0626\u0642\u0629 \u062a\u0645 \u0627\u062e\u062a\u064a\u0627\u0631\u0647\u0627 \u0639\u0634\u0648\u0627\u0626\u064a\u064b\u0627 \u0648\u0645\u0639 \u0627\u0644\u0645\u0639\u0644\u0645\u0627\u062a \u0627\u0644\u0641\u0627\u0626\u0642\u0629 \u0627\u0644\u0645\u0642\u0627\u0628\u0644\u0629 \u0644\u0623\u0643\u0628\u0631 \u0627\u062d\u062a\u0645\u0627\u0644 \u0647\u0627\u0645\u0634\u064a \u0644\u0648\u063a\u0627\u0631\u064a\u062a\u0645\u064a (LML).\n\n\u0628\u064a\u0646\u0645\u0627 \u062a\u062a\u0645\u062a\u0639 \u0627\u0644\u0645\u0639\u0644\u0645\u0627\u062a \u0627\u0644\u0641\u0627\u0626\u0642\u0629 \u0627\u0644\u062a\u064a \u062a\u0645 \u0627\u062e\u062a\u064a\u0627\u0631\u0647\u0627 \u0639\u0646 \u0637\u0631\u064a\u0642 \u062a\u062d\u0633\u064a\u0646 LML \u0628\u0627\u062d\u062a\u0645\u0627\u0644 \u0647\u0627\u0645\u0634\u064a \u0644\u0648\u063a\u0627\u0631\u064a\u062a\u0645\u064a \u0623\u0643\u0628\u0631 \u0628\u0643\u062b\u064a\u0631 \u060c \u0641\u0625\u0646\u0647\u0627 \u062a\u0639\u0645\u0644 \u0628\u0634\u0643\u0644 \u0623\u0633\u0648\u0623 \u0642\u0644\u064a\u0644\u0627\u064b \u0648\u0641\u0642\u064b\u0627 \u0644\u0640 log-loss \u0639\u0644\u0649 \u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u0627\u062e\u062a\u0628\u0627\u0631. \u064a\u064f\u0638\u0647\u0631 \u0627\u0644\u0634\u0643\u0644 \u0623\u0646 \u0647\u0630\u0627 \u0628\u0633\u0628\u0628 \u0623\u0646\u0647\u0627 \u062a\u064f\u0638\u0647\u0631 \u062a\u063a\u064a\u0631\u064b\u0627 \u062d\u0627\u062f\u064b\u0627 \u0641\u064a \u0627\u062d\u062a\u0645\u0627\u0644\u0627\u062a \u0627\u0644\u0641\u0626\u0629 \u0639\u0646\u062f \u062d\u062f\u0648\u062f \u0627\u0644\u0641\u0626\u0629 (\u0648\u0647\u0648 \u0623\u0645\u0631 \u062c\u064a\u062f) \u0648\u0644\u0643\u0646 \u0644\u062f\u064a\u0647\u0627 \u0627\u062d\u062a\u0645\u0627\u0644\u0627\u062a \u0645\u062a\u0648\u0642\u0639\u0629 \u0642\u0631\u064a\u0628\u0629 \u0645\u0646 0.5 \u0628\u0639\u064a\u062f\u064b\u0627 \u0639\u0646 \u062d\u062f\u0648\u062f \u0627\u0644\u0641\u0626\u0629 (\u0648\u0647\u0648 \u0623\u0645\u0631 \u0633\u064a\u0626). \u064a\u062d\u062f\u062b \u0647\u0630\u0627 \u0627\u0644\u062a\u0623\u062b\u064a\u0631 \u063a\u064a\u0631 \u0627\u0644\u0645\u0631\u063a\u0648\u0628 \u0641\u064a\u0647 \u0628\u0633\u0628\u0628 \u062a\u0642\u0631\u064a\u0628 \u0644\u0627\u0628\u0644\u0627\u0633 \u0627\u0644\u0645\u0633\u062a\u062e\u062f\u0645 \u062f\u0627\u062e\u0644\u064a\u064b\u0627 \u0628\u0648\u0627\u0633\u0637\u0629 GPC.\n\n\u064a\u064f\u0638\u0647\u0631 \u0627\u0644\u0634\u0643\u0644 \u0627\u0644\u062b\u0627\u0646\u064a \u0627\u0644\u0627\u062d\u062a\u0645\u0627\u0644 \u0627\u0644\u0647\u0627\u0645\u0634\u064a \u0627\u0644\u0644\u0648\u063a\u0627\u0631\u064a\u062a\u0645\u064a \u0644\u0627\u062e\u062a\u064a\u0627\u0631\u0627\u062a \u0645\u062e\u062a\u0644\u0641\u0629 \u0644\u0645\u0639\u0644\u0645\u0627\u062a \u0627\u0644\u0646\u0648\u0627\u0629 \u0627\u0644\u0641\u0627\u0626\u0642\u0629 \u060c \u0645\u0639 \u0625\u0628\u0631\u0627\u0632 \u062e\u064a\u0627\u0631\u064a \u0627\u0644\u0645\u0639\u0644\u0645\u0627\u062a \u0627\u0644\u0641\u0627\u0626\u0642\u0629 \u0627\u0644\u0645\u0633\u062a\u062e\u062f\u0645\u0629 \u0641\u064a \u0627\u0644\u0634\u0643\u0644 \u0627\u0644\u0623\u0648\u0644 \u0628\u0646\u0642\u0627\u0637 \u0633\u0648\u062f\u0627\u0621.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: The scikit-learn developers\n# SPDX-License-Identifier: BSD-3-Clause\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.metrics import accuracy_score, log_loss\n\n# \u062a\u0648\u0644\u064a\u062f \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a\ntrain_size = 50\nrng = np.random.RandomState(0)\nX = rng.uniform(0, 5, 100)[:, np.newaxis]\ny = np.array(X[:, 0] > 2.5, dtype=int)\n\n# \u062a\u062d\u062f\u064a\u062f \u0639\u0645\u0644\u064a\u0627\u062a \u063a\u0627\u0648\u0633\u064a\u0629 \u0628\u0645\u0639\u0644\u0645\u0627\u062a \u0641\u0627\u0626\u0642\u0629 \u062b\u0627\u0628\u062a\u0629 \u0648\u0645\u062d\u0633\u0646\u0629\ngp_fix = GaussianProcessClassifier(kernel=1.0 * RBF(length_scale=1.0), optimizer=None)\ngp_fix.fit(X[:train_size], y[:train_size])\n\ngp_opt = GaussianProcessClassifier(kernel=1.0 * RBF(length_scale=1.0))\ngp_opt.fit(X[:train_size], y[:train_size])\n\nprint(\n    \"\u0627\u0644\u0627\u062d\u062a\u0645\u0627\u0644 \u0627\u0644\u0647\u0627\u0645\u0634\u064a \u0627\u0644\u0644\u0648\u063a\u0627\u0631\u064a\u062a\u0645\u064a (\u0623\u0648\u0644\u064a): %.3f\"\n    % gp_fix.log_marginal_likelihood(gp_fix.kernel_.theta)\n)\nprint(\n    \"\u0627\u0644\u0627\u062d\u062a\u0645\u0627\u0644 \u0627\u0644\u0647\u0627\u0645\u0634\u064a \u0627\u0644\u0644\u0648\u063a\u0627\u0631\u064a\u062a\u0645\u064a (\u0645\u062d\u0633\u0646): %.3f\"\n    % gp_opt.log_marginal_likelihood(gp_opt.kernel_.theta)\n)\n\nprint(\n    \"\u0627\u0644\u062f\u0642\u0629: %.3f (\u0623\u0648\u0644\u064a) %.3f (\u0645\u062d\u0633\u0646)\"\n    % (\n        accuracy_score(y[:train_size], gp_fix.predict(X[:train_size])),\n        accuracy_score(y[:train_size], gp_opt.predict(X[:train_size])),\n    )\n)\nprint(\n    \"Log-loss: %.3f (\u0623\u0648\u0644\u064a) %.3f (\u0645\u062d\u0633\u0646)\"\n    % (\n        log_loss(y[:train_size], gp_fix.predict_proba(X[:train_size])[:, 1]),\n        log_loss(y[:train_size], gp_opt.predict_proba(X[:train_size])[:, 1]),\n    )\n)\n\n\n# \u0631\u0633\u0645 \u0627\u0644\u062a\u0648\u0632\u064a\u0639\u0627\u062a \u0627\u0644\u0644\u0627\u062d\u0642\u0629\nplt.figure()\nplt.scatter(\n    X[:train_size, 0], y[:train_size], c=\"k\", label=\"Train data\", edgecolors=(0, 0, 0)\n)\nplt.scatter(\n    X[train_size:, 0], y[train_size:], c=\"g\", label=\"Test data\", edgecolors=(0, 0, 0)\n)\nX_ = np.linspace(0, 5, 100)\nplt.plot(\n    X_,\n    gp_fix.predict_proba(X_[:, np.newaxis])[:, 1],\n    \"r\",\n    label=\"Initial kernel: %s\" % gp_fix.kernel_,\n)\nplt.plot(\n    X_,\n    gp_opt.predict_proba(X_[:, np.newaxis])[:, 1],\n    \"b\",\n    label=\"Optimized kernel: %s\" % gp_opt.kernel_,\n)\nplt.xlabel(\"\u0627\u0644\u0645\u064a\u0632\u0629\")\nplt.ylabel(\"\u0627\u062d\u062a\u0645\u0627\u0644 \u0627\u0644\u0641\u0626\u0629 1\")\nplt.xlim(0, 5)\nplt.ylim(-0.25, 1.5)\nplt.legend(loc=\"best\")\n\n# \u0631\u0633\u0645 \u0627\u0644\u0645\u0634\u0647\u062f LML\nplt.figure()\ntheta0 = np.logspace(0, 8, 30)\ntheta1 = np.logspace(-1, 1, 29)\nTheta0, Theta1 = np.meshgrid(theta0, theta1)\nLML = [\n    [\n        gp_opt.log_marginal_likelihood(np.log([Theta0[i, j], Theta1[i, j]]))\n        for i in range(Theta0.shape[0])\n    ]\n    for j in range(Theta0.shape[1])\n]\nLML = np.array(LML).T\nplt.plot(\n    np.exp(gp_fix.kernel_.theta)[0], np.exp(gp_fix.kernel_.theta)[1], \"ko\", zorder=10\n)\nplt.plot(\n    np.exp(gp_opt.kernel_.theta)[0], np.exp(gp_opt.kernel_.theta)[1], \"ko\", zorder=10\n)\nplt.pcolor(Theta0, Theta1, LML)\nplt.xscale(\"log\")\nplt.yscale(\"log\")\nplt.colorbar()\nplt.xlabel(\"\u0627\u0644\u062d\u062c\u0645\")\nplt.ylabel(\"\u0645\u0642\u064a\u0627\u0633 \u0627\u0644\u0637\u0648\u0644\")\nplt.title(\"\u0627\u0644\u0627\u062d\u062a\u0645\u0627\u0644 \u0627\u0644\u0647\u0627\u0645\u0634\u064a \u0627\u0644\u0644\u0648\u063a\u0627\u0631\u064a\u062a\u0645\u064a\")\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}