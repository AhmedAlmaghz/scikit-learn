{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class='alert alert-warning'>\n\n# JupyterLite warning\n\nRunning the scikit-learn examples in JupyterLite is experimental and you may encounter some unexpected behavior.\n\nThe main difference is that imports will take a lot longer than usual, for example the first `import sklearn` can take roughly 10-20s.\n\nIf you notice problems, feel free to open an [issue](https://github.com/scikit-learn/scikit-learn/issues/new/choose) about it.\n</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# JupyterLite-specific code\nimport matplotlib\nimport pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# \u062a\u062c\u0631\u064a\u062f \u0627\u0644\u0645\u064a\u0632\u0627\u062a\n\n\u062a\u0648\u0636\u064a\u062d \u0644\u062a\u062c\u0631\u064a\u062f \u0627\u0644\u0645\u064a\u0632\u0627\u062a \u0639\u0644\u0649 \u0645\u062c\u0645\u0648\u0639\u0627\u062a \u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0627\u0635\u0637\u0646\u0627\u0639\u064a\u0629.\n\u064a\u0642\u0648\u0645 \u062a\u062c\u0631\u064a\u062f \u0627\u0644\u0645\u064a\u0632\u0627\u062a \u0628\u062a\u0641\u0643\u064a\u0643 \u0643\u0644 \u0645\u064a\u0632\u0629 \u0625\u0644\u0649 \u0645\u062c\u0645\u0648\u0639\u0629 \u0645\u0646 \u0627\u0644\u0635\u0646\u0627\u062f\u064a\u0642, \u0647\u0646\u0627 \u0645\u0648\u0632\u0639\u0629 \u0628\u0627\u0644\u062a\u0633\u0627\u0648\u064a\n\u0641\u064a \u0627\u0644\u0639\u0631\u0636. \u062b\u0645 \u064a\u062a\u0645 \u062a\u0631\u0645\u064a\u0632 \u0627\u0644\u0642\u064a\u0645 \u0627\u0644\u0645\u0646\u0641\u0635\u0644\u0629 \u0628\u0637\u0631\u064a\u0642\u0629 \u0627\u0644\u062a\u0631\u0645\u064a\u0632 \u0623\u062d\u0627\u062f\u064a \u0627\u0644\u0633\u0627\u062e\u0646, \u0648\u062a\u0639\u0637\u0649\n\u0644\u0645\u0635\u0646\u0641 \u062e\u0637\u064a. \u062a\u0645\u0643\u0646 \u0647\u0630\u0647 \u0627\u0644\u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0645\u0633\u0628\u0642\u0629 \u0645\u0646 \u0633\u0644\u0648\u0643 \u063a\u064a\u0631 \u062e\u0637\u064a \u062d\u062a\u0649\n\u0639\u0644\u0649 \u0627\u0644\u0631\u063a\u0645 \u0645\u0646 \u0623\u0646 \u0627\u0644\u0645\u0635\u0646\u0641 \u062e\u0637\u064a.\n\n\u0641\u064a \u0647\u0630\u0627 \u0627\u0644\u0645\u062b\u0627\u0644, \u064a\u0645\u062b\u0644 \u0627\u0644\u0635\u0641\u0627\u0646 \u0627\u0644\u0623\u0648\u0644\u0627\u0646 \u0645\u062c\u0645\u0648\u0639\u0627\u062a \u0628\u064a\u0627\u0646\u0627\u062a \u063a\u064a\u0631 \u0642\u0627\u0628\u0644\u0629 \u0644\u0644\u0641\u0635\u0644 \u062e\u0637\u064a\u064b\u0627\n(\u0623\u0642\u0645\u0627\u0631 \u0635\u0646\u0627\u0639\u064a\u0629 \u0648\u062f\u0648\u0627\u0626\u0631 \u0645\u062a\u062d\u062f\u0629 \u0627\u0644\u0645\u0631\u0643\u0632) \u0628\u064a\u0646\u0645\u0627 \u0627\u0644\u062b\u0627\u0644\u062b\u0629 \u0642\u0627\u0628\u0644\u0629 \u0644\u0644\u0641\u0635\u0644 \u062a\u0642\u0631\u064a\u0628\u064b\u0627.\n\u062e\u0637\u064a. \u0639\u0644\u0649 \u0645\u062c\u0645\u0648\u0639\u0627\u062a \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a \u063a\u064a\u0631 \u0627\u0644\u0642\u0627\u0628\u0644\u0629 \u0644\u0644\u0641\u0635\u0644 \u062e\u0637\u064a\u064b\u0627, \u064a\u0632\u064a\u062f \u062a\u062c\u0631\u064a\u062f \u0627\u0644\u0645\u064a\u0632\u0627\u062a\n\u0628\u0634\u0643\u0644 \u0643\u0628\u064a\u0631 \u0645\u0646 \u0623\u062f\u0627\u0621 \u0627\u0644\u0645\u0635\u0646\u0641\u0627\u062a \u0627\u0644\u062e\u0637\u064a\u0629. \u0639\u0644\u0649 \u0645\u062c\u0645\u0648\u0639\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u0642\u0627\u0628\u0644\u0629 \u0644\u0644\u0641\u0635\u0644 \u062e\u0637\u064a\u064b\u0627,\n\u064a\u0642\u0644\u0644 \u062a\u062c\u0631\u064a\u062f \u0627\u0644\u0645\u064a\u0632\u0627\u062a \u0645\u0646 \u0623\u062f\u0627\u0621 \u0627\u0644\u0645\u0635\u0646\u0641\u0627\u062a \u0627\u0644\u062e\u0637\u064a\u0629. \u064a\u062a\u0645 \u0623\u064a\u0636\u064b\u0627 \u0639\u0631\u0636 \u0645\u0635\u0646\u0641\u064a\u0646 \u063a\u064a\u0631 \u062e\u0637\u064a\u064a\u0646\n\u0644\u0644\u0645\u0642\u0627\u0631\u0646\u0629.\n\n\u064a\u062c\u0628 \u0623\u062e\u0630 \u0647\u0630\u0627 \u0627\u0644\u0645\u062b\u0627\u0644 \u0645\u0639 \u062d\u0628\u0629 \u0645\u0646 \u0627\u0644\u0645\u0644\u062d, \u062d\u064a\u062b \u0623\u0646 \u0627\u0644\u062d\u062f\u0633 \u0627\u0644\u0645\u0646\u0642\u0648\u0644\n\u0644\u0627 \u064a\u0646\u062a\u0642\u0644 \u0628\u0627\u0644\u0636\u0631\u0648\u0631\u0629 \u0625\u0644\u0649 \u0645\u062c\u0645\u0648\u0639\u0627\u062a \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u062d\u0642\u064a\u0642\u064a\u0629. \u062e\u0627\u0635\u0629 \u0641\u064a\n\u0627\u0644\u0623\u0628\u0639\u0627\u062f \u0627\u0644\u0639\u0627\u0644\u064a\u0629, \u064a\u0645\u0643\u0646 \u0641\u0635\u0644 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a \u0628\u0633\u0647\u0648\u0644\u0629 \u0623\u0643\u0628\u0631 \u0628\u0634\u0643\u0644 \u062e\u0637\u064a. \u0639\u0644\u0627\u0648\u0629 \u0639\u0644\u0649 \u0630\u0644\u0643,\n\u064a\u0624\u062f\u064a \u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u062a\u062c\u0631\u064a\u062f \u0627\u0644\u0645\u064a\u0632\u0627\u062a \u0648\u0627\u0644\u062a\u0631\u0645\u064a\u0632 \u0623\u062d\u0627\u062f\u064a \u0627\u0644\u0633\u0627\u062e\u0646 \u0625\u0644\u0649 \u0632\u064a\u0627\u062f\u0629 \u0639\u062f\u062f\n\u0627\u0644\u0645\u064a\u0632\u0627\u062a, \u0648\u0627\u0644\u062a\u064a \u062a\u0624\u062f\u064a \u0628\u0633\u0647\u0648\u0644\u0629 \u0625\u0644\u0649 \u0627\u0644\u0625\u0641\u0631\u0627\u0637 \u0641\u064a \u0627\u0644\u062a\u0643\u064a\u0641 \u0639\u0646\u062f\u0645\u0627 \u064a\u0643\u0648\u0646 \u0639\u062f\u062f \u0627\u0644\u0639\u064a\u0646\u0627\u062a \u0635\u063a\u064a\u0631\u064b\u0627.\n\n\u062a\u0638\u0647\u0631 \u0627\u0644\u0645\u062e\u0637\u0637\u0627\u062a \u0646\u0642\u0627\u0637 \u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0628\u0623\u0644\u0648\u0627\u0646 \u0635\u0644\u0628\u0629 \u0648\u0646\u0642\u0627\u0637 \u0627\u0644\u0627\u062e\u062a\u0628\u0627\u0631\n\u0634\u0628\u0647 \u0634\u0641\u0627\u0641\u0629. \u064a\u0638\u0647\u0631 \u0627\u0644\u064a\u0645\u064a\u0646 \u0627\u0644\u0633\u0641\u0644\u064a \u062f\u0642\u0629 \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0639\u0644\u0649 \u0645\u062c\u0645\u0648\u0639\u0629 \u0627\u0644\u0627\u062e\u062a\u0628\u0627\u0631.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \u0627\u0644\u0645\u0624\u0644\u0641\u0648\u0646: \u0645\u0637\u0648\u0631\u064a \u0633\u0643\u0627\u064a\u062a-\u0644\u064a\u0631\u0646\n# \u0645\u0639\u0631\u0641 SPDX-License: BSD-3-Clause\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.colors import ListedColormap\n\nfrom sklearn.datasets import make_circles, make_classification, make_moons\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.exceptions import ConvergenceWarning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import KBinsDiscretizer, StandardScaler\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.utils._testing import ignore_warnings\n\nh = 0.02  # \u062d\u062c\u0645 \u0627\u0644\u062e\u0637\u0648\u0629 \u0641\u064a \u0627\u0644\u0634\u0628\u0643\u0629\n\n\ndef get_name(estimator):\n    name = estimator.__class__.__name__\n    if name == \"Pipeline\":\n        name = [get_name(est[1]) for est in estimator.steps]\n        name = \" + \".join(name)\n    return name\n\n\n\n# \u0642\u0627\u0626\u0645\u0629 (\u0627\u0644\u0645\u0642\u062f\u0631, param_grid), \u062d\u064a\u062b \u064a\u062a\u0645 \u0627\u0633\u062a\u062e\u062f\u0627\u0645 param_grid \u0641\u064a GridSearchCV\n# \u062a\u0645 \u062a\u062d\u062f\u064a\u062f \u0645\u0633\u0627\u062d\u0627\u062a \u0627\u0644\u0645\u0639\u0644\u0645\u0627\u062a \u0641\u064a \u0647\u0630\u0627 \u0627\u0644\u0645\u062b\u0627\u0644 \u0644\u062a\u0643\u0648\u0646 \u0645\u062d\u062f\u0648\u062f\u0629 \u0627\u0644\u0646\u0637\u0627\u0642 \u0644\u062a\u0642\u0644\u064a\u0644\n# \u0648\u0642\u062a \u062a\u0634\u063a\u064a\u0644\u0647. \u0641\u064a \u062d\u0627\u0644\u0629 \u0627\u0644\u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u0627\u0644\u0641\u0639\u0644\u064a, \u064a\u062c\u0628 \u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u0645\u0633\u0627\u062d\u0629 \u0628\u062d\u062b \u0623\u0648\u0633\u0639 \u0644\u0644\u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0627\u062a\n# \u064a\u062c\u0628 \u0627\u0633\u062a\u062e\u062f\u0627\u0645.\nclassifiers = [\n    (\n        make_pipeline (StandardScaler (), LogisticRegression (random_state = 0)),\n        {\"logisticregression__C\": np.logspace (-1, 1, 3)},\n    ),\n    (\n        make_pipeline (StandardScaler (), LinearSVC (random_state = 0)),\n        {\"linearsvc__C\": np.logspace (-1, 1, 3)},\n    ),\n    (\n        make_pipeline (\n            StandardScaler (),\n            KBinsDiscretizer (encode = \"onehot\", random_state = 0),\n            LogisticRegression (random_state = 0),\n        ),\n        {\n            \"kbinsdiscretizer__n_bins\": np.arange (5, 8),\n            \"logisticregression__C\": np.logspace (-1, 1, 3),\n        },\n    ),\n    (\n        make_pipeline (\n            StandardScaler (),\n            KBinsDiscretizer (encode = \"onehot\", random_state = 0),\n            LinearSVC (random_state = 0),\n        ),\n        {\n            \"kbinsdiscretizer__n_bins\": np.arange (5, 8),\n            \"linearsvc__C\": np.logspace (-1, 1, 3),\n        },\n    ),\n    (\n        make_pipeline (\n            StandardScaler (), GradientBoostingClassifier (n_estimators = 5, random_state = 0)\n        ),\n        {\"gradientboostingclassifier__learning_rate\": np.logspace (-2, 0, 5)},\n    ),\n    (\n        make_pipeline (StandardScaler (), SVC (random_state = 0)),\n        {\"svc__C\": np.logspace (-1, 1, 3)},\n    ),\n]\n\nnames = [get_name(e).replace(\"StandardScaler + \", \"\") for e, _ in classifiers]\n\nn_samples = 100\ndatasets = [\n    make_moons (n_samples = n_samples, noise = 0.2, random_state = 0),\n    make_circles (n_samples = n_samples, noise = 0.2, factor = 0.5, random_state = 1),\n    make_classification (\n        n_samples = n_samples,\n        n_features = 2,\n        n_redundant = 0,\n        n_informative = 2,\n        random_state = 2,\n        n_clusters_per_class = 1,\n    ),\n]\n\nfig, axes = plt.subplots(\n    nrows=len(datasets), ncols=len(classifiers) + 1, figsize=(21, 9)\n)\n\ncm_piyg = plt.cm.PiYG\ncm_bright = ListedColormap([\"#b30065\", \"#178000\"])\n\n# \u0627\u0644\u062a\u0643\u0631\u0627\u0631 \u0639\u0628\u0631 \u0645\u062c\u0645\u0648\u0639\u0627\u062a \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a\nfor ds_cnt, (X, y) in enumerate(datasets):\n    print(f\"\\ndataset {ds_cnt}\\n---------\")\n\n    # \u062a\u0642\u0633\u064a\u0645 \u0625\u0644\u0649 \u062c\u0632\u0621 \u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0648\u0627\u0644\u0627\u062e\u062a\u0628\u0627\u0631\n    X_train, X_test, y_train, y_test = train_test_split (\n        X, y, test_size = 0.5, random_state = 42\n    )\n\n    # \u0625\u0646\u0634\u0627\u0621 \u0627\u0644\u0634\u0628\u0643\u0629 \u0644\u0623\u0644\u0648\u0627\u0646 \u0627\u0644\u062e\u0644\u0641\u064a\u0629\n    x_min, x_max = X [:, 0].min () - 0.5, X [:, 0].max () + 0.5\n    y_min, y_max = X [:, 1].min () - 0.5, X [:, 1].max () + 0.5\n    xx, yy = np.meshgrid (np.arange (x_min, x_max, h), np.arange (y_min, y_max, h))\n\n    # \u0642\u0645 \u0628\u0631\u0633\u0645 \u0645\u062c\u0645\u0648\u0639\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a \u0623\u0648\u0644\u0627\u064b\n    ax = axes [ds_cnt, 0]\n    if ds_cnt == 0:\n        ax.set_title (\"Input data\")\n    # \u0642\u0645 \u0628\u0631\u0633\u0645 \u0646\u0642\u0627\u0637 \u0627\u0644\u062a\u062f\u0631\u064a\u0628\n    ax.scatter (X_train [:, 0], X_train [:, 1], c = y_train, cmap = cm_bright, edgecolors = \"k\")\n    # \u0648\u0646\u0642\u0627\u0637 \u0627\u0644\u0627\u062e\u062a\u0628\u0627\u0631\n    ax.scatter (\n        X_test [:, 0], X_test [:, 1], c = y_test, cmap = cm_bright, alpha = 0.6, edgecolors = \"k\"\n    )\n    ax.set_xlim (xx.min (), xx.max ())\n    ax.set_ylim (yy.min (), yy.max ())\n    ax.set_xticks (())\n    ax.set_yticks (())\n\n    # \u0627\u0644\u062a\u0643\u0631\u0627\u0631 \u0639\u0628\u0631 \u0627\u0644\u0645\u0635\u0646\u0641\u0627\u062a\n    for est_idx, (name, (estimator, param_grid)) in enumerate(zip(names, classifiers)):\n        ax = axes[ds_cnt, est_idx + 1]\n\n        clf = GridSearchCV(estimator=estimator, param_grid=param_grid)\n        with ignore_warnings(category=ConvergenceWarning):\n            clf.fit(X_train, y_train)\n        score = clf.score(X_test, y_test)\n        print(f\"{name}: {score:.2f}\")\n\n        # \u0642\u0645 \u0628\u0631\u0633\u0645 \u062d\u062f\u0648\u062f \u0627\u0644\u0642\u0631\u0627\u0631. \u0644\u0647\u0630\u0627, \u0633\u0646\u0642\u0648\u0645 \u0628\u062a\u0639\u064a\u064a\u0646 \u0644\u0648\u0646 \u0644\u0643\u0644\n        # \u0646\u0642\u0637\u0629 \u0641\u064a \u0627\u0644\u0634\u0628\u0643\u0629 [x_min, x_max] * [y_min, y_max].\n        if hasattr(clf, \"decision_function\"):\n            Z = clf.decision_function(np.column_stack([xx.ravel(), yy.ravel()]))\n        else:\n            Z = clf.predict_proba(np.column_stack([xx.ravel(), yy.ravel()]))[:, 1]\n\n        # \u0636\u0639 \u0627\u0644\u0646\u062a\u064a\u062c\u0629 \u0641\u064a \u0631\u0633\u0645 \u062a\u062e\u0637\u064a\u0637\u064a \u0645\u0644\u0648\u0646\n        Z = Z.reshape (xx.shape)\n        ax.contourf (xx, yy, Z, cmap = cm_piyg, alpha = 0.8)\n\n        # \u0642\u0645 \u0628\u0631\u0633\u0645 \u0646\u0642\u0627\u0637 \u0627\u0644\u062a\u062f\u0631\u064a\u0628\n        ax.scatter (\n            X_train [:, 0], X_train [:, 1], c = y_train, cmap = cm_bright, edgecolors = \"k\"\n        )\n        # \u0648\u0646\u0642\u0627\u0637 \u0627\u0644\u0627\u062e\u062a\u0628\u0627\u0631\n        ax.scatter (\n            X_test [:, 0],\n            X_test [:, 1],\n            c = y_test,\n            cmap = cm_bright,\n            edgecolors = \"k\",\n            alpha = 0.6,\n        )\n        ax.set_xlim (xx.min (), xx.max ())\n        ax.set_ylim (yy.min (), yy.max ())\n        ax.set_xticks (())\n        ax.set_yticks (())\n\n        if ds_cnt == 0:\n            ax.set_title(name.replace(\" + \", \"\\n\"))\n        ax.text(\n            0.95,\n            0.06,\n            (f\"{score:.2f}\").lstrip(\"0\"),\n            size=15,\n            bbox=dict(boxstyle=\"round\", alpha=0.8, facecolor=\"white\"),\n            transform=ax.transAxes,\n            horizontalalignment=\"right\",\n        )\n\n\nplt.tight_layout()\n\n# \u0625\u0636\u0627\u0641\u0629 suptitles \u0641\u0648\u0642 \u0627\u0644\u0634\u0643\u0644\nplt.subplots_adjust (top = 0.90)\nsuptitles = [\n    \"\u0627\u0644\u0645\u0635\u0646\u0641\u0627\u062a \u0627\u0644\u062e\u0637\u064a\u0629\",\n    \"\u062a\u062c\u0631\u064a\u062f \u0627\u0644\u0645\u064a\u0632\u0627\u062a \u0648\u0627\u0644\u0645\u0635\u0646\u0641\u0627\u062a \u0627\u0644\u062e\u0637\u064a\u0629\",\n    \"\u0627\u0644\u0645\u0635\u0646\u0641\u0627\u062a \u063a\u064a\u0631 \u0627\u0644\u062e\u0637\u064a\u0629\",\n]\nfor i, suptitle in zip([1, 3, 5], suptitles):\n    ax = axes[0, i]\n    ax.text(\n        1.05,\n        1.25,\n        suptitle,\n        transform=ax.transAxes,\n        horizontalalignment=\"center\",\n        size=\"x-large\",\n    )\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}