{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class='alert alert-warning'>\n\n# JupyterLite warning\n\nRunning the scikit-learn examples in JupyterLite is experimental and you may encounter some unexpected behavior.\n\nThe main difference is that imports will take a lot longer than usual, for example the first `import sklearn` can take roughly 10-20s.\n\nIf you notice problems, feel free to open an [issue](https://github.com/scikit-learn/scikit-learn/issues/new/choose) about it.\n</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# JupyterLite-specific code\n%pip install pyodide-http\nimport pyodide_http\npyodide_http.patch_all()\nimport matplotlib\nimport pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0644\u0648\u062c\u0633\u062a\u064a \u0627\u0644\u0645\u062a\u0646\u0627\u062b\u0631 \u0645\u062a\u0639\u062f\u062f \u0627\u0644\u0641\u0626\u0627\u062a \u0639\u0644\u0649 20newgroups\n\n\u0645\u0642\u0627\u0631\u0646\u0629 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0644\u0648\u062c\u0633\u062a\u064a \u0645\u062a\u0639\u062f\u062f \u0627\u0644\u062d\u062f\u0648\u062f L1 \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0644\u0648\u062c\u0633\u062a\u064a \u0648\u0627\u062d\u062f \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u0628\u0642\u064a\u0629 L1\n\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u0645\u0633\u062a\u0646\u062f\u0627\u062a \u0645\u0646 \u0645\u062c\u0645\u0648\u0639\u0629 \u0628\u064a\u0627\u0646\u0627\u062a newgroups20. \u064a\u0646\u062a\u062c \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0644\u0648\u062c\u0633\u062a\u064a\n\u0645\u062a\u0639\u062f\u062f \u0627\u0644\u062d\u062f\u0648\u062f \u0646\u062a\u0627\u0626\u062c \u0623\u0643\u062b\u0631 \u062f\u0642\u0629 \u0648\u0647\u0648 \u0623\u0633\u0631\u0639 \u0641\u064a \u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0639\u0644\u0649 \u0645\u062c\u0645\u0648\u0639\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u0623\u0643\u0628\u0631 \u062d\u062c\u0645\u064b\u0627.\n\n\u0647\u0646\u0627 \u0646\u0633\u062a\u062e\u062f\u0645 \u0627\u0644\u062a\u0646\u0627\u062b\u0631 l1 \u0627\u0644\u0630\u064a \u064a\u0642\u0644\u0635 \u0623\u0648\u0632\u0627\u0646 \u0627\u0644\u0645\u064a\u0632\u0627\u062a \u063a\u064a\u0631 \u0627\u0644\u0645\u0641\u064a\u062f\u0629 \u0625\u0644\u0649 \u0627\u0644\u0635\u0641\u0631. \u0647\u0630\u0627 \u062c\u064a\u062f \u0625\u0630\u0627 \u0643\u0627\u0646\n\u0627\u0644\u0647\u062f\u0641 \u0647\u0648 \u0627\u0633\u062a\u062e\u0631\u0627\u062c \u0627\u0644\u0645\u0641\u0631\u062f\u0627\u062a \u0627\u0644\u062a\u0645\u064a\u064a\u0632\u064a\u0629 \u0627\u0644\u0642\u0648\u064a\u0629 \u0644\u0643\u0644 \u0641\u0626\u0629. \u0625\u0630\u0627 \u0643\u0627\u0646 \u0627\u0644\u0647\u062f\u0641 \u0647\u0648 \u0627\u0644\u062d\u0635\u0648\u0644 \u0639\u0644\u0649 \u0623\u0641\u0636\u0644\n\u062f\u0642\u0629 \u062a\u0646\u0628\u0624\u064a\u0629\u060c \u0641\u0645\u0646 \u0627\u0644\u0623\u0641\u0636\u0644 \u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u0639\u0642\u0648\u0628\u0629 l2 \u063a\u064a\u0631 \u0627\u0644\u0645\u0633\u0628\u0628\u0629 \u0644\u0644\u062a\u0646\u0627\u062b\u0631 \u0628\u062f\u0644\u0627\u064b \u0645\u0646 \u0630\u0644\u0643.\n\n\u0647\u0646\u0627\u0643 \u0637\u0631\u064a\u0642\u0629 \u0623\u0643\u062b\u0631 \u062a\u0642\u0644\u064a\u062f\u064a\u0629 (\u0648\u0631\u0628\u0645\u0627 \u0623\u0641\u0636\u0644) \u0644\u0644\u062a\u0646\u0628\u0624 \u0639\u0644\u0649 \u0645\u062c\u0645\u0648\u0639\u0629 \u0641\u0631\u0639\u064a\u0629 \u0645\u062a\u0646\u0627\u062b\u0631\u0629 \u0645\u0646\n\u0645\u064a\u0632\u0627\u062a \u0627\u0644\u0625\u062f\u062e\u0627\u0644 \u0648\u0647\u064a \u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u0627\u062e\u062a\u064a\u0627\u0631 \u0627\u0644\u0645\u064a\u0632\u0627\u062a \u0623\u062d\u0627\u062f\u064a \u0627\u0644\u0645\u062a\u063a\u064a\u0631 \u0645\u062a\u0628\u0648\u0639\u064b\u0627 \u0628\u0646\u0645\u0648\u0630\u062c\n\u0627\u0646\u062d\u062f\u0627\u0631 \u0644\u0648\u062c\u0633\u062a\u064a \u062a\u0642\u0644\u064a\u062f\u064a (\u0645\u0639\u0627\u0642\u0628 \u0628\u0640 l2).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: The scikit-learn developers\n# SPDX-License-Identifier: BSD-3-Clause\n\nimport timeit\nimport warnings\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn.datasets import fetch_20newsgroups_vectorized\nfrom sklearn.exceptions import ConvergenceWarning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.multiclass import OneVsRestClassifier\n\nwarnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"sklearn\")\nt0 = timeit.default_timer()\n\n# \u0646\u062d\u0646 \u0646\u0633\u062a\u062e\u062f\u0645 \u0645\u064f\u062d\u0644 SAGA\nsolver = \"saga\"\n\n# \u0642\u0644\u0644 \u0645\u0646 \u0623\u062c\u0644 \u0648\u0642\u062a \u062a\u0634\u063a\u064a\u0644 \u0623\u0633\u0631\u0639\nn_samples = 5000\n\nX, y = fetch_20newsgroups_vectorized(subset=\"all\", return_X_y=True)\nX = X[:n_samples]\ny = y[:n_samples]\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, random_state=42, stratify=y, test_size=0.1\n)\ntrain_samples, n_features = X_train.shape\nn_classes = np.unique(y).shape[0]\n\nprint(\n    \"\u0645\u062c\u0645\u0648\u0639\u0629 \u0628\u064a\u0627\u0646\u0627\u062a 20newsgroup\u060c train_samples=%i\u060c n_features=%i\u060c n_classes=%i\"\n    % (train_samples, n_features, n_classes)\n)\n\nmodels = {\n    \"ovr\": {\"name\": \"\u0648\u0627\u062d\u062f \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u0628\u0642\u064a\u0629\", \"iters\": [1, 2, 3]},\n    \"multinomial\": {\"name\": \"\u0645\u062a\u0639\u062f\u062f \u0627\u0644\u062d\u062f\u0648\u062f\", \"iters\": [1, 2, 5]},\n}\n\nfor model in models:\n    # \u0625\u0636\u0627\u0641\u0629 \u0642\u064a\u0645 \u0645\u0633\u062a\u0648\u0649 \u0627\u0644\u0641\u0631\u0635\u0629 \u0627\u0644\u0623\u0648\u0644\u064a\u0629 \u0644\u0623\u063a\u0631\u0627\u0636 \u0627\u0644\u0631\u0633\u0645\n    accuracies = [1 / n_classes]\n    times = [0]\n    densities = [1]\n\n    model_params = models[model]\n\n    # \u0639\u062f\u062f \u0642\u0644\u064a\u0644 \u0645\u0646 \u0627\u0644\u0639\u0647\u0648\u062f \u0644\u0648\u0642\u062a \u062a\u0634\u063a\u064a\u0644 \u0633\u0631\u064a\u0639\n    for this_max_iter in model_params[\"iters\"]:\n        print(\n            \"[model=%s, solver=%s] \u0639\u062f\u062f \u0627\u0644\u0639\u0647\u0648\u062f: %s\"\n            % (model_params[\"name\"], solver, this_max_iter)\n        )\n        clf = LogisticRegression(\n            solver=solver,\n            penalty=\"l1\",\n            max_iter=this_max_iter,\n            random_state=42,\n        )\n        if model == \"ovr\":\n            clf = OneVsRestClassifier(clf)\n        t1 = timeit.default_timer()\n        clf.fit(X_train, y_train)\n        train_time = timeit.default_timer() - t1\n\n        y_pred = clf.predict(X_test)\n        accuracy = np.sum(y_pred == y_test) / y_test.shape[0]\n        if model == \"ovr\":\n            coef = np.concatenate([est.coef_ for est in clf.estimators_])\n        else:\n            coef = clf.coef_\n        density = np.mean(coef != 0, axis=1) * 100\n        accuracies.append(accuracy)\n        densities.append(density)\n        times.append(train_time)\n    models[model][\"times\"] = times\n    models[model][\"densities\"] = densities\n    models[model][\"accuracies\"] = accuracies\n    print(\"\u062f\u0642\u0629 \u0627\u0644\u0627\u062e\u062a\u0628\u0627\u0631 \u0644\u0644\u0646\u0645\u0648\u0630\u062c %s: %.4f\" % (model, accuracies[-1]))\n    print(\n        \"%% \u0645\u0639\u0627\u0645\u0644\u0627\u062a \u063a\u064a\u0631 \u0635\u0641\u0631\u064a\u0629 \u0644\u0644\u0646\u0645\u0648\u0630\u062c %s\u060c \u0644\u0643\u0644 \u0641\u0626\u0629:\\n %s\"\n        % (model, densities[-1])\n    )\n    print(\n        \"\u0648\u0642\u062a \u0627\u0644\u062a\u0634\u063a\u064a\u0644 (%i \u0639\u0647\u0648\u062f) \u0644\u0644\u0646\u0645\u0648\u0630\u062c %s:%.2f\"\n        % (model_params[\"iters\"][-1], model, times[-1])\n    )\n\nfig = plt.figure()\nax = fig.add_subplot(111)\n\nfor model in models:\n    name = models[model][\"name\"]\n    times = models[model][\"times\"]\n    accuracies = models[model][\"accuracies\"]\n    ax.plot(times, accuracies, marker=\"o\", label=\"\u0627\u0644\u0646\u0645\u0648\u0630\u062c: %s\" % name)\n    ax.set_xlabel(\"\u0648\u0642\u062a \u0627\u0644\u062a\u062f\u0631\u064a\u0628 (s)\")\n    ax.set_ylabel(\"\u062f\u0642\u0629 \u0627\u0644\u0627\u062e\u062a\u0628\u0627\u0631\")\nax.legend()\nfig.suptitle(\n    \"\u0645\u062a\u0639\u062f\u062f \u0627\u0644\u062d\u062f\u0648\u062f \u0645\u0642\u0627\u0628\u0644 \u0648\u0627\u062d\u062f \u0645\u0642\u0627\u0628\u0644 \u0627\u0644\u0628\u0642\u064a\u0629 \u0627\u0644\u0644\u0648\u062c\u0633\u062a\u064a L1\\n\u0645\u062c\u0645\u0648\u0639\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a %s\" % \"20newsgroups\"\n)\nfig.tight_layout()\nfig.subplots_adjust(top=0.85)\nrun_time = timeit.default_timer() - t0\nprint(\"\u062a\u0645 \u062a\u0634\u063a\u064a\u0644 \u0627\u0644\u0645\u062b\u0627\u0644 \u0641\u064a %.3f s\" % run_time)\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}