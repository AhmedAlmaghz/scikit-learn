{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class='alert alert-warning'>\n\n# JupyterLite warning\n\nRunning the scikit-learn examples in JupyterLite is experimental and you may encounter some unexpected behavior.\n\nThe main difference is that imports will take a lot longer than usual, for example the first `import sklearn` can take roughly 10-20s.\n\nIf you notice problems, feel free to open an [issue](https://github.com/scikit-learn/scikit-learn/issues/new/choose) about it.\n</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# JupyterLite-specific code\nimport matplotlib\nimport pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# \u0623\u062e\u0637\u0627\u0621 OOB \u0644\u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 Random Forests\n\n\u062a\u0645 \u062a\u062f\u0631\u064a\u0628 \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 ``RandomForestClassifier`` \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 *bootstrap aggregation*\u060c \u062d\u064a\u062b \u064a\u062a\u0645 \u0645\u0644\u0627\u0621\u0645\u0629 \u0643\u0644 \u0634\u062c\u0631\u0629 \u062c\u062f\u064a\u062f\u0629 \u0645\u0646 \u0639\u064a\u0646\u0629 bootstrap \u0645\u0646 \u0627\u0644\u0645\u0644\u0627\u062d\u0638\u0627\u062a \u0627\u0644\u062a\u062f\u0631\u064a\u0628\u064a\u0629 $z_i = (x_i, y_i)$. \u062e\u0637\u0623 *out-of-bag* (OOB) \u0647\u0648 \u0645\u062a\u0648\u0633\u0637 \u0627\u0644\u062e\u0637\u0623 \u0644\u0643\u0644 $z_i$ \u0645\u062d\u0633\u0648\u0628\u0629 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u062a\u0646\u0628\u0624\u0627\u062a \u0645\u0646 \u0627\u0644\u0623\u0634\u062c\u0627\u0631 \u0627\u0644\u062a\u064a \u0644\u0627 \u062a\u062d\u062a\u0648\u064a \u0639\u0644\u0649 $z_i$ \u0641\u064a \u0639\u064a\u0646\u0629 bootstrap \u0627\u0644\u062e\u0627\u0635\u0629 \u0628\u0647\u0627. \u064a\u0633\u0645\u062d \u0647\u0630\u0627 \u0644\u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 ``RandomForestClassifier`` \u0628\u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0648\u0627\u0644\u062a\u062d\u0642\u0642 \u0623\u062b\u0646\u0627\u0621 \u0627\u0644\u062a\u062f\u0631\u064a\u0628 [1]_.\n\n\u064a\u0648\u0636\u062d \u0627\u0644\u0645\u062b\u0627\u0644 \u0623\u062f\u0646\u0627\u0647 \u0643\u064a\u0641\u064a\u0629 \u0642\u064a\u0627\u0633 \u062e\u0637\u0623 OOB \u0639\u0646\u062f \u0625\u0636\u0627\u0641\u0629 \u0643\u0644 \u0634\u062c\u0631\u0629 \u062c\u062f\u064a\u062f\u0629 \u0623\u062b\u0646\u0627\u0621 \u0627\u0644\u062a\u062f\u0631\u064a\u0628. \u064a\u0633\u0645\u062d \u0627\u0644\u0645\u062e\u0637\u0637 \u0627\u0644\u0646\u0627\u062a\u062c \u0644\u0645\u0645\u0627\u0631\u0633 \u062a\u0642\u0631\u064a\u0628 \u0642\u064a\u0645\u0629 \u0645\u0646\u0627\u0633\u0628\u0629 \u0644\u0640 ``n_estimators`` \u0648\u0627\u0644\u062a\u064a \u064a\u0633\u062a\u0642\u0631 \u0639\u0646\u062f\u0647\u0627 \u0627\u0644\u062e\u0637\u0623.\n\n.. [1] T. Hastie, R. Tibshirani and J. Friedman, \"Elements of Statistical\n       Learning Ed. 2\", p592-593, Springer, 2009.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \u0627\u0644\u0645\u0624\u0644\u0641\u0648\u0646: \u0645\u0637\u0648\u0631\u064a scikit-learn\n# \u0645\u0639\u0631\u0641 \u0627\u0644\u062a\u0631\u062e\u064a\u0635: BSD-3-Clause\n\nfrom collections import OrderedDict\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_classification\nfrom sklearn.ensemble import RandomForestClassifier\n\nRANDOM_STATE = 123\n\n# \u0625\u0646\u0634\u0627\u0621 \u0645\u062c\u0645\u0648\u0639\u0629 \u0628\u064a\u0627\u0646\u0627\u062a \u0644\u0644\u062a\u0635\u0646\u064a\u0641 \u0627\u0644\u062b\u0646\u0627\u0626\u064a.\nX, y = make_classification(\n    n_samples=500,\n    n_features=25,\n    n_clusters_per_class=1,\n    n_informative=15,\n    random_state=RANDOM_STATE,\n)\n\n# \u0645\u0644\u0627\u062d\u0638\u0629: \u062a\u0639\u064a\u064a\u0646 \u0645\u0639\u0644\u0645\u0629 \u0627\u0644\u0628\u0646\u0627\u0621 `warm_start` \u0625\u0644\u0649 `True` \u062a\u0639\u0637\u0644\n# \u062f\u0639\u0645 \u0627\u0644\u0645\u062c\u0645\u0648\u0639\u0627\u062a \u0627\u0644\u0645\u0648\u0627\u0632\u064a\u0629 \u0648\u0644\u0643\u0646\u0647\u0627 \u0636\u0631\u0648\u0631\u064a\u0629 \u0644\u062a\u062a\u0628\u0639 \u0645\u0633\u0627\u0631 \u062e\u0637\u0623 OOB\n# \u0623\u062b\u0646\u0627\u0621 \u0627\u0644\u062a\u062f\u0631\u064a\u0628.\nensemble_clfs = [\n    (\n        \"RandomForestClassifier, max_features='sqrt'\",\n        RandomForestClassifier(\n            warm_start=True,\n            oob_score=True,\n            max_features=\"sqrt\",\n            random_state=RANDOM_STATE,\n        ),\n    ),\n    (\n        \"RandomForestClassifier, max_features='log2'\",\n        RandomForestClassifier(\n            warm_start=True,\n            max_features=\"log2\",\n            oob_score=True,\n            random_state=RANDOM_STATE,\n        ),\n    ),\n    (\n        \"RandomForestClassifier, max_features=None\",\n        RandomForestClassifier(\n            warm_start=True,\n            max_features=None,\n            oob_score=True,\n            random_state=RANDOM_STATE,\n        ),\n    ),\n]\n\n# \u0631\u0628\u0637 \u0627\u0633\u0645 \u0627\u0644\u0645\u0635\u0646\u0641 \u0628\u0642\u0627\u0626\u0645\u0629 \u0645\u0646 \u0623\u0632\u0648\u0627\u062c (<n_estimators>, <error rate>).\nerror_rate = OrderedDict((label, []) for label, _ in ensemble_clfs)\n\n# \u0646\u0637\u0627\u0642 \u0642\u064a\u0645 `n_estimators` \u0644\u0627\u0633\u062a\u0643\u0634\u0627\u0641\u0647\u0627.\nmin_estimators = 15\nmax_estimators = 150\n\nfor label, clf in ensemble_clfs:\n    for i in range(min_estimators, max_estimators + 1, 5):\n        clf.set_params(n_estimators=i)\n        clf.fit(X, y)\n\n        # \u062a\u0633\u062c\u064a\u0644 \u062e\u0637\u0623 OOB \u0644\u0643\u0644 \u0625\u0639\u062f\u0627\u062f `n_estimators=i`.\n        oob_error = 1 - clf.oob_score_\n        error_rate[label].append((i, oob_error))\n\n# \u0625\u0646\u0634\u0627\u0621 \u0645\u062e\u0637\u0637 \"\u0645\u0639\u062f\u0644 \u062e\u0637\u0623 OOB\" \u0645\u0642\u0627\u0628\u0644 \"n_estimators\".\nfor label, clf_err in error_rate.items():\n    xs, ys = zip(*clf_err)\n    plt.plot(xs, ys, label=label)\n\nplt.xlim(min_estimators, max_estimators)\nplt.xlabel(\"n_estimators\")\nplt.ylabel(\"OOB error rate\")\nplt.legend(loc=\"upper right\")\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}