{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class='alert alert-warning'>\n\n# JupyterLite warning\n\nRunning the scikit-learn examples in JupyterLite is experimental and you may encounter some unexpected behavior.\n\nThe main difference is that imports will take a lot longer than usual, for example the first `import sklearn` can take roughly 10-20s.\n\nIf you notice problems, feel free to open an [issue](https://github.com/scikit-learn/scikit-learn/issues/new/choose) about it.\n</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# JupyterLite-specific code\nimport matplotlib\nimport pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# \u0631\u0633\u0645 \u0627\u062d\u062a\u0645\u0627\u0644\u0627\u062a \u0627\u0644\u0641\u0626\u0627\u062a \u0627\u0644\u0645\u062d\u0633\u0648\u0628\u0629 \u0628\u0648\u0627\u0633\u0637\u0629 VotingClassifier\n\n.. currentmodule:: sklearn\n\n\u0631\u0633\u0645 \u0627\u062d\u062a\u0645\u0627\u0644\u0627\u062a \u0627\u0644\u0641\u0626\u0627\u062a \u0644\u0644\u0639\u064a\u0646\u0629 \u0627\u0644\u0623\u0648\u0644\u0649 \u0641\u064a \u0645\u062c\u0645\u0648\u0639\u0629 \u0628\u064a\u0627\u0646\u0627\u062a \u062a\u062c\u0631\u064a\u0628\u064a\u0629 \u0645\u062a\u0648\u0642\u0639\u0629 \u0628\u0648\u0627\u0633\u0637\u0629\n\u062b\u0644\u0627\u062b\u0629 \u0645\u0635\u0646\u0641\u0627\u062a \u0645\u062e\u062a\u0644\u0641\u0629 \u0648\u0645\u062a\u0648\u0633\u0637 \u0628\u0648\u0627\u0633\u0637\u0629\n:class:`~ensemble.VotingClassifier`.\n\n\u0623\u0648\u0644\u0627\u064b\u060c \u062a\u062a\u0645 \u062a\u0647\u064a\u0626\u0629 \u062b\u0644\u0627\u062b\u0629 \u0645\u0635\u0646\u0641\u0627\u062a \u0646\u0645\u0648\u0630\u062c\u064a\u0629\n(:class:`~linear_model.LogisticRegression` \u0648 :class:`~naive_bayes.GaussianNB`\n\u0648 :class:`~ensemble.RandomForestClassifier`) \u0648\u062a\u0633\u062a\u062e\u062f\u0645 \u0644\u062a\u0647\u064a\u0626\u0629\n:class:`~ensemble.VotingClassifier` \u0644\u0644\u062a\u0635\u0648\u064a\u062a \u0627\u0644\u0646\u0627\u0639\u0645 \u0645\u0639 \u0623\u0648\u0632\u0627\u0646 `[1\u060c 1\u060c 5]`\u060c \u0645\u0645\u0627\n\u064a\u0639\u0646\u064a \u0623\u0646 \u0627\u062d\u062a\u0645\u0627\u0644\u0627\u062a \u0627\u0644\u062a\u0646\u0628\u0624 \u0644\u0640\n:class:`~ensemble.RandomForestClassifier` \u062a\u062d\u0633\u0628 5 \u0645\u0631\u0627\u062a \u0628\u0642\u062f\u0631 \u0623\u0648\u0632\u0627\u0646\n\u0627\u0644\u0645\u0635\u0646\u0641\u0627\u062a \u0627\u0644\u0623\u062e\u0631\u0649 \u0639\u0646\u062f \u062d\u0633\u0627\u0628 \u0627\u0644\u0627\u062d\u062a\u0645\u0627\u0644 \u0627\u0644\u0645\u062a\u0648\u0633\u0637.\n\n\u0644\u062a\u0635\u0648\u0631 \u062a\u0631\u062c\u064a\u062d \u0627\u0644\u0627\u062d\u062a\u0645\u0627\u0644\u060c \u0646\u0642\u0648\u0645 \u0628\u0645\u0644\u0627\u0621\u0645\u0629 \u0643\u0644 \u0645\u0635\u0646\u0641 \u0639\u0644\u0649 \u0645\u062c\u0645\u0648\u0639\u0629 \u0627\u0644\u062a\u062f\u0631\u064a\u0628\n\u0648\u0631\u0633\u0645 \u0627\u062d\u062a\u0645\u0627\u0644\u0627\u062a \u0627\u0644\u0641\u0626\u0627\u062a \u0627\u0644\u0645\u062a\u0648\u0642\u0639\u0629 \u0644\u0644\u0639\u064a\u0646\u0629 \u0627\u0644\u0623\u0648\u0644\u0649 \u0641\u064a \u0645\u062c\u0645\u0648\u0639\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a\n\u0627\u0644\u0646\u0645\u0648\u0630\u062c\u064a\u0629 \u0647\u0630\u0647.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: The scikit-learn developers\n# SPDX-License-Identifier: BSD-3-Clause\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\n\nclf1 = LogisticRegression(max_iter=1000, random_state=123)\nclf2 = RandomForestClassifier(n_estimators=100, random_state=123)\nclf3 = GaussianNB()\nX = np.array([[-1.0, -1.0], [-1.2, -1.4], [-3.4, -2.2], [1.1, 1.2]])\ny = np.array([1, 1, 2, 2])\n\neclf = VotingClassifier(\n    estimators=[(\"lr\", clf1), (\"rf\", clf2), (\"gnb\", clf3)],\n    voting=\"soft\",\n    weights=[1, 1, 5],\n)\n\n# \u062a\u0646\u0628\u0624 \u0628\u0627\u062d\u062a\u0645\u0627\u0644\u0627\u062a \u0627\u0644\u0641\u0626\u0627\u062a \u0644\u062c\u0645\u064a\u0639 \u0627\u0644\u0645\u0635\u0646\u0641\u0627\u062a\nprobas = [c.fit(X, y).predict_proba(X) for c in (clf1, clf2, clf3, eclf)]\n\n# \u0627\u0644\u062d\u0635\u0648\u0644 \u0639\u0644\u0649 \u0627\u062d\u062a\u0645\u0627\u0644\u0627\u062a \u0627\u0644\u0641\u0626\u0627\u062a \u0644\u0644\u0639\u064a\u0646\u0629 \u0627\u0644\u0623\u0648\u0644\u0649 \u0641\u064a \u0645\u062c\u0645\u0648\u0639\u0629 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a\nclass1_1 = [pr[0, 0] for pr in probas]\nclass2_1 = [pr[0, 1] for pr in probas]\n\n\n# \u0627\u0644\u0631\u0633\u0645\n\nN = 4  # \u0639\u062f\u062f \u0627\u0644\u0645\u062c\u0645\u0648\u0639\u0627\u062a\nind = np.arange(N)  # \u0645\u0648\u0627\u0636\u0639 \u0627\u0644\u0645\u062c\u0645\u0648\u0639\u0627\u062a\nwidth = 0.35  # \u0639\u0631\u0636 \u0627\u0644\u0634\u0631\u064a\u0637\n\nfig, ax = plt.subplots()\n\n# \u0623\u0634\u0631\u0637\u0629 \u0644\u0644\u0645\u0635\u0646\u0641 1-3\np1 = ax.bar(ind, np.hstack(([class1_1[:-1], [0]])), width, color=\"green\", edgecolor=\"k\")\np2 = ax.bar(\n    ind + width,\n    np.hstack(([class2_1[:-1], [0]])),\n    width,\n    color=\"lightgreen\",\n    edgecolor=\"k\",\n)\n\n# \u0623\u0634\u0631\u0637\u0629 \u0644\u0640 VotingClassifier\np3 = ax.bar(ind, [0, 0, 0, class1_1[-1]], width, color=\"blue\", edgecolor=\"k\")\np4 = ax.bar(\n    ind + width, [0, 0, 0, class2_1[-1]], width, color=\"steelblue\", edgecolor=\"k\"\n)\n\n# \u062a\u0639\u0644\u064a\u0642\u0627\u062a \u0628\u064a\u0627\u0646\u064a\u0629\nplt.axvline(2.8, color=\"k\", linestyle=\"dashed\")\nax.set_xticks(ind + width)\nax.set_xticklabels(\n    [\n        \"LogisticRegression\\n \u0627\u0644\u0648\u0632\u0646 1\",\n        \"GaussianNB\\n \u0627\u0644\u0648\u0632\u0646 1\",\n        \"RandomForestClassifier\\n \u0627\u0644\u0648\u0632\u0646 5\",\n        \"VotingClassifier\\n (\u0645\u062a\u0648\u0633\u0637 \u0627\u0644\u0627\u062d\u062a\u0645\u0627\u0644\u0627\u062a)\",\n    ],\n    rotation=40,\n    ha=\"right\",\n)\nplt.ylim([0, 1])\nplt.title(\"\u0627\u062d\u062a\u0645\u0627\u0644\u0627\u062a \u0627\u0644\u0641\u0626\u0627\u062a \u0644\u0644\u0639\u064a\u0646\u0629 1 \u0628\u0648\u0627\u0633\u0637\u0629 \u0645\u0635\u0646\u0641\u0627\u062a \u0645\u062e\u062a\u0644\u0641\u0629\")\nplt.legend([p1[0], p2[0]], [\"\u0627\u0644\u0641\u0626\u0629 1\", \"\u0627\u0644\u0641\u0626\u0629 2\"], loc=\"upper left\")\nplt.tight_layout()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}