{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class='alert alert-warning'>\n\n# JupyterLite warning\n\nRunning the scikit-learn examples in JupyterLite is experimental and you may encounter some unexpected behavior.\n\nThe main difference is that imports will take a lot longer than usual, for example the first `import sklearn` can take roughly 10-20s.\n\nIf you notice problems, feel free to open an [issue](https://github.com/scikit-learn/scikit-learn/issues/new/choose) about it.\n</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# JupyterLite-specific code\nimport matplotlib\nimport pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# \u062a\u0642\u062f\u064a\u0631 \u0643\u062b\u0627\u0641\u0629 \u0627\u0644\u0646\u0648\u0627\u0629 \u0627\u0644\u0628\u0633\u064a\u0637\u0629 \u0623\u062d\u0627\u062f\u064a\u0629 \u0627\u0644\u0628\u0639\u062f\n\u064a\u0633\u062a\u062e\u062f\u0645 \u0647\u0630\u0627 \u0627\u0644\u0645\u062b\u0627\u0644 \u0641\u0626\u0629 :class:`~sklearn.neighbors.KernelDensity`\n\u0644\u062a\u0648\u0636\u064a\u062d \u0645\u0628\u0627\u062f\u0626 \u062a\u0642\u062f\u064a\u0631 \u0643\u062b\u0627\u0641\u0629 \u0627\u0644\u0646\u0648\u0627\u0629 \u0641\u064a \u0627\u0644\u0628\u0639\u062f \u0623\u062d\u0627\u062f\u064a.\n\n\u064a\u0648\u0636\u062d \u0627\u0644\u0645\u062e\u0637\u0637 \u0627\u0644\u0623\u0648\u0644 \u0623\u062d\u062f \u0627\u0644\u0645\u0634\u0627\u0643\u0644 \u0627\u0644\u0645\u062a\u0639\u0644\u0642\u0629 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u0627\u0644\u062a\u0648\u0632\u064a\u0639\u0627\u062a \u0627\u0644\u062a\u0643\u0631\u0627\u0631\u064a\u0629 \u0644\u062a\u0635\u0648\u0631\n\u0643\u062b\u0627\u0641\u0629 \u0627\u0644\u0646\u0642\u0627\u0637 \u0641\u064a \u0627\u0644\u0628\u0639\u062f \u0623\u062d\u0627\u062f\u064a. \u0628\u062f\u064a\u0647\u064a\u0627\u064b\u060c \u064a\u0645\u0643\u0646 \u0627\u0639\u062a\u0628\u0627\u0631 \u0627\u0644\u062a\u0648\u0632\u064a\u0639 \u0627\u0644\u062a\u0643\u0631\u0627\u0631\u064a \u0639\u0644\u0649 \u0623\u0646\u0647\n\u0645\u062e\u0637\u0637 \u064a\u062a\u0645 \u0641\u064a\u0647 \u0648\u0636\u0639 \"\u0643\u062a\u0644\u0629\" \u0648\u062d\u062f\u0629 \u0641\u0648\u0642 \u0643\u0644 \u0646\u0642\u0637\u0629 \u0639\u0644\u0649 \u0634\u0628\u0643\u0629 \u0645\u0646\u062a\u0638\u0645\u0629. \u0648\u0645\u0639 \u0630\u0644\u0643\u060c \u0643\u0645\u0627 \u062a\u0648\u0636\u062d\n\u0644\u0648\u062d\u062a\u0627\u0646 \u0627\u0644\u0639\u0644\u0648\u064a\u062a\u0627\u0646\u060c \u064a\u0645\u0643\u0646 \u0623\u0646 \u064a\u0624\u062f\u064a \u0627\u062e\u062a\u064a\u0627\u0631 \u0627\u0644\u0634\u0628\u0643\u0629 \u0644\u0647\u0630\u0647 \u0627\u0644\u0643\u062a\u0644 \u0625\u0644\u0649 \u0623\u0641\u0643\u0627\u0631 \u0645\u062a\u0628\u0627\u064a\u0646\u0629\n\u0628\u0634\u0643\u0644 \u0643\u0628\u064a\u0631 \u062d\u0648\u0644 \u0627\u0644\u0634\u0643\u0644 \u0627\u0644\u0623\u0633\u0627\u0633\u064a \u0644\u062a\u0648\u0632\u064a\u0639 \u0627\u0644\u0643\u062b\u0627\u0641\u0629. \u0625\u0630\u0627 \u0642\u0645\u0646\u0627 \u0628\u062f\u0644\u0627\u064b \u0645\u0646 \u0630\u0644\u0643 \u0628\u062a\u0631\u0643\u064a\u0632 \u0643\u0644\n\u0643\u062a\u0644\u0629 \u0639\u0644\u0649 \u0627\u0644\u0646\u0642\u0637\u0629 \u0627\u0644\u062a\u064a \u062a\u0645\u062b\u0644\u0647\u0627\u060c \u0641\u0625\u0646\u0646\u0627 \u0646\u062d\u0635\u0644 \u0639\u0644\u0649 \u0627\u0644\u062a\u0642\u062f\u064a\u0631 \u0627\u0644\u0645\u0648\u0636\u062d \u0641\u064a \u0627\u0644\u0644\u0648\u062d\u0629 \u0627\u0644\u0633\u0641\u0644\u064a\u0629\n\u0627\u0644\u064a\u0633\u0631\u0649. \u0647\u0630\u0627 \u0647\u0648 \u062a\u0642\u062f\u064a\u0631 \u0643\u062b\u0627\u0641\u0629 \u0627\u0644\u0646\u0648\u0627\u0629 \u0645\u0639 \u0646\u0648\u0627\u0629 \"\u0642\u0628\u0639\u0629 \u0639\u0644\u0648\u064a\u0629\". \u064a\u0645\u0643\u0646 \u062a\u0639\u0645\u064a\u0645 \u0647\u0630\u0647 \u0627\u0644\u0641\u0643\u0631\u0629\n\u0639\u0644\u0649 \u0623\u0634\u0643\u0627\u0644 \u0646\u0648\u0627\u0629 \u0623\u062e\u0631\u0649: \u062a\u0648\u0636\u062d \u0627\u0644\u0644\u0648\u062d\u0629 \u0627\u0644\u0633\u0641\u0644\u064a\u0629 \u0627\u0644\u064a\u0645\u0646\u0649 \u0645\u0646 \u0627\u0644\u0634\u0643\u0644 \u0627\u0644\u0623\u0648\u0644 \u062a\u0642\u062f\u064a\u0631 \u0643\u062b\u0627\u0641\u0629\n\u0627\u0644\u0646\u0648\u0627\u0629 \u0627\u0644\u063a\u0627\u0648\u0633\u064a\u0629 \u0639\u0644\u0649 \u0646\u0641\u0633 \u0627\u0644\u062a\u0648\u0632\u064a\u0639.\n\n\u064a\u0646\u0641\u0630 Scikit-learn \u062a\u0642\u062f\u064a\u0631 \u0643\u062b\u0627\u0641\u0629 \u0627\u0644\u0646\u0648\u0627\u0629 \u0628\u0643\u0641\u0627\u0621\u0629 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u0625\u0645\u0627 \u0628\u0646\u064a\u0629 \u0634\u062c\u0631\u0629 \u0627\u0644\u0643\u0631\u0629 \u0623\u0648\n\u0634\u062c\u0631\u0629 KD\u060c \u0645\u0646 \u062e\u0644\u0627\u0644 :class:`~sklearn.neighbors.KernelDensity` estimator. \u064a\u062a\u0645\n\u0639\u0631\u0636 \u0627\u0644\u0646\u0648\u0627\u0629 \u0627\u0644\u0645\u062a\u0627\u062d\u0629 \u0641\u064a \u0627\u0644\u0634\u0643\u0644 \u0627\u0644\u062b\u0627\u0646\u064a \u0645\u0646 \u0647\u0630\u0627 \u0627\u0644\u0645\u062b\u0627\u0644.\n\n\u064a\u0642\u0627\u0631\u0646 \u0627\u0644\u0634\u0643\u0644 \u0627\u0644\u062b\u0627\u0644\u062b \u062a\u0642\u062f\u064a\u0631\u0627\u062a \u0643\u062b\u0627\u0641\u0629 \u0627\u0644\u0646\u0648\u0627\u0629 \u0644\u062a\u0648\u0632\u064a\u0639 100 \u0639\u064a\u0646\u0629 \u0641\u064a \u0627\u0644\u0628\u0639\u062f \u0623\u062d\u0627\u062f\u064a. \u0639\u0644\u0649\n\u0627\u0644\u0631\u063a\u0645 \u0645\u0646 \u0623\u0646 \u0647\u0630\u0627 \u0627\u0644\u0645\u062b\u0627\u0644 \u064a\u0633\u062a\u062e\u062f\u0645 \u062a\u0648\u0632\u064a\u0639\u0627\u062a \u0623\u062d\u0627\u062f\u064a\u0629 \u0627\u0644\u0628\u0639\u062f\u060c \u0625\u0644\u0627 \u0623\u0646 \u062a\u0642\u062f\u064a\u0631 \u0643\u062b\u0627\u0641\u0629 \u0627\u0644\u0646\u0648\u0627\u0629\n\u064a\u0645\u0643\u0646 \u062a\u0645\u062f\u064a\u062f\u0647 \u0628\u0633\u0647\u0648\u0644\u0629 \u0648\u0643\u0641\u0627\u0621\u0629 \u0625\u0644\u0649 \u0623\u0628\u0639\u0627\u062f \u0623\u0639\u0644\u0649 \u0623\u064a\u0636\u064b\u0627.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \u0627\u0644\u0645\u0624\u0644\u0641\u0648\u0646: \u0645\u0637\u0648\u0631\u064a scikit-learn\n# \u0645\u0639\u0631\u0641 \u0627\u0644\u062a\u0631\u062e\u064a\u0635: BSD-3-Clause\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.stats import norm\n\nfrom sklearn.neighbors import KernelDensity\n\n# ----------------------------------------------------------------------\n# \u0631\u0633\u0645 \u062a\u0637\u0648\u0631 \u0627\u0644\u062a\u0648\u0632\u064a\u0639\u0627\u062a \u0627\u0644\u062a\u0643\u0631\u0627\u0631\u064a\u0629 \u0625\u0644\u0649 \u0646\u0648\u0627\u0629\nnp.random.seed(1)\nN = 20\nX = np.concatenate(\n    (np.random.normal(0, 1, int(0.3 * N)), np.random.normal(5, 1, int(0.7 * N)))\n)[:, np.newaxis]\nX_plot = np.linspace(-5, 10, 1000)[:, np.newaxis]\nbins = np.linspace(-5, 10, 10)\n\nfig, ax = plt.subplots(2, 2, sharex=True, sharey=True)\nfig.subplots_adjust(hspace=0.05, wspace=0.05)\n\n# \u0627\u0644\u062a\u0648\u0632\u064a\u0639 \u0627\u0644\u062a\u0643\u0631\u0627\u0631\u064a 1\nax[0, 0].hist(X[:, 0], bins=bins, fc=\"#AAAAFF\", density=True)\nax[0, 0].text(-3.5, 0.31, \"Histogram\")\n\n# \u0627\u0644\u062a\u0648\u0632\u064a\u0639 \u0627\u0644\u062a\u0643\u0631\u0627\u0631\u064a 2\nax[0, 1].hist(X[:, 0], bins=bins + 0.75, fc=\"#AAAAFF\", density=True)\nax[0, 1].text(-3.5, 0.31, \"Histogram, bins shifted\")\n\n# \u062a\u0642\u062f\u064a\u0631 \u0643\u062b\u0627\u0641\u0629 \u0627\u0644\u0646\u0648\u0627\u0629 \"\u0642\u0628\u0639\u0629 \u0639\u0644\u0648\u064a\u0629\"\nkde = KernelDensity(kernel=\"tophat\", bandwidth=0.75).fit(X)\nlog_dens = kde.score_samples(X_plot)\nax[1, 0].fill(X_plot[:, 0], np.exp(log_dens), fc=\"#AAAAFF\")\nax[1, 0].text(-3.5, 0.31, \"Tophat Kernel Density\")\n\n# \u062a\u0642\u062f\u064a\u0631 \u0643\u062b\u0627\u0641\u0629 \u0627\u0644\u0646\u0648\u0627\u0629 \u0627\u0644\u063a\u0627\u0648\u0633\u064a\u0629\nkde = KernelDensity(kernel=\"gaussian\", bandwidth=0.75).fit(X)\nlog_dens = kde.score_samples(X_plot)\nax[1, 1].fill(X_plot[:, 0], np.exp(log_dens), fc=\"#AAAAFF\")\nax[1, 1].text(-3.5, 0.31, \"Gaussian Kernel Density\")\n\nfor axi in ax.ravel():\n    axi.plot(X[:, 0], np.full(X.shape[0], -0.01), \"+k\")\n    axi.set_xlim(-4, 9)\n    axi.set_ylim(-0.02, 0.34)\n\nfor axi in ax[:, 0]:\n    axi.set_ylabel(\"Normalized Density\")\n\nfor axi in ax[1, :]:\n    axi.set_xlabel(\"x\")\n\n# ----------------------------------------------------------------------\n# \u0631\u0633\u0645 \u062c\u0645\u064a\u0639 \u0627\u0644\u0646\u0648\u0627\u0629 \u0627\u0644\u0645\u062a\u0627\u062d\u0629\nX_plot = np.linspace(-6, 6, 1000)[:, None]\nX_src = np.zeros((1, 1))\n\nfig, ax = plt.subplots(2, 3, sharex=True, sharey=True)\nfig.subplots_adjust(left=0.05, right=0.95, hspace=0.05, wspace=0.05)\n\n\ndef format_func(x, loc):\n    if x == 0:\n        return \"0\"\n    elif x == 1:\n        return \"h\"\n    elif x == -1:\n        return \"-h\"\n    else:\n        return \"%ih\" % x\n\n\nfor i, kernel in enumerate(\n    [\"gaussian\", \"tophat\", \"epanechnikov\", \"exponential\", \"linear\", \"cosine\"]\n):\n    axi = ax.ravel()[i]\n    log_dens = KernelDensity(kernel=kernel).fit(X_src).score_samples(X_plot)\n    axi.fill(X_plot[:, 0], np.exp(log_dens), \"-k\", fc=\"#AAAAFF\")\n    axi.text(-2.6, 0.95, kernel)\n\n    axi.xaxis.set_major_formatter(plt.FuncFormatter(format_func))\n    axi.xaxis.set_major_locator(plt.MultipleLocator(1))\n    axi.yaxis.set_major_locator(plt.NullLocator())\n\n    axi.set_ylim(0, 1.05)\n    axi.set_xlim(-2.9, 2.9)\n\nax[0, 1].set_title(\"Available Kernels\")\n\n# ----------------------------------------------------------------------\n# \u0631\u0633\u0645 \u0645\u062b\u0627\u0644 \u0639\u0644\u0649 \u0643\u062b\u0627\u0641\u0629 \u0623\u062d\u0627\u062f\u064a\u0629 \u0627\u0644\u0628\u0639\u062f\nN = 100\nnp.random.seed(1)\nX = np.concatenate(\n    (np.random.normal(0, 1, int(0.3 * N)), np.random.normal(5, 1, int(0.7 * N)))\n)[:, np.newaxis]\n\nX_plot = np.linspace(-5, 10, 1000)[:, np.newaxis]\n\ntrue_dens = 0.3 * norm(0, 1).pdf(X_plot[:, 0]) + 0.7 * norm(5, 1).pdf(X_plot[:, 0])\n\nfig, ax = plt.subplots()\nax.fill(X_plot[:, 0], true_dens, fc=\"black\", alpha=0.2, label=\"input distribution\")\ncolors = [\"navy\", \"cornflowerblue\", \"darkorange\"]\nkernels = [\"gaussian\", \"tophat\", \"epanechnikov\"]\nlw = 2\n\nfor color, kernel in zip(colors, kernels):\n    kde = KernelDensity(kernel=kernel, bandwidth=0.5).fit(X)\n    log_dens = kde.score_samples(X_plot)\n    ax.plot(\n        X_plot[:, 0],\n        np.exp(log_dens),\n        color=color,\n        lw=lw,\n        linestyle=\"-\",\n        label=\"kernel = '{0}'\".format(kernel),\n    )\n\nax.text(6, 0.38, \"N={0} points\".format(N))\n\nax.legend(loc=\"upper left\")\nax.plot(X[:, 0], -0.005 - 0.01 * np.random.random(X.shape[0]), \"+k\")\n\nax.set_xlim(-4, 9)\nax.set_ylim(-0.02, 0.4)\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}