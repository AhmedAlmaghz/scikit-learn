
<!DOCTYPE html>


<html lang="ar" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Examples" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://scikit-learn/stable/auto_examples/index.html" />
<meta property="og:site_name" content="scikit-learn" />
<meta property="og:description" content="This is the gallery of examples that showcase how scikit-learn can be used. Some examples demonstrate the use of the API in general and some demonstrate specific applications in tutorial form. Also..." />
<meta property="og:image" content="https://scikit-learn/stable/_images/sphx_glr_plot_release_highlights_1_5_0_thumb.png" />
<meta property="og:image:alt" content="" />
<meta name="description" content="This is the gallery of examples that showcase how scikit-learn can be used. Some examples demonstrate the use of the API in general and some demonstrate specific applications in tutorial form. Also..." />

    <title>Examples &#8212; scikit-learn 1.6.dev0 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css?v=7f9a90b1" />
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Vibur" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyterlite_sphinx.css?v=ca70e7f1" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/colors.css?v=cc94ab7d" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/custom.css?v=85b0813d" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="../_static/documentation_options.js?v=3cd28d06"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=97f0b27d"></script>
    <script src="../_static/jupyterlite_sphinx.js?v=d6bdf5f8"></script>
    <script src="../_static/translations.js?v=87cb2081"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script data-domain="scikit-learn.org" defer="defer" src="https://views.scientific-python.org/js/script.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'auto_examples/index';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.0';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://scikit-learn.org/dev/_static/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '1.6.dev0';
        DOCUMENTATION_OPTIONS.show_version_warning_banner = true;
        </script>
    <script src="../_static/scripts/dropdown.js?v=e2048168"></script>
    <script src="../_static/scripts/version-switcher.js?v=a6dd8357"></script>
    <link rel="icon" href="../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="search" title="بحث" href="../search.html" />
    <link rel="next" title="Release Highlights" href="release_highlights/index.html" />
    <link rel="prev" title="register_parallel_backend" href="../modules/generated/sklearn.utils.register_parallel_backend.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="ar"/>
  <meta name="docsearch:version" content="1.6" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/scikit-learn-logo-small.png" class="logo__image only-light" alt="scikit-learn homepage"/>
    <img src="../_static/scikit-learn-logo-small.png" class="logo__image only-dark pst-js-only" alt="scikit-learn homepage"/>
  
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../install.html">
    Install
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../user_guide.html">
    دليل المستخدم
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api/index.html">
    API
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="#">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://blog.scikit-learn.org/">
    Community
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../getting_started.html">
    البدء
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../whats_new.html">
    Release History
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../glossary.html">
    Glossary
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../developers/index.html">
    Development
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../faq.html">
    FAQ
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../support.html">
    الدعم الفني
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../related_projects.html">
    مشاريع ذات علاقة
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../roadmap.html">
    Roadmap
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../governance.html">
    Governance
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../about.html">
    من نحن
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="بحث" aria-label="بحث" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/scikit-learn/scikit-learn" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
      
        <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="بحث" aria-label="بحث" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
    </div>
  

  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../install.html">
    Install
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../user_guide.html">
    دليل المستخدم
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api/index.html">
    API
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="#">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://blog.scikit-learn.org/">
    Community
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../getting_started.html">
    البدء
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../whats_new.html">
    Release History
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../glossary.html">
    Glossary
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../developers/index.html">
    Development
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../faq.html">
    FAQ
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../support.html">
    الدعم الفني
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../related_projects.html">
    مشاريع ذات علاقة
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../roadmap.html">
    Roadmap
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../governance.html">
    Governance
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../about.html">
    من نحن
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/scikit-learn/scikit-learn" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
        
          <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="release_highlights/index.html">Release Highlights</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="release_highlights/plot_release_highlights_1_5_0.html">Release Highlights for scikit-learn 1.5</a></li>
<li class="toctree-l2"><a class="reference internal" href="release_highlights/plot_release_highlights_1_4_0.html">Release Highlights for scikit-learn 1.4</a></li>
<li class="toctree-l2"><a class="reference internal" href="release_highlights/plot_release_highlights_1_3_0.html">Release Highlights for scikit-learn 1.3</a></li>
<li class="toctree-l2"><a class="reference internal" href="release_highlights/plot_release_highlights_1_2_0.html">Release Highlights for scikit-learn 1.2</a></li>
<li class="toctree-l2"><a class="reference internal" href="release_highlights/plot_release_highlights_1_1_0.html">Release Highlights for scikit-learn 1.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="release_highlights/plot_release_highlights_1_0_0.html">Release Highlights for scikit-learn 1.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="release_highlights/plot_release_highlights_0_24_0.html">Release Highlights for scikit-learn 0.24</a></li>
<li class="toctree-l2"><a class="reference internal" href="release_highlights/plot_release_highlights_0_23_0.html">Release Highlights for scikit-learn 0.23</a></li>
<li class="toctree-l2"><a class="reference internal" href="release_highlights/plot_release_highlights_0_22_0.html">Release Highlights for scikit-learn 0.22</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="tree/index.html">Decision Trees</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="tree/plot_tree_regression.html">Decision Tree Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="tree/plot_iris_dtc.html">Plot the decision surface of decision trees trained on the iris dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="tree/plot_cost_complexity_pruning.html">Post pruning decision trees with cost complexity pruning</a></li>
<li class="toctree-l2"><a class="reference internal" href="tree/plot_unveil_tree_structure.html">Understanding the decision tree structure</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="mixture/index.html">Gaussian Mixture Models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="mixture/plot_concentration_prior.html">Concentration Prior Type Analysis of Variation Bayesian Gaussian Mixture</a></li>
<li class="toctree-l2"><a class="reference internal" href="mixture/plot_gmm_pdf.html">Density Estimation for a Gaussian mixture</a></li>
<li class="toctree-l2"><a class="reference internal" href="mixture/plot_gmm_init.html">GMM Initialization Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="mixture/plot_gmm_covariances.html">GMM covariances</a></li>
<li class="toctree-l2"><a class="reference internal" href="mixture/plot_gmm.html">Gaussian Mixture Model Ellipsoids</a></li>
<li class="toctree-l2"><a class="reference internal" href="mixture/plot_gmm_selection.html">Gaussian Mixture Model Selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="mixture/plot_gmm_sin.html">Gaussian Mixture Model Sine Curve</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="manifold/index.html">Manifold learning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="manifold/plot_compare_methods.html">Comparison of Manifold Learning methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="manifold/plot_manifold_sphere.html">Manifold Learning methods on a severed sphere</a></li>
<li class="toctree-l2"><a class="reference internal" href="manifold/plot_lle_digits.html">Manifold learning on handwritten digits: Locally Linear Embedding, Isomap...</a></li>
<li class="toctree-l2"><a class="reference internal" href="manifold/plot_mds.html">Multi-dimensional scaling</a></li>
<li class="toctree-l2"><a class="reference internal" href="manifold/plot_swissroll.html">Swiss Roll And Swiss-Hole Reduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="manifold/plot_t_sne_perplexity.html">t-SNE: The effect of various perplexity values on the shape</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="miscellaneous/index.html">Miscellaneous</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="miscellaneous/plot_partial_dependence_visualization_api.html">Advanced Plotting With Partial Dependence</a></li>
<li class="toctree-l2"><a class="reference internal" href="miscellaneous/plot_anomaly_comparison.html">Comparing anomaly detection algorithms for outlier detection on toy datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="miscellaneous/plot_kernel_ridge_regression.html">Comparison of kernel ridge regression and SVR</a></li>
<li class="toctree-l2"><a class="reference internal" href="miscellaneous/plot_pipeline_display.html">Displaying Pipelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="miscellaneous/plot_estimator_representation.html">Displaying estimators and complex pipelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="miscellaneous/plot_outlier_detection_bench.html">Evaluation of outlier detection estimators</a></li>
<li class="toctree-l2"><a class="reference internal" href="miscellaneous/plot_kernel_approximation.html">Explicit feature map approximation for RBF kernels</a></li>
<li class="toctree-l2"><a class="reference internal" href="miscellaneous/plot_multioutput_face_completion.html">Face completion with a multi-output estimators</a></li>
<li class="toctree-l2"><a class="reference internal" href="miscellaneous/plot_set_output.html">Introducing the <code class="docutils literal notranslate"><span class="pre">set_output</span></code> API</a></li>
<li class="toctree-l2"><a class="reference internal" href="miscellaneous/plot_isotonic_regression.html">Isotonic Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="miscellaneous/plot_metadata_routing.html">Metadata Routing</a></li>
<li class="toctree-l2"><a class="reference internal" href="miscellaneous/plot_multilabel.html">Multilabel classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="miscellaneous/plot_roc_curve_visualization_api.html">ROC Curve with Visualization API</a></li>
<li class="toctree-l2"><a class="reference internal" href="miscellaneous/plot_johnson_lindenstrauss_bound.html">The Johnson-Lindenstrauss bound for embedding with random projections</a></li>
<li class="toctree-l2"><a class="reference internal" href="miscellaneous/plot_display_object_visualization.html">Visualizations with Display Objects</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="model_selection/index.html">Model Selection</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="model_selection/plot_grid_search_refit_callable.html">Balance model complexity and cross-validated score</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_selection/plot_likelihood_ratios.html">Class Likelihood Ratios to measure classification performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_selection/plot_randomized_search.html">Comparing randomized search and grid search for hyperparameter estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_selection/plot_successive_halving_heatmap.html">Comparison between grid search and successive halving</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_selection/plot_confusion_matrix.html">Confusion matrix</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_selection/plot_grid_search_digits.html">Custom refit strategy of a grid search with cross-validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_selection/plot_multi_metric_evaluation.html">Demonstration of multi-metric evaluation on cross_val_score and GridSearchCV</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_selection/plot_det.html">Detection error tradeoff (DET) curve</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_selection/plot_train_error_vs_test_error.html">Effect of model regularization on training and test error</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_selection/plot_roc.html">Multiclass Receiver Operating Characteristic (ROC)</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_selection/plot_nested_cross_validation_iris.html">Nested versus non-nested cross-validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_selection/plot_cv_predict.html">Plotting Cross-Validated Predictions</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_selection/plot_learning_curve.html">Plotting Learning Curves and Checking Models' Scalability</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_selection/plot_tuned_decision_threshold.html">Post-hoc tuning the cut-off point of decision function</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_selection/plot_cost_sensitive_learning.html">Post-tuning the decision threshold for cost-sensitive learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_selection/plot_precision_recall.html">Precision-Recall</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_selection/plot_roc_crossval.html">Receiver Operating Characteristic (ROC) with cross validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_selection/plot_grid_search_text_feature_extraction.html">Sample pipeline for text feature extraction and evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_selection/plot_grid_search_stats.html">Statistical comparison of models using grid search</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_selection/plot_successive_halving_iterations.html">Successive Halving Iterations</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_selection/plot_permutation_tests_for_classification.html">Test with permutations the significance of a classification score</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_selection/plot_underfitting_overfitting.html">Underfitting vs. Overfitting</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_selection/plot_cv_indices.html">Visualizing cross-validation behavior in scikit-learn</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="multiclass/index.html">Multiclass methods</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="multiclass/plot_multiclass_overview.html">Overview of multiclass training meta-estimators</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="multioutput/index.html">Multioutput methods</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="multioutput/plot_classifier_chain_yeast.html">Multilabel classification using a classifier chain</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="neighbors/index.html">Nearest Neighbors</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="neighbors/approximate_nearest_neighbors.html">Approximate nearest neighbors in TSNE</a></li>
<li class="toctree-l2"><a class="reference internal" href="neighbors/plot_caching_nearest_neighbors.html">Caching nearest neighbors</a></li>
<li class="toctree-l2"><a class="reference internal" href="neighbors/plot_nca_classification.html">Comparing Nearest Neighbors with and without Neighborhood Components Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="neighbors/plot_nca_dim_reduction.html">Dimensionality Reduction with Neighborhood Components Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="neighbors/plot_species_kde.html">Kernel Density Estimate of Species Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="neighbors/plot_digits_kde_sampling.html">Kernel Density Estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="neighbors/plot_nearest_centroid.html">Nearest Centroid Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="neighbors/plot_classification.html">Nearest Neighbors Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="neighbors/plot_regression.html">Nearest Neighbors regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="neighbors/plot_nca_illustration.html">Neighborhood Components Analysis Illustration</a></li>
<li class="toctree-l2"><a class="reference internal" href="neighbors/plot_lof_novelty_detection.html">Novelty detection with Local Outlier Factor (LOF)</a></li>
<li class="toctree-l2"><a class="reference internal" href="neighbors/plot_lof_outlier_detection.html">Outlier detection with Local Outlier Factor (LOF)</a></li>
<li class="toctree-l2"><a class="reference internal" href="neighbors/plot_kde_1d.html">Simple 1D Kernel Density Estimation</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="neural_networks/index.html">Neural Networks</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="neural_networks/plot_mlp_training_curves.html">Compare Stochastic learning strategies for MLPClassifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="neural_networks/plot_rbm_logistic_classification.html">Restricted Boltzmann Machine features for digit classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="neural_networks/plot_mlp_alpha.html">Varying regularization in Multi-layer Perceptron</a></li>
<li class="toctree-l2"><a class="reference internal" href="neural_networks/plot_mnist_filters.html">Visualization of MLP weights on MNIST</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="preprocessing/index.html">Preprocessing</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="preprocessing/plot_all_scaling.html">Compare the effect of different scalers on data with outliers</a></li>
<li class="toctree-l2"><a class="reference internal" href="preprocessing/plot_target_encoder.html">Comparing Target Encoder with Other Encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="preprocessing/plot_discretization_strategies.html">Demonstrating the different strategies of KBinsDiscretizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="preprocessing/plot_discretization_classification.html">Feature discretization</a></li>
<li class="toctree-l2"><a class="reference internal" href="preprocessing/plot_scaling_importance.html">Importance of Feature Scaling</a></li>
<li class="toctree-l2"><a class="reference internal" href="preprocessing/plot_map_data_to_normal.html">Map data to a normal distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="preprocessing/plot_target_encoder_cross_val.html">Target Encoder's Internal Cross fitting</a></li>
<li class="toctree-l2"><a class="reference internal" href="preprocessing/plot_discretization.html">Using KBinsDiscretizer to discretize continuous features</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="semi_supervised/index.html">Semi Supervised Classification</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="semi_supervised/plot_semi_supervised_versus_svm_iris.html">Decision boundary of semi-supervised classifiers versus SVM on the Iris dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="semi_supervised/plot_self_training_varying_threshold.html">Effect of varying threshold for self-training</a></li>
<li class="toctree-l2"><a class="reference internal" href="semi_supervised/plot_label_propagation_digits_active_learning.html">Label Propagation digits active learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="semi_supervised/plot_label_propagation_digits.html">Label Propagation digits: Demonstrating performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="semi_supervised/plot_label_propagation_structure.html">Label Propagation learning a complex structure</a></li>
<li class="toctree-l2"><a class="reference internal" href="semi_supervised/plot_semi_supervised_newsgroups.html">Semi-supervised Classification on a Text Dataset</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="svm/index.html">Support Vector Machines</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="svm/plot_oneclass.html">One-class SVM with non-linear kernel (RBF)</a></li>
<li class="toctree-l2"><a class="reference internal" href="svm/plot_svm_kernels.html">Plot classification boundaries with different SVM Kernels</a></li>
<li class="toctree-l2"><a class="reference internal" href="svm/plot_iris_svc.html">Plot different SVM classifiers in the iris dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="svm/plot_linearsvc_support_vectors.html">Plot the support vectors in LinearSVC</a></li>
<li class="toctree-l2"><a class="reference internal" href="svm/plot_rbf_parameters.html">RBF SVM parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="svm/plot_svm_margin.html">SVM Margins Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="svm/plot_svm_tie_breaking.html">SVM Tie Breaking Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="svm/plot_custom_kernel.html">SVM with custom kernel</a></li>
<li class="toctree-l2"><a class="reference internal" href="svm/plot_svm_anova.html">SVM-Anova: SVM with univariate feature selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="svm/plot_separating_hyperplane.html">SVM: Maximum margin separating hyperplane</a></li>
<li class="toctree-l2"><a class="reference internal" href="svm/plot_separating_hyperplane_unbalanced.html">SVM: Separating hyperplane for unbalanced classes</a></li>
<li class="toctree-l2"><a class="reference internal" href="svm/plot_weighted_samples.html">SVM: Weighted samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="svm/plot_svm_scale_c.html">Scaling the regularization parameter for SVCs</a></li>
<li class="toctree-l2"><a class="reference internal" href="svm/plot_svm_regression.html">Support Vector Regression (SVR) using linear and non-linear kernels</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="text/index.html">Working with text documents</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="text/plot_document_classification_20newsgroups.html">Classification of text documents using sparse features</a></li>
<li class="toctree-l2"><a class="reference internal" href="text/plot_document_clustering.html">Clustering text documents using k-means</a></li>
<li class="toctree-l2"><a class="reference internal" href="text/plot_hashing_vs_dict_vectorizer.html">FeatureHasher and DictVectorizer Comparison</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="applications/index.html">أمثلة مبنية على مجموعات بيانات من العالم الحقيقي</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="applications/plot_out_of_core_classification.html">Out-of-core classification of text documents</a></li>
<li class="toctree-l2"><a class="reference internal" href="applications/plot_digits_denoising.html">إزالة التشويش من الصور باستخدام PCA النواة</a></li>
<li class="toctree-l2"><a class="reference internal" href="applications/plot_outlier_detection_wine.html">الكشف عن القيم الشاذة في مجموعة بيانات حقيقية</a></li>
<li class="toctree-l2"><a class="reference internal" href="applications/wikipedia_principal_eigenvector.html">المتجه الذاتي الرئيسي لويكيبيديا</a></li>
<li class="toctree-l2"><a class="reference internal" href="applications/plot_time_series_lagged_features.html">الميزات المتأخرة للتنبؤ بالسلاسل الزمنية</a></li>
<li class="toctree-l2"><a class="reference internal" href="applications/plot_model_complexity_influence.html">تأثير تعقيد النموذج</a></li>
<li class="toctree-l2"><a class="reference internal" href="applications/plot_prediction_latency.html">تأخير التنبؤ</a></li>
<li class="toctree-l2"><a class="reference internal" href="applications/plot_face_recognition.html">مثال على التعرف على الوجوه باستخدام الوجوه المميزة وآلات المتجهات الداعمة</a></li>
<li class="toctree-l2"><a class="reference internal" href="applications/plot_species_distribution_modeling.html">نمذجة توزيع الأنواع</a></li>
<li class="toctree-l2"><a class="reference internal" href="applications/plot_cyclical_feature_engineering.html">هندسة الميزات ذات الصلة بالوقت</a></li>
<li class="toctree-l2"><a class="reference internal" href="applications/plot_stock_market.html">هيكلة سوق الأسهم المرئية</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="datasets/index.html">أمثلة مجموعات البيانات</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="datasets/plot_random_multilabel_dataset.html">رسم مجموعة بيانات متعددة التصنيفات مُولدة عشوائياً</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="feature_selection/index.html">إختيار الميزة</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="feature_selection/plot_select_from_model_diabetes.html">Model-based and sequential feature selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="feature_selection/plot_feature_selection_pipeline.html">Pipeline ANOVA SVM</a></li>
<li class="toctree-l2"><a class="reference internal" href="feature_selection/plot_rfe_with_cross_validation.html">إزالة الميزات المتكررة باستخدام التحقق المتبادل</a></li>
<li class="toctree-l2"><a class="reference internal" href="feature_selection/plot_rfe_digits.html">إزالة الميزة المتكررة</a></li>
<li class="toctree-l2"><a class="reference internal" href="feature_selection/plot_feature_selection.html">اختيار الميزة أحادية المتغير</a></li>
<li class="toctree-l2"><a class="reference internal" href="feature_selection/plot_f_test_vs_mi.html">مقارنة بين اختبار F والمعلومات المتبادلة</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="cluster/index.html">التجميع</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="cluster/plot_segmentation_toy.html">توليد البيانات</a></li>


<li class="toctree-l2"><a class="reference internal" href="cluster/plot_agglomerative_clustering_metrics.html"># التجميع التجميعي مع مقاييس مختلفة</a></li>
<li class="toctree-l2"><a class="reference internal" href="cluster/plot_agglomerative_clustering.html"># التجميع التجميعي مع وبغير بنية</a></li>
<li class="toctree-l2"><a class="reference internal" href="cluster/plot_inductive_clustering.html">التصنيف الاستقرائي</a></li>
<li class="toctree-l2"><a class="reference internal" href="cluster/plot_ward_structured_vs_unstructured.html">العنقدة الهرمية: العنقدة المنظمة وغير المنظمة</a></li>
<li class="toctree-l2"><a class="reference internal" href="cluster/plot_digits_agglomeration.html">تجميع الميزات</a></li>
<li class="toctree-l2"><a class="reference internal" href="cluster/plot_kmeans_silhouette_analysis.html">تحليل السيلويت لتحديد عدد التجمعات في التجميع التجميعي KMeans</a></li>
<li class="toctree-l2"><a class="reference internal" href="cluster/plot_kmeans_digits.html">تطبيق خوارزمية k-means على مجموعة البيانات digits</a></li>
<li class="toctree-l2"><a class="reference internal" href="cluster/plot_adjusted_for_chance_measures.html">تعديل الفرصة في تقييم أداء التجميع</a></li>
<li class="toctree-l2"><a class="reference internal" href="cluster/plot_dict_face_patches.html">تعلم القاموس عبر الإنترنت لأجزاء الوجوه</a></li>
<li class="toctree-l2"><a class="reference internal" href="cluster/plot_kmeans_stability_low_dim_dense.html">تقييم تجريبي لتأثير تهيئة k-means</a></li>
<li class="toctree-l2"><a class="reference internal" href="cluster/plot_coin_segmentation.html">تم تقسيم صورة العملات اليونانية إلى مناطق</a></li>
<li class="toctree-l2"><a class="reference internal" href="cluster/plot_kmeans_assumptions.html">توضيح افتراضات خوارزمية كاي-مينز</a></li>
<li class="toctree-l2"><a class="reference internal" href="cluster/plot_agglomerative_dendrogram.html">رسم مخطط شجرة التجميع الهرمي</a></li>
<li class="toctree-l2"><a class="reference internal" href="cluster/plot_coin_ward_segmentation.html">عرض توضيحي لتجميع هرمي منظم على صورة عملات معدنية</a></li>
<li class="toctree-l2"><a class="reference internal" href="cluster/plot_dbscan.html">عرض توضيحي لخوارزمية التجميع DBSCAN</a></li>
<li class="toctree-l2"><a class="reference internal" href="cluster/plot_hdbscan.html">عرض توضيحي لخوارزمية التجميع HDBSCAN</a></li>
<li class="toctree-l2"><a class="reference internal" href="cluster/plot_optics.html">عرض توضيحي لخوارزمية التجميع OPTICS</a></li>
<li class="toctree-l2"><a class="reference internal" href="cluster/plot_mean_shift.html">عرض توضيحي لخوارزمية التجميع متوسط التحول</a></li>
<li class="toctree-l2"><a class="reference internal" href="cluster/plot_affinity_propagation.html">عرض توضيحي لخوارزمية تجميع انتشار الانتماء</a></li>
<li class="toctree-l2"><a class="reference internal" href="cluster/plot_kmeans_plusplus.html">مثال على التهيئة K-Means++</a></li>
<li class="toctree-l2"><a class="reference internal" href="cluster/plot_face_compress.html">مثال على تكميم المتجهات</a></li>
<li class="toctree-l2"><a class="reference internal" href="cluster/plot_digits_linkage.html">مختلف خوارزميات التجميع الهرمي على تضمين ثنائي الأبعاد لمجموعة بيانات الأرقام</a></li>
<li class="toctree-l2"><a class="reference internal" href="cluster/plot_birch_vs_minibatchkmeans.html">مقارنة بين BIRCH و MiniBatchKMeans</a></li>
<li class="toctree-l2"><a class="reference internal" href="cluster/plot_mini_batch_kmeans.html">مقارنة خوارزميات التجميع K-Means و MiniBatchKMeans</a></li>
<li class="toctree-l2"><a class="reference internal" href="cluster/plot_cluster_comparison.html">مقارنة خوارزميات التجميع المختلفة على مجموعات البيانات التجريبية</a></li>
<li class="toctree-l2"><a class="reference internal" href="cluster/plot_linkage_comparison.html">مقارنة طرق الربط الهرمي المختلفة على مجموعات بيانات تجريبية</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="bicluster/index.html">التجميع الثنائي</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="bicluster/plot_bicluster_newsgroups.html">التجميع الثنائي للمستندات باستخدام خوارزمية التجميع الطيفي المشترك</a></li>
<li class="toctree-l2"><a class="reference internal" href="bicluster/plot_spectral_biclustering.html">عرض توضيحي لخوارزمية التجميع الطيفي الثنائي</a></li>
<li class="toctree-l2"><a class="reference internal" href="bicluster/plot_spectral_coclustering.html">عرض توضيحي لخوارزمية التجميع الطيفي المشترك</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="cross_decomposition/index.html">التحلل المتقاطع</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="cross_decomposition/plot_pcr_vs_pls.html">الانحدار باستخدام المكونات الرئيسية مقابل الانحدار باستخدام المربعات الجزئية</a></li>
<li class="toctree-l2"><a class="reference internal" href="cross_decomposition/plot_compare_cross_decomposition.html">مقارنة طرق التحليل التفاضلي</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="classification/index.html">التصنيف</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="classification/plot_lda.html">Normal, Ledoit-Wolf and OAS Linear Discriminant Analysis for classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="classification/plot_digits_classification.html">التعرف على الأرقام المكتوبة بخط اليد</a></li>
<li class="toctree-l2"><a class="reference internal" href="classification/plot_classification_probability.html">رسم احتمالية التصنيف</a></li>
<li class="toctree-l2"><a class="reference internal" href="classification/plot_classifier_comparison.html">مقارنة المصنفات</a></li>
<li class="toctree-l2"><a class="reference internal" href="classification/plot_lda_qda.html">توليد البيانات</a></li>


</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="inspection/index.html">الفحص</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="inspection/plot_permutation_importance_multicollinear.html">أهمية التبديل مع الميزات متعددة الخطية أو المرتبطة</a></li>
<li class="toctree-l2"><a class="reference internal" href="inspection/plot_permutation_importance.html">أهمية التبديل مقابل أهمية ميزة الغابة العشوائية (MDI)</a></li>
<li class="toctree-l2"><a class="reference internal" href="inspection/plot_linear_model_coefficient_interpretation.html">المزالق الشائعة في تفسير معاملات النماذج الخطية</a></li>
<li class="toctree-l2"><a class="reference internal" href="inspection/plot_causal_interpretation.html">فشل التعلم الآلي في استنتاج الآثار السببية</a></li>
<li class="toctree-l2"><a class="reference internal" href="inspection/plot_partial_dependence.html">مخططات التبعية الجزئية والتوقع الشرطي الفردي</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="linear_model/index.html">النماذج الخطية المعممة</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_bayesian_ridge_curvefit.html">توليد بيانات توافقية مع الضوضاء</a></li>


<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_ard.html"># مقارنة المنحنيات الخطية للانحدار البايزي</a></li>


<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_lasso_dense_vs_sparse_data.html">Lasso على البيانات الكثيفة والمتفرقة</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_sgdocsvm_vs_ocsvm.html">One-Class SVM مقابل One-Class SVM باستخدام Stochastic Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_sgd_penalties.html">SGD: العقوبات</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_sgd_weighted_samples.html">SGD: العينات المرجحة</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_sgd_separating_hyperplane.html">SGD: المستوى الفاصل ذو الهامش الأقصى</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_sgd_loss_functions.html">SGD: دالات الخسارة المقعرة</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_sgd_early_stopping.html">إيقاف مبكر لنزول التدرج العشوائي</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_lasso_lars_ic.html">اختيار نموذج لاصو عبر معايير المعلومات</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_multi_task_lasso_support.html">الاختيار المشترك للميزات باستخدام Lasso متعدد المهام</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_ols_ridge_variance.html">الانحدار الخطي العادي وانحدار ريدج والتباين</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_sparse_logistic_regression_20newsgroups.html">الانحدار اللوجستي المتناثر متعدد الفئات على 20newgroups</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_polynomial_interpolation.html">التكامل متعدد الحدود والتقسيم</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_logistic.html">الدالة اللوغستية</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_poisson_regression_non_normal_loss.html">انحدار بواسون والخسارة غير الطبيعية</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_tweedie_regression_insurance_claims.html">انحدار تويدي على مطالبات التأمين</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_theilsen.html">انحدار ثيل-سين</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_quantile_regression.html">انحدار كمي</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_sparse_logistic_regression_mnist.html">تصنيف MNIST باستخدام اللوغاريتم متعدد الحدود + L1</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_ransac.html">تقدير النموذج الخطي القوي باستخدام RANSAC</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_robust_fit.html">تقدير خطي قوي</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_elastic_net_precomputed_gram_matrix_with_weighted_samples.html">تناسب شبكة مرنة مع مصفوفة جرام مسبقة الحساب وعينات مرجحة</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_logistic_multinomial.html">حدود القرار للانحدار متعدد الحدود والانحدار اللوجستي من النوع واحد مقابل البقية</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_sgd_iris.html">رسم متعدد الفئات SGD على مجموعة بيانات الزهرة</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_ridge_path.html">رسم معاملات Ridge كدالة للتنظيم</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_logistic_l1_l2_sparsity.html">عقوبة L1 والندرة في الانحدار اللوجستي</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_ols.html">مثال على المربعات الصغرى العادية</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_nnls.html">مربعات أقل غير سالبة</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_logistic_path.html">مسار التنظيم لـ L1 - الانحدار اللوجستي</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_lasso_lasso_lars_elasticnet_path.html">مسارات لاصو ولاصو-لارس وشبكة مرنة</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_omp.html">مطابقة متعامدة</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_ridge_coeffs.html">معاملات Ridge كدالة لتنظيم L2</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_huber_vs_ridge.html">مقارنة بين HuberRegressor و Ridge على مجموعة بيانات تحتوي على قيم شاذة قوية</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_sgd_comparison.html">مقارنة بين المحللات المختلفة عبر الإنترنت</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_lasso_and_elasticnet.html">نماذج L1 للاشارات المتناثرة</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_model/plot_lasso_model_selection.html">نموذج لاصو: اختيار النموذج باستخدام معايير AIC-BIC والتحقق المتقاطع</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="decomposition/index.html">تحليل التركيب</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="decomposition/plot_ica_vs_pca.html">FastICA على سحب النقاط ثنائية الأبعاد</a></li>
<li class="toctree-l2"><a class="reference internal" href="decomposition/plot_kernel_pca.html">Kernel PCA</a></li>
<li class="toctree-l2"><a class="reference internal" href="decomposition/plot_image_denoising.html">إزالة تشويش الصور باستخدام تعلم القاموس</a></li>
<li class="toctree-l2"><a class="reference internal" href="decomposition/plot_pca_vs_fa_model_selection.html">اختيار النموذج باستخدام التحليل الرئيسي للمكونات الاحتمالي وتحليل العوامل (FA)</a></li>
<li class="toctree-l2"><a class="reference internal" href="decomposition/plot_sparse_coding.html">الترميز المتناثر مع قاموس محسوب مسبقًا</a></li>
<li class="toctree-l2"><a class="reference internal" href="decomposition/plot_varimax_fa.html">تحليل العوامل (مع الدوران) لتصور الأنماط</a></li>
<li class="toctree-l2"><a class="reference internal" href="decomposition/plot_pca_iris.html">تحليل المكونات الرئيسية (PCA) على مجموعة بيانات Iris</a></li>
<li class="toctree-l2"><a class="reference internal" href="decomposition/plot_faces_decomposition.html">تحليلات مجموعة بيانات الوجوه</a></li>
<li class="toctree-l2"><a class="reference internal" href="decomposition/plot_ica_blind_source_separation.html">فصل المصدر الأعمى باستخدام FastICA</a></li>
<li class="toctree-l2"><a class="reference internal" href="decomposition/plot_pca_vs_lda.html">مقارنة بين الإسقاط ثنائي الأبعاد للمجموعة البيانات آيريس باستخدام LDA وPCA</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="developing_estimators/index.html">تطوير المقدرين</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="developing_estimators/sklearn_is_fitted.html"><code class="docutils literal notranslate"><span class="pre">__sklearn_is_fitted__</span></code> كـ API للمطورين</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="impute/index.html">تعويض القيم المفقودة</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="impute/plot_missing_values.html">استنتاج القيم المفقودة قبل بناء أداة تقدير</a></li>
<li class="toctree-l2"><a class="reference internal" href="impute/plot_iterative_imputer_variants_comparison.html">استنتاج القيم المفقودة مع متغيرات من IterativeImputer</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="covariance/index.html">تقدير التغاير</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="covariance/plot_covariance_estimation.html">تأثير تحويل الأهداف في نموذج الانحدار</a></li>
<li class="toctree-l2"><a class="reference internal" href="covariance/plot_lw_vs_oas.html">تقدير Ledoit-Wolf مقابل OAS</a></li>
<li class="toctree-l2"><a class="reference internal" href="covariance/plot_robust_vs_empirical_covariance.html">تقدير التغاير القوي مقابل التجريبي</a></li>
<li class="toctree-l2"><a class="reference internal" href="covariance/plot_mahalanobis_distances.html">تقدير التغاير القوي وأهمية مسافات Mahalanobis</a></li>
<li class="toctree-l2"><a class="reference internal" href="covariance/plot_sparse_cov.html">تقدير معكوس التغاير النادر</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="kernel_approximation/index.html">تقريب النواة</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="kernel_approximation/plot_scalable_poly_kernels.html">التعلم القابل للتطوير مع تقريب نواة متعددة الحدود</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="exercises/index.html">تمارين تعليمية</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="exercises/plot_cv_diabetes.html">التحقق المتقاطع على تمرين مجموعة بيانات مرض السكري</a></li>
<li class="toctree-l2"><a class="reference internal" href="exercises/plot_iris_exercise.html">تمرين SVM</a></li>
<li class="toctree-l2"><a class="reference internal" href="exercises/plot_digits_classification_exercise.html">تمرين تصنيف الأرقام</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="compose/index.html">خطوط الأنابيب والمقدرين المركبين</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="compose/plot_compare_reduction.html">اختيار تقليل الأبعاد باستخدام Pipeline و GridSearchCV</a></li>
<li class="toctree-l2"><a class="reference internal" href="compose/plot_transformed_target.html">تأثير تحويل الأهداف في نموذج الانحدار</a></li>
<li class="toctree-l2"><a class="reference internal" href="compose/plot_feature_union.html">دمج طرق استخراج ميزات متعددة</a></li>
<li class="toctree-l2"><a class="reference internal" href="compose/plot_digits_pipe.html">ربط الأنابيب: ربط PCA والانحدار اللوجستي</a></li>
<li class="toctree-l2"><a class="reference internal" href="compose/plot_column_transformer_mixed_types.html">محول الأعمدة مع الأنواع المختلطة</a></li>
<li class="toctree-l2"><a class="reference internal" href="compose/plot_column_transformer.html">محول الأعمدة مع مصادر بيانات غير متجانسة</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="ensemble/index.html">طرق المجموعة</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="ensemble/plot_ensemble_oob.html">أخطاء OOB لخوارزمية Random Forests</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble/plot_forest_importances.html">أهمية الميزات باستخدام غابة من الأشجار</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble/plot_gradient_boosting_early_stopping.html">إيقاف التدريب المبكر في Gradient Boosting</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble/plot_monotonic_constraints.html">القيود الرتيبة</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble/plot_hgbt_regression.html">الميزات في أشجار التعزيز المتدرج للهيستوغرام</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble/plot_gradient_boosting_regression.html">انحدار التعزيز المتدرج</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble/plot_adaboost_regression.html">انحدار شجرة القرار مع AdaBoost</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble/plot_feature_transformation.html">تحويل الميزات باستخدام مجموعات الأشجار</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble/plot_random_forest_embedding.html">تحويل ميزة التجزئة باستخدام الأشجار العشوائية تمامًا</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble/plot_adaboost_twoclass.html">تصنيف ثنائي باستخدام AdaBoost</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble/plot_gradient_boosting_oob.html">تقديرات Gradient Boosting Out-of-Bag</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble/plot_gradient_boosting_regularization.html">تنظيم التعزيز المتدرج</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble/plot_gradient_boosting_categorical.html">دعم الميزات التصنيفية في التدرج التعزيزي</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble/plot_stack_predictors.html">دمج المتنبئات باستخدام التكديس</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble/plot_forest_iris.html">رسم أسطح القرار لمجموعات الأشجار على مجموعة بيانات إيريس</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble/plot_voting_probas.html">رسم احتمالات الفئات المحسوبة بواسطة VotingClassifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble/plot_voting_regressor.html">رسم تنبؤات الانحدار الفردية والتصويتية</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble/plot_voting_decision_regions.html">رسم حدود القرار لـ VotingClassifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble/plot_adaboost_multiclass.html">شجرة قرارات معززة متعددة الفئات</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble/plot_gradient_boosting_quantile.html">فترات التنبؤ لانحدار التعزيز المتدرج</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble/plot_isolation_forest.html">مثال IsolationForest</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble/plot_random_forest_regression_multioutput.html">مقارنة الغابات العشوائية ومقدر المخرجات المتعددة التلوي</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble/plot_bias_variance.html">مقارنة بين المُقدر الفردي والتجميع: تحليل الانحياز والتشتت</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble/plot_forest_hist_grad_boosting_comparison.html">مقارنة بين نماذج الغابات العشوائية ورفع التدرج بالرسم البياني</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="gaussian_process/index.html">عملية غاوسية للتعلم الآلي</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="gaussian_process/plot_gpr_co2.html">التنبؤ بمستوى ثاني أكسيد الكربون في مجموعة بيانات Mona Loa باستخدام انحدار العملية الغاوسية (GPR)</a></li>
<li class="toctree-l2"><a class="reference internal" href="gaussian_process/plot_gpc.html">التنبؤات الاحتمالية مع تصنيف العملية الغاوسية (GPC)</a></li>
<li class="toctree-l2"><a class="reference internal" href="gaussian_process/plot_gpr_on_structured_data.html">العمليات الغاوسية على هياكل البيانات المنقوصة</a></li>
<li class="toctree-l2"><a class="reference internal" href="gaussian_process/plot_gpr_noisy_targets.html">انحدار العمليات الغاوسية: مثال تمهيدي أساسي</a></li>
<li class="toctree-l2"><a class="reference internal" href="gaussian_process/plot_gpc_iris.html">تصنيف العملية الغاوسية (GPC) على مجموعة بيانات iris</a></li>
<li class="toctree-l2"><a class="reference internal" href="gaussian_process/plot_gpr_prior_posterior.html">توضيح العملية الغاوسية المسبقة واللاحقة لنوى مختلفة</a></li>
<li class="toctree-l2"><a class="reference internal" href="gaussian_process/plot_gpc_xor.html">توضيح تصنيف العملية الغاوسية (GPC) على مجموعة بيانات XOR</a></li>
<li class="toctree-l2"><a class="reference internal" href="gaussian_process/plot_gpc_isoprobability.html">خطوط تساوي الاحتمال لتصنيف العمليات الغاوسية (GPC)</a></li>
<li class="toctree-l2"><a class="reference internal" href="gaussian_process/plot_gpr_noisy.html">قدرة انحدار العمليات الغاوسية (GPR) على تقدير مستوى ضوضاء البيانات</a></li>
<li class="toctree-l2"><a class="reference internal" href="gaussian_process/plot_compare_gpr_krr.html">مقارنة انحدار kernel ridge وانحدار العمليات الغاوسية</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="calibration/index.html">معايرة الإحتمالات</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="calibration/plot_calibration.html">معايرة احتمالات المصنفات</a></li>
<li class="toctree-l2"><a class="reference internal" href="calibration/plot_calibration_multiclass.html">معايرة الاحتمالات لتصنيف ثلاثي الفئات</a></li>
<li class="toctree-l2"><a class="reference internal" href="calibration/plot_compare_calibration.html">مقارنة معايرة المصنفات</a></li>
<li class="toctree-l2"><a class="reference internal" href="calibration/plot_calibration_curve.html">منحنيات معايرة الاحتمالية</a></li>
</ul>
</details></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">Examples</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="examples">
<span id="general-examples"></span><h1>Examples<a class="headerlink" href="#examples" title="Link to this heading">#</a></h1>
<p>This is the gallery of examples that showcase how scikit-learn can be used. Some
examples demonstrate the use of the <a class="reference internal" href="../api/index.html#api-ref"><span class="std std-ref">API</span></a> in general and some
demonstrate specific applications in tutorial form. Also check out our
<a class="reference internal" href="../user_guide.html#user-guide"><span class="std std-ref">user guide</span></a> for more detailed illustrations.</p>
<div class="sphx-glr-thumbnails"></div><section id="release-highlights">
<h2>Release Highlights<a class="headerlink" href="#release-highlights" title="Link to this heading">#</a></h2>
<p>These examples illustrate the main features of the releases of scikit-learn.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="We are pleased to announce the release of scikit-learn 1.5! Many bug fixes and improvements were added, as well as some key new features. Below we detail the highlights of this release. For an exhaustive list of all the changes, please refer to the release notes &lt;release_notes_1_5&gt;."><img alt="" src="../_images/sphx_glr_plot_release_highlights_1_5_0_thumb.png" />
<p><a class="reference internal" href="release_highlights/plot_release_highlights_1_5_0.html#sphx-glr-auto-examples-release-highlights-plot-release-highlights-1-5-0-py"><span class="std std-ref">Release Highlights for scikit-learn 1.5</span></a></p>
  <div class="sphx-glr-thumbnail-title">Release Highlights for scikit-learn 1.5</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="We are pleased to announce the release of scikit-learn 1.4! Many bug fixes and improvements were added, as well as some new key features. We detail below a few of the major features of this release. For an exhaustive list of all the changes, please refer to the release notes &lt;release_notes_1_4&gt;."><img alt="" src="../_images/sphx_glr_plot_release_highlights_1_4_0_thumb.png" />
<p><a class="reference internal" href="release_highlights/plot_release_highlights_1_4_0.html#sphx-glr-auto-examples-release-highlights-plot-release-highlights-1-4-0-py"><span class="std std-ref">Release Highlights for scikit-learn 1.4</span></a></p>
  <div class="sphx-glr-thumbnail-title">Release Highlights for scikit-learn 1.4</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="We are pleased to announce the release of scikit-learn 1.3! Many bug fixes and improvements were added, as well as some new key features. We detail below a few of the major features of this release. For an exhaustive list of all the changes, please refer to the release notes &lt;release_notes_1_3&gt;."><img alt="" src="../_images/sphx_glr_plot_release_highlights_1_3_0_thumb.png" />
<p><a class="reference internal" href="release_highlights/plot_release_highlights_1_3_0.html#sphx-glr-auto-examples-release-highlights-plot-release-highlights-1-3-0-py"><span class="std std-ref">Release Highlights for scikit-learn 1.3</span></a></p>
  <div class="sphx-glr-thumbnail-title">Release Highlights for scikit-learn 1.3</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="We are pleased to announce the release of scikit-learn 1.2! Many bug fixes and improvements were added, as well as some new key features. We detail below a few of the major features of this release. For an exhaustive list of all the changes, please refer to the release notes &lt;release_notes_1_2&gt;."><img alt="" src="../_images/sphx_glr_plot_release_highlights_1_2_0_thumb.png" />
<p><a class="reference internal" href="release_highlights/plot_release_highlights_1_2_0.html#sphx-glr-auto-examples-release-highlights-plot-release-highlights-1-2-0-py"><span class="std std-ref">Release Highlights for scikit-learn 1.2</span></a></p>
  <div class="sphx-glr-thumbnail-title">Release Highlights for scikit-learn 1.2</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="We are pleased to announce the release of scikit-learn 1.1! Many bug fixes and improvements were added, as well as some new key features. We detail below a few of the major features of this release. For an exhaustive list of all the changes, please refer to the release notes &lt;release_notes_1_1&gt;."><img alt="" src="../_images/sphx_glr_plot_release_highlights_1_1_0_thumb.png" />
<p><a class="reference internal" href="release_highlights/plot_release_highlights_1_1_0.html#sphx-glr-auto-examples-release-highlights-plot-release-highlights-1-1-0-py"><span class="std std-ref">Release Highlights for scikit-learn 1.1</span></a></p>
  <div class="sphx-glr-thumbnail-title">Release Highlights for scikit-learn 1.1</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="We are very pleased to announce the release of scikit-learn 1.0! The library has been stable for quite some time, releasing version 1.0 is recognizing that and signalling it to our users. This release does not include any breaking changes apart from the usual two-release deprecation cycle. For the future, we do our best to keep this pattern."><img alt="" src="../_images/sphx_glr_plot_release_highlights_1_0_0_thumb.png" />
<p><a class="reference internal" href="release_highlights/plot_release_highlights_1_0_0.html#sphx-glr-auto-examples-release-highlights-plot-release-highlights-1-0-0-py"><span class="std std-ref">Release Highlights for scikit-learn 1.0</span></a></p>
  <div class="sphx-glr-thumbnail-title">Release Highlights for scikit-learn 1.0</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="We are pleased to announce the release of scikit-learn 0.24! Many bug fixes and improvements were added, as well as some new key features. We detail below a few of the major features of this release. For an exhaustive list of all the changes, please refer to the release notes &lt;release_notes_0_24&gt;."><img alt="" src="../_images/sphx_glr_plot_release_highlights_0_24_0_thumb.png" />
<p><a class="reference internal" href="release_highlights/plot_release_highlights_0_24_0.html#sphx-glr-auto-examples-release-highlights-plot-release-highlights-0-24-0-py"><span class="std std-ref">Release Highlights for scikit-learn 0.24</span></a></p>
  <div class="sphx-glr-thumbnail-title">Release Highlights for scikit-learn 0.24</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="We are pleased to announce the release of scikit-learn 0.23! Many bug fixes and improvements were added, as well as some new key features. We detail below a few of the major features of this release. For an exhaustive list of all the changes, please refer to the release notes &lt;release_notes_0_23&gt;."><img alt="" src="../_images/sphx_glr_plot_release_highlights_0_23_0_thumb.png" />
<p><a class="reference internal" href="release_highlights/plot_release_highlights_0_23_0.html#sphx-glr-auto-examples-release-highlights-plot-release-highlights-0-23-0-py"><span class="std std-ref">Release Highlights for scikit-learn 0.23</span></a></p>
  <div class="sphx-glr-thumbnail-title">Release Highlights for scikit-learn 0.23</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="We are pleased to announce the release of scikit-learn 0.22, which comes with many bug fixes and new features! We detail below a few of the major features of this release. For an exhaustive list of all the changes, please refer to the release notes &lt;release_notes_0_22&gt;."><img alt="" src="../_images/sphx_glr_plot_release_highlights_0_22_0_thumb.png" />
<p><a class="reference internal" href="release_highlights/plot_release_highlights_0_22_0.html#sphx-glr-auto-examples-release-highlights-plot-release-highlights-0-22-0-py"><span class="std std-ref">Release Highlights for scikit-learn 0.22</span></a></p>
  <div class="sphx-glr-thumbnail-title">Release Highlights for scikit-learn 0.22</div>
</div></div></section>
<section id="decision-trees">
<h2>Decision Trees<a class="headerlink" href="#decision-trees" title="Link to this heading">#</a></h2>
<p>Examples concerning the <a class="reference internal" href="../api/sklearn.tree.html#module-sklearn.tree" title="sklearn.tree"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.tree</span></code></a> module.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Decision Tree Regression"><img alt="" src="../_images/sphx_glr_plot_tree_regression_thumb.png" />
<p><a class="reference internal" href="tree/plot_tree_regression.html#sphx-glr-auto-examples-tree-plot-tree-regression-py"><span class="std std-ref">Decision Tree Regression</span></a></p>
  <div class="sphx-glr-thumbnail-title">Decision Tree Regression</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Plot the decision surface of a decision tree trained on pairs of features of the iris dataset."><img alt="" src="../_images/sphx_glr_plot_iris_dtc_thumb.png" />
<p><a class="reference internal" href="tree/plot_iris_dtc.html#sphx-glr-auto-examples-tree-plot-iris-dtc-py"><span class="std std-ref">Plot the decision surface of decision trees trained on the iris dataset</span></a></p>
  <div class="sphx-glr-thumbnail-title">Plot the decision surface of decision trees trained on the iris dataset</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The DecisionTreeClassifier provides parameters such as min_samples_leaf and max_depth to prevent a tree from overfiting. Cost complexity pruning provides another option to control the size of a tree. In DecisionTreeClassifier, this pruning technique is parameterized by the cost complexity parameter, ccp_alpha. Greater values of ccp_alpha increase the number of nodes pruned. Here we only show the effect of ccp_alpha on regularizing the trees and how to choose a ccp_alpha based on validation scores."><img alt="" src="../_images/sphx_glr_plot_cost_complexity_pruning_thumb.png" />
<p><a class="reference internal" href="tree/plot_cost_complexity_pruning.html#sphx-glr-auto-examples-tree-plot-cost-complexity-pruning-py"><span class="std std-ref">Post pruning decision trees with cost complexity pruning</span></a></p>
  <div class="sphx-glr-thumbnail-title">Post pruning decision trees with cost complexity pruning</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The decision tree structure can be analysed to gain further insight on the relation between the features and the target to predict. In this example, we show how to retrieve:"><img alt="" src="../_images/sphx_glr_plot_unveil_tree_structure_thumb.png" />
<p><a class="reference internal" href="tree/plot_unveil_tree_structure.html#sphx-glr-auto-examples-tree-plot-unveil-tree-structure-py"><span class="std std-ref">Understanding the decision tree structure</span></a></p>
  <div class="sphx-glr-thumbnail-title">Understanding the decision tree structure</div>
</div></div></section>
<section id="gaussian-mixture-models">
<h2>Gaussian Mixture Models<a class="headerlink" href="#gaussian-mixture-models" title="Link to this heading">#</a></h2>
<p>Examples concerning the <a class="reference internal" href="../api/sklearn.mixture.html#module-sklearn.mixture" title="sklearn.mixture"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.mixture</span></code></a> module.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This example plots the ellipsoids obtained from a toy dataset (mixture of three Gaussians) fitted by the BayesianGaussianMixture class models with a Dirichlet distribution prior (``weight_concentration_prior_type=&#x27;dirichlet_distribution&#x27;``) and a Dirichlet process prior (``weight_concentration_prior_type=&#x27;dirichlet_process&#x27;``). On each figure, we plot the results for three different values of the weight concentration prior."><img alt="" src="../_images/sphx_glr_plot_concentration_prior_thumb.png" />
<p><a class="reference internal" href="mixture/plot_concentration_prior.html#sphx-glr-auto-examples-mixture-plot-concentration-prior-py"><span class="std std-ref">Concentration Prior Type Analysis of Variation Bayesian Gaussian Mixture</span></a></p>
  <div class="sphx-glr-thumbnail-title">Concentration Prior Type Analysis of Variation Bayesian Gaussian Mixture</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Plot the density estimation of a mixture of two Gaussians. Data is generated from two Gaussians with different centers and covariance matrices."><img alt="" src="../_images/sphx_glr_plot_gmm_pdf_thumb.png" />
<p><a class="reference internal" href="mixture/plot_gmm_pdf.html#sphx-glr-auto-examples-mixture-plot-gmm-pdf-py"><span class="std std-ref">Density Estimation for a Gaussian mixture</span></a></p>
  <div class="sphx-glr-thumbnail-title">Density Estimation for a Gaussian mixture</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Examples of the different methods of initialization in Gaussian Mixture Models"><img alt="" src="../_images/sphx_glr_plot_gmm_init_thumb.png" />
<p><a class="reference internal" href="mixture/plot_gmm_init.html#sphx-glr-auto-examples-mixture-plot-gmm-init-py"><span class="std std-ref">GMM Initialization Methods</span></a></p>
  <div class="sphx-glr-thumbnail-title">GMM Initialization Methods</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Demonstration of several covariances types for Gaussian mixture models."><img alt="" src="../_images/sphx_glr_plot_gmm_covariances_thumb.png" />
<p><a class="reference internal" href="mixture/plot_gmm_covariances.html#sphx-glr-auto-examples-mixture-plot-gmm-covariances-py"><span class="std std-ref">GMM covariances</span></a></p>
  <div class="sphx-glr-thumbnail-title">GMM covariances</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Plot the confidence ellipsoids of a mixture of two Gaussians obtained with Expectation Maximisation (``GaussianMixture`` class) and Variational Inference (``BayesianGaussianMixture`` class models with a Dirichlet process prior)."><img alt="" src="../_images/sphx_glr_plot_gmm_thumb.png" />
<p><a class="reference internal" href="mixture/plot_gmm.html#sphx-glr-auto-examples-mixture-plot-gmm-py"><span class="std std-ref">Gaussian Mixture Model Ellipsoids</span></a></p>
  <div class="sphx-glr-thumbnail-title">Gaussian Mixture Model Ellipsoids</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows that model selection can be performed with Gaussian Mixture Models (GMM) using information-theory criteria &lt;aic_bic&gt;. Model selection concerns both the covariance type and the number of components in the model."><img alt="" src="../_images/sphx_glr_plot_gmm_selection_thumb.png" />
<p><a class="reference internal" href="mixture/plot_gmm_selection.html#sphx-glr-auto-examples-mixture-plot-gmm-selection-py"><span class="std std-ref">Gaussian Mixture Model Selection</span></a></p>
  <div class="sphx-glr-thumbnail-title">Gaussian Mixture Model Selection</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the behavior of Gaussian mixture models fit on data that was not sampled from a mixture of Gaussian random variables. The dataset is formed by 100 points loosely spaced following a noisy sine curve. There is therefore no ground truth value for the number of Gaussian components."><img alt="" src="../_images/sphx_glr_plot_gmm_sin_thumb.png" />
<p><a class="reference internal" href="mixture/plot_gmm_sin.html#sphx-glr-auto-examples-mixture-plot-gmm-sin-py"><span class="std std-ref">Gaussian Mixture Model Sine Curve</span></a></p>
  <div class="sphx-glr-thumbnail-title">Gaussian Mixture Model Sine Curve</div>
</div></div></section>
<section id="manifold-learning">
<h2>Manifold learning<a class="headerlink" href="#manifold-learning" title="Link to this heading">#</a></h2>
<p>Examples concerning the <a class="reference internal" href="../api/sklearn.manifold.html#module-sklearn.manifold" title="sklearn.manifold"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.manifold</span></code></a> module.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="An illustration of dimensionality reduction on the S-curve dataset with various manifold learning methods."><img alt="" src="../_images/sphx_glr_plot_compare_methods_thumb.png" />
<p><a class="reference internal" href="manifold/plot_compare_methods.html#sphx-glr-auto-examples-manifold-plot-compare-methods-py"><span class="std std-ref">Comparison of Manifold Learning methods</span></a></p>
  <div class="sphx-glr-thumbnail-title">Comparison of Manifold Learning methods</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="An application of the different manifold techniques on a spherical data-set. Here one can see the use of dimensionality reduction in order to gain some intuition regarding the manifold learning methods. Regarding the dataset, the poles are cut from the sphere, as well as a thin slice down its side. This enables the manifold learning techniques to &#x27;spread it open&#x27; whilst projecting it onto two dimensions."><img alt="" src="../_images/sphx_glr_plot_manifold_sphere_thumb.png" />
<p><a class="reference internal" href="manifold/plot_manifold_sphere.html#sphx-glr-auto-examples-manifold-plot-manifold-sphere-py"><span class="std std-ref">Manifold Learning methods on a severed sphere</span></a></p>
  <div class="sphx-glr-thumbnail-title">Manifold Learning methods on a severed sphere</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="We illustrate various embedding techniques on the digits dataset."><img alt="" src="../_images/sphx_glr_plot_lle_digits_thumb.png" />
<p><a class="reference internal" href="manifold/plot_lle_digits.html#sphx-glr-auto-examples-manifold-plot-lle-digits-py"><span class="std std-ref">Manifold learning on handwritten digits: Locally Linear Embedding, Isomap...</span></a></p>
  <div class="sphx-glr-thumbnail-title">Manifold learning on handwritten digits: Locally Linear Embedding, Isomap...</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="An illustration of the metric and non-metric MDS on generated noisy data."><img alt="" src="../_images/sphx_glr_plot_mds_thumb.png" />
<p><a class="reference internal" href="manifold/plot_mds.html#sphx-glr-auto-examples-manifold-plot-mds-py"><span class="std std-ref">Multi-dimensional scaling</span></a></p>
  <div class="sphx-glr-thumbnail-title">Multi-dimensional scaling</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Swiss Roll And Swiss-Hole Reduction"><img alt="" src="../_images/sphx_glr_plot_swissroll_thumb.png" />
<p><a class="reference internal" href="manifold/plot_swissroll.html#sphx-glr-auto-examples-manifold-plot-swissroll-py"><span class="std std-ref">Swiss Roll And Swiss-Hole Reduction</span></a></p>
  <div class="sphx-glr-thumbnail-title">Swiss Roll And Swiss-Hole Reduction</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="An illustration of t-SNE on the two concentric circles and the S-curve datasets for different perplexity values."><img alt="" src="../_images/sphx_glr_plot_t_sne_perplexity_thumb.png" />
<p><a class="reference internal" href="manifold/plot_t_sne_perplexity.html#sphx-glr-auto-examples-manifold-plot-t-sne-perplexity-py"><span class="std std-ref">t-SNE: The effect of various perplexity values on the shape</span></a></p>
  <div class="sphx-glr-thumbnail-title">t-SNE: The effect of various perplexity values on the shape</div>
</div></div></section>
<section id="miscellaneous">
<h2>Miscellaneous<a class="headerlink" href="#miscellaneous" title="Link to this heading">#</a></h2>
<p>Miscellaneous and introductory examples for scikit-learn.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="    See also sphx_glr_auto_examples_miscellaneous_plot_roc_curve_visualization_api.py"><img alt="" src="../_images/sphx_glr_plot_partial_dependence_visualization_api_thumb.png" />
<p><a class="reference internal" href="miscellaneous/plot_partial_dependence_visualization_api.html#sphx-glr-auto-examples-miscellaneous-plot-partial-dependence-visualization-api-py"><span class="std std-ref">Advanced Plotting With Partial Dependence</span></a></p>
  <div class="sphx-glr-thumbnail-title">Advanced Plotting With Partial Dependence</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows characteristics of different anomaly detection algorithms on 2D datasets. Datasets contain one or two modes (regions of high density) to illustrate the ability of algorithms to cope with multimodal data."><img alt="" src="../_images/sphx_glr_plot_anomaly_comparison_thumb.png" />
<p><a class="reference internal" href="miscellaneous/plot_anomaly_comparison.html#sphx-glr-auto-examples-miscellaneous-plot-anomaly-comparison-py"><span class="std std-ref">Comparing anomaly detection algorithms for outlier detection on toy datasets</span></a></p>
  <div class="sphx-glr-thumbnail-title">Comparing anomaly detection algorithms for outlier detection on toy datasets</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Both kernel ridge regression (KRR) and SVR learn a non-linear function by employing the kernel trick, i.e., they learn a linear function in the space induced by the respective kernel which corresponds to a non-linear function in the original space. They differ in the loss functions (ridge versus epsilon-insensitive loss). In contrast to SVR, fitting a KRR can be done in closed-form and is typically faster for medium-sized datasets. On the other hand, the learned model is non-sparse and thus slower than SVR at prediction-time."><img alt="" src="../_images/sphx_glr_plot_kernel_ridge_regression_thumb.png" />
<p><a class="reference internal" href="miscellaneous/plot_kernel_ridge_regression.html#sphx-glr-auto-examples-miscellaneous-plot-kernel-ridge-regression-py"><span class="std std-ref">Comparison of kernel ridge regression and SVR</span></a></p>
  <div class="sphx-glr-thumbnail-title">Comparison of kernel ridge regression and SVR</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The default configuration for displaying a pipeline in a Jupyter Notebook is &#x27;diagram&#x27; where set_config(display=&#x27;diagram&#x27;). To deactivate HTML representation, use set_config(display=&#x27;text&#x27;)."><img alt="" src="../_images/sphx_glr_plot_pipeline_display_thumb.png" />
<p><a class="reference internal" href="miscellaneous/plot_pipeline_display.html#sphx-glr-auto-examples-miscellaneous-plot-pipeline-display-py"><span class="std std-ref">Displaying Pipelines</span></a></p>
  <div class="sphx-glr-thumbnail-title">Displaying Pipelines</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example illustrates different ways estimators and pipelines can be displayed."><img alt="" src="../_images/sphx_glr_plot_estimator_representation_thumb.png" />
<p><a class="reference internal" href="miscellaneous/plot_estimator_representation.html#sphx-glr-auto-examples-miscellaneous-plot-estimator-representation-py"><span class="std std-ref">Displaying estimators and complex pipelines</span></a></p>
  <div class="sphx-glr-thumbnail-title">Displaying estimators and complex pipelines</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example compares two outlier detection algorithms, namely local_outlier_factor (LOF) and isolation_forest (IForest), on real-world datasets available in sklearn.datasets. The goal is to show that different algorithms perform well on different datasets and contrast their training speed and sensitivity to hyperparameters."><img alt="" src="../_images/sphx_glr_plot_outlier_detection_bench_thumb.png" />
<p><a class="reference internal" href="miscellaneous/plot_outlier_detection_bench.html#sphx-glr-auto-examples-miscellaneous-plot-outlier-detection-bench-py"><span class="std std-ref">Evaluation of outlier detection estimators</span></a></p>
  <div class="sphx-glr-thumbnail-title">Evaluation of outlier detection estimators</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="An example illustrating the approximation of the feature map of an RBF kernel."><img alt="" src="../_images/sphx_glr_plot_kernel_approximation_thumb.png" />
<p><a class="reference internal" href="miscellaneous/plot_kernel_approximation.html#sphx-glr-auto-examples-miscellaneous-plot-kernel-approximation-py"><span class="std std-ref">Explicit feature map approximation for RBF kernels</span></a></p>
  <div class="sphx-glr-thumbnail-title">Explicit feature map approximation for RBF kernels</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows the use of multi-output estimator to complete images. The goal is to predict the lower half of a face given its upper half."><img alt="" src="../_images/sphx_glr_plot_multioutput_face_completion_thumb.png" />
<p><a class="reference internal" href="miscellaneous/plot_multioutput_face_completion.html#sphx-glr-auto-examples-miscellaneous-plot-multioutput-face-completion-py"><span class="std std-ref">Face completion with a multi-output estimators</span></a></p>
  <div class="sphx-glr-thumbnail-title">Face completion with a multi-output estimators</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example will demonstrate the set_output API to configure transformers to output pandas DataFrames. set_output can be configured per estimator by calling the set_output method or globally by setting set_config(transform_output=&quot;pandas&quot;). For details, see SLEP018."><img alt="" src="../_images/sphx_glr_plot_set_output_thumb.png" />
<p><a class="reference internal" href="miscellaneous/plot_set_output.html#sphx-glr-auto-examples-miscellaneous-plot-set-output-py"><span class="std std-ref">Introducing the set_output API</span></a></p>
  <div class="sphx-glr-thumbnail-title">Introducing the set_output API</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="An illustration of the isotonic regression on generated data (non-linear monotonic trend with homoscedastic uniform noise)."><img alt="" src="../_images/sphx_glr_plot_isotonic_regression_thumb.png" />
<p><a class="reference internal" href="miscellaneous/plot_isotonic_regression.html#sphx-glr-auto-examples-miscellaneous-plot-isotonic-regression-py"><span class="std std-ref">Isotonic Regression</span></a></p>
  <div class="sphx-glr-thumbnail-title">Isotonic Regression</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This document shows how you can use the metadata routing mechanism &lt;metadata_routing&gt; in scikit-learn to route metadata to the estimators, scorers, and CV splitters consuming them."><img alt="" src="../_images/sphx_glr_plot_metadata_routing_thumb.png" />
<p><a class="reference internal" href="miscellaneous/plot_metadata_routing.html#sphx-glr-auto-examples-miscellaneous-plot-metadata-routing-py"><span class="std std-ref">Metadata Routing</span></a></p>
  <div class="sphx-glr-thumbnail-title">Metadata Routing</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example simulates a multi-label document classification problem. The dataset is generated randomly based on the following process:"><img alt="" src="../_images/sphx_glr_plot_multilabel_thumb.png" />
<p><a class="reference internal" href="miscellaneous/plot_multilabel.html#sphx-glr-auto-examples-miscellaneous-plot-multilabel-py"><span class="std std-ref">Multilabel classification</span></a></p>
  <div class="sphx-glr-thumbnail-title">Multilabel classification</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="ROC Curve with Visualization API"><img alt="" src="../_images/sphx_glr_plot_roc_curve_visualization_api_thumb.png" />
<p><a class="reference internal" href="miscellaneous/plot_roc_curve_visualization_api.html#sphx-glr-auto-examples-miscellaneous-plot-roc-curve-visualization-api-py"><span class="std std-ref">ROC Curve with Visualization API</span></a></p>
  <div class="sphx-glr-thumbnail-title">ROC Curve with Visualization API</div>
</div><div class="sphx-glr-thumbcontainer" tooltip=" The `Johnson-Lindenstrauss lemma`_ states that any high dimensional dataset can be randomly projected into a lower dimensional Euclidean space while controlling the distortion in the pairwise distances."><img alt="" src="../_images/sphx_glr_plot_johnson_lindenstrauss_bound_thumb.png" />
<p><a class="reference internal" href="miscellaneous/plot_johnson_lindenstrauss_bound.html#sphx-glr-auto-examples-miscellaneous-plot-johnson-lindenstrauss-bound-py"><span class="std std-ref">The Johnson-Lindenstrauss bound for embedding with random projections</span></a></p>
  <div class="sphx-glr-thumbnail-title">The Johnson-Lindenstrauss bound for embedding with random projections</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we will construct display objects, ConfusionMatrixDisplay, RocCurveDisplay, and PrecisionRecallDisplay directly from their respective metrics. This is an alternative to using their corresponding plot functions when a model&#x27;s predictions are already computed or expensive to compute. Note that this is advanced usage, and in general we recommend using their respective plot functions."><img alt="" src="../_images/sphx_glr_plot_display_object_visualization_thumb.png" />
<p><a class="reference internal" href="miscellaneous/plot_display_object_visualization.html#sphx-glr-auto-examples-miscellaneous-plot-display-object-visualization-py"><span class="std std-ref">Visualizations with Display Objects</span></a></p>
  <div class="sphx-glr-thumbnail-title">Visualizations with Display Objects</div>
</div></div></section>
<section id="model-selection">
<h2>Model Selection<a class="headerlink" href="#model-selection" title="Link to this heading">#</a></h2>
<p>Examples related to the <a class="reference internal" href="../api/sklearn.model_selection.html#module-sklearn.model_selection" title="sklearn.model_selection"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.model_selection</span></code></a> module.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This example balances model complexity and cross-validated score by finding a decent accuracy within 1 standard deviation of the best accuracy score while minimising the number of PCA components [1]."><img alt="" src="../_images/sphx_glr_plot_grid_search_refit_callable_thumb.png" />
<p><a class="reference internal" href="model_selection/plot_grid_search_refit_callable.html#sphx-glr-auto-examples-model-selection-plot-grid-search-refit-callable-py"><span class="std std-ref">Balance model complexity and cross-validated score</span></a></p>
  <div class="sphx-glr-thumbnail-title">Balance model complexity and cross-validated score</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the class_likelihood_ratios function, which computes the positive and negative likelihood ratios (`LR+`, LR-) to assess the predictive power of a binary classifier. As we will see, these metrics are independent of the proportion between classes in the test set, which makes them very useful when the available data for a study has a different class proportion than the target application."><img alt="" src="../_images/sphx_glr_plot_likelihood_ratios_thumb.png" />
<p><a class="reference internal" href="model_selection/plot_likelihood_ratios.html#sphx-glr-auto-examples-model-selection-plot-likelihood-ratios-py"><span class="std std-ref">Class Likelihood Ratios to measure classification performance</span></a></p>
  <div class="sphx-glr-thumbnail-title">Class Likelihood Ratios to measure classification performance</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Compare randomized search and grid search for optimizing hyperparameters of a linear SVM with SGD training. All parameters that influence the learning are searched simultaneously (except for the number of estimators, which poses a time / quality tradeoff)."><img alt="" src="../_images/sphx_glr_plot_randomized_search_thumb.png" />
<p><a class="reference internal" href="model_selection/plot_randomized_search.html#sphx-glr-auto-examples-model-selection-plot-randomized-search-py"><span class="std std-ref">Comparing randomized search and grid search for hyperparameter estimation</span></a></p>
  <div class="sphx-glr-thumbnail-title">Comparing randomized search and grid search for hyperparameter estimation</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example compares the parameter search performed by HalvingGridSearchCV and GridSearchCV."><img alt="" src="../_images/sphx_glr_plot_successive_halving_heatmap_thumb.png" />
<p><a class="reference internal" href="model_selection/plot_successive_halving_heatmap.html#sphx-glr-auto-examples-model-selection-plot-successive-halving-heatmap-py"><span class="std std-ref">Comparison between grid search and successive halving</span></a></p>
  <div class="sphx-glr-thumbnail-title">Comparison between grid search and successive halving</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Example of confusion matrix usage to evaluate the quality of the output of a classifier on the iris data set. The diagonal elements represent the number of points for which the predicted label is equal to the true label, while off-diagonal elements are those that are mislabeled by the classifier. The higher the diagonal values of the confusion matrix the better, indicating many correct predictions."><img alt="" src="../_images/sphx_glr_plot_confusion_matrix_thumb.png" />
<p><a class="reference internal" href="model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"><span class="std std-ref">Confusion matrix</span></a></p>
  <div class="sphx-glr-thumbnail-title">Confusion matrix</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This examples shows how a classifier is optimized by cross-validation, which is done using the GridSearchCV object on a development set that comprises only half of the available labeled data."><img alt="" src="../_images/sphx_glr_plot_grid_search_digits_thumb.png" />
<p><a class="reference internal" href="model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py"><span class="std std-ref">Custom refit strategy of a grid search with cross-validation</span></a></p>
  <div class="sphx-glr-thumbnail-title">Custom refit strategy of a grid search with cross-validation</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Multiple metric parameter search can be done by setting the scoring parameter to a list of metric scorer names or a dict mapping the scorer names to the scorer callables."><img alt="" src="../_images/sphx_glr_plot_multi_metric_evaluation_thumb.png" />
<p><a class="reference internal" href="model_selection/plot_multi_metric_evaluation.html#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py"><span class="std std-ref">Demonstration of multi-metric evaluation on cross_val_score and GridSearchCV</span></a></p>
  <div class="sphx-glr-thumbnail-title">Demonstration of multi-metric evaluation on cross_val_score and GridSearchCV</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we compare two binary classification multi-threshold metrics: the Receiver Operating Characteristic (ROC) and the Detection Error Tradeoff (DET). For such purpose, we evaluate two different classifiers for the same classification task."><img alt="" src="../_images/sphx_glr_plot_det_thumb.png" />
<p><a class="reference internal" href="model_selection/plot_det.html#sphx-glr-auto-examples-model-selection-plot-det-py"><span class="std std-ref">Detection error tradeoff (DET) curve</span></a></p>
  <div class="sphx-glr-thumbnail-title">Detection error tradeoff (DET) curve</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we evaluate the impact of the regularization parameter in a linear model called ElasticNet. To carry out this evaluation, we use a validation curve using ValidationCurveDisplay. This curve shows the training and test scores of the model for different values of the regularization parameter."><img alt="" src="../_images/sphx_glr_plot_train_error_vs_test_error_thumb.png" />
<p><a class="reference internal" href="model_selection/plot_train_error_vs_test_error.html#sphx-glr-auto-examples-model-selection-plot-train-error-vs-test-error-py"><span class="std std-ref">Effect of model regularization on training and test error</span></a></p>
  <div class="sphx-glr-thumbnail-title">Effect of model regularization on training and test error</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example describes the use of the Receiver Operating Characteristic (ROC) metric to evaluate the quality of multiclass classifiers."><img alt="" src="../_images/sphx_glr_plot_roc_thumb.png" />
<p><a class="reference internal" href="model_selection/plot_roc.html#sphx-glr-auto-examples-model-selection-plot-roc-py"><span class="std std-ref">Multiclass Receiver Operating Characteristic (ROC)</span></a></p>
  <div class="sphx-glr-thumbnail-title">Multiclass Receiver Operating Characteristic (ROC)</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example compares non-nested and nested cross-validation strategies on a classifier of the iris data set. Nested cross-validation (CV) is often used to train a model in which hyperparameters also need to be optimized. Nested CV estimates the generalization error of the underlying model and its (hyper)parameter search. Choosing the parameters that maximize non-nested CV biases the model to the dataset, yielding an overly-optimistic score."><img alt="" src="../_images/sphx_glr_plot_nested_cross_validation_iris_thumb.png" />
<p><a class="reference internal" href="model_selection/plot_nested_cross_validation_iris.html#sphx-glr-auto-examples-model-selection-plot-nested-cross-validation-iris-py"><span class="std std-ref">Nested versus non-nested cross-validation</span></a></p>
  <div class="sphx-glr-thumbnail-title">Nested versus non-nested cross-validation</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to use cross_val_predict together with PredictionErrorDisplay to visualize prediction errors."><img alt="" src="../_images/sphx_glr_plot_cv_predict_thumb.png" />
<p><a class="reference internal" href="model_selection/plot_cv_predict.html#sphx-glr-auto-examples-model-selection-plot-cv-predict-py"><span class="std std-ref">Plotting Cross-Validated Predictions</span></a></p>
  <div class="sphx-glr-thumbnail-title">Plotting Cross-Validated Predictions</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we show how to use the class LearningCurveDisplay to easily plot learning curves. In addition, we give an interpretation to the learning curves obtained for a naive Bayes and SVM classifiers."><img alt="" src="../_images/sphx_glr_plot_learning_curve_thumb.png" />
<p><a class="reference internal" href="model_selection/plot_learning_curve.html#sphx-glr-auto-examples-model-selection-plot-learning-curve-py"><span class="std std-ref">Plotting Learning Curves and Checking Models' Scalability</span></a></p>
  <div class="sphx-glr-thumbnail-title">Plotting Learning Curves and Checking Models' Scalability</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Once a binary classifier is trained, the predict method outputs class label predictions corresponding to a thresholding of either the decision_function or the predict_proba output. The default threshold is defined as a posterior probability estimate of 0.5 or a decision score of 0.0. However, this default strategy may not be optimal for the task at hand."><img alt="" src="../_images/sphx_glr_plot_tuned_decision_threshold_thumb.png" />
<p><a class="reference internal" href="model_selection/plot_tuned_decision_threshold.html#sphx-glr-auto-examples-model-selection-plot-tuned-decision-threshold-py"><span class="std std-ref">Post-hoc tuning the cut-off point of decision function</span></a></p>
  <div class="sphx-glr-thumbnail-title">Post-hoc tuning the cut-off point of decision function</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Once a classifier is trained, the output of the predict method outputs class label predictions corresponding to a thresholding of either the decision_function or the predict_proba output. For a binary classifier, the default threshold is defined as a posterior probability estimate of 0.5 or a decision score of 0.0."><img alt="" src="../_images/sphx_glr_plot_cost_sensitive_learning_thumb.png" />
<p><a class="reference internal" href="model_selection/plot_cost_sensitive_learning.html#sphx-glr-auto-examples-model-selection-plot-cost-sensitive-learning-py"><span class="std std-ref">Post-tuning the decision threshold for cost-sensitive learning</span></a></p>
  <div class="sphx-glr-thumbnail-title">Post-tuning the decision threshold for cost-sensitive learning</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Example of Precision-Recall metric to evaluate classifier output quality."><img alt="" src="../_images/sphx_glr_plot_precision_recall_thumb.png" />
<p><a class="reference internal" href="model_selection/plot_precision_recall.html#sphx-glr-auto-examples-model-selection-plot-precision-recall-py"><span class="std std-ref">Precision-Recall</span></a></p>
  <div class="sphx-glr-thumbnail-title">Precision-Recall</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example presents how to estimate and visualize the variance of the Receiver Operating Characteristic (ROC) metric using cross-validation."><img alt="" src="../_images/sphx_glr_plot_roc_crossval_thumb.png" />
<p><a class="reference internal" href="model_selection/plot_roc_crossval.html#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py"><span class="std std-ref">Receiver Operating Characteristic (ROC) with cross validation</span></a></p>
  <div class="sphx-glr-thumbnail-title">Receiver Operating Characteristic (ROC) with cross validation</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The dataset used in this example is 20newsgroups_dataset which will be automatically downloaded, cached and reused for the document classification example."><img alt="" src="../_images/sphx_glr_plot_grid_search_text_feature_extraction_thumb.png" />
<p><a class="reference internal" href="model_selection/plot_grid_search_text_feature_extraction.html#sphx-glr-auto-examples-model-selection-plot-grid-search-text-feature-extraction-py"><span class="std std-ref">Sample pipeline for text feature extraction and evaluation</span></a></p>
  <div class="sphx-glr-thumbnail-title">Sample pipeline for text feature extraction and evaluation</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how to statistically compare the performance of models trained and evaluated using GridSearchCV."><img alt="" src="../_images/sphx_glr_plot_grid_search_stats_thumb.png" />
<p><a class="reference internal" href="model_selection/plot_grid_search_stats.html#sphx-glr-auto-examples-model-selection-plot-grid-search-stats-py"><span class="std std-ref">Statistical comparison of models using grid search</span></a></p>
  <div class="sphx-glr-thumbnail-title">Statistical comparison of models using grid search</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how a successive halving search (~sklearn.model_selection.HalvingGridSearchCV and HalvingRandomSearchCV) iteratively chooses the best parameter combination out of multiple candidates."><img alt="" src="../_images/sphx_glr_plot_successive_halving_iterations_thumb.png" />
<p><a class="reference internal" href="model_selection/plot_successive_halving_iterations.html#sphx-glr-auto-examples-model-selection-plot-successive-halving-iterations-py"><span class="std std-ref">Successive Halving Iterations</span></a></p>
  <div class="sphx-glr-thumbnail-title">Successive Halving Iterations</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the use of permutation_test_score to evaluate the significance of a cross-validated score using permutations."><img alt="" src="../_images/sphx_glr_plot_permutation_tests_for_classification_thumb.png" />
<p><a class="reference internal" href="model_selection/plot_permutation_tests_for_classification.html#sphx-glr-auto-examples-model-selection-plot-permutation-tests-for-classification-py"><span class="std std-ref">Test with permutations the significance of a classification score</span></a></p>
  <div class="sphx-glr-thumbnail-title">Test with permutations the significance of a classification score</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the problems of underfitting and overfitting and how we can use linear regression with polynomial features to approximate nonlinear functions. The plot shows the function that we want to approximate, which is a part of the cosine function. In addition, the samples from the real function and the approximations of different models are displayed. The models have polynomial features of different degrees. We can see that a linear function (polynomial with degree 1) is not sufficient to fit the training samples. This is called underfitting. A polynomial of degree 4 approximates the true function almost perfectly. However, for higher degrees the model will overfit the training data, i.e. it learns the noise of the training data. We evaluate quantitatively overfitting / underfitting by using cross-validation. We calculate the mean squared error (MSE) on the validation set, the higher, the less likely the model generalizes correctly from the training data."><img alt="" src="../_images/sphx_glr_plot_underfitting_overfitting_thumb.png" />
<p><a class="reference internal" href="model_selection/plot_underfitting_overfitting.html#sphx-glr-auto-examples-model-selection-plot-underfitting-overfitting-py"><span class="std std-ref">Underfitting vs. Overfitting</span></a></p>
  <div class="sphx-glr-thumbnail-title">Underfitting vs. Overfitting</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Choosing the right cross-validation object is a crucial part of fitting a model properly. There are many ways to split data into training and test sets in order to avoid model overfitting, to standardize the number of groups in test sets, etc."><img alt="" src="../_images/sphx_glr_plot_cv_indices_thumb.png" />
<p><a class="reference internal" href="model_selection/plot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py"><span class="std std-ref">Visualizing cross-validation behavior in scikit-learn</span></a></p>
  <div class="sphx-glr-thumbnail-title">Visualizing cross-validation behavior in scikit-learn</div>
</div></div></section>
<section id="multiclass-methods">
<h2>Multiclass methods<a class="headerlink" href="#multiclass-methods" title="Link to this heading">#</a></h2>
<p>Examples concerning the <a class="reference internal" href="../api/sklearn.multiclass.html#module-sklearn.multiclass" title="sklearn.multiclass"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.multiclass</span></code></a> module.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="In this example, we discuss the problem of classification when the target variable is composed of more than two classes. This is called multiclass classification."><img alt="" src="../_images/sphx_glr_plot_multiclass_overview_thumb.png" />
<p><a class="reference internal" href="multiclass/plot_multiclass_overview.html#sphx-glr-auto-examples-multiclass-plot-multiclass-overview-py"><span class="std std-ref">Overview of multiclass training meta-estimators</span></a></p>
  <div class="sphx-glr-thumbnail-title">Overview of multiclass training meta-estimators</div>
</div></div></section>
<section id="multioutput-methods">
<h2>Multioutput methods<a class="headerlink" href="#multioutput-methods" title="Link to this heading">#</a></h2>
<p>Examples concerning the <a class="reference internal" href="../api/sklearn.multioutput.html#module-sklearn.multioutput" title="sklearn.multioutput"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.multioutput</span></code></a> module.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="The most naive strategy to solve such a task is to independently train a binary classifier on each label (i.e. each column of the target variable). At prediction time, the ensemble of binary classifiers is used to assemble multitask prediction."><img alt="" src="../_images/sphx_glr_plot_classifier_chain_yeast_thumb.png" />
<p><a class="reference internal" href="multioutput/plot_classifier_chain_yeast.html#sphx-glr-auto-examples-multioutput-plot-classifier-chain-yeast-py"><span class="std std-ref">Multilabel classification using a classifier chain</span></a></p>
  <div class="sphx-glr-thumbnail-title">Multilabel classification using a classifier chain</div>
</div></div></section>
<section id="nearest-neighbors">
<h2>Nearest Neighbors<a class="headerlink" href="#nearest-neighbors" title="Link to this heading">#</a></h2>
<p>Examples concerning the <a class="reference internal" href="../api/sklearn.neighbors.html#module-sklearn.neighbors" title="sklearn.neighbors"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.neighbors</span></code></a> module.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This example presents how to chain KNeighborsTransformer and TSNE in a pipeline. It also shows how to wrap the packages nmslib and pynndescent to replace KNeighborsTransformer and perform approximate nearest neighbors. These packages can be installed with pip install nmslib pynndescent."><img alt="" src="../_images/sphx_glr_approximate_nearest_neighbors_thumb.png" />
<p><a class="reference internal" href="neighbors/approximate_nearest_neighbors.html#sphx-glr-auto-examples-neighbors-approximate-nearest-neighbors-py"><span class="std std-ref">Approximate nearest neighbors in TSNE</span></a></p>
  <div class="sphx-glr-thumbnail-title">Approximate nearest neighbors in TSNE</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This examples demonstrates how to precompute the k nearest neighbors before using them in KNeighborsClassifier. KNeighborsClassifier can compute the nearest neighbors internally, but precomputing them can have several benefits, such as finer parameter control, caching for multiple use, or custom implementations."><img alt="" src="../_images/sphx_glr_plot_caching_nearest_neighbors_thumb.png" />
<p><a class="reference internal" href="neighbors/plot_caching_nearest_neighbors.html#sphx-glr-auto-examples-neighbors-plot-caching-nearest-neighbors-py"><span class="std std-ref">Caching nearest neighbors</span></a></p>
  <div class="sphx-glr-thumbnail-title">Caching nearest neighbors</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="An example comparing nearest neighbors classification with and without Neighborhood Components Analysis."><img alt="" src="../_images/sphx_glr_plot_nca_classification_thumb.png" />
<p><a class="reference internal" href="neighbors/plot_nca_classification.html#sphx-glr-auto-examples-neighbors-plot-nca-classification-py"><span class="std std-ref">Comparing Nearest Neighbors with and without Neighborhood Components Analysis</span></a></p>
  <div class="sphx-glr-thumbnail-title">Comparing Nearest Neighbors with and without Neighborhood Components Analysis</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Sample usage of Neighborhood Components Analysis for dimensionality reduction."><img alt="" src="../_images/sphx_glr_plot_nca_dim_reduction_thumb.png" />
<p><a class="reference internal" href="neighbors/plot_nca_dim_reduction.html#sphx-glr-auto-examples-neighbors-plot-nca-dim-reduction-py"><span class="std std-ref">Dimensionality Reduction with Neighborhood Components Analysis</span></a></p>
  <div class="sphx-glr-thumbnail-title">Dimensionality Reduction with Neighborhood Components Analysis</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example does not perform any learning over the data (see sphx_glr_auto_examples_applications_plot_species_distribution_modeling.py for an example of classification based on the attributes in this dataset).  It simply shows the kernel density estimate of observed data points in geospatial coordinates."><img alt="" src="../_images/sphx_glr_plot_species_kde_thumb.png" />
<p><a class="reference internal" href="neighbors/plot_species_kde.html#sphx-glr-auto-examples-neighbors-plot-species-kde-py"><span class="std std-ref">Kernel Density Estimate of Species Distributions</span></a></p>
  <div class="sphx-glr-thumbnail-title">Kernel Density Estimate of Species Distributions</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how kernel density estimation (KDE), a powerful non-parametric density estimation technique, can be used to learn a generative model for a dataset.  With this generative model in place, new samples can be drawn.  These new samples reflect the underlying model of the data."><img alt="" src="../_images/sphx_glr_plot_digits_kde_sampling_thumb.png" />
<p><a class="reference internal" href="neighbors/plot_digits_kde_sampling.html#sphx-glr-auto-examples-neighbors-plot-digits-kde-sampling-py"><span class="std std-ref">Kernel Density Estimation</span></a></p>
  <div class="sphx-glr-thumbnail-title">Kernel Density Estimation</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Sample usage of Nearest Centroid classification. It will plot the decision boundaries for each class."><img alt="" src="../_images/sphx_glr_plot_nearest_centroid_thumb.png" />
<p><a class="reference internal" href="neighbors/plot_nearest_centroid.html#sphx-glr-auto-examples-neighbors-plot-nearest-centroid-py"><span class="std std-ref">Nearest Centroid Classification</span></a></p>
  <div class="sphx-glr-thumbnail-title">Nearest Centroid Classification</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to use KNeighborsClassifier. We train such a classifier on the iris dataset and observe the difference of the decision boundary obtained with regards to the parameter weights."><img alt="" src="../_images/sphx_glr_plot_classification_thumb.png" />
<p><a class="reference internal" href="neighbors/plot_classification.html#sphx-glr-auto-examples-neighbors-plot-classification-py"><span class="std std-ref">Nearest Neighbors Classification</span></a></p>
  <div class="sphx-glr-thumbnail-title">Nearest Neighbors Classification</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Demonstrate the resolution of a regression problem using a k-Nearest Neighbor and the interpolation of the target using both barycenter and constant weights."><img alt="" src="../_images/sphx_glr_plot_regression_thumb.png" />
<p><a class="reference internal" href="neighbors/plot_regression.html#sphx-glr-auto-examples-neighbors-plot-regression-py"><span class="std std-ref">Nearest Neighbors regression</span></a></p>
  <div class="sphx-glr-thumbnail-title">Nearest Neighbors regression</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example illustrates a learned distance metric that maximizes the nearest neighbors classification accuracy. It provides a visual representation of this metric compared to the original point space. Please refer to the User Guide &lt;nca&gt; for more information."><img alt="" src="../_images/sphx_glr_plot_nca_illustration_thumb.png" />
<p><a class="reference internal" href="neighbors/plot_nca_illustration.html#sphx-glr-auto-examples-neighbors-plot-nca-illustration-py"><span class="std std-ref">Neighborhood Components Analysis Illustration</span></a></p>
  <div class="sphx-glr-thumbnail-title">Neighborhood Components Analysis Illustration</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The Local Outlier Factor (LOF) algorithm is an unsupervised anomaly detection method which computes the local density deviation of a given data point with respect to its neighbors. It considers as outliers the samples that have a substantially lower density than their neighbors. This example shows how to use LOF for novelty detection. Note that when LOF is used for novelty detection you MUST not use predict, decision_function and score_samples on the training set as this would lead to wrong results. You must only use these methods on new unseen data (which are not in the training set). See User Guide &lt;outlier_detection&gt;: for details on the difference between outlier detection and novelty detection and how to use LOF for outlier detection."><img alt="" src="../_images/sphx_glr_plot_lof_novelty_detection_thumb.png" />
<p><a class="reference internal" href="neighbors/plot_lof_novelty_detection.html#sphx-glr-auto-examples-neighbors-plot-lof-novelty-detection-py"><span class="std std-ref">Novelty detection with Local Outlier Factor (LOF)</span></a></p>
  <div class="sphx-glr-thumbnail-title">Novelty detection with Local Outlier Factor (LOF)</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The Local Outlier Factor (LOF) algorithm is an unsupervised anomaly detection method which computes the local density deviation of a given data point with respect to its neighbors. It considers as outliers the samples that have a substantially lower density than their neighbors. This example shows how to use LOF for outlier detection which is the default use case of this estimator in scikit-learn. Note that when LOF is used for outlier detection it has no predict, decision_function and score_samples methods. See the User Guide &lt;outlier_detection&gt; for details on the difference between outlier detection and novelty detection and how to use LOF for novelty detection."><img alt="" src="../_images/sphx_glr_plot_lof_outlier_detection_thumb.png" />
<p><a class="reference internal" href="neighbors/plot_lof_outlier_detection.html#sphx-glr-auto-examples-neighbors-plot-lof-outlier-detection-py"><span class="std std-ref">Outlier detection with Local Outlier Factor (LOF)</span></a></p>
  <div class="sphx-glr-thumbnail-title">Outlier detection with Local Outlier Factor (LOF)</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The first plot shows one of the problems with using histograms to visualize the density of points in 1D. Intuitively, a histogram can be thought of as a scheme in which a unit &quot;block&quot; is stacked above each point on a regular grid. As the top two panels show, however, the choice of gridding for these blocks can lead to wildly divergent ideas about the underlying shape of the density distribution.  If we instead center each block on the point it represents, we get the estimate shown in the bottom left panel.  This is a kernel density estimation with a &quot;top hat&quot; kernel.  This idea can be generalized to other kernel shapes: the bottom-right panel of the first figure shows a Gaussian kernel density estimate over the same distribution."><img alt="" src="../_images/sphx_glr_plot_kde_1d_thumb.png" />
<p><a class="reference internal" href="neighbors/plot_kde_1d.html#sphx-glr-auto-examples-neighbors-plot-kde-1d-py"><span class="std std-ref">Simple 1D Kernel Density Estimation</span></a></p>
  <div class="sphx-glr-thumbnail-title">Simple 1D Kernel Density Estimation</div>
</div></div></section>
<section id="neural-networks">
<h2>Neural Networks<a class="headerlink" href="#neural-networks" title="Link to this heading">#</a></h2>
<p>Examples concerning the <a class="reference internal" href="../api/sklearn.neural_network.html#module-sklearn.neural_network" title="sklearn.neural_network"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.neural_network</span></code></a> module.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This example visualizes some training loss curves for different stochastic learning strategies, including SGD and Adam. Because of time-constraints, we use several small datasets, for which L-BFGS might be more suitable. The general trend shown in these examples seems to carry over to larger datasets, however."><img alt="" src="../_images/sphx_glr_plot_mlp_training_curves_thumb.png" />
<p><a class="reference internal" href="neural_networks/plot_mlp_training_curves.html#sphx-glr-auto-examples-neural-networks-plot-mlp-training-curves-py"><span class="std std-ref">Compare Stochastic learning strategies for MLPClassifier</span></a></p>
  <div class="sphx-glr-thumbnail-title">Compare Stochastic learning strategies for MLPClassifier</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="For greyscale image data where pixel values can be interpreted as degrees of blackness on a white background, like handwritten digit recognition, the Bernoulli Restricted Boltzmann machine model (BernoulliRBM) can perform effective non-linear feature extraction."><img alt="" src="../_images/sphx_glr_plot_rbm_logistic_classification_thumb.png" />
<p><a class="reference internal" href="neural_networks/plot_rbm_logistic_classification.html#sphx-glr-auto-examples-neural-networks-plot-rbm-logistic-classification-py"><span class="std std-ref">Restricted Boltzmann Machine features for digit classification</span></a></p>
  <div class="sphx-glr-thumbnail-title">Restricted Boltzmann Machine features for digit classification</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="A comparison of different values for regularization parameter &#x27;alpha&#x27; on synthetic datasets. The plot shows that different alphas yield different decision functions."><img alt="" src="../_images/sphx_glr_plot_mlp_alpha_thumb.png" />
<p><a class="reference internal" href="neural_networks/plot_mlp_alpha.html#sphx-glr-auto-examples-neural-networks-plot-mlp-alpha-py"><span class="std std-ref">Varying regularization in Multi-layer Perceptron</span></a></p>
  <div class="sphx-glr-thumbnail-title">Varying regularization in Multi-layer Perceptron</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Sometimes looking at the learned coefficients of a neural network can provide insight into the learning behavior. For example if weights look unstructured, maybe some were not used at all, or if very large coefficients exist, maybe regularization was too low or the learning rate too high."><img alt="" src="../_images/sphx_glr_plot_mnist_filters_thumb.png" />
<p><a class="reference internal" href="neural_networks/plot_mnist_filters.html#sphx-glr-auto-examples-neural-networks-plot-mnist-filters-py"><span class="std std-ref">Visualization of MLP weights on MNIST</span></a></p>
  <div class="sphx-glr-thumbnail-title">Visualization of MLP weights on MNIST</div>
</div></div></section>
<section id="preprocessing">
<h2>Preprocessing<a class="headerlink" href="#preprocessing" title="Link to this heading">#</a></h2>
<p>Examples concerning the <a class="reference internal" href="../api/sklearn.preprocessing.html#module-sklearn.preprocessing" title="sklearn.preprocessing"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.preprocessing</span></code></a> module.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="Feature 0 (median income in a block) and feature 5 (average house occupancy) of the california_housing_dataset have very different scales and contain some very large outliers. These two characteristics lead to difficulties to visualize the data and, more importantly, they can degrade the predictive performance of many machine learning algorithms. Unscaled data can also slow down or even prevent the convergence of many gradient-based estimators."><img alt="" src="../_images/sphx_glr_plot_all_scaling_thumb.png" />
<p><a class="reference internal" href="preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py"><span class="std std-ref">Compare the effect of different scalers on data with outliers</span></a></p>
  <div class="sphx-glr-thumbnail-title">Compare the effect of different scalers on data with outliers</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The TargetEncoder uses the value of the target to encode each categorical feature. In this example, we will compare three different approaches for handling categorical features: TargetEncoder, OrdinalEncoder, OneHotEncoder and dropping the category."><img alt="" src="../_images/sphx_glr_plot_target_encoder_thumb.png" />
<p><a class="reference internal" href="preprocessing/plot_target_encoder.html#sphx-glr-auto-examples-preprocessing-plot-target-encoder-py"><span class="std std-ref">Comparing Target Encoder with Other Encoders</span></a></p>
  <div class="sphx-glr-thumbnail-title">Comparing Target Encoder with Other Encoders</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example presents the different strategies implemented in KBinsDiscretizer:"><img alt="" src="../_images/sphx_glr_plot_discretization_strategies_thumb.png" />
<p><a class="reference internal" href="preprocessing/plot_discretization_strategies.html#sphx-glr-auto-examples-preprocessing-plot-discretization-strategies-py"><span class="std std-ref">Demonstrating the different strategies of KBinsDiscretizer</span></a></p>
  <div class="sphx-glr-thumbnail-title">Demonstrating the different strategies of KBinsDiscretizer</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="A demonstration of feature discretization on synthetic classification datasets. Feature discretization decomposes each feature into a set of bins, here equally distributed in width. The discrete values are then one-hot encoded, and given to a linear classifier. This preprocessing enables a non-linear behavior even though the classifier is linear."><img alt="" src="../_images/sphx_glr_plot_discretization_classification_thumb.png" />
<p><a class="reference internal" href="preprocessing/plot_discretization_classification.html#sphx-glr-auto-examples-preprocessing-plot-discretization-classification-py"><span class="std std-ref">Feature discretization</span></a></p>
  <div class="sphx-glr-thumbnail-title">Feature discretization</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Feature scaling through standardization, also called Z-score normalization, is an important preprocessing step for many machine learning algorithms. It involves rescaling each feature such that it has a standard deviation of 1 and a mean of 0."><img alt="" src="../_images/sphx_glr_plot_scaling_importance_thumb.png" />
<p><a class="reference internal" href="preprocessing/plot_scaling_importance.html#sphx-glr-auto-examples-preprocessing-plot-scaling-importance-py"><span class="std std-ref">Importance of Feature Scaling</span></a></p>
  <div class="sphx-glr-thumbnail-title">Importance of Feature Scaling</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the use of the Box-Cox and Yeo-Johnson transforms through PowerTransformer to map data from various distributions to a normal distribution."><img alt="" src="../_images/sphx_glr_plot_map_data_to_normal_thumb.png" />
<p><a class="reference internal" href="preprocessing/plot_map_data_to_normal.html#sphx-glr-auto-examples-preprocessing-plot-map-data-to-normal-py"><span class="std std-ref">Map data to a normal distribution</span></a></p>
  <div class="sphx-glr-thumbnail-title">Map data to a normal distribution</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The TargetEncoder replaces each category of a categorical feature with the shrunk mean of the target variable for that category. This method is useful in cases where there is a strong relationship between the categorical feature and the target. To prevent overfitting, TargetEncoder.fit_transform uses an internal cross fitting scheme to encode the training data to be used by a downstream model. This scheme involves splitting the data into k folds and encoding each fold using the encodings learnt using the other k-1 folds. In this example, we demonstrate the importance of the cross fitting procedure to prevent overfitting."><img alt="" src="../_images/sphx_glr_plot_target_encoder_cross_val_thumb.png" />
<p><a class="reference internal" href="preprocessing/plot_target_encoder_cross_val.html#sphx-glr-auto-examples-preprocessing-plot-target-encoder-cross-val-py"><span class="std std-ref">Target Encoder's Internal Cross fitting</span></a></p>
  <div class="sphx-glr-thumbnail-title">Target Encoder's Internal Cross fitting</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The example compares prediction result of linear regression (linear model) and decision tree (tree based model) with and without discretization of real-valued features."><img alt="" src="../_images/sphx_glr_plot_discretization_thumb.png" />
<p><a class="reference internal" href="preprocessing/plot_discretization.html#sphx-glr-auto-examples-preprocessing-plot-discretization-py"><span class="std std-ref">Using KBinsDiscretizer to discretize continuous features</span></a></p>
  <div class="sphx-glr-thumbnail-title">Using KBinsDiscretizer to discretize continuous features</div>
</div></div></section>
<section id="semi-supervised-classification">
<h2>Semi Supervised Classification<a class="headerlink" href="#semi-supervised-classification" title="Link to this heading">#</a></h2>
<p>Examples concerning the <a class="reference internal" href="../api/sklearn.semi_supervised.html#module-sklearn.semi_supervised" title="sklearn.semi_supervised"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.semi_supervised</span></code></a> module.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="A comparison for the decision boundaries generated on the iris dataset by Label Spreading, Self-training and SVM."><img alt="" src="../_images/sphx_glr_plot_semi_supervised_versus_svm_iris_thumb.png" />
<p><a class="reference internal" href="semi_supervised/plot_semi_supervised_versus_svm_iris.html#sphx-glr-auto-examples-semi-supervised-plot-semi-supervised-versus-svm-iris-py"><span class="std std-ref">Decision boundary of semi-supervised classifiers versus SVM on the Iris dataset</span></a></p>
  <div class="sphx-glr-thumbnail-title">Decision boundary of semi-supervised classifiers versus SVM on the Iris dataset</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example illustrates the effect of a varying threshold on self-training. The breast_cancer dataset is loaded, and labels are deleted such that only 50 out of 569 samples have labels. A SelfTrainingClassifier is fitted on this dataset, with varying thresholds."><img alt="" src="../_images/sphx_glr_plot_self_training_varying_threshold_thumb.png" />
<p><a class="reference internal" href="semi_supervised/plot_self_training_varying_threshold.html#sphx-glr-auto-examples-semi-supervised-plot-self-training-varying-threshold-py"><span class="std std-ref">Effect of varying threshold for self-training</span></a></p>
  <div class="sphx-glr-thumbnail-title">Effect of varying threshold for self-training</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Demonstrates an active learning technique to learn handwritten digits using label propagation."><img alt="" src="../_images/sphx_glr_plot_label_propagation_digits_active_learning_thumb.png" />
<p><a class="reference internal" href="semi_supervised/plot_label_propagation_digits_active_learning.html#sphx-glr-auto-examples-semi-supervised-plot-label-propagation-digits-active-learning-py"><span class="std std-ref">Label Propagation digits active learning</span></a></p>
  <div class="sphx-glr-thumbnail-title">Label Propagation digits active learning</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the power of semisupervised learning by training a Label Spreading model to classify handwritten digits with sets of very few labels."><img alt="" src="../_images/sphx_glr_plot_label_propagation_digits_thumb.png" />
<p><a class="reference internal" href="semi_supervised/plot_label_propagation_digits.html#sphx-glr-auto-examples-semi-supervised-plot-label-propagation-digits-py"><span class="std std-ref">Label Propagation digits: Demonstrating performance</span></a></p>
  <div class="sphx-glr-thumbnail-title">Label Propagation digits: Demonstrating performance</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Example of LabelPropagation learning a complex internal structure to demonstrate &quot;manifold learning&quot;. The outer circle should be labeled &quot;red&quot; and the inner circle &quot;blue&quot;. Because both label groups lie inside their own distinct shape, we can see that the labels propagate correctly around the circle."><img alt="" src="../_images/sphx_glr_plot_label_propagation_structure_thumb.png" />
<p><a class="reference internal" href="semi_supervised/plot_label_propagation_structure.html#sphx-glr-auto-examples-semi-supervised-plot-label-propagation-structure-py"><span class="std std-ref">Label Propagation learning a complex structure</span></a></p>
  <div class="sphx-glr-thumbnail-title">Label Propagation learning a complex structure</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, semi-supervised classifiers are trained on the 20 newsgroups dataset (which will be automatically downloaded)."><img alt="" src="../_images/sphx_glr_plot_semi_supervised_newsgroups_thumb.png" />
<p><a class="reference internal" href="semi_supervised/plot_semi_supervised_newsgroups.html#sphx-glr-auto-examples-semi-supervised-plot-semi-supervised-newsgroups-py"><span class="std std-ref">Semi-supervised Classification on a Text Dataset</span></a></p>
  <div class="sphx-glr-thumbnail-title">Semi-supervised Classification on a Text Dataset</div>
</div></div></section>
<section id="support-vector-machines">
<h2>Support Vector Machines<a class="headerlink" href="#support-vector-machines" title="Link to this heading">#</a></h2>
<p>Examples concerning the <a class="reference internal" href="../api/sklearn.svm.html#module-sklearn.svm" title="sklearn.svm"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.svm</span></code></a> module.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="An example using a one-class SVM for novelty detection."><img alt="" src="../_images/sphx_glr_plot_oneclass_thumb.png" />
<p><a class="reference internal" href="svm/plot_oneclass.html#sphx-glr-auto-examples-svm-plot-oneclass-py"><span class="std std-ref">One-class SVM with non-linear kernel (RBF)</span></a></p>
  <div class="sphx-glr-thumbnail-title">One-class SVM with non-linear kernel (RBF)</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="SVCs aim to find a hyperplane that effectively separates the classes in their training data by maximizing the margin between the outermost data points of each class. This is achieved by finding the best weight vector w that defines the decision boundary hyperplane and minimizes the sum of hinge losses for misclassified samples, as measured by the hinge_loss function. By default, regularization is applied with the parameter C=1, which allows for a certain degree of misclassification tolerance."><img alt="" src="../_images/sphx_glr_plot_svm_kernels_thumb.png" />
<p><a class="reference internal" href="svm/plot_svm_kernels.html#sphx-glr-auto-examples-svm-plot-svm-kernels-py"><span class="std std-ref">Plot classification boundaries with different SVM Kernels</span></a></p>
  <div class="sphx-glr-thumbnail-title">Plot classification boundaries with different SVM Kernels</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Comparison of different linear SVM classifiers on a 2D projection of the iris dataset. We only consider the first 2 features of this dataset:"><img alt="" src="../_images/sphx_glr_plot_iris_svc_thumb.png" />
<p><a class="reference internal" href="svm/plot_iris_svc.html#sphx-glr-auto-examples-svm-plot-iris-svc-py"><span class="std std-ref">Plot different SVM classifiers in the iris dataset</span></a></p>
  <div class="sphx-glr-thumbnail-title">Plot different SVM classifiers in the iris dataset</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Unlike SVC (based on LIBSVM), LinearSVC (based on LIBLINEAR) does not provide the support vectors. This example demonstrates how to obtain the support vectors in LinearSVC."><img alt="" src="../_images/sphx_glr_plot_linearsvc_support_vectors_thumb.png" />
<p><a class="reference internal" href="svm/plot_linearsvc_support_vectors.html#sphx-glr-auto-examples-svm-plot-linearsvc-support-vectors-py"><span class="std std-ref">Plot the support vectors in LinearSVC</span></a></p>
  <div class="sphx-glr-thumbnail-title">Plot the support vectors in LinearSVC</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example illustrates the effect of the parameters gamma and C of the Radial Basis Function (RBF) kernel SVM."><img alt="" src="../_images/sphx_glr_plot_rbf_parameters_thumb.png" />
<p><a class="reference internal" href="svm/plot_rbf_parameters.html#sphx-glr-auto-examples-svm-plot-rbf-parameters-py"><span class="std std-ref">RBF SVM parameters</span></a></p>
  <div class="sphx-glr-thumbnail-title">RBF SVM parameters</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="A small value of C includes more/all the observations, allowing the margins to be calculated using all the data in the area."><img alt="" src="../_images/sphx_glr_plot_svm_margin_thumb.png" />
<p><a class="reference internal" href="svm/plot_svm_margin.html#sphx-glr-auto-examples-svm-plot-svm-margin-py"><span class="std std-ref">SVM Margins Example</span></a></p>
  <div class="sphx-glr-thumbnail-title">SVM Margins Example</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The two plots differ only in the area in the middle where the classes are tied. If break_ties=False, all input in that area would be classified as one class, whereas if break_ties=True, the tie-breaking mechanism will create a non-convex decision boundary in that area."><img alt="" src="../_images/sphx_glr_plot_svm_tie_breaking_thumb.png" />
<p><a class="reference internal" href="svm/plot_svm_tie_breaking.html#sphx-glr-auto-examples-svm-plot-svm-tie-breaking-py"><span class="std std-ref">SVM Tie Breaking Example</span></a></p>
  <div class="sphx-glr-thumbnail-title">SVM Tie Breaking Example</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Simple usage of Support Vector Machines to classify a sample. It will plot the decision surface and the support vectors."><img alt="" src="../_images/sphx_glr_plot_custom_kernel_thumb.png" />
<p><a class="reference internal" href="svm/plot_custom_kernel.html#sphx-glr-auto-examples-svm-plot-custom-kernel-py"><span class="std std-ref">SVM with custom kernel</span></a></p>
  <div class="sphx-glr-thumbnail-title">SVM with custom kernel</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to perform univariate feature selection before running a SVC (support vector classifier) to improve the classification scores. We use the iris dataset (4 features) and add 36 non-informative features. We can find that our model achieves best performance when we select around 10% of features."><img alt="" src="../_images/sphx_glr_plot_svm_anova_thumb.png" />
<p><a class="reference internal" href="svm/plot_svm_anova.html#sphx-glr-auto-examples-svm-plot-svm-anova-py"><span class="std std-ref">SVM-Anova: SVM with univariate feature selection</span></a></p>
  <div class="sphx-glr-thumbnail-title">SVM-Anova: SVM with univariate feature selection</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Plot the maximum margin separating hyperplane within a two-class separable dataset using a Support Vector Machine classifier with linear kernel."><img alt="" src="../_images/sphx_glr_plot_separating_hyperplane_thumb.png" />
<p><a class="reference internal" href="svm/plot_separating_hyperplane.html#sphx-glr-auto-examples-svm-plot-separating-hyperplane-py"><span class="std std-ref">SVM: Maximum margin separating hyperplane</span></a></p>
  <div class="sphx-glr-thumbnail-title">SVM: Maximum margin separating hyperplane</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Find the optimal separating hyperplane using an SVC for classes that are unbalanced."><img alt="" src="../_images/sphx_glr_plot_separating_hyperplane_unbalanced_thumb.png" />
<p><a class="reference internal" href="svm/plot_separating_hyperplane_unbalanced.html#sphx-glr-auto-examples-svm-plot-separating-hyperplane-unbalanced-py"><span class="std std-ref">SVM: Separating hyperplane for unbalanced classes</span></a></p>
  <div class="sphx-glr-thumbnail-title">SVM: Separating hyperplane for unbalanced classes</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Plot decision function of a weighted dataset, where the size of points is proportional to its weight."><img alt="" src="../_images/sphx_glr_plot_weighted_samples_thumb.png" />
<p><a class="reference internal" href="svm/plot_weighted_samples.html#sphx-glr-auto-examples-svm-plot-weighted-samples-py"><span class="std std-ref">SVM: Weighted samples</span></a></p>
  <div class="sphx-glr-thumbnail-title">SVM: Weighted samples</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The following example illustrates the effect of scaling the regularization parameter when using svm for svm_classification. For SVC classification, we are interested in a risk minimization for the equation:"><img alt="" src="../_images/sphx_glr_plot_svm_scale_c_thumb.png" />
<p><a class="reference internal" href="svm/plot_svm_scale_c.html#sphx-glr-auto-examples-svm-plot-svm-scale-c-py"><span class="std std-ref">Scaling the regularization parameter for SVCs</span></a></p>
  <div class="sphx-glr-thumbnail-title">Scaling the regularization parameter for SVCs</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Toy example of 1D regression using linear, polynomial and RBF kernels."><img alt="" src="../_images/sphx_glr_plot_svm_regression_thumb.png" />
<p><a class="reference internal" href="svm/plot_svm_regression.html#sphx-glr-auto-examples-svm-plot-svm-regression-py"><span class="std std-ref">Support Vector Regression (SVR) using linear and non-linear kernels</span></a></p>
  <div class="sphx-glr-thumbnail-title">Support Vector Regression (SVR) using linear and non-linear kernels</div>
</div></div></section>
<section id="working-with-text-documents">
<h2>Working with text documents<a class="headerlink" href="#working-with-text-documents" title="Link to this heading">#</a></h2>
<p>Examples concerning the <a class="reference internal" href="../api/sklearn.feature_extraction.html#module-sklearn.feature_extraction.text" title="sklearn.feature_extraction.text"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.feature_extraction.text</span></code></a> module.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This is an example showing how scikit-learn can be used to classify documents by topics using a Bag of Words approach. This example uses a Tf-idf-weighted document-term sparse matrix to encode the features and demonstrates various classifiers that can efficiently handle sparse matrices."><img alt="" src="../_images/sphx_glr_plot_document_classification_20newsgroups_thumb.png" />
<p><a class="reference internal" href="text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py"><span class="std std-ref">Classification of text documents using sparse features</span></a></p>
  <div class="sphx-glr-thumbnail-title">Classification of text documents using sparse features</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This is an example showing how the scikit-learn API can be used to cluster documents by topics using a Bag of Words approach."><img alt="" src="../_images/sphx_glr_plot_document_clustering_thumb.png" />
<p><a class="reference internal" href="text/plot_document_clustering.html#sphx-glr-auto-examples-text-plot-document-clustering-py"><span class="std std-ref">Clustering text documents using k-means</span></a></p>
  <div class="sphx-glr-thumbnail-title">Clustering text documents using k-means</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example we illustrate text vectorization, which is the process of representing non-numerical input data (such as dictionaries or text documents) as vectors of real numbers."><img alt="" src="../_images/sphx_glr_plot_hashing_vs_dict_vectorizer_thumb.png" />
<p><a class="reference internal" href="text/plot_hashing_vs_dict_vectorizer.html#sphx-glr-auto-examples-text-plot-hashing-vs-dict-vectorizer-py"><span class="std std-ref">FeatureHasher and DictVectorizer Comparison</span></a></p>
  <div class="sphx-glr-thumbnail-title">FeatureHasher and DictVectorizer Comparison</div>
</div></div></section>
<section id="id1">
<h2>أمثلة مبنية على مجموعات بيانات من العالم الحقيقي<a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
<p>تطبيقات على مشاكل العالم الحقيقي مع مجموعات بيانات متوسطة الحجم أو
واجهة مستخدم تفاعلية.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="This is an example showing how scikit-learn can be used for classification using an out-of-core approach: learning from data that doesn&#x27;t fit into main memory. We make use of an online classifier, i.e., one that supports the partial_fit method, that will be fed with batches of examples. To guarantee that the features space remains the same over time we leverage a HashingVectorizer that will project each example into the same feature space. This is especially useful in the case of text classification where new features (words) may appear in each batch."><img alt="" src="../_images/sphx_glr_plot_out_of_core_classification_thumb.png" />
<p><a class="reference internal" href="applications/plot_out_of_core_classification.html#sphx-glr-auto-examples-applications-plot-out-of-core-classification-py"><span class="std std-ref">Out-of-core classification of text documents</span></a></p>
  <div class="sphx-glr-thumbnail-title">Out-of-core classification of text documents</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="هذا المثال يوضح كيفية استخدام KernelPCA لإزالة التشويش من الصور. باختصار، نستفيد من دالة التقريب المُتعلمة أثناء fit لإعادة بناء الصورة الأصلية."><img alt="" src="../_images/sphx_glr_plot_digits_denoising_thumb.png" />
<p><a class="reference internal" href="applications/plot_digits_denoising.html#sphx-glr-auto-examples-applications-plot-digits-denoising-py"><span class="std std-ref">إزالة التشويش من الصور باستخدام PCA النواة</span></a></p>
  <div class="sphx-glr-thumbnail-title">إزالة التشويش من الصور باستخدام PCA النواة</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="هذا مثال على تطبيق NMF و LatentDirichletAllocation على مجموعة من الوثائق واستخراج نماذج إضافية لهيكل الموضوعات في المجموعة.  المخرجات عبارة عن رسم بياني للموضوعات، يمثل كل منها رسمًا بيانيًا باستخدام عدد قليل من الكلمات العليا بناءً على الأوزان."><img alt="" src="../_images/sphx_glr_plot_topics_extraction_with_nmf_lda_thumb.png" />
<p><span class="xref std std-ref">sphx_glr_auto_examples_applications_plot_topics_extraction_with_nmf_lda.py</span></p>
  <div class="sphx-glr-thumbnail-title">استخراج الموضوعات باستخدام تحليل المصفوفات غير السالبة وتخصيص ديريتشليت الكامن</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يوضح هذا المثال الحاجة إلى تقدير متانة التغاير على مجموعة بيانات حقيقية. وهو مفيد لكل من الكشف عن القيم الشاذة وفهم أفضل لهيكل البيانات."><img alt="" src="../_images/sphx_glr_plot_outlier_detection_wine_thumb.png" />
<p><a class="reference internal" href="applications/plot_outlier_detection_wine.html#sphx-glr-auto-examples-applications-plot-outlier-detection-wine-py"><span class="std std-ref">الكشف عن القيم الشاذة في مجموعة بيانات حقيقية</span></a></p>
  <div class="sphx-glr-thumbnail-title">الكشف عن القيم الشاذة في مجموعة بيانات حقيقية</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="هناك طريقة كلاسيكية لتأكيد الأهمية النسبية للرؤوس في الرسم البياني هو حساب المتجه الذاتي الرئيسي لمصفوفة المجاورة حتى يتم تعيين قيم مكونات المتجه الذاتي الأول لكل رأس كدرجة مركزية: https://en.wikipedia.org/wiki/Eigenvector_centrality. على رسم بياني للصفحات والروابط تسمى هذه القيم بتصنيفات PageRank من قبل Google."><img alt="" src="../_images/sphx_glr_wikipedia_principal_eigenvector_thumb.png" />
<p><a class="reference internal" href="applications/wikipedia_principal_eigenvector.html#sphx-glr-auto-examples-applications-wikipedia-principal-eigenvector-py"><span class="std std-ref">المتجه الذاتي الرئيسي لويكيبيديا</span></a></p>
  <div class="sphx-glr-thumbnail-title">المتجه الذاتي الرئيسي لويكيبيديا</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="هذا المثال يوضح كيفية استخدام الميزات المتأخرة التي تم تصميمها بواسطة Polars في التنبؤ بالسلاسل الزمنية باستخدام HistGradientBoostingRegressor على مجموعة بيانات طلب مشاركة الدراجات."><img alt="" src="../_images/sphx_glr_plot_time_series_lagged_features_thumb.png" />
<p><a class="reference internal" href="applications/plot_time_series_lagged_features.html#sphx-glr-auto-examples-applications-plot-time-series-lagged-features-py"><span class="std std-ref">الميزات المتأخرة للتنبؤ بالسلاسل الزمنية</span></a></p>
  <div class="sphx-glr-thumbnail-title">الميزات المتأخرة للتنبؤ بالسلاسل الزمنية</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="توضيح كيف يؤثر تعقيد النموذج على كل من دقة التنبؤ والأداء الحسابي."><img alt="" src="../_images/sphx_glr_plot_model_complexity_influence_thumb.png" />
<p><a class="reference internal" href="applications/plot_model_complexity_influence.html#sphx-glr-auto-examples-applications-plot-model-complexity-influence-py"><span class="std std-ref">تأثير تعقيد النموذج</span></a></p>
  <div class="sphx-glr-thumbnail-title">تأثير تعقيد النموذج</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="هذا مثال يوضح تأخير التنبؤ لمختلف الخوارزميات في مكتبة ساي كيت ليرن."><img alt="" src="../_images/sphx_glr_plot_prediction_latency_thumb.png" />
<p><a class="reference internal" href="applications/plot_prediction_latency.html#sphx-glr-auto-examples-applications-plot-prediction-latency-py"><span class="std std-ref">تأخير التنبؤ</span></a></p>
  <div class="sphx-glr-thumbnail-title">تأخير التنبؤ</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="مجموعة البيانات المستخدمة في هذا المثال هي مقتطف مُعالج مسبقًا من &quot;الوجوه المسماة في البرية&quot;، المعروف باسم LFW_: http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz (233MB)"><img alt="" src="../_images/sphx_glr_plot_face_recognition_thumb.png" />
<p><a class="reference internal" href="applications/plot_face_recognition.html#sphx-glr-auto-examples-applications-plot-face-recognition-py"><span class="std std-ref">مثال على التعرف على الوجوه باستخدام الوجوه المميزة وآلات المتجهات الداعمة</span></a></p>
  <div class="sphx-glr-thumbnail-title">مثال على التعرف على الوجوه باستخدام الوجوه المميزة وآلات المتجهات الداعمة</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="نمذجة التوزيعات الجغرافية للأنواع هي مشكلة مهمة في علم الأحياء الحفاظي. في هذا المثال، نقوم بنمذجة التوزيع الجغرافي لثدييين من أمريكا الجنوبية بناءً على الملاحظات السابقة و14 متغيرًا بيئيًا. نظرًا لأن لدينا فقط أمثلة إيجابية (لا توجد ملاحظات غير ناجحة), فإننا نطرح هذه المشكلة كتقدير كثافة ونستخدم OneClassSVM كأداة النمذجة الخاصة بنا. توفر مجموعة البيانات من قبل فيليبس وآخرون. (2006). إذا كان متاحًا، يستخدم المثال basemap لرسم خطوط السواحل والحدود الوطنية لأمريكا الجنوبية."><img alt="" src="../_images/sphx_glr_plot_species_distribution_modeling_thumb.png" />
<p><a class="reference internal" href="applications/plot_species_distribution_modeling.html#sphx-glr-auto-examples-applications-plot-species-distribution-modeling-py"><span class="std std-ref">نمذجة توزيع الأنواع</span></a></p>
  <div class="sphx-glr-thumbnail-title">نمذجة توزيع الأنواع</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="بدون أي معلومات مسبقة عن العينة، فإن عدد الإسقاطات المطلوبة لإعادة بناء الصورة هو من نفس ترتيب الحجم الخطي l للصورة (بالبكسل). من أجل البساطة، نحن نعتبر هنا صورة نادرة، حيث تحتوي البكسلات على حدود الأجسام فقط على قيمة غير صفرية. يمكن أن تتوافق مثل هذه البيانات، على سبيل المثال، مع مادة خلوية."><img alt="" src="../_images/sphx_glr_plot_tomography_l1_reconstruction_thumb.png" />
<p><span class="xref std std-ref">sphx_glr_auto_examples_applications_plot_tomography_l1_reconstruction.py</span></p>
  <div class="sphx-glr-thumbnail-title">هذا مثال يوضح إعادة بناء صورة من مجموعة من الإسقاطات المتوازية، والتي تم الحصول عليها على طول زوايا مختلفة. يتم الحصول على مثل هذه البيانات في التصوير المقطعي المحوسب (CT).</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يُقدم هذا الدفتر طرقًا مختلفة للاستفادة من الميزات ذات الصلة بالوقت لمهمة انحدار طلب مشاركة الدراجات التي تعتمد بشكل كبير على دورات العمل (الأيام، والأسابيع، والشهور) ودورات المواسم السنوية."><img alt="" src="../_images/sphx_glr_plot_cyclical_feature_engineering_thumb.png" />
<p><a class="reference internal" href="applications/plot_cyclical_feature_engineering.html#sphx-glr-auto-examples-applications-plot-cyclical-feature-engineering-py"><span class="std std-ref">هندسة الميزات ذات الصلة بالوقت</span></a></p>
  <div class="sphx-glr-thumbnail-title">هندسة الميزات ذات الصلة بالوقت</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يستخدم هذا المثال عدة تقنيات تعلم غير خاضعة للإشراف لاستخراج هيكل سوق الأسهم من الاختلافات في الاقتباسات التاريخية."><img alt="" src="../_images/sphx_glr_plot_stock_market_thumb.png" />
<p><a class="reference internal" href="applications/plot_stock_market.html#sphx-glr-auto-examples-applications-plot-stock-market-py"><span class="std std-ref">هيكلة سوق الأسهم المرئية</span></a></p>
  <div class="sphx-glr-thumbnail-title">هيكلة سوق الأسهم المرئية</div>
</div></div></section>
<section id="id2">
<h2>أمثلة مجموعات البيانات<a class="headerlink" href="#id2" title="Link to this heading">#</a></h2>
<p>أمثلة تتعلق بوحدة <a class="reference internal" href="../api/sklearn.datasets.html#module-sklearn.datasets" title="sklearn.datasets"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.datasets</span></code></a> .</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="هذا يوضح مولد مجموعة البيانات make_multilabel_classification . تتكون كل عينة من عدد من ميزتين (حتى 50 في المجموع)، والتي تُوزع بشكل مختلف في كل من الفئتين."><img alt="" src="../_images/sphx_glr_plot_random_multilabel_dataset_thumb.png" />
<p><a class="reference internal" href="datasets/plot_random_multilabel_dataset.html#sphx-glr-auto-examples-datasets-plot-random-multilabel-dataset-py"><span class="std std-ref">رسم مجموعة بيانات متعددة التصنيفات مُولدة عشوائياً</span></a></p>
  <div class="sphx-glr-thumbnail-title">رسم مجموعة بيانات متعددة التصنيفات مُولدة عشوائياً</div>
</div></div></section>
<section id="id3">
<h2>إختيار الميزة<a class="headerlink" href="#id3" title="Link to this heading">#</a></h2>
<p>أمثلة تتعلق بوحدة <a class="reference internal" href="../api/sklearn.feature_selection.html#module-sklearn.feature_selection" title="sklearn.feature_selection"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.feature_selection</span></code></a>.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="يوضح هذا المثال ويقارن نهجين لاختيار الميزات: SelectFromModel الذي يعتمد على أهمية الميزات، و SequentialFeatureSelector الذي يعتمد على نهج جشع."><img alt="" src="../_images/sphx_glr_plot_select_from_model_diabetes_thumb.png" />
<p><a class="reference internal" href="feature_selection/plot_select_from_model_diabetes.html#sphx-glr-auto-examples-feature-selection-plot-select-from-model-diabetes-py"><span class="std std-ref">Model-based and sequential feature selection</span></a></p>
  <div class="sphx-glr-thumbnail-title">Model-based and sequential feature selection</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يوضح هذا المثال كيف يمكن دمج اختيار الميزات بسهولة ضمن مجرى تعلم الآلة."><img alt="" src="../_images/sphx_glr_plot_feature_selection_pipeline_thumb.png" />
<p><a class="reference internal" href="feature_selection/plot_feature_selection_pipeline.html#sphx-glr-auto-examples-feature-selection-plot-feature-selection-pipeline-py"><span class="std std-ref">Pipeline ANOVA SVM</span></a></p>
  <div class="sphx-glr-thumbnail-title">Pipeline ANOVA SVM</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="مثال على حذف الميزات التكراري (RFE) مع الضبط التلقائي لعدد الميزات المحددة مع التحقق المتبادل."><img alt="" src="../_images/sphx_glr_plot_rfe_with_cross_validation_thumb.png" />
<p><a class="reference internal" href="feature_selection/plot_rfe_with_cross_validation.html#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py"><span class="std std-ref">إزالة الميزات المتكررة باستخدام التحقق المتبادل</span></a></p>
  <div class="sphx-glr-thumbnail-title">إزالة الميزات المتكررة باستخدام التحقق المتبادل</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يوضح هذا المثال كيفية استخدام حذف الميزات التكراري (~sklearn.feature_selection.RFE) لتحديد أهمية وحدات البكسل الفردية لتصنيف الأرقام المكتوبة بخط اليد. RFE يزيل بشكل تكراري الميزات الأقل أهمية، ويخصص الرتب بناءً على أهميتها، حيث تشير قيم ranking_ الأعلى إلى أهمية أقل. يتم تصور الترتيب باستخدام كل من درجات اللون الأزرق وشروح البكسل من أجل الوضوح. كما هو متوقع، تميل وحدات البكسل الموجودة في وسط الصورة إلى أن تكون أكثر قدرة على التنبؤ من تلك القريبة من الحواف."><img alt="" src="../_images/sphx_glr_plot_rfe_digits_thumb.png" />
<p><a class="reference internal" href="feature_selection/plot_rfe_digits.html#sphx-glr-auto-examples-feature-selection-plot-rfe-digits-py"><span class="std std-ref">إزالة الميزة المتكررة</span></a></p>
  <div class="sphx-glr-thumbnail-title">إزالة الميزة المتكررة</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="هذا الدفتر هو مثال على استخدام اختيار الميزات أحادي المتغير لتحسين دقة التصنيف على مجموعة بيانات صاخبة."><img alt="" src="../_images/sphx_glr_plot_feature_selection_thumb.png" />
<p><a class="reference internal" href="feature_selection/plot_feature_selection.html#sphx-glr-auto-examples-feature-selection-plot-feature-selection-py"><span class="std std-ref">اختيار الميزة أحادية المتغير</span></a></p>
  <div class="sphx-glr-thumbnail-title">اختيار الميزة أحادية المتغير</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يوضح هذا المثال الاختلافات بين إحصائيات اختبار F أحادي المتغير والمعلومات المتبادلة."><img alt="" src="../_images/sphx_glr_plot_f_test_vs_mi_thumb.png" />
<p><a class="reference internal" href="feature_selection/plot_f_test_vs_mi.html#sphx-glr-auto-examples-feature-selection-plot-f-test-vs-mi-py"><span class="std std-ref">مقارنة بين اختبار F والمعلومات المتبادلة</span></a></p>
  <div class="sphx-glr-thumbnail-title">مقارنة بين اختبار F والمعلومات المتبادلة</div>
</div></div></section>
<section id="id4">
<h2>التجميع<a class="headerlink" href="#id4" title="Link to this heading">#</a></h2>
<p>أمثلة تتعلق بوحدة <a class="reference internal" href="../api/sklearn.cluster.html#module-sklearn.cluster" title="sklearn.cluster"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.cluster</span></code></a> .</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="في هذا المثال، يتم توليد صورة بدوائر متصلة ويتم استخدام التجميع الطيفي لفصل الدوائر."><img alt="" src="../_images/sphx_glr_plot_segmentation_toy_thumb.png" />
<p><span class="xref std std-ref">sphx_glr_auto_examples_cluster_plot_segmentation_toy.py</span></p>
  <div class="sphx-glr-thumbnail-title"># ===========================================</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="توضح تأثير مقاييس مختلفة على التجميع الهرمي."><img alt="" src="../_images/sphx_glr_plot_agglomerative_clustering_metrics_thumb.png" />
<p><a class="reference internal" href="cluster/plot_agglomerative_clustering_metrics.html#sphx-glr-auto-examples-cluster-plot-agglomerative-clustering-metrics-py"><span class="std std-ref"># التجميع التجميعي مع مقاييس مختلفة</span></a></p>
  <div class="sphx-glr-thumbnail-title"># التجميع التجميعي مع مقاييس مختلفة</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="هذا المثال يوضح تأثير فرض رسم بياني للاتصال لالتقاط البنية المحلية في البيانات. الرسم البياني هو ببساطة رسم بياني لأقرب 20 جارًا."><img alt="" src="../_images/sphx_glr_plot_agglomerative_clustering_thumb.png" />
<p><a class="reference internal" href="cluster/plot_agglomerative_clustering.html#sphx-glr-auto-examples-cluster-plot-agglomerative-clustering-py"><span class="std std-ref"># التجميع التجميعي مع وبغير بنية</span></a></p>
  <div class="sphx-glr-thumbnail-title"># التجميع التجميعي مع وبغير بنية</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="هذا المثال يقارن بين استراتيجيتين لخفض الأبعاد:"><img alt="" src="../_images/sphx_glr_plot_feature_agglomeration_vs_univariate_selection_thumb.png" />
<p><span class="xref std std-ref">sphx_glr_auto_examples_cluster_plot_feature_agglomeration_vs_univariate_selection.py</span></p>
  <div class="sphx-glr-thumbnail-title"># مقارنة بين تجميع الميزات والاختيار أحادي المتغير</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يمكن أن تكون عملية التصنيف مكلفة، خاصة عندما تحتوي مجموعتنا البياناتية على ملايين النقاط البياناتية. العديد من خوارزميات التصنيف ليست استقرائية، وبالتالي لا يمكن تطبيقها مباشرة على عينات بيانات جديدة دون إعادة حساب التصنيف، والذي قد يكون غير قابل للحساب. بدلاً من ذلك، يمكننا استخدام التصنيف لتعلم نموذج استقرائي باستخدام مصنف، والذي له عدة فوائد:"><img alt="" src="../_images/sphx_glr_plot_inductive_clustering_thumb.png" />
<p><a class="reference internal" href="cluster/plot_inductive_clustering.html#sphx-glr-auto-examples-cluster-plot-inductive-clustering-py"><span class="std std-ref">التصنيف الاستقرائي</span></a></p>
  <div class="sphx-glr-thumbnail-title">التصنيف الاستقرائي</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="مثال يبني مجموعة بيانات Swiss Roll ويقوم بتشغيل العنقدة الهرمية على موقعها."><img alt="" src="../_images/sphx_glr_plot_ward_structured_vs_unstructured_thumb.png" />
<p><a class="reference internal" href="cluster/plot_ward_structured_vs_unstructured.html#sphx-glr-auto-examples-cluster-plot-ward-structured-vs-unstructured-py"><span class="std std-ref">العنقدة الهرمية: العنقدة المنظمة وغير المنظمة</span></a></p>
  <div class="sphx-glr-thumbnail-title">العنقدة الهرمية: العنقدة المنظمة وغير المنظمة</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="توضح هذه الصور كيف يتم دمج الميزات المتشابهة معًا باستخدام تجميع الميزات."><img alt="" src="../_images/sphx_glr_plot_digits_agglomeration_thumb.png" />
<p><a class="reference internal" href="cluster/plot_digits_agglomeration.html#sphx-glr-auto-examples-cluster-plot-digits-agglomeration-py"><span class="std std-ref">تجميع الميزات</span></a></p>
  <div class="sphx-glr-thumbnail-title">تجميع الميزات</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يمكن استخدام تحليل السيلويت لدراسة مسافة الفصل بين التجمعات الناتجة. يعرض مخطط السيلويت مقياسًا لمدى قرب كل نقطة في تجمع واحد من النقاط في التجمعات المجاورة، وبالتالي يوفر طريقة لتقييم المعلمات مثل عدد التجمعات بصريًا. يتراوح هذا المقياس بين [-1, 1]."><img alt="" src="../_images/sphx_glr_plot_kmeans_silhouette_analysis_thumb.png" />
<p><a class="reference internal" href="cluster/plot_kmeans_silhouette_analysis.html#sphx-glr-auto-examples-cluster-plot-kmeans-silhouette-analysis-py"><span class="std std-ref">تحليل السيلويت لتحديد عدد التجمعات في التجميع التجميعي KMeans</span></a></p>
  <div class="sphx-glr-thumbnail-title">تحليل السيلويت لتحديد عدد التجمعات في التجميع التجميعي KMeans</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="هذا المثال يهدف إلى توضيح المواقف التي تنتج فيها خوارزمية كاي-مينز (k-means) تجميعات غير بديهية وربما غير مرغوب فيها."><img alt="" src="../_images/sphx_glr_plot_kmeans_digits_thumb.png" />
<p><a class="reference internal" href="cluster/plot_kmeans_digits.html#sphx-glr-auto-examples-cluster-plot-kmeans-digits-py"><span class="std std-ref">تطبيق خوارزمية k-means على مجموعة البيانات digits</span></a></p>
  <div class="sphx-glr-thumbnail-title">تطبيق خوارزمية k-means على مجموعة البيانات digits</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="- تجربة أولى مع &quot;علامات الحقيقة الأرضية&quot; الثابتة (وبالتالي عدد ثابت من الفئات) و&quot;علامات متوقعة&quot; عشوائية؛ - تجربة ثانية مع &quot;علامات الحقيقة الأرضية&quot; المتغيرة، &quot;علامات متوقعة&quot; عشوائية. تحتوي &quot;العلامات المتوقعة&quot; على نفس عدد الفئات والتجمعات مثل &quot;علامات الحقيقة الأرضية&quot;."><img alt="" src="../_images/sphx_glr_plot_adjusted_for_chance_measures_thumb.png" />
<p><a class="reference internal" href="cluster/plot_adjusted_for_chance_measures.html#sphx-glr-auto-examples-cluster-plot-adjusted-for-chance-measures-py"><span class="std std-ref">تعديل الفرصة في تقييم أداء التجميع</span></a></p>
  <div class="sphx-glr-thumbnail-title">تعديل الفرصة في تقييم أداء التجميع</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يستخدم هذا المثال مجموعة كبيرة من الوجوه لتعلم مجموعة من الصور مقاس 20x20 التي تشكل الوجوه."><img alt="" src="../_images/sphx_glr_plot_dict_face_patches_thumb.png" />
<p><a class="reference internal" href="cluster/plot_dict_face_patches.html#sphx-glr-auto-examples-cluster-plot-dict-face-patches-py"><span class="std std-ref">تعلم القاموس عبر الإنترنت لأجزاء الوجوه</span></a></p>
  <div class="sphx-glr-thumbnail-title">تعلم القاموس عبر الإنترنت لأجزاء الوجوه</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="تقييم قدرة إستراتيجيات تهيئة k-means على جعل خوارزمية التقارب قوية، كما يقاس بالانحراف المعياري النسبي للقصور الذاتي للتجميع (أي مجموع مربعات المسافات إلى أقرب مركز للتجميع)."><img alt="" src="../_images/sphx_glr_plot_kmeans_stability_low_dim_dense_thumb.png" />
<p><a class="reference internal" href="cluster/plot_kmeans_stability_low_dim_dense.html#sphx-glr-auto-examples-cluster-plot-kmeans-stability-low-dim-dense-py"><span class="std std-ref">تقييم تجريبي لتأثير تهيئة k-means</span></a></p>
  <div class="sphx-glr-thumbnail-title">تقييم تجريبي لتأثير تهيئة k-means</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يستخدم هذا المثال spectral_clustering على رسم بياني تم إنشاؤه من الفرق بين البكسلات في صورة لتقسيم هذه الصورة إلى مناطق متعددة جزئيا متجانسة."><img alt="" src="../_images/sphx_glr_plot_coin_segmentation_thumb.png" />
<p><a class="reference internal" href="cluster/plot_coin_segmentation.html#sphx-glr-auto-examples-cluster-plot-coin-segmentation-py"><span class="std std-ref">تم تقسيم صورة العملات اليونانية إلى مناطق</span></a></p>
  <div class="sphx-glr-thumbnail-title">تم تقسيم صورة العملات اليونانية إلى مناطق</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="هذا المثال يهدف إلى توضيح المواقف التي تنتج فيها خوارزمية كاي-مينز (k-means) تجميعات غير بديهية وربما غير مرغوب فيها."><img alt="" src="../_images/sphx_glr_plot_kmeans_assumptions_thumb.png" />
<p><a class="reference internal" href="cluster/plot_kmeans_assumptions.html#sphx-glr-auto-examples-cluster-plot-kmeans-assumptions-py"><span class="std std-ref">توضيح افتراضات خوارزمية كاي-مينز</span></a></p>
  <div class="sphx-glr-thumbnail-title">توضيح افتراضات خوارزمية كاي-مينز</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="رسم مخطط شجرة التجميع الهرمي"><img alt="" src="../_images/sphx_glr_plot_agglomerative_dendrogram_thumb.png" />
<p><a class="reference internal" href="cluster/plot_agglomerative_dendrogram.html#sphx-glr-auto-examples-cluster-plot-agglomerative-dendrogram-py"><span class="std std-ref">رسم مخطط شجرة التجميع الهرمي</span></a></p>
  <div class="sphx-glr-thumbnail-title">رسم مخطط شجرة التجميع الهرمي</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="احسب تجزئة صورة ثنائية الأبعاد باستخدام التجميع الهرمي. التجميع مقيد مكانيًا لضمان أن تكون كل منطقة مجزأة قطعة واحدة."><img alt="" src="../_images/sphx_glr_plot_coin_ward_segmentation_thumb.png" />
<p><a class="reference internal" href="cluster/plot_coin_ward_segmentation.html#sphx-glr-auto-examples-cluster-plot-coin-ward-segmentation-py"><span class="std std-ref">عرض توضيحي لتجميع هرمي منظم على صورة عملات معدنية</span></a></p>
  <div class="sphx-glr-thumbnail-title">عرض توضيحي لتجميع هرمي منظم على صورة عملات معدنية</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="DBSCAN (Density-Based Spatial Clustering of Applications with Noise) يجد العينات الأساسية في مناطق ذات كثافة عالية ويوسع التجمعات منها. هذا الخوارزم جيد للبيانات التي تحتوي على تجمعات ذات كثافة مماثلة."><img alt="" src="../_images/sphx_glr_plot_dbscan_thumb.png" />
<p><a class="reference internal" href="cluster/plot_dbscan.html#sphx-glr-auto-examples-cluster-plot-dbscan-py"><span class="std std-ref">عرض توضيحي لخوارزمية التجميع DBSCAN</span></a></p>
  <div class="sphx-glr-thumbnail-title">عرض توضيحي لخوارزمية التجميع DBSCAN</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="في هذا العرض التوضيحي، سنلقي نظرة على cluster.HDBSCAN من منظور تعميم خوارزمية cluster.DBSCAN. سنقارن بين الخوارزميتين على مجموعات بيانات محددة. وأخيرًا، سنقيم حساسية HDBSCAN تجاه بعض المعاملات."><img alt="" src="../_images/sphx_glr_plot_hdbscan_thumb.png" />
<p><a class="reference internal" href="cluster/plot_hdbscan.html#sphx-glr-auto-examples-cluster-plot-hdbscan-py"><span class="std std-ref">عرض توضيحي لخوارزمية التجميع HDBSCAN</span></a></p>
  <div class="sphx-glr-thumbnail-title">عرض توضيحي لخوارزمية التجميع HDBSCAN</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يحدد العينات الأساسية ذات الكثافة العالية ويوسع التجمعات منها. يستخدم هذا المثال بيانات تم إنشاؤها بحيث يكون للتجمعات كثافات مختلفة."><img alt="" src="../_images/sphx_glr_plot_optics_thumb.png" />
<p><a class="reference internal" href="cluster/plot_optics.html#sphx-glr-auto-examples-cluster-plot-optics-py"><span class="std std-ref">عرض توضيحي لخوارزمية التجميع OPTICS</span></a></p>
  <div class="sphx-glr-thumbnail-title">عرض توضيحي لخوارزمية التجميع OPTICS</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="المرجع:"><img alt="" src="../_images/sphx_glr_plot_mean_shift_thumb.png" />
<p><a class="reference internal" href="cluster/plot_mean_shift.html#sphx-glr-auto-examples-cluster-plot-mean-shift-py"><span class="std std-ref">عرض توضيحي لخوارزمية التجميع متوسط التحول</span></a></p>
  <div class="sphx-glr-thumbnail-title">عرض توضيحي لخوارزمية التجميع متوسط التحول</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="المرجع: برندان ج. فري وديلبرت دويك، &quot;التجميع عن طريق تمرير الرسائل بين نقاط البيانات&quot;، مجلة ساينس، فبراير 2007"><img alt="" src="../_images/sphx_glr_plot_affinity_propagation_thumb.png" />
<p><a class="reference internal" href="cluster/plot_affinity_propagation.html#sphx-glr-auto-examples-cluster-plot-affinity-propagation-py"><span class="std std-ref">عرض توضيحي لخوارزمية تجميع انتشار الانتماء</span></a></p>
  <div class="sphx-glr-thumbnail-title">عرض توضيحي لخوارزمية تجميع انتشار الانتماء</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="مثال لإظار ناتج دالة sklearn.cluster.kmeans_plusplus لإنشاء بذور أولية للتجميع."><img alt="" src="../_images/sphx_glr_plot_kmeans_plusplus_thumb.png" />
<p><a class="reference internal" href="cluster/plot_kmeans_plusplus.html#sphx-glr-auto-examples-cluster-plot-kmeans-plusplus-py"><span class="std std-ref">مثال على التهيئة K-Means++</span></a></p>
  <div class="sphx-glr-thumbnail-title">مثال على التهيئة K-Means++</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يوضح هذا المثال كيف يمكن استخدام KBinsDiscretizer لإجراء تكميم المتجهات على مجموعة من الصور التجريبية، وجه الراكون."><img alt="" src="../_images/sphx_glr_plot_face_compress_thumb.png" />
<p><a class="reference internal" href="cluster/plot_face_compress.html#sphx-glr-auto-examples-cluster-plot-face-compress-py"><span class="std std-ref">مثال على تكميم المتجهات</span></a></p>
  <div class="sphx-glr-thumbnail-title">مثال على تكميم المتجهات</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="وثيقة توضيحية لخيارات الربط المختلفة للتجميع الهرمي على تضمين ثنائي الأبعاد لمجموعة بيانات الأرقام."><img alt="" src="../_images/sphx_glr_plot_digits_linkage_thumb.png" />
<p><a class="reference internal" href="cluster/plot_digits_linkage.html#sphx-glr-auto-examples-cluster-plot-digits-linkage-py"><span class="std std-ref">مختلف خوارزميات التجميع الهرمي على تضمين ثنائي الأبعاد لمجموعة بيانات الأرقام</span></a></p>
  <div class="sphx-glr-thumbnail-title">مختلف خوارزميات التجميع الهرمي على تضمين ثنائي الأبعاد لمجموعة بيانات الأرقام</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="هذا المثال يوضح الفروق بين خوارزمية K-Means العادية وخوارزمية Bisecting K-Means."><img alt="" src="../_images/sphx_glr_plot_bisect_kmeans_thumb.png" />
<p><span class="xref std std-ref">sphx_glr_auto_examples_cluster_plot_bisect_kmeans.py</span></p>
  <div class="sphx-glr-thumbnail-title">مقارنة الأداء بين خوارزمية K-Means العادية وخوارزمية Bisecting K-Means</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يقارن هذا المثال توقيت BIRCH (مع وبدون خطوة التجميع العالمي) و MiniBatchKMeans على مجموعة بيانات اصطناعية تحتوي على 25,000 عينة و2 من الميزات التي تم إنشاؤها باستخدام make_blobs."><img alt="" src="../_images/sphx_glr_plot_birch_vs_minibatchkmeans_thumb.png" />
<p><a class="reference internal" href="cluster/plot_birch_vs_minibatchkmeans.html#sphx-glr-auto-examples-cluster-plot-birch-vs-minibatchkmeans-py"><span class="std std-ref">مقارنة بين BIRCH و MiniBatchKMeans</span></a></p>
  <div class="sphx-glr-thumbnail-title">مقارنة بين BIRCH و MiniBatchKMeans</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="نريد مقارنة أداء خوارزميتي MiniBatchKMeans و KMeans: خوارزمية MiniBatchKMeans أسرع، لكنها تعطي نتائج مختلفة قليلاً (انظر: mini_batch_kmeans)."><img alt="" src="../_images/sphx_glr_plot_mini_batch_kmeans_thumb.png" />
<p><a class="reference internal" href="cluster/plot_mini_batch_kmeans.html#sphx-glr-auto-examples-cluster-plot-mini-batch-kmeans-py"><span class="std std-ref">مقارنة خوارزميات التجميع K-Means و MiniBatchKMeans</span></a></p>
  <div class="sphx-glr-thumbnail-title">مقارنة خوارزميات التجميع K-Means و MiniBatchKMeans</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="هذا المثال يوضح خصائص خوارزميات التجميع المختلفة على مجموعات البيانات التي تعتبر &quot;مثيرة للاهتمام&quot; ولكنها لا تزال ثنائية الأبعاد. باستثناء مجموعة البيانات الأخيرة، تم ضبط معلمات كل من هذه الأزواج من مجموعة البيانات والخوارزمية لإنتاج نتائج تجميع جيدة. بعض الخوارزميات أكثر حساسية لقيم المعلمات من غيرها."><img alt="" src="../_images/sphx_glr_plot_cluster_comparison_thumb.png" />
<p><a class="reference internal" href="cluster/plot_cluster_comparison.html#sphx-glr-auto-examples-cluster-plot-cluster-comparison-py"><span class="std std-ref">مقارنة خوارزميات التجميع المختلفة على مجموعات البيانات التجريبية</span></a></p>
  <div class="sphx-glr-thumbnail-title">مقارنة خوارزميات التجميع المختلفة على مجموعات البيانات التجريبية</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يوضح هذا المثال خصائص طرق الربط المختلفة للتجميع الهرمي على مجموعات البيانات التي &quot;مثيرة للاهتمام&quot; ولكنها لا تزال ثنائية الأبعاد."><img alt="" src="../_images/sphx_glr_plot_linkage_comparison_thumb.png" />
<p><a class="reference internal" href="cluster/plot_linkage_comparison.html#sphx-glr-auto-examples-cluster-plot-linkage-comparison-py"><span class="std std-ref">مقارنة طرق الربط الهرمي المختلفة على مجموعات بيانات تجريبية</span></a></p>
  <div class="sphx-glr-thumbnail-title">مقارنة طرق الربط الهرمي المختلفة على مجموعات بيانات تجريبية</div>
</div></div></section>
<section id="id5">
<h2>التجميع الثنائي<a class="headerlink" href="#id5" title="Link to this heading">#</a></h2>
<p>أمثلة تتعلق بتقنيات التجميع الثنائي.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="هذا المثال يوضح خوارزمية التجميع الطيفي المشترك على مجموعة بيانات مجموعات الأخبار العشرين. تم استبعاد الفئة &#x27;comp.os.ms-windows.misc&#x27; لأنها تحتوي على العديد من المنشورات التي لا تحتوي إلا على بيانات."><img alt="" src="../_images/sphx_glr_plot_bicluster_newsgroups_thumb.png" />
<p><a class="reference internal" href="bicluster/plot_bicluster_newsgroups.html#sphx-glr-auto-examples-bicluster-plot-bicluster-newsgroups-py"><span class="std std-ref">التجميع الثنائي للمستندات باستخدام خوارزمية التجميع الطيفي المشترك</span></a></p>
  <div class="sphx-glr-thumbnail-title">التجميع الثنائي للمستندات باستخدام خوارزمية التجميع الطيفي المشترك</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="هذا المثال يوضح كيفية إنشاء مجموعة بيانات لوحة الشطرنج وتجميعها باستخدام خوارزمية SpectralBiclustering. تم تصميم خوارزمية التجميع الطيفي الثنائي خصيصًا لتجميع البيانات عن طريق النظر في كل من الصفوف (العينات) والأعمدة (الميزات) للمصفوفة في نفس الوقت. تهدف إلى تحديد الأنماط ليس فقط بين العينات ولكن أيضًا داخل المجموعات الفرعية من العينات، مما يسمح بالكشف عن البنية الموضعية داخل البيانات. وهذا يجعل التجميع الطيفي الثنائي مناسبًا بشكل خاص لمجموعات البيانات حيث يكون ترتيب الميزات أو ترتيبها ثابتًا، كما هو الحال في الصور أو السلاسل الزمنية أو الجينومات."><img alt="" src="../_images/sphx_glr_plot_spectral_biclustering_thumb.png" />
<p><a class="reference internal" href="bicluster/plot_spectral_biclustering.html#sphx-glr-auto-examples-bicluster-plot-spectral-biclustering-py"><span class="std std-ref">عرض توضيحي لخوارزمية التجميع الطيفي الثنائي</span></a></p>
  <div class="sphx-glr-thumbnail-title">عرض توضيحي لخوارزمية التجميع الطيفي الثنائي</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="هذا المثال يوضح كيفية إنشاء مجموعة بيانات وتجميعها باستخدام خوارزمية التجميع الطيفي المشترك."><img alt="" src="../_images/sphx_glr_plot_spectral_coclustering_thumb.png" />
<p><a class="reference internal" href="bicluster/plot_spectral_coclustering.html#sphx-glr-auto-examples-bicluster-plot-spectral-coclustering-py"><span class="std std-ref">عرض توضيحي لخوارزمية التجميع الطيفي المشترك</span></a></p>
  <div class="sphx-glr-thumbnail-title">عرض توضيحي لخوارزمية التجميع الطيفي المشترك</div>
</div></div></section>
<section id="id6">
<h2>التحلل المتقاطع<a class="headerlink" href="#id6" title="Link to this heading">#</a></h2>
<p>أمثلة تتعلق بوحدة <a class="reference internal" href="../api/sklearn.cross_decomposition.html#module-sklearn.cross_decomposition" title="sklearn.cross_decomposition"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.cross_decomposition</span></code></a> .</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="يقارن هذا المثال بين Principal Component Regression (PCR) و Partial Least Squares Regression (PLS) على مجموعة بيانات تجريبية. هدفنا هو توضيح كيف يمكن لـ PLS أن يتفوق على PCR عندما يكون الهدف مرتبطًا بقوة ببعض الاتجاهات في البيانات التي لها تباين منخفض."><img alt="" src="../_images/sphx_glr_plot_pcr_vs_pls_thumb.png" />
<p><a class="reference internal" href="cross_decomposition/plot_pcr_vs_pls.html#sphx-glr-auto-examples-cross-decomposition-plot-pcr-vs-pls-py"><span class="std std-ref">الانحدار باستخدام المكونات الرئيسية مقابل الانحدار باستخدام المربعات الجزئية</span></a></p>
  <div class="sphx-glr-thumbnail-title">الانحدار باستخدام المكونات الرئيسية مقابل الانحدار باستخدام المربعات الجزئية</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="الاستخدام البسيط لخوارزميات التحليل التفاضلي المختلفة:"><img alt="" src="../_images/sphx_glr_plot_compare_cross_decomposition_thumb.png" />
<p><a class="reference internal" href="cross_decomposition/plot_compare_cross_decomposition.html#sphx-glr-auto-examples-cross-decomposition-plot-compare-cross-decomposition-py"><span class="std std-ref">مقارنة طرق التحليل التفاضلي</span></a></p>
  <div class="sphx-glr-thumbnail-title">مقارنة طرق التحليل التفاضلي</div>
</div></div></section>
<section id="id7">
<h2>التصنيف<a class="headerlink" href="#id7" title="Link to this heading">#</a></h2>
<p>أمثلة عامة حول خوارزميات التصنيف</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="هذا المثال يوضح كيف أن مقدرات Ledoit-Wolf وOracle Approximating Shrinkage (OAS) لمصفوفة التباين يمكن أن تحسن التصنيف."><img alt="" src="../_images/sphx_glr_plot_lda_thumb.png" />
<p><a class="reference internal" href="classification/plot_lda.html#sphx-glr-auto-examples-classification-plot-lda-py"><span class="std std-ref">Normal, Ledoit-Wolf and OAS Linear Discriminant Analysis for classification</span></a></p>
  <div class="sphx-glr-thumbnail-title">Normal, Ledoit-Wolf and OAS Linear Discriminant Analysis for classification</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="هذا المثال يوضح كيفية استخدام scikit-learn للتعرف على صور الأرقام المكتوبة بخط اليد، من 0 إلى 9."><img alt="" src="../_images/sphx_glr_plot_digits_classification_thumb.png" />
<p><a class="reference internal" href="classification/plot_digits_classification.html#sphx-glr-auto-examples-classification-plot-digits-classification-py"><span class="std std-ref">التعرف على الأرقام المكتوبة بخط اليد</span></a></p>
  <div class="sphx-glr-thumbnail-title">التعرف على الأرقام المكتوبة بخط اليد</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="ارسم احتمالية التصنيف لمصنفات مختلفة. نستخدم مجموعة بيانات من 3 فئات، ونصنفها باستخدام مصنف الدعم الموجه، والانحدار اللوجستي المعاقب L1 وL2 (متعدد الحدود متعدد الفئات)، وإصدار One-Vs-Rest مع الانحدار اللوجستي، وتصنيف عملية جاوس."><img alt="" src="../_images/sphx_glr_plot_classification_probability_thumb.png" />
<p><a class="reference internal" href="classification/plot_classification_probability.html#sphx-glr-auto-examples-classification-plot-classification-probability-py"><span class="std std-ref">رسم احتمالية التصنيف</span></a></p>
  <div class="sphx-glr-thumbnail-title">رسم احتمالية التصنيف</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="مقارنة بين عدة مصنفات في scikit-learn على مجموعات بيانات اصطناعية. الغرض من هذا المثال هو توضيح طبيعة حدود القرار لمصنفات مختلفة. يجب أخذ هذا بعين الاعتبار، حيث أن الحدس الذي توفره هذه الأمثلة لا ينتقل بالضرورة إلى مجموعات البيانات الحقيقية."><img alt="" src="../_images/sphx_glr_plot_classifier_comparison_thumb.png" />
<p><a class="reference internal" href="classification/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py"><span class="std std-ref">مقارنة المصنفات</span></a></p>
  <div class="sphx-glr-thumbnail-title">مقارنة المصنفات</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="هذا مثال لرسم حدود التمييز والقطع الناقص لتشتت كل فئة، والتي تم تعلمها بواسطة LinearDiscriminantAnalysis (LDA) و QuadraticDiscriminantAnalysis (QDA). يُظهر القطع الناقص الانحراف المعياري المزدوج لكل فئة. مع LDA، يكون الانحراف المعياري هو نفسه لجميع الفئات، في حين أن لكل فئة انحرافها المعياري الخاص بها مع QDA."><img alt="" src="../_images/sphx_glr_plot_lda_qda_thumb.png" />
<p><span class="xref std std-ref">sphx_glr_auto_examples_classification_plot_lda_qda.py</span></p>
  <div class="sphx-glr-thumbnail-title">هذا مثال لرسم حدود التمييز والقطع الناقص لتشتت كل فئة، والتي تم تعلمها بواسطة LinearDiscriminantAnalysis (LDA) و QuadraticDiscriminantAnalysis (QDA). يُظهر القطع الناقص الانحراف المعياري المزدوج لكل فئة. مع LDA، يكون الانحراف المعياري هو نفسه لجميع الفئات، في حين أن لكل فئة انحرافها المعياري الخاص بها مع QDA.</div>
</div></div></section>
<section id="id8">
<h2>الفحص<a class="headerlink" href="#id8" title="Link to this heading">#</a></h2>
<p>أمثلة تتعلق بوحدة <a class="reference internal" href="../api/sklearn.inspection.html#module-sklearn.inspection" title="sklearn.inspection"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.inspection</span></code></a> .</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="في هذا المثال، نحسب permutation_importance للميزات لـ RandomForestClassifier مدربة باستخدام breast_cancer_dataset. يمكن للنموذج بسهولة الحصول على دقة تبلغ حوالي 97% على مجموعة بيانات الاختبار. نظرًا لأن مجموعة البيانات هذه تحتوي على ميزات متعددة الخطية، فإن أهمية التبديل تُظهر أنه لا توجد أي من الميزات مهمة، في تناقض مع دقة الاختبار العالية."><img alt="" src="../_images/sphx_glr_plot_permutation_importance_multicollinear_thumb.png" />
<p><a class="reference internal" href="inspection/plot_permutation_importance_multicollinear.html#sphx-glr-auto-examples-inspection-plot-permutation-importance-multicollinear-py"><span class="std std-ref">أهمية التبديل مع الميزات متعددة الخطية أو المرتبطة</span></a></p>
  <div class="sphx-glr-thumbnail-title">أهمية التبديل مع الميزات متعددة الخطية أو المرتبطة</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="في هذا المثال، سنقارن أهمية الميزة القائمة على الشوائب لـ RandomForestClassifier مع أهمية التبديل على مجموعة بيانات تيتانيك باستخدام permutation_importance. سنوضح أن أهمية الميزة القائمة على الشوائب يمكن أن تبالغ في أهمية الميزات الرقمية."><img alt="" src="../_images/sphx_glr_plot_permutation_importance_thumb.png" />
<p><a class="reference internal" href="inspection/plot_permutation_importance.html#sphx-glr-auto-examples-inspection-plot-permutation-importance-py"><span class="std std-ref">أهمية التبديل مقابل أهمية ميزة الغابة العشوائية (MDI)</span></a></p>
  <div class="sphx-glr-thumbnail-title">أهمية التبديل مقابل أهمية ميزة الغابة العشوائية (MDI)</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="في النماذج الخطية، يتم نمذجة القيمة المستهدفة كمجموعة خطية من الميزات (انظر قسم linear_model في دليل المستخدم لوصف مجموعة من النماذج الخطية المتاحة في scikit-learn). تمثل المعاملات في النماذج الخطية المتعددة العلاقة بين الميزة المعينة، X_i والهدف، y، بافتراض أن جميع الميزات الأخرى تظل ثابتة ( التبعية الشرطية). هذا يختلف عن رسم X_i مقابل y وملاءمة علاقة خطية: في هذه الحالة، تؤخذ جميع القيم الممكنة للميزات الأخرى في الاعتبار في التقدير (التبعية الهامشية)."><img alt="" src="../_images/sphx_glr_plot_linear_model_coefficient_interpretation_thumb.png" />
<p><a class="reference internal" href="inspection/plot_linear_model_coefficient_interpretation.html#sphx-glr-auto-examples-inspection-plot-linear-model-coefficient-interpretation-py"><span class="std std-ref">المزالق الشائعة في تفسير معاملات النماذج الخطية</span></a></p>
  <div class="sphx-glr-thumbnail-title">المزالق الشائعة في تفسير معاملات النماذج الخطية</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="تُعد نماذج التعلم الآلي رائعة لقياس الارتباطات الإحصائية. لسوء الحظ، ما لم نكن على استعداد لوضع افتراضات قوية حول البيانات، فإن هذه النماذج غير قادرة على استنتاج الآثار السببية."><img alt="" src="../_images/sphx_glr_plot_causal_interpretation_thumb.png" />
<p><a class="reference internal" href="inspection/plot_causal_interpretation.html#sphx-glr-auto-examples-inspection-plot-causal-interpretation-py"><span class="std std-ref">فشل التعلم الآلي في استنتاج الآثار السببية</span></a></p>
  <div class="sphx-glr-thumbnail-title">فشل التعلم الآلي في استنتاج الآثار السببية</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="توضح مخططات التبعية الجزئية العلاقة بين دالة الهدف [2]_ ومجموعة من الميزات محل الاهتمام، مع تهميش قيم جميع الميزات الأخرى (الميزات المتممة). نظرًا لحدود الإدراك البشري، يجب أن يكون حجم مجموعة الميزات محل الاهتمام صغيرًا (عادةً، واحد أو اثنين) وبالتالي يتم اختيارها عادةً من بين أهم الميزات."><img alt="" src="../_images/sphx_glr_plot_partial_dependence_thumb.png" />
<p><a class="reference internal" href="inspection/plot_partial_dependence.html#sphx-glr-auto-examples-inspection-plot-partial-dependence-py"><span class="std std-ref">مخططات التبعية الجزئية والتوقع الشرطي الفردي</span></a></p>
  <div class="sphx-glr-thumbnail-title">مخططات التبعية الجزئية والتوقع الشرطي الفردي</div>
</div></div></section>
<section id="id9">
<h2>النماذج الخطية المعممة<a class="headerlink" href="#id9" title="Link to this heading">#</a></h2>
<p>أمثلة تتعلق بوحدة <a class="reference internal" href="../api/sklearn.linear_model.html#module-sklearn.linear_model" title="sklearn.linear_model"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.linear_model</span></code></a>.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="# يحسب الانحدار الخليط الخليط للمنحنيات التوافقية."><img alt="" src="../_images/sphx_glr_plot_bayesian_ridge_curvefit_thumb.png" />
<p><span class="xref std std-ref">sphx_glr_auto_examples_linear_model_plot_bayesian_ridge_curvefit.py</span></p>
  <div class="sphx-glr-thumbnail-title"># ========================================================</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يقارن هذا المثال بين طريقتين مختلفتين للانحدار البايزي:"><img alt="" src="../_images/sphx_glr_plot_ard_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_ard.html#sphx-glr-auto-examples-linear-model-plot-ard-py"><span class="std std-ref"># مقارنة المنحنيات الخطية للانحدار البايزي</span></a></p>
  <div class="sphx-glr-thumbnail-title"># مقارنة المنحنيات الخطية للانحدار البايزي</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="نبين أن linear_model.Lasso يوفر نفس النتائج للبيانات الكثيفة والمتفرقة وأن السرعة تتحسن في حالة البيانات المتفرقة."><img alt="" src="../_images/sphx_glr_plot_lasso_dense_vs_sparse_data_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_lasso_dense_vs_sparse_data.html#sphx-glr-auto-examples-linear-model-plot-lasso-dense-vs-sparse-data-py"><span class="std std-ref">Lasso على البيانات الكثيفة والمتفرقة</span></a></p>
  <div class="sphx-glr-thumbnail-title">Lasso على البيانات الكثيفة والمتفرقة</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يوضح هذا المثال كيفية تقريب حل sklearn.svm.OneClassSVM في حالة استخدام نواة RBF مع sklearn.linear_model.SGDOneClassSVM، وهي نسخة Stochastic Gradient Descent (SGD) من One-Class SVM. يتم استخدام تقريب النواة أولاً من أجل تطبيق sklearn.linear_model.SGDOneClassSVM الذي ينفذ One-Class SVM خطي باستخدام SGD."><img alt="" src="../_images/sphx_glr_plot_sgdocsvm_vs_ocsvm_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_sgdocsvm_vs_ocsvm.html#sphx-glr-auto-examples-linear-model-plot-sgdocsvm-vs-ocsvm-py"><span class="std std-ref">One-Class SVM مقابل One-Class SVM باستخدام Stochastic Gradient Descent</span></a></p>
  <div class="sphx-glr-thumbnail-title">One-Class SVM مقابل One-Class SVM باستخدام Stochastic Gradient Descent</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="مخططات توضح حيث تكون العقوبة تساوي 1 للعقوبات الثلاثة L1 وL2 وelastic-net."><img alt="" src="../_images/sphx_glr_plot_sgd_penalties_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_sgd_penalties.html#sphx-glr-auto-examples-linear-model-plot-sgd-penalties-py"><span class="std std-ref">SGD: العقوبات</span></a></p>
  <div class="sphx-glr-thumbnail-title">SGD: العقوبات</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="رسم دالة القرار لمجموعة بيانات مرجحة، حيث يتناسب حجم النقاط مع وزنها."><img alt="" src="../_images/sphx_glr_plot_sgd_weighted_samples_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_sgd_weighted_samples.html#sphx-glr-auto-examples-linear-model-plot-sgd-weighted-samples-py"><span class="std std-ref">SGD: العينات المرجحة</span></a></p>
  <div class="sphx-glr-thumbnail-title">SGD: العينات المرجحة</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="ارسم المستوى الفاصل ذو الهامش الأقصى ضمن مجموعة بيانات ثنائية الفصل باستخدام مصنف آلات المتجهات الداعمة الخطي الذي تم تدريبه باستخدام SGD."><img alt="" src="../_images/sphx_glr_plot_sgd_separating_hyperplane_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_sgd_separating_hyperplane.html#sphx-glr-auto-examples-linear-model-plot-sgd-separating-hyperplane-py"><span class="std std-ref">SGD: المستوى الفاصل ذو الهامش الأقصى</span></a></p>
  <div class="sphx-glr-thumbnail-title">SGD: المستوى الفاصل ذو الهامش الأقصى</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="رسم بياني يقارن بين دالات الخسارة المقعرة المختلفة المدعومة من قبل SGDClassifier ."><img alt="" src="../_images/sphx_glr_plot_sgd_loss_functions_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_sgd_loss_functions.html#sphx-glr-auto-examples-linear-model-plot-sgd-loss-functions-py"><span class="std std-ref">SGD: دالات الخسارة المقعرة</span></a></p>
  <div class="sphx-glr-thumbnail-title">SGD: دالات الخسارة المقعرة</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="نزول التدرج العشوائي هي تقنية تحسين تقلل من دالة الخسارة بطريقة عشوائية، حيث تقوم بخطوة نزول التدرج للعينة تلو الأخرى. وهي طريقة فعالة للغاية لملاءمة النماذج الخطية."><img alt="" src="../_images/sphx_glr_plot_sgd_early_stopping_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_sgd_early_stopping.html#sphx-glr-auto-examples-linear-model-plot-sgd-early-stopping-py"><span class="std std-ref">إيقاف مبكر لنزول التدرج العشوائي</span></a></p>
  <div class="sphx-glr-thumbnail-title">إيقاف مبكر لنزول التدرج العشوائي</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="هذا المثال يعيد إنتاج مثال الشكل 2 من [ZHT2007]_. يقوم مقدر LassoLarsIC بالتناسب مع مجموعة بيانات مرض السكري ويتم استخدام معياري معلومات أكايكي (AIC) ومعلومات بايز (BIC) لاختيار أفضل نموذج."><img alt="" src="../_images/sphx_glr_plot_lasso_lars_ic_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_lasso_lars_ic.html#sphx-glr-auto-examples-linear-model-plot-lasso-lars-ic-py"><span class="std std-ref">اختيار نموذج لاصو عبر معايير المعلومات</span></a></p>
  <div class="sphx-glr-thumbnail-title">اختيار نموذج لاصو عبر معايير المعلومات</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يسمح Lasso متعدد المهام بتناسب مشاكل الانحدار المتعددة فرض اختيار الميزات نفسها عبر المهام. يحاكي هذا المثال القياسات التسلسلية، حيث تمثل كل مهمة لحظة زمنية، وتختلف الميزات ذات الصلة في السعة بمرور الوقت مع بقائها نفسها. يفرض Lasso متعدد المهام أن الميزات التي يتم اختيارها في لحظة زمنية واحدة يتم اختيارها لجميع اللحظات الزمنية. وهذا يجعل اختيار الميزات بواسطة Lasso أكثر استقرارًا."><img alt="" src="../_images/sphx_glr_plot_multi_task_lasso_support_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_multi_task_lasso_support.html#sphx-glr-auto-examples-linear-model-plot-multi-task-lasso-support-py"><span class="std std-ref">الاختيار المشترك للميزات باستخدام Lasso متعدد المهام</span></a></p>
  <div class="sphx-glr-thumbnail-title">الاختيار المشترك للميزات باستخدام Lasso متعدد المهام</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="بسبب قلة النقاط في كل بُعد والخط المستقيم الذي يستخدمه الانحدار الخطي لمتابعة هذه النقاط بأفضل ما يمكن، فإن الضوضاء على الملاحظات ستسبب تباينًا كبيرًا كما هو موضح في الرسم البياني الأول. يمكن أن يختلف ميل كل خط بشكل كبير لكل توقع بسبب الضوضاء في الملاحظات."><img alt="" src="../_images/sphx_glr_plot_ols_ridge_variance_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_ols_ridge_variance.html#sphx-glr-auto-examples-linear-model-plot-ols-ridge-variance-py"><span class="std std-ref">الانحدار الخطي العادي وانحدار ريدج والتباين</span></a></p>
  <div class="sphx-glr-thumbnail-title">الانحدار الخطي العادي وانحدار ريدج والتباين</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="مقارنة الانحدار اللوجستي متعدد الحدود L1 مقابل الانحدار اللوجستي واحد مقابل البقية L1 لتصنيف المستندات من مجموعة بيانات newgroups20. ينتج الانحدار اللوجستي متعدد الحدود نتائج أكثر دقة وهو أسرع في التدريب على مجموعة البيانات الأكبر حجمًا."><img alt="" src="../_images/sphx_glr_plot_sparse_logistic_regression_20newsgroups_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_sparse_logistic_regression_20newsgroups.html#sphx-glr-auto-examples-linear-model-plot-sparse-logistic-regression-20newsgroups-py"><span class="std std-ref">الانحدار اللوجستي المتناثر متعدد الفئات على 20newgroups</span></a></p>
  <div class="sphx-glr-thumbnail-title">الانحدار اللوجستي المتناثر متعدد الفئات على 20newgroups</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يوضح هذا المثال كيفية تقريب دالة باستخدام متعددات الحدود حتى الدرجة degree باستخدام الانحدار المحدب. نعرض طريقتين مختلفتين نظرًا لـ n_samples من النقاط 1d x_i:"><img alt="" src="../_images/sphx_glr_plot_polynomial_interpolation_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_polynomial_interpolation.html#sphx-glr-auto-examples-linear-model-plot-polynomial-interpolation-py"><span class="std std-ref">التكامل متعدد الحدود والتقسيم</span></a></p>
  <div class="sphx-glr-thumbnail-title">التكامل متعدد الحدود والتقسيم</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يوضح الرسم البياني كيف أن الانحدار اللوجستي، في مجموعة البيانات الاصطناعية هذه، سيصنف القيم إما 0 أو 1، أي الفئة الأولى أو الثانية، باستخدام المنحنى اللوغستي."><img alt="" src="../_images/sphx_glr_plot_logistic_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_logistic.html#sphx-glr-auto-examples-linear-model-plot-logistic-py"><span class="std std-ref">الدالة اللوغستية</span></a></p>
  <div class="sphx-glr-thumbnail-title">الدالة اللوغستية</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يوضح هذا المثال استخدام الانحدار اللوغاريتمي الخطي بواسون على مجموعة بيانات مطالبات المسؤولية الطرفية الثالثة للسيارات الفرنسية من [1]_ ويقارنها بنموذج خطي يتم تركيبه باستخدام خطأ المربعات الأقل المعتاد ونموذج GBRT غير خطي يتم تركيبه باستخدام خسارة بواسون (ورابط تسجيل الدخول)."><img alt="" src="../_images/sphx_glr_plot_poisson_regression_non_normal_loss_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_poisson_regression_non_normal_loss.html#sphx-glr-auto-examples-linear-model-plot-poisson-regression-non-normal-loss-py"><span class="std std-ref">انحدار بواسون والخسارة غير الطبيعية</span></a></p>
  <div class="sphx-glr-thumbnail-title">انحدار بواسون والخسارة غير الطبيعية</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يوضح هذا المثال استخدام الانحدار الشعاعي، جاما وتويدي على مجموعة بيانات مطالبات المسؤولية المدنية الفرنسية لطرف ثالث، مستوحى من درس تعليمي R [1]_."><img alt="" src="../_images/sphx_glr_plot_tweedie_regression_insurance_claims_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_tweedie_regression_insurance_claims.html#sphx-glr-auto-examples-linear-model-plot-tweedie-regression-insurance-claims-py"><span class="std std-ref">انحدار تويدي على مطالبات التأمين</span></a></p>
  <div class="sphx-glr-thumbnail-title">انحدار تويدي على مطالبات التأمين</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يحسب انحدار ثيل-سين على مجموعة بيانات اصطناعية."><img alt="" src="../_images/sphx_glr_plot_theilsen_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_theilsen.html#sphx-glr-auto-examples-linear-model-plot-theilsen-py"><span class="std std-ref">انحدار ثيل-سين</span></a></p>
  <div class="sphx-glr-thumbnail-title">انحدار ثيل-سين</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يوضح هذا المثال كيف يمكن لانحدار كمي التنبؤ بالكميات الشرطية غير التافهة."><img alt="" src="../_images/sphx_glr_plot_quantile_regression_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_quantile_regression.html#sphx-glr-auto-examples-linear-model-plot-quantile-regression-py"><span class="std std-ref">انحدار كمي</span></a></p>
  <div class="sphx-glr-thumbnail-title">انحدار كمي</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="هنا نقوم بضبط الانحدار اللوغاريتمي متعدد الحدود مع عقوبة L1 على مجموعة فرعية من مهمة تصنيف أرقام MNIST. نستخدم خوارزمية SAGA لهذا الغرض: هذه أداة حل سريعة عندما يكون عدد العينات أكبر بشكل ملحوظ من عدد الميزات وقادرة على تحسين دقيق وظائف الهدف غير الملساء والتي هي الحالة مع عقوبة l1. تصل دقة الاختبار &gt; 0.8، بينما تبقى متجهات الوزن متفرقة وبالتالي أكثر سهولة قابل للتفسير."><img alt="" src="../_images/sphx_glr_plot_sparse_logistic_regression_mnist_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_sparse_logistic_regression_mnist.html#sphx-glr-auto-examples-linear-model-plot-sparse-logistic-regression-mnist-py"><span class="std std-ref">تصنيف MNIST باستخدام اللوغاريتم متعدد الحدود + L1</span></a></p>
  <div class="sphx-glr-thumbnail-title">تصنيف MNIST باستخدام اللوغاريتم متعدد الحدود + L1</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="في هذا المثال، نرى كيفية ملاءمة نموذج خطي بشكل قوي لبيانات معيبة باستخدام خوارزمية ransac_regression."><img alt="" src="../_images/sphx_glr_plot_ransac_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_ransac.html#sphx-glr-auto-examples-linear-model-plot-ransac-py"><span class="std std-ref">تقدير النموذج الخطي القوي باستخدام RANSAC</span></a></p>
  <div class="sphx-glr-thumbnail-title">تقدير النموذج الخطي القوي باستخدام RANSAC</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="هنا يتم ملاءمة دالة الجيب مع متعددة حدود من الدرجة 3، للقيم قريبة من الصفر."><img alt="" src="../_images/sphx_glr_plot_robust_fit_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_robust_fit.html#sphx-glr-auto-examples-linear-model-plot-robust-fit-py"><span class="std std-ref">تقدير خطي قوي</span></a></p>
  <div class="sphx-glr-thumbnail-title">تقدير خطي قوي</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يوضح المثال التالي كيفية حساب مصفوفة جرام مسبقًا مع استخدام عينات مرجحة مع ElasticNet."><img alt="" src="../_images/sphx_glr_plot_elastic_net_precomputed_gram_matrix_with_weighted_samples_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_elastic_net_precomputed_gram_matrix_with_weighted_samples.html#sphx-glr-auto-examples-linear-model-plot-elastic-net-precomputed-gram-matrix-with-weighted-samples-py"><span class="std std-ref">تناسب شبكة مرنة مع مصفوفة جرام مسبقة الحساب وعينات مرجحة</span></a></p>
  <div class="sphx-glr-thumbnail-title">تناسب شبكة مرنة مع مصفوفة جرام مسبقة الحساب وعينات مرجحة</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يقارن هذا المثال حدود القرار للانحدار متعدد الحدود والانحدار اللوجستي من النوع واحد مقابل البقية على مجموعة بيانات ثنائية الأبعاد بثلاث فئات."><img alt="" src="../_images/sphx_glr_plot_logistic_multinomial_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_logistic_multinomial.html#sphx-glr-auto-examples-linear-model-plot-logistic-multinomial-py"><span class="std std-ref">حدود القرار للانحدار متعدد الحدود والانحدار اللوجستي من النوع واحد مقابل البقية</span></a></p>
  <div class="sphx-glr-thumbnail-title">حدود القرار للانحدار متعدد الحدود والانحدار اللوجستي من النوع واحد مقابل البقية</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="رسم سطح القرار لمتعدد الفئات SGD على مجموعة بيانات الزهرة. تمثل الخطوط المتقطعة المستويات الفاصلة المقابلة للثلاثة مصنفات من نوع واحد مقابل الجميع (OVA)."><img alt="" src="../_images/sphx_glr_plot_sgd_iris_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_sgd_iris.html#sphx-glr-auto-examples-linear-model-plot-sgd-iris-py"><span class="std std-ref">رسم متعدد الفئات SGD على مجموعة بيانات الزهرة</span></a></p>
  <div class="sphx-glr-thumbnail-title">رسم متعدد الفئات SGD على مجموعة بيانات الزهرة</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يظهر هذا المثال تأثير التلازم في معاملات أداة التقدير."><img alt="" src="../_images/sphx_glr_plot_ridge_path_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_ridge_path.html#sphx-glr-auto-examples-linear-model-plot-ridge-path-py"><span class="std std-ref">رسم معاملات Ridge كدالة للتنظيم</span></a></p>
  <div class="sphx-glr-thumbnail-title">رسم معاملات Ridge كدالة للتنظيم</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="مقارنة الندرة (نسبة المعاملات الصفرية) للحلول عند استخدام عقوبة L1 و L2 و Elastic-Net لقيم مختلفة من C. يمكننا أن نرى أن القيم الكبيرة من C تعطي المزيد من الحرية للنموذج. على العكس من ذلك، القيم الأصغر من C تقيد النموذج أكثر. في حالة عقوبة L1، يؤدي ذلك إلى حلول أكثر ندرة. كما هو متوقع، ندرة عقوبة Elastic-Net تقع بين عقوبة L1 و L2."><img alt="" src="../_images/sphx_glr_plot_logistic_l1_l2_sparsity_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_logistic_l1_l2_sparsity.html#sphx-glr-auto-examples-linear-model-plot-logistic-l1-l2-sparsity-py"><span class="std std-ref">عقوبة L1 والندرة في الانحدار اللوجستي</span></a></p>
  <div class="sphx-glr-thumbnail-title">عقوبة L1 والندرة في الانحدار اللوجستي</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يوضح هذا المثال كيفية استخدام نموذج المربعات الصغرى العادية (OLS) المسمى LinearRegression في مكتبة ساي كيت ليرن (scikit-learn)."><img alt="" src="../_images/sphx_glr_plot_ols_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py"><span class="std std-ref">مثال على المربعات الصغرى العادية</span></a></p>
  <div class="sphx-glr-thumbnail-title">مثال على المربعات الصغرى العادية</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="في هذا المثال، نقوم بملاءمة نموذج خطي مع قيود إيجابية على معاملات الانحدار ومقارنة المعاملات المقدرة مع الانحدار الخطي الكلاسيكي."><img alt="" src="../_images/sphx_glr_plot_nnls_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_nnls.html#sphx-glr-auto-examples-linear-model-plot-nnls-py"><span class="std std-ref">مربعات أقل غير سالبة</span></a></p>
  <div class="sphx-glr-thumbnail-title">مربعات أقل غير سالبة</div>
</div><div class="sphx-glr-thumbcontainer" tooltip=" قم بتدريب نماذج الانحدار اللوجستي المنتظمة بـ L1 على مشكلة تصنيف ثنائي مستمدة من مجموعة بيانات Iris."><img alt="" src="../_images/sphx_glr_plot_logistic_path_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_logistic_path.html#sphx-glr-auto-examples-linear-model-plot-logistic-path-py"><span class="std std-ref">مسار التنظيم لـ L1 - الانحدار اللوجستي</span></a></p>
  <div class="sphx-glr-thumbnail-title">مسار التنظيم لـ L1 - الانحدار اللوجستي</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="هذا المثال يوضح كيفية حساب &quot;المسارات&quot; لمعاملات لاصو، لاصو-لارس، ومسارات الشبكة المرنة. وبعبارة أخرى، فإنه يظهر العلاقة بين معامل التنظيم (ألفا) والمعاملات."><img alt="" src="../_images/sphx_glr_plot_lasso_lasso_lars_elasticnet_path_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_lasso_lasso_lars_elasticnet_path.html#sphx-glr-auto-examples-linear-model-plot-lasso-lasso-lars-elasticnet-path-py"><span class="std std-ref">مسارات لاصو ولاصو-لارس وشبكة مرنة</span></a></p>
  <div class="sphx-glr-thumbnail-title">مسارات لاصو ولاصو-لارس وشبكة مرنة</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="استخدام مطابقة متعامدة لاستعادة إشارة متفرقة من قياس مشوش مشفر بقاموس"><img alt="" src="../_images/sphx_glr_plot_omp_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_omp.html#sphx-glr-auto-examples-linear-model-plot-omp-py"><span class="std std-ref">مطابقة متعامدة</span></a></p>
  <div class="sphx-glr-thumbnail-title">مطابقة متعامدة</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="النموذج الذي يبالغ في التعميم يتعلم بيانات التدريب جيدًا جدًا، حيث يلتقط كل من الأنماط الأساسية والضوضاء في البيانات. ومع ذلك، عند تطبيقه على بيانات غير معروفة، قد لا تستمر الارتباطات المكتسبة. عادة ما نكتشف ذلك عندما نطبق تنبؤاتنا المدربة على بيانات الاختبار ونرى الأداء الإحصائي ينخفض بشكل كبير مقارنة ببيانات التدريب."><img alt="" src="../_images/sphx_glr_plot_ridge_coeffs_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_ridge_coeffs.html#sphx-glr-auto-examples-linear-model-plot-ridge-coeffs-py"><span class="std std-ref">معاملات Ridge كدالة لتنظيم L2</span></a></p>
  <div class="sphx-glr-thumbnail-title">معاملات Ridge كدالة لتنظيم L2</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="قم بضبط نموذج Ridge و HuberRegressor على مجموعة بيانات تحتوي على قيم شاذة."><img alt="" src="../_images/sphx_glr_plot_huber_vs_ridge_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_huber_vs_ridge.html#sphx-glr-auto-examples-linear-model-plot-huber-vs-ridge-py"><span class="std std-ref">مقارنة بين HuberRegressor و Ridge على مجموعة بيانات تحتوي على قيم شاذة قوية</span></a></p>
  <div class="sphx-glr-thumbnail-title">مقارنة بين HuberRegressor و Ridge على مجموعة بيانات تحتوي على قيم شاذة قوية</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="مقارنة بين المحللات المختلفة عبر الإنترنت"><img alt="" src="../_images/sphx_glr_plot_sgd_comparison_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_sgd_comparison.html#sphx-glr-auto-examples-linear-model-plot-sgd-comparison-py"><span class="std std-ref">مقارنة بين المحللات المختلفة عبر الإنترنت</span></a></p>
  <div class="sphx-glr-thumbnail-title">مقارنة بين المحللات المختلفة عبر الإنترنت</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يقارن المثال الحالي ثلاثة نماذج ارتجاع L1 على إشارة اصطناعية تم الحصول عليها من ميزات متناثرة ومتناسقة يتم إفسادها مع ضوضاء غاوسية إضافية:"><img alt="" src="../_images/sphx_glr_plot_lasso_and_elasticnet_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_lasso_and_elasticnet.html#sphx-glr-auto-examples-linear-model-plot-lasso-and-elasticnet-py"><span class="std std-ref">نماذج L1 للاشارات المتناثرة</span></a></p>
  <div class="sphx-glr-thumbnail-title">نماذج L1 للاشارات المتناثرة</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يركز هذا المثال على اختيار النموذج لنموذج لاصو، وهي نماذج خطية مع عقوبة L1 لمشاكل الانحدار."><img alt="" src="../_images/sphx_glr_plot_lasso_model_selection_thumb.png" />
<p><a class="reference internal" href="linear_model/plot_lasso_model_selection.html#sphx-glr-auto-examples-linear-model-plot-lasso-model-selection-py"><span class="std std-ref">نموذج لاصو: اختيار النموذج باستخدام معايير AIC-BIC والتحقق المتقاطع</span></a></p>
  <div class="sphx-glr-thumbnail-title">نموذج لاصو: اختيار النموذج باستخدام معايير AIC-BIC والتحقق المتقاطع</div>
</div></div></section>
<section id="id10">
<h2>تحليل التركيب<a class="headerlink" href="#id10" title="Link to this heading">#</a></h2>
<p>Decomposition
أمثلة تتعلق بوحدة <a class="reference internal" href="../api/sklearn.decomposition.html#module-sklearn.decomposition" title="sklearn.decomposition"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.decomposition</span></code></a>.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="يستخدم تحليل المكونات الأساسية التزايدي (IPCA) عادة كبديل لتحليل المكونات الأساسية (PCA) عندما تكون مجموعة البيانات المراد تحليلها كبيرة جدًا بحيث لا يمكن تحميلها في الذاكرة. يقوم IPCA ببناء تقريب منخفض الرتبة لبيانات الإدخال باستخدام كمية من الذاكرة لا تعتمد على عدد عينات بيانات الإدخال. لا يزال يعتمد على ميزات بيانات الإدخال، ولكن تغيير حجم الدفعة يسمح بالتحكم في استخدام الذاكرة."><img alt="" src="../_images/sphx_glr_plot_incremental_pca_thumb.png" />
<p><span class="xref std std-ref">sphx_glr_auto_examples_decomposition_plot_incremental_pca.py</span></p>
  <div class="sphx-glr-thumbnail-title"># تحليل المكونات الأساسية التزايدي</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يوضح هذا المثال بصريًا في فضاء الميزات مقارنة بالنتائج باستخدام تقنيتين مختلفتين لتحليل المكونات."><img alt="" src="../_images/sphx_glr_plot_ica_vs_pca_thumb.png" />
<p><a class="reference internal" href="decomposition/plot_ica_vs_pca.html#sphx-glr-auto-examples-decomposition-plot-ica-vs-pca-py"><span class="std std-ref">FastICA على سحب النقاط ثنائية الأبعاد</span></a></p>
  <div class="sphx-glr-thumbnail-title">FastICA على سحب النقاط ثنائية الأبعاد</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يوضح هذا المثال الفرق بين تحليل المكونات الرئيسية (~sklearn.decomposition.PCA) ونسخته المطبقة مع النواة (~sklearn.decomposition.KernelPCA)."><img alt="" src="../_images/sphx_glr_plot_kernel_pca_thumb.png" />
<p><a class="reference internal" href="decomposition/plot_kernel_pca.html#sphx-glr-auto-examples-decomposition-plot-kernel-pca-py"><span class="std std-ref">Kernel PCA</span></a></p>
  <div class="sphx-glr-thumbnail-title">Kernel PCA</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="مثال يقارن تأثير إعادة بناء أجزاء مشوشة من صورة وجه راكون باستخدام أولاً DictionaryLearning عبر الإنترنت وطرق تحويل مختلفة."><img alt="" src="../_images/sphx_glr_plot_image_denoising_thumb.png" />
<p><a class="reference internal" href="decomposition/plot_image_denoising.html#sphx-glr-auto-examples-decomposition-plot-image-denoising-py"><span class="std std-ref">إزالة تشويش الصور باستخدام تعلم القاموس</span></a></p>
  <div class="sphx-glr-thumbnail-title">إزالة تشويش الصور باستخدام تعلم القاموس</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="التحليل الرئيسي للمكونات الاحتمالي وتحليل العوامل هما نموذجان احتماليان. والنتيجة هي أنه يمكن استخدام احتمالية البيانات الجديدة لاختيار النموذج وتقدير التباين. هنا نقارن بين التحليل الرئيسي للمكونات وتحليل العوامل باستخدام التحقق المتقاطع على البيانات منخفضة الرتبة التي تتعرض للتشويش بضوضاء متماثلة (تكون تباين الضوضاء نفس الشيء لكل ميزة) أو الضوضاء غير المتماثلة (تكون تباين الضوضاء مختلفًا لكل ميزة). في الخطوة الثانية، نقارن بين نموذج الاحتمالية مع الاحتمالات التي تم الحصول عليها من مقدرات التباين الانكماشي."><img alt="" src="../_images/sphx_glr_plot_pca_vs_fa_model_selection_thumb.png" />
<p><a class="reference internal" href="decomposition/plot_pca_vs_fa_model_selection.html#sphx-glr-auto-examples-decomposition-plot-pca-vs-fa-model-selection-py"><span class="std std-ref">اختيار النموذج باستخدام التحليل الرئيسي للمكونات الاحتمالي وتحليل العوامل (FA)</span></a></p>
  <div class="sphx-glr-thumbnail-title">اختيار النموذج باستخدام التحليل الرئيسي للمكونات الاحتمالي وتحليل العوامل (FA)</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="تحويل إشارة كمزيج متناثر من مويجات Ricker. يقارن هذا المثال بصريًا طرق الترميز المتناثر المختلفة باستخدام مقدر SparseCoder. إن مويجة Ricker (المعروفة أيضًا باسم القبعة المكسيكية أو المشتقة الثانية لدالة غاوسية) ليست نواة جيدة بشكل خاص لتمثيل الإشارات الثابتة متعددة التعريف مثل هذه الإشارة. لذلك يمكن ملاحظة مدى أهمية إضافة عروض مختلفة من الذرات، وبالتالي يحفز ذلك على تعلم القاموس ليناسب نوع الإشارات الخاصة بك على أفضل وجه."><img alt="" src="../_images/sphx_glr_plot_sparse_coding_thumb.png" />
<p><a class="reference internal" href="decomposition/plot_sparse_coding.html#sphx-glr-auto-examples-decomposition-plot-sparse-coding-py"><span class="std std-ref">الترميز المتناثر مع قاموس محسوب مسبقًا</span></a></p>
  <div class="sphx-glr-thumbnail-title">الترميز المتناثر مع قاموس محسوب مسبقًا</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="عند دراسة مجموعة بيانات Iris، نلاحظ أن طول السبلة وطول البتلة وعرض البتلة مترابطة بشكل كبير. عرض السبلة أقل تكراراً. يمكن لتقنيات تحليل المصفوفات الكشف عن هذه الأنماط الكامنة. لا يؤدي تطبيق الدوران على المكونات الناتجة إلى تحسين القيمة التنبؤية للمساحة الكامنة المستنبطة بشكل جوهري، ولكن يمكن أن يساعد في تصور بنيتها؛ هنا، على سبيل المثال، يجد دوران Varimax، والذي يتم العثور عليه عن طريق تعظيم التباين التربيعي للأوزان، بنية حيث يحمل المكون الثاني فقط بشكل إيجابي على عرض السبلة."><img alt="" src="../_images/sphx_glr_plot_varimax_fa_thumb.png" />
<p><a class="reference internal" href="decomposition/plot_varimax_fa.html#sphx-glr-auto-examples-decomposition-plot-varimax-fa-py"><span class="std std-ref">تحليل العوامل (مع الدوران) لتصور الأنماط</span></a></p>
  <div class="sphx-glr-thumbnail-title">تحليل العوامل (مع الدوران) لتصور الأنماط</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="هذا المثال يوضح تقنية تحليل معروفة باسم تحليل المكونات الرئيسية (PCA) على مجموعة بيانات Iris."><img alt="" src="../_images/sphx_glr_plot_pca_iris_thumb.png" />
<p><a class="reference internal" href="decomposition/plot_pca_iris.html#sphx-glr-auto-examples-decomposition-plot-pca-iris-py"><span class="std std-ref">تحليل المكونات الرئيسية (PCA) على مجموعة بيانات Iris</span></a></p>
  <div class="sphx-glr-thumbnail-title">تحليل المكونات الرئيسية (PCA) على مجموعة بيانات Iris</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يطبق هذا المثال على olivetti_faces_dataset طرقًا مختلفة لتحليل المصفوفة غير الخاضعة للإشراف (تقليل الأبعاد) من الوحدة sklearn.decomposition (انظر فصل الوثائق decompositions)."><img alt="" src="../_images/sphx_glr_plot_faces_decomposition_thumb.png" />
<p><a class="reference internal" href="decomposition/plot_faces_decomposition.html#sphx-glr-auto-examples-decomposition-plot-faces-decomposition-py"><span class="std std-ref">تحليلات مجموعة بيانات الوجوه</span></a></p>
  <div class="sphx-glr-thumbnail-title">تحليلات مجموعة بيانات الوجوه</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="مثال على تقدير المصادر من بيانات مشوشة."><img alt="" src="../_images/sphx_glr_plot_ica_blind_source_separation_thumb.png" />
<p><a class="reference internal" href="decomposition/plot_ica_blind_source_separation.html#sphx-glr-auto-examples-decomposition-plot-ica-blind-source-separation-py"><span class="std std-ref">فصل المصدر الأعمى باستخدام FastICA</span></a></p>
  <div class="sphx-glr-thumbnail-title">فصل المصدر الأعمى باستخدام FastICA</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="تمثل مجموعة بيانات آيريس 3 أنواع من زهور آيريس (سيتوسا، وفيرسيكولور، وفيرجينيكا) مع 4 خصائص: طول الكأس، وعرض الكأس، وطول البتلة، وعرض البتلة."><img alt="" src="../_images/sphx_glr_plot_pca_vs_lda_thumb.png" />
<p><a class="reference internal" href="decomposition/plot_pca_vs_lda.html#sphx-glr-auto-examples-decomposition-plot-pca-vs-lda-py"><span class="std std-ref">مقارنة بين الإسقاط ثنائي الأبعاد للمجموعة البيانات آيريس باستخدام LDA وPCA</span></a></p>
  <div class="sphx-glr-thumbnail-title">مقارنة بين الإسقاط ثنائي الأبعاد للمجموعة البيانات آيريس باستخدام LDA وPCA</div>
</div></div></section>
<section id="id11">
<h2>تطوير المقدرين<a class="headerlink" href="#id11" title="Link to this heading">#</a></h2>
<p>Developing Estimators</p>
<p>أمثلة تتعلق بتطوير مُقدَر مخصص.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="طريقة __sklearn_is_fitted__ هي اتفاقية مستخدمة في scikit-learn للتحقق مما إذا كان كائن المُقدر (estimator) قد تم تكييفه (fitted) أم لا. هذه الطريقة يتم تنفيذها عادةً في فئات المُقدرات المخصصة التي يتم بناؤها على فئات القاعدة في scikit-learn مثل BaseEstimator أو فئاتها الفرعية."><img alt="" src="../_images/sphx_glr_sklearn_is_fitted_thumb.png" />
<p><a class="reference internal" href="developing_estimators/sklearn_is_fitted.html#sphx-glr-auto-examples-developing-estimators-sklearn-is-fitted-py"><span class="std std-ref">__sklearn_is_fitted__ كـ API للمطورين</span></a></p>
  <div class="sphx-glr-thumbnail-title">__sklearn_is_fitted__ كـ API للمطورين</div>
</div></div></section>
<section id="id12">
<h2>تعويض القيم المفقودة<a class="headerlink" href="#id12" title="Link to this heading">#</a></h2>
<p>أمثلة تتعلق بوحدة <a class="reference internal" href="../api/sklearn.impute.html#module-sklearn.impute" title="sklearn.impute"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.impute</span></code></a> .</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="يمكن استبدال القيم المفقودة بالمتوسط أو الوسيط أو القيمة الأكثر تكرارًا باستخدام SimpleImputer الأساسي."><img alt="" src="../_images/sphx_glr_plot_missing_values_thumb.png" />
<p><a class="reference internal" href="impute/plot_missing_values.html#sphx-glr-auto-examples-impute-plot-missing-values-py"><span class="std std-ref">استنتاج القيم المفقودة قبل بناء أداة تقدير</span></a></p>
  <div class="sphx-glr-thumbnail-title">استنتاج القيم المفقودة قبل بناء أداة تقدير</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="الفئة IterativeImputer مرنة للغاية - يمكن استخدامها مع مجموعة متنوعة من أدوات التقدير للقيام بانحدار دائري، معاملة كل متغير كمخرج بدوره."><img alt="" src="../_images/sphx_glr_plot_iterative_imputer_variants_comparison_thumb.png" />
<p><a class="reference internal" href="impute/plot_iterative_imputer_variants_comparison.html#sphx-glr-auto-examples-impute-plot-iterative-imputer-variants-comparison-py"><span class="std std-ref">استنتاج القيم المفقودة مع متغيرات من IterativeImputer</span></a></p>
  <div class="sphx-glr-thumbnail-title">استنتاج القيم المفقودة مع متغيرات من IterativeImputer</div>
</div></div></section>
<section id="id13">
<h2>تقدير التغاير<a class="headerlink" href="#id13" title="Link to this heading">#</a></h2>
<p>Covariance estimation</p>
<p>أمثلة تتعلق بوحدة <a class="reference internal" href="../api/sklearn.covariance.html#module-sklearn.covariance" title="sklearn.covariance"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.covariance</span></code></a>.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="في هذا المثال، نقدم نظرة عامة على TransformedTargetRegressor. نستخدم مثالين لتوضيح فائدة تحويل الأهداف قبل تعلم نموذج انحدار خطي. يستخدم المثال الأول بيانات تركيبية بينما يعتمد المثال الثاني على مجموعة بيانات منازل Ames."><img alt="" src="../_images/sphx_glr_plot_covariance_estimation_thumb.png" />
<p><a class="reference internal" href="covariance/plot_covariance_estimation.html#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py"><span class="std std-ref">تأثير تحويل الأهداف في نموذج الانحدار</span></a></p>
  <div class="sphx-glr-thumbnail-title">تأثير تحويل الأهداف في نموذج الانحدار</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يمكن تنظيم تقدير أقصى احتمال للتغاير المعتاد باستخدام الانكماش. اقترح Ledoit و Wolf صيغة مغلقة لحساب معامل الانكماش الأمثل بشكل مقارب (تقليل معيار MSE )، مما ينتج عنه تقدير التغاير Ledoit-Wolf."><img alt="" src="../_images/sphx_glr_plot_lw_vs_oas_thumb.png" />
<p><a class="reference internal" href="covariance/plot_lw_vs_oas.html#sphx-glr-auto-examples-covariance-plot-lw-vs-oas-py"><span class="std std-ref">تقدير Ledoit-Wolf مقابل OAS</span></a></p>
  <div class="sphx-glr-thumbnail-title">تقدير Ledoit-Wolf مقابل OAS</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="تقدير أقصى احتمال للتغاير المعتاد حساس جدًا لوجود القيم المتطرفة في مجموعة البيانات. في مثل هذه الحالة، سيكون من الأفضل استخدام مقدر قوي للتغاير لضمان أن يكون التقدير مقاوماً للملاحظات &quot;الخاطئة&quot; في مجموعة البيانات. [1]_, [2]_"><img alt="" src="../_images/sphx_glr_plot_robust_vs_empirical_covariance_thumb.png" />
<p><a class="reference internal" href="covariance/plot_robust_vs_empirical_covariance.html#sphx-glr-auto-examples-covariance-plot-robust-vs-empirical-covariance-py"><span class="std std-ref">تقدير التغاير القوي مقابل التجريبي</span></a></p>
  <div class="sphx-glr-thumbnail-title">تقدير التغاير القوي مقابل التجريبي</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يوضح هذا المثال تقدير التغاير باستخدام مسافات Mahalanobis على بيانات موزعة غاوسيًا."><img alt="" src="../_images/sphx_glr_plot_mahalanobis_distances_thumb.png" />
<p><a class="reference internal" href="covariance/plot_mahalanobis_distances.html#sphx-glr-auto-examples-covariance-plot-mahalanobis-distances-py"><span class="std std-ref">تقدير التغاير القوي وأهمية مسافات Mahalanobis</span></a></p>
  <div class="sphx-glr-thumbnail-title">تقدير التغاير القوي وأهمية مسافات Mahalanobis</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="استخدام أداة تقدير GraphicalLasso لتعلم التغاير والانحراف النادر من عدد صغير من العينات."><img alt="" src="../_images/sphx_glr_plot_sparse_cov_thumb.png" />
<p><a class="reference internal" href="covariance/plot_sparse_cov.html#sphx-glr-auto-examples-covariance-plot-sparse-cov-py"><span class="std std-ref">تقدير معكوس التغاير النادر</span></a></p>
  <div class="sphx-glr-thumbnail-title">تقدير معكوس التغاير النادر</div>
</div></div></section>
<section id="id14">
<h2>تقريب النواة<a class="headerlink" href="#id14" title="Link to this heading">#</a></h2>
<p>أمثلة تتعلق بوحدة <a class="reference internal" href="../api/sklearn.kernel_approximation.html#module-sklearn.kernel_approximation" title="sklearn.kernel_approximation"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.kernel_approximation</span></code></a> .</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="يوضح هذا المثال استخدام PolynomialCountSketch لتوليد تقريبات مساحة ميزات نواة متعددة الحدود بكفاءة. يتم استخدام هذا لتدريب المصنفات الخطية التي تقارب دقة التصنيفات المُكَرَّسَة."><img alt="" src="../_images/sphx_glr_plot_scalable_poly_kernels_thumb.png" />
<p><a class="reference internal" href="kernel_approximation/plot_scalable_poly_kernels.html#sphx-glr-auto-examples-kernel-approximation-plot-scalable-poly-kernels-py"><span class="std std-ref">التعلم القابل للتطوير مع تقريب نواة متعددة الحدود</span></a></p>
  <div class="sphx-glr-thumbnail-title">التعلم القابل للتطوير مع تقريب نواة متعددة الحدود</div>
</div></div></section>
<section id="id15">
<h2>تمارين تعليمية<a class="headerlink" href="#id15" title="Link to this heading">#</a></h2>
<p>تمارين للدروس التعليمية</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="تمرين تعليمي يستخدم التحقق المتقاطع مع النماذج الخطية."><img alt="" src="../_images/sphx_glr_plot_cv_diabetes_thumb.png" />
<p><a class="reference internal" href="exercises/plot_cv_diabetes.html#sphx-glr-auto-examples-exercises-plot-cv-diabetes-py"><span class="std std-ref">التحقق المتقاطع على تمرين مجموعة بيانات مرض السكري</span></a></p>
  <div class="sphx-glr-thumbnail-title">التحقق المتقاطع على تمرين مجموعة بيانات مرض السكري</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="تمرين تعليمي لاستخدام نوى SVM المختلفة."><img alt="" src="../_images/sphx_glr_plot_iris_exercise_thumb.png" />
<p><a class="reference internal" href="exercises/plot_iris_exercise.html#sphx-glr-auto-examples-exercises-plot-iris-exercise-py"><span class="std std-ref">تمرين SVM</span></a></p>
  <div class="sphx-glr-thumbnail-title">تمرين SVM</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="تمرين تعليمي يتعلق باستخدام تقنيات التصنيف على مجموعة بيانات الأرقام."><img alt="" src="../_images/sphx_glr_plot_digits_classification_exercise_thumb.png" />
<p><a class="reference internal" href="exercises/plot_digits_classification_exercise.html#sphx-glr-auto-examples-exercises-plot-digits-classification-exercise-py"><span class="std std-ref">تمرين تصنيف الأرقام</span></a></p>
  <div class="sphx-glr-thumbnail-title">تمرين تصنيف الأرقام</div>
</div></div></section>
<section id="id16">
<h2>خطوط الأنابيب والمقدرين المركبين<a class="headerlink" href="#id16" title="Link to this heading">#</a></h2>
<p>Pipelines and composite estimators</p>
<p>أمثلة حول كيفية تكوين المحولات وخطوط الأنابيب من مقدرين آخرين. راجع <a class="reference internal" href="../modules/compose.html#combining-estimators"><span class="std std-ref">دليل المستخدم</span></a>.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="يبني هذا المثال خط أنابيب يقوم بتقليل الأبعاد متبوعًا بالتنبؤ باستخدام مصنف متجه الدعم. يوضح استخدام GridSearchCV و Pipeline للتحسين على فئات مختلفة من المقدرات في تشغيل CV واحد - تتم مقارنة تقليل الأبعاد غير الخاضع للإشراف PCA و NMF باختيار الميزات أحادي المتغير أثناء البحث الشبكي."><img alt="" src="../_images/sphx_glr_plot_compare_reduction_thumb.png" />
<p><a class="reference internal" href="compose/plot_compare_reduction.html#sphx-glr-auto-examples-compose-plot-compare-reduction-py"><span class="std std-ref">اختيار تقليل الأبعاد باستخدام Pipeline و GridSearchCV</span></a></p>
  <div class="sphx-glr-thumbnail-title">اختيار تقليل الأبعاد باستخدام Pipeline و GridSearchCV</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="في هذا المثال، نقدم نظرة عامة على TransformedTargetRegressor. نستخدم مثالين لتوضيح فائدة تحويل الأهداف قبل تعلم نموذج الانحدار الخطي. يستخدم المثال الأول بيانات اصطناعية بينما يعتمد المثال الثاني على مجموعة بيانات إسكان إيمز."><img alt="" src="../_images/sphx_glr_plot_transformed_target_thumb.png" />
<p><a class="reference internal" href="compose/plot_transformed_target.html#sphx-glr-auto-examples-compose-plot-transformed-target-py"><span class="std std-ref">تأثير تحويل الأهداف في نموذج الانحدار</span></a></p>
  <div class="sphx-glr-thumbnail-title">تأثير تحويل الأهداف في نموذج الانحدار</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="في العديد من الأمثلة الواقعية، هناك العديد من الطرق لاستخراج الميزات من مجموعة بيانات. غالبًا ما يكون من المفيد الجمع بين عدة طرق للحصول على أداء جيد. يوضح هذا المثال كيفية استخدام FeatureUnion لدمج الميزات التي تم الحصول عليها بواسطة PCA والاختيار أحادي المتغير."><img alt="" src="../_images/sphx_glr_plot_feature_union_thumb.png" />
<p><a class="reference internal" href="compose/plot_feature_union.html#sphx-glr-auto-examples-compose-plot-feature-union-py"><span class="std std-ref">دمج طرق استخراج ميزات متعددة</span></a></p>
  <div class="sphx-glr-thumbnail-title">دمج طرق استخراج ميزات متعددة</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يقوم PCA بتقليل الأبعاد بطريقة غير خاضعة للإشراف، بينما يقوم الانحدار اللوجستي بالتنبؤ."><img alt="" src="../_images/sphx_glr_plot_digits_pipe_thumb.png" />
<p><a class="reference internal" href="compose/plot_digits_pipe.html#sphx-glr-auto-examples-compose-plot-digits-pipe-py"><span class="std std-ref">ربط الأنابيب: ربط PCA والانحدار اللوجستي</span></a></p>
  <div class="sphx-glr-thumbnail-title">ربط الأنابيب: ربط PCA والانحدار اللوجستي</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يوضح هذا المثال كيفية تطبيق خطوط أنابيب مختلفة للمعالجة المسبقة واستخراج الميزات على مجموعات فرعية مختلفة من الميزات، باستخدام ColumnTransformer. هذا مفيد بشكل خاص في حالة مجموعات البيانات التي تحتوي على أنواع بيانات غير متجانسة، حيث قد نرغب في قياس الميزات الرقمية وترميز الميزات الفئوية بنظام الترميز الثنائي."><img alt="" src="../_images/sphx_glr_plot_column_transformer_mixed_types_thumb.png" />
<p><a class="reference internal" href="compose/plot_column_transformer_mixed_types.html#sphx-glr-auto-examples-compose-plot-column-transformer-mixed-types-py"><span class="std std-ref">محول الأعمدة مع الأنواع المختلطة</span></a></p>
  <div class="sphx-glr-thumbnail-title">محول الأعمدة مع الأنواع المختلطة</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يمكن أن تحتوي مجموعات البيانات غالبًا على مكونات تتطلب معالجة واستخراج مميزات مختلفة. قد يحدث هذا السيناريو عندما:"><img alt="" src="../_images/sphx_glr_plot_column_transformer_thumb.png" />
<p><a class="reference internal" href="compose/plot_column_transformer.html#sphx-glr-auto-examples-compose-plot-column-transformer-py"><span class="std std-ref">محول الأعمدة مع مصادر بيانات غير متجانسة</span></a></p>
  <div class="sphx-glr-thumbnail-title">محول الأعمدة مع مصادر بيانات غير متجانسة</div>
</div></div></section>
<section id="id17">
<h2>طرق المجموعة<a class="headerlink" href="#id17" title="Link to this heading">#</a></h2>
<p>Ensemble methods</p>
<p>أمثلة تتعلق بوحدة <a class="reference internal" href="../api/sklearn.ensemble.html#module-sklearn.ensemble" title="sklearn.ensemble"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.ensemble</span></code></a>.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="تم تدريب خوارزمية RandomForestClassifier باستخدام bootstrap aggregation، حيث يتم ملاءمة كل شجرة جديدة من عينة bootstrap من الملاحظات التدريبية z_i = (x_i, y_i). خطأ out-of-bag (OOB) هو متوسط الخطأ لكل z_i محسوبة باستخدام تنبؤات من الأشجار التي لا تحتوي على z_i في عينة bootstrap الخاصة بها. يسمح هذا لخوارزمية RandomForestClassifier بالتدريب والتحقق أثناء التدريب [1]_."><img alt="" src="../_images/sphx_glr_plot_ensemble_oob_thumb.png" />
<p><a class="reference internal" href="ensemble/plot_ensemble_oob.html#sphx-glr-auto-examples-ensemble-plot-ensemble-oob-py"><span class="std std-ref">أخطاء OOB لخوارزمية Random Forests</span></a></p>
  <div class="sphx-glr-thumbnail-title">أخطاء OOB لخوارزمية Random Forests</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="هذا المثال يوضح استخدام غابة من الأشجار لتقييم أهمية الميزات في مهمة تصنيف اصطناعية. تمثل الأعمدة الزرقاء أهمية الميزات للغابة، إلى جانب تباينها بين الأشجار الذي يمثله خطأ الأعمدة."><img alt="" src="../_images/sphx_glr_plot_forest_importances_thumb.png" />
<p><a class="reference internal" href="ensemble/plot_forest_importances.html#sphx-glr-auto-examples-ensemble-plot-forest-importances-py"><span class="std std-ref">أهمية الميزات باستخدام غابة من الأشجار</span></a></p>
  <div class="sphx-glr-thumbnail-title">أهمية الميزات باستخدام غابة من الأشجار</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Gradient Boosting هي تقنية تجميعية تجمع بين عدة متعلمين ضعفاء، عادةً ما تكون أشجار القرار، لإنشاء نموذج تنبؤي قوي ومتين. تقوم بذلك بطريقة تكرارية، حيث تقوم كل مرحلة جديدة (شجرة) بتصحيح أخطاء المراحل السابقة."><img alt="" src="../_images/sphx_glr_plot_gradient_boosting_early_stopping_thumb.png" />
<p><a class="reference internal" href="ensemble/plot_gradient_boosting_early_stopping.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-early-stopping-py"><span class="std std-ref">إيقاف التدريب المبكر في Gradient Boosting</span></a></p>
  <div class="sphx-glr-thumbnail-title">إيقاف التدريب المبكر في Gradient Boosting</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يوضح هذا المثال تأثير القيود الرتيبة على مقدر التعزيز المتدرج."><img alt="" src="../_images/sphx_glr_plot_monotonic_constraints_thumb.png" />
<p><a class="reference internal" href="ensemble/plot_monotonic_constraints.html#sphx-glr-auto-examples-ensemble-plot-monotonic-constraints-py"><span class="std std-ref">القيود الرتيبة</span></a></p>
  <div class="sphx-glr-thumbnail-title">القيود الرتيبة</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="قد تكون نماذج histogram_based_gradient_boosting (HGBT) واحدة من أكثر نماذج التعلم الخاضع للإشراف فائدة في scikit-learn. إنها تستند إلى تطبيق حديث للتعزيز المتدرج قابل للمقارنة مع LightGBM و XGBoost. على هذا النحو، تتميز نماذج HGBT بميزات أكثر ثراءً وغالبًا ما تتفوق في الأداء على النماذج البديلة مثل الغابات العشوائية، خاصةً عندما يكون عدد العينات أكبر من عشرات الآلاف (انظر sphx_glr_auto_examples_ensemble_plot_forest_hist_grad_boosting_comparison.py)."><img alt="" src="../_images/sphx_glr_plot_hgbt_regression_thumb.png" />
<p><a class="reference internal" href="ensemble/plot_hgbt_regression.html#sphx-glr-auto-examples-ensemble-plot-hgbt-regression-py"><span class="std std-ref">الميزات في أشجار التعزيز المتدرج للهيستوغرام</span></a></p>
  <div class="sphx-glr-thumbnail-title">الميزات في أشجار التعزيز المتدرج للهيستوغرام</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يوضح هذا المثال التعزيز المتدرج لإنتاج نموذج تنبؤي من مجموعة من النماذج التنبؤية الضعيفة. يمكن استخدام التعزيز المتدرج لمشاكل الانحدار والتصنيف. هنا، سوف نقوم بتدريب نموذج لمعالجة مهمة انحدار مرض السكري. سنحصل على النتائج من GradientBoostingRegressor مع خسارة المربعات الصغرى و 500 شجرة انحدار بعمق 4."><img alt="" src="../_images/sphx_glr_plot_gradient_boosting_regression_thumb.png" />
<p><a class="reference internal" href="ensemble/plot_gradient_boosting_regression.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-regression-py"><span class="std std-ref">انحدار التعزيز المتدرج</span></a></p>
  <div class="sphx-glr-thumbnail-title">انحدار التعزيز المتدرج</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="شجرة القرار معززة باستخدام خوارزمية AdaBoost.R2 [1]_ على مجموعة بيانات جيبية أحادية البعد مع كمية صغيرة من الضوضاء الغاوسية. يتم مقارنة 299 دفعة (300 شجرة قرار) مع منظم شجرة قرار واحد. مع زيادة عدد الدفعات، يمكن لمنظم الانحدار أن يلائم المزيد من التفاصيل."><img alt="" src="../_images/sphx_glr_plot_adaboost_regression_thumb.png" />
<p><a class="reference internal" href="ensemble/plot_adaboost_regression.html#sphx-glr-auto-examples-ensemble-plot-adaboost-regression-py"><span class="std std-ref">انحدار شجرة القرار مع AdaBoost</span></a></p>
  <div class="sphx-glr-thumbnail-title">انحدار شجرة القرار مع AdaBoost</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="قم بتحويل ميزاتك إلى مساحة متفرقة ذات أبعاد أعلى. ثم قم بتدريب نموذج خطي على هذه الميزات."><img alt="" src="../_images/sphx_glr_plot_feature_transformation_thumb.png" />
<p><a class="reference internal" href="ensemble/plot_feature_transformation.html#sphx-glr-auto-examples-ensemble-plot-feature-transformation-py"><span class="std std-ref">تحويل الميزات باستخدام مجموعات الأشجار</span></a></p>
  <div class="sphx-glr-thumbnail-title">تحويل الميزات باستخدام مجموعات الأشجار</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يوفر RandomTreesEmbedding طريقة لتعيين البيانات إلى تمثيل متناثر عالي الأبعاد، والذي قد يكون مفيدًا للتصنيف. التعيين غير خاضع للإشراف تمامًا وفعال للغاية."><img alt="" src="../_images/sphx_glr_plot_random_forest_embedding_thumb.png" />
<p><a class="reference internal" href="ensemble/plot_random_forest_embedding.html#sphx-glr-auto-examples-ensemble-plot-random-forest-embedding-py"><span class="std std-ref">تحويل ميزة التجزئة باستخدام الأشجار العشوائية تمامًا</span></a></p>
  <div class="sphx-glr-thumbnail-title">تحويل ميزة التجزئة باستخدام الأشجار العشوائية تمامًا</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="هذا المثال يقوم بتدريب نموذج شجرة قرار معزز باستخدام AdaBoost على مجموعة بيانات تصنيف غير خطية، مكونة من مجموعتين &quot;Gaussian quantiles&quot; (انظر: sklearn.datasets.make_gaussian_quantiles) ويعرض حدود القرار ودرجات القرار. يتم عرض توزيعات درجات القرار بشكل منفصل للعينات من الفئة A والفئة B. يتم تحديد تسمية الفئة المتوقعة لكل عينة بناءً على إشارة درجة القرار. يتم تصنيف العينات التي لها درجات قرار أكبر من الصفر على أنها من الفئة B، وإلا يتم تصنيفها على أنها من الفئة A. يحدد مقدار درجة القرار درجة التشابه مع تسمية الفئة المتوقعة. بالإضافة إلى ذلك، يمكن بناء مجموعة بيانات جديدة تحتوي على نقاء مرغوب فيه من الفئة B، على سبيل المثال، عن طريق اختيار العينات فقط بدرجة قرار أعلى من قيمة معينة."><img alt="" src="../_images/sphx_glr_plot_adaboost_twoclass_thumb.png" />
<p><a class="reference internal" href="ensemble/plot_adaboost_twoclass.html#sphx-glr-auto-examples-ensemble-plot-adaboost-twoclass-py"><span class="std std-ref">تصنيف ثنائي باستخدام AdaBoost</span></a></p>
  <div class="sphx-glr-thumbnail-title">تصنيف ثنائي باستخدام AdaBoost</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="تقديرات Gradient Boosting Out-of-Bag"><img alt="" src="../_images/sphx_glr_plot_gradient_boosting_oob_thumb.png" />
<p><a class="reference internal" href="ensemble/plot_gradient_boosting_oob.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-oob-py"><span class="std std-ref">تقديرات Gradient Boosting Out-of-Bag</span></a></p>
  <div class="sphx-glr-thumbnail-title">تقديرات Gradient Boosting Out-of-Bag</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="توضيح لتأثير استراتيجيات تنظيم مختلفة للتعزيز المتدرج. المثال مأخوذ من Hastie et al 2009 [1]_."><img alt="" src="../_images/sphx_glr_plot_gradient_boosting_regularization_thumb.png" />
<p><a class="reference internal" href="ensemble/plot_gradient_boosting_regularization.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-regularization-py"><span class="std std-ref">تنظيم التعزيز المتدرج</span></a></p>
  <div class="sphx-glr-thumbnail-title">تنظيم التعزيز المتدرج</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="في هذا المثال، سنقارن أوقات التدريب وأداء التنبؤ لـ HistGradientBoostingRegressor مع استراتيجيات الترميز المختلفة للميزات التصنيفية. على وجه الخصوص، سنقيم:"><img alt="" src="../_images/sphx_glr_plot_gradient_boosting_categorical_thumb.png" />
<p><a class="reference internal" href="ensemble/plot_gradient_boosting_categorical.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-categorical-py"><span class="std std-ref">دعم الميزات التصنيفية في التدرج التعزيزي</span></a></p>
  <div class="sphx-glr-thumbnail-title">دعم الميزات التصنيفية في التدرج التعزيزي</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يشير التكديس إلى طريقة لمزج المقدرات. في هذه الاستراتيجية، يتم ملاءمة بعض المقدرات بشكل فردي على بعض بيانات التدريب بينما يتم تدريب مقدر نهائي باستخدام التنبؤات المكدسة لهذه المقدرات الأساسية."><img alt="" src="../_images/sphx_glr_plot_stack_predictors_thumb.png" />
<p><a class="reference internal" href="ensemble/plot_stack_predictors.html#sphx-glr-auto-examples-ensemble-plot-stack-predictors-py"><span class="std std-ref">دمج المتنبئات باستخدام التكديس</span></a></p>
  <div class="sphx-glr-thumbnail-title">دمج المتنبئات باستخدام التكديس</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="ارسم أسطح القرار لغابات الأشجار العشوائية المدربة على أزواج من سمات مجموعة بيانات إيريس."><img alt="" src="../_images/sphx_glr_plot_forest_iris_thumb.png" />
<p><a class="reference internal" href="ensemble/plot_forest_iris.html#sphx-glr-auto-examples-ensemble-plot-forest-iris-py"><span class="std std-ref">رسم أسطح القرار لمجموعات الأشجار على مجموعة بيانات إيريس</span></a></p>
  <div class="sphx-glr-thumbnail-title">رسم أسطح القرار لمجموعات الأشجار على مجموعة بيانات إيريس</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="رسم احتمالات الفئات للعينة الأولى في مجموعة بيانات تجريبية متوقعة بواسطة ثلاثة مصنفات مختلفة ومتوسط بواسطة VotingClassifier."><img alt="" src="../_images/sphx_glr_plot_voting_probas_thumb.png" />
<p><a class="reference internal" href="ensemble/plot_voting_probas.html#sphx-glr-auto-examples-ensemble-plot-voting-probas-py"><span class="std std-ref">رسم احتمالات الفئات المحسوبة بواسطة VotingClassifier</span></a></p>
  <div class="sphx-glr-thumbnail-title">رسم احتمالات الفئات المحسوبة بواسطة VotingClassifier</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="مُنحدِر التصويت هو مقدر تلوي جماعي يقوم بملاءمة العديد من المُنحدرات الأساسية، كل منها على مجموعة البيانات بأكملها. ثم يقوم بمتوسط ​​التنبؤات الفردية لتشكيل تنبؤ نهائي. سنستخدم ثلاثة مُنحدرات مختلفة للتنبؤ بالبيانات: GradientBoostingRegressor و RandomForestRegressor و LinearRegression). ثم سيتم استخدام المُنحدرات الثلاثة المذكورة أعلاه لـ VotingRegressor."><img alt="" src="../_images/sphx_glr_plot_voting_regressor_thumb.png" />
<p><a class="reference internal" href="ensemble/plot_voting_regressor.html#sphx-glr-auto-examples-ensemble-plot-voting-regressor-py"><span class="std std-ref">رسم تنبؤات الانحدار الفردية والتصويتية</span></a></p>
  <div class="sphx-glr-thumbnail-title">رسم تنبؤات الانحدار الفردية والتصويتية</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="رسم حدود القرار لـ VotingClassifier لميزتين من مجموعة بيانات Iris."><img alt="" src="../_images/sphx_glr_plot_voting_decision_regions_thumb.png" />
<p><a class="reference internal" href="ensemble/plot_voting_decision_regions.html#sphx-glr-auto-examples-ensemble-plot-voting-decision-regions-py"><span class="std std-ref">رسم حدود القرار لـ VotingClassifier</span></a></p>
  <div class="sphx-glr-thumbnail-title">رسم حدود القرار لـ VotingClassifier</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="هذا المثال يوضح كيف يمكن لتقنية التعزيز (Boosting) أن تحسن دقة التنبؤ في مشكلة تصنيف متعددة التصنيفات. وهو يعيد إنتاج تجربة مشابهة لما هو موضح في الشكل 1 في بحث Zhu et al [1]_."><img alt="" src="../_images/sphx_glr_plot_adaboost_multiclass_thumb.png" />
<p><a class="reference internal" href="ensemble/plot_adaboost_multiclass.html#sphx-glr-auto-examples-ensemble-plot-adaboost-multiclass-py"><span class="std std-ref">شجرة قرارات معززة متعددة الفئات</span></a></p>
  <div class="sphx-glr-thumbnail-title">شجرة قرارات معززة متعددة الفئات</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يوضح هذا المثال كيفية استخدام انحدار الكميات لإنشاء فترات تنبؤ. انظر sphx_glr_auto_examples_ensemble_plot_hgbt_regression.py لمثال يعرض بعض الميزات الأخرى لـ HistGradientBoostingRegressor."><img alt="" src="../_images/sphx_glr_plot_gradient_boosting_quantile_thumb.png" />
<p><a class="reference internal" href="ensemble/plot_gradient_boosting_quantile.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-quantile-py"><span class="std std-ref">فترات التنبؤ لانحدار التعزيز المتدرج</span></a></p>
  <div class="sphx-glr-thumbnail-title">فترات التنبؤ لانحدار التعزيز المتدرج</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="مثال يستخدم IsolationForest للكشف عن الشذوذ."><img alt="" src="../_images/sphx_glr_plot_isolation_forest_thumb.png" />
<p><a class="reference internal" href="ensemble/plot_isolation_forest.html#sphx-glr-auto-examples-ensemble-plot-isolation-forest-py"><span class="std std-ref">مثال IsolationForest</span></a></p>
  <div class="sphx-glr-thumbnail-title">مثال IsolationForest</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="مثال لمقارنة انحدار المخرجات المتعددة مع الغابة العشوائية والمقدر التلوي multiclass."><img alt="" src="../_images/sphx_glr_plot_random_forest_regression_multioutput_thumb.png" />
<p><a class="reference internal" href="ensemble/plot_random_forest_regression_multioutput.html#sphx-glr-auto-examples-ensemble-plot-random-forest-regression-multioutput-py"><span class="std std-ref">مقارنة الغابات العشوائية ومقدر المخرجات المتعددة التلوي</span></a></p>
  <div class="sphx-glr-thumbnail-title">مقارنة الغابات العشوائية ومقدر المخرجات المتعددة التلوي</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يوضح هذا المثال ويقارن تحليل الانحياز والتشتت للخطأ التربيعي المتوسط المتوقع لمقدر فردي مقابل مجموعة تجميع."><img alt="" src="../_images/sphx_glr_plot_bias_variance_thumb.png" />
<p><a class="reference internal" href="ensemble/plot_bias_variance.html#sphx-glr-auto-examples-ensemble-plot-bias-variance-py"><span class="std std-ref">مقارنة بين المُقدر الفردي والتجميع: تحليل الانحياز والتشتت</span></a></p>
  <div class="sphx-glr-thumbnail-title">مقارنة بين المُقدر الفردي والتجميع: تحليل الانحياز والتشتت</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="في هذا المثال، نقارن بين أداء نموذج الغابة العشوائية (RF) ونموذج رفع التدرج بالرسم البياني (HGBT) من حيث النتيجة ووقت الحساب لمجموعة بيانات الانحدار، على الرغم من أن جميع المفاهيم المقدمة هنا تنطبق على التصنيف أيضًا."><img alt="" src="../_images/sphx_glr_plot_forest_hist_grad_boosting_comparison_thumb.png" />
<p><a class="reference internal" href="ensemble/plot_forest_hist_grad_boosting_comparison.html#sphx-glr-auto-examples-ensemble-plot-forest-hist-grad-boosting-comparison-py"><span class="std std-ref">مقارنة بين نماذج الغابات العشوائية ورفع التدرج بالرسم البياني</span></a></p>
  <div class="sphx-glr-thumbnail-title">مقارنة بين نماذج الغابات العشوائية ورفع التدرج بالرسم البياني</div>
</div></div></section>
<section id="id18">
<h2>عملية غاوسية للتعلم الآلي<a class="headerlink" href="#id18" title="Link to this heading">#</a></h2>
<p>أمثلة تتعلق بوحدة <a class="reference internal" href="../api/sklearn.gaussian_process.html#module-sklearn.gaussian_process" title="sklearn.gaussian_process"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.gaussian_process</span></code></a>.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="يستند هذا المثال إلى القسم 5.4.3 من &quot;العمليات الغاوسية للتعلم الآلي&quot; [1]_. يوضح مثالاً على هندسة النواة المعقدة وتحسين المعلمات الفائقة باستخدام صعود التدرج على الاحتمال الهامشي اللوغاريتمي. تتكون البيانات من متوسط ​​التركيزات الشهرية لثاني أكسيد الكربون في الغلاف الجوي (مقاسة بأجزاء لكل مليون من حيث الحجم (ppm)) التي تم جمعها في مرصد مونا لوا في هاواي ، بين عامي 1958 و 2001. الهدف هو نمذجة تركيز ثاني أكسيد الكربون كدالة للوقت t واستقراءه للسنوات التي تلي عام 2001."><img alt="" src="../_images/sphx_glr_plot_gpr_co2_thumb.png" />
<p><a class="reference internal" href="gaussian_process/plot_gpr_co2.html#sphx-glr-auto-examples-gaussian-process-plot-gpr-co2-py"><span class="std std-ref">التنبؤ بمستوى ثاني أكسيد الكربون في مجموعة بيانات Mona Loa باستخدام انحدار العملية الغاوسية (GPR)</span></a></p>
  <div class="sphx-glr-thumbnail-title">التنبؤ بمستوى ثاني أكسيد الكربون في مجموعة بيانات Mona Loa باستخدام انحدار العملية الغاوسية (GPR)</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يوضح هذا المثال الاحتمال المتوقع لـ GPC لنواة RBF مع خيارات مختلفة للمعلمات الفائقة. يُظهر الشكل الأول الاحتمال المتوقع لـ GPC مع معلمات فائقة تم اختيارها عشوائيًا ومع المعلمات الفائقة المقابلة لأكبر احتمال هامشي لوغاريتمي (LML)."><img alt="" src="../_images/sphx_glr_plot_gpc_thumb.png" />
<p><a class="reference internal" href="gaussian_process/plot_gpc.html#sphx-glr-auto-examples-gaussian-process-plot-gpc-py"><span class="std std-ref">التنبؤات الاحتمالية مع تصنيف العملية الغاوسية (GPC)</span></a></p>
  <div class="sphx-glr-thumbnail-title">التنبؤات الاحتمالية مع تصنيف العملية الغاوسية (GPC)</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يوضح هذا المثال استخدام العمليات الغاوسية لمهام الانحدار والتصنيف على البيانات التي ليست في شكل متجه ميزات بطول ثابت. يتم تحقيق ذلك من خلال استخدام دوال النواة التي تعمل مباشرة على هياكل منقوصة مثل التسلسلات متغيرة الطول والأشجار والرسوم البيانية."><img alt="" src="../_images/sphx_glr_plot_gpr_on_structured_data_thumb.png" />
<p><a class="reference internal" href="gaussian_process/plot_gpr_on_structured_data.html#sphx-glr-auto-examples-gaussian-process-plot-gpr-on-structured-data-py"><span class="std std-ref">العمليات الغاوسية على هياكل البيانات المنقوصة</span></a></p>
  <div class="sphx-glr-thumbnail-title">العمليات الغاوسية على هياكل البيانات المنقوصة</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="مثال بسيط أحادي البعد للانحدار محسوب بطريقتين مختلفتين:"><img alt="" src="../_images/sphx_glr_plot_gpr_noisy_targets_thumb.png" />
<p><a class="reference internal" href="gaussian_process/plot_gpr_noisy_targets.html#sphx-glr-auto-examples-gaussian-process-plot-gpr-noisy-targets-py"><span class="std std-ref">انحدار العمليات الغاوسية: مثال تمهيدي أساسي</span></a></p>
  <div class="sphx-glr-thumbnail-title">انحدار العمليات الغاوسية: مثال تمهيدي أساسي</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يوضح هذا المثال الاحتمال المتوقع لـ GPC لنواة RBF متناحرة وغير متناحرة على نسخة ثنائية الأبعاد لمجموعة بيانات iris. تحصل نواة RBF غير المتناحرة على احتمال هامشي لوغاريتمي أعلى قليلاً عن طريق تعيين مقاييس طول مختلفة لأبعاد الميزتين."><img alt="" src="../_images/sphx_glr_plot_gpc_iris_thumb.png" />
<p><a class="reference internal" href="gaussian_process/plot_gpc_iris.html#sphx-glr-auto-examples-gaussian-process-plot-gpc-iris-py"><span class="std std-ref">تصنيف العملية الغاوسية (GPC) على مجموعة بيانات iris</span></a></p>
  <div class="sphx-glr-thumbnail-title">تصنيف العملية الغاوسية (GPC) على مجموعة بيانات iris</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يوضح هذا المثال التوزيع المسبق واللاحق لـ GaussianProcessRegressor مع نوى مختلفة. يتم عرض المتوسط والانحراف المعياري و 5 عينات لكل من التوزيعات المسبقة واللاحقة."><img alt="" src="../_images/sphx_glr_plot_gpr_prior_posterior_thumb.png" />
<p><a class="reference internal" href="gaussian_process/plot_gpr_prior_posterior.html#sphx-glr-auto-examples-gaussian-process-plot-gpr-prior-posterior-py"><span class="std std-ref">توضيح العملية الغاوسية المسبقة واللاحقة لنوى مختلفة</span></a></p>
  <div class="sphx-glr-thumbnail-title">توضيح العملية الغاوسية المسبقة واللاحقة لنوى مختلفة</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يوضح هذا المثال GPC على بيانات XOR. تتم مقارنة نواة ثابتة ومتناحرة (RBF) بنواة غير ثابتة (DotProduct). في مجموعة البيانات هذه تحديدًا ، تحصل نواة DotProduct على نتائج أفضل بكثير لأن حدود الفئة خطية وتتوافق مع محاور الإحداثيات. بشكل عام ، غالبًا ما تحقق النوى الثابتة نتائج أفضل."><img alt="" src="../_images/sphx_glr_plot_gpc_xor_thumb.png" />
<p><a class="reference internal" href="gaussian_process/plot_gpc_xor.html#sphx-glr-auto-examples-gaussian-process-plot-gpc-xor-py"><span class="std std-ref">توضيح تصنيف العملية الغاوسية (GPC) على مجموعة بيانات XOR</span></a></p>
  <div class="sphx-glr-thumbnail-title">توضيح تصنيف العملية الغاوسية (GPC) على مجموعة بيانات XOR</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="مثال تصنيف ثنائي الأبعاد يوضح خطوط تساوي الاحتمال للاحتمالات المتوقعة."><img alt="" src="../_images/sphx_glr_plot_gpc_isoprobability_thumb.png" />
<p><a class="reference internal" href="gaussian_process/plot_gpc_isoprobability.html#sphx-glr-auto-examples-gaussian-process-plot-gpc-isoprobability-py"><span class="std std-ref">خطوط تساوي الاحتمال لتصنيف العمليات الغاوسية (GPC)</span></a></p>
  <div class="sphx-glr-thumbnail-title">خطوط تساوي الاحتمال لتصنيف العمليات الغاوسية (GPC)</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يوضح هذا المثال قدرة  WhiteKernel على تقدير مستوى الضوضاء في البيانات. علاوة على ذلك، سنوضح أهمية تهيئة المعلمات الفائقة للنواة."><img alt="" src="../_images/sphx_glr_plot_gpr_noisy_thumb.png" />
<p><a class="reference internal" href="gaussian_process/plot_gpr_noisy.html#sphx-glr-auto-examples-gaussian-process-plot-gpr-noisy-py"><span class="std std-ref">قدرة انحدار العمليات الغاوسية (GPR) على تقدير مستوى ضوضاء البيانات</span></a></p>
  <div class="sphx-glr-thumbnail-title">قدرة انحدار العمليات الغاوسية (GPR) على تقدير مستوى ضوضاء البيانات</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يوضح هذا المثال الاختلافات بين انحدار kernel ridge وانحدار العمليات الغاوسية."><img alt="" src="../_images/sphx_glr_plot_compare_gpr_krr_thumb.png" />
<p><a class="reference internal" href="gaussian_process/plot_compare_gpr_krr.html#sphx-glr-auto-examples-gaussian-process-plot-compare-gpr-krr-py"><span class="std std-ref">مقارنة انحدار kernel ridge وانحدار العمليات الغاوسية</span></a></p>
  <div class="sphx-glr-thumbnail-title">مقارنة انحدار kernel ridge وانحدار العمليات الغاوسية</div>
</div></div></section>
<section id="id19">
<h2>معايرة الإحتمالات<a class="headerlink" href="#id19" title="Link to this heading">#</a></h2>
<p>أمثلة توضح معايرة الاحتمالات المتوقعة للمصنفات.</p>
<div class="sphx-glr-thumbnails"><div class="sphx-glr-thumbcontainer" tooltip="عند إجراء التصنيف، غالبًا ما تريد التنبؤ ليس فقط بتسمية الفئة، ولكن أيضًا الاحتمالية المرتبطة بها. هذه الاحتمالية تعطيك نوعًا من الثقة في التنبؤ. ومع ذلك، لا توفر جميع المصنفات احتمالات معايرة جيدًا، بعضها مفرط الثقة في حين أن البعض الآخر غير واثق. لذلك، غالبًا ما تكون معايرة الاحتمالات المتوقعة مرغوبة كعملية ما بعد المعالجة. يوضح هذا المثال طريقتان مختلفتان لهذه المعايرة ويقيم جودة الاحتمالات المعادة باستخدام درجة Brier (انظر https://en.wikipedia.org/wiki/Brier_score)."><img alt="" src="../_images/sphx_glr_plot_calibration_thumb.png" />
<p><a class="reference internal" href="calibration/plot_calibration.html#sphx-glr-auto-examples-calibration-plot-calibration-py"><span class="std std-ref">معايرة احتمالات المصنفات</span></a></p>
  <div class="sphx-glr-thumbnail-title">معايرة احتمالات المصنفات</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="يوضح هذا المثال كيف أن معايرة سيجمويد calibration تغير الاحتمالات المتوقعة لمشكلة تصنيف ثلاثي الفئات. يتم توضيح المضلع الثنائي القياسي، حيث تتوافق الزوايا الثلاثة مع الفئات الثلاث. تشير الأسهم من متجهات الاحتمالات المتوقعة بواسطة مصنف غير معاير إلى متجهات الاحتمالات المتوقعة بواسطة نفس المصنف بعد معايرة سيجمويد على مجموعة بيانات التحقق. تشير الألوان إلى الفئة الحقيقية للعينة (الأحمر: الفئة 1، الأخضر: الفئة 2، الأزرق: الفئة 3)."><img alt="" src="../_images/sphx_glr_plot_calibration_multiclass_thumb.png" />
<p><a class="reference internal" href="calibration/plot_calibration_multiclass.html#sphx-glr-auto-examples-calibration-plot-calibration-multiclass-py"><span class="std std-ref">معايرة الاحتمالات لتصنيف ثلاثي الفئات</span></a></p>
  <div class="sphx-glr-thumbnail-title">معايرة الاحتمالات لتصنيف ثلاثي الفئات</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="المصنفات المعايرة جيدًا هي مصنفات احتمالية يمكن تفسير ناتجها من predict_proba مباشرةً كدرجة ثقة. على سبيل المثال، يجب أن يقوم المصنف المعاير جيدًا (الثنائي) بتصنيف العينات بحيث للعينات التي أعطاها قيمة predict_proba قريبة من 0.8، تنتمي بالفعل حوالي 80% إلى الفئة الإيجابية."><img alt="" src="../_images/sphx_glr_plot_compare_calibration_thumb.png" />
<p><a class="reference internal" href="calibration/plot_compare_calibration.html#sphx-glr-auto-examples-calibration-plot-compare-calibration-py"><span class="std std-ref">مقارنة معايرة المصنفات</span></a></p>
  <div class="sphx-glr-thumbnail-title">مقارنة معايرة المصنفات</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="عند إجراء التصنيف، غالبًا ما يرغب المرء في التنبؤ ليس فقط بتسمية الفئة، ولكن أيضًا بالاحتمالية المرتبطة بها. يعطي هذا الاحتمال نوعًا من الثقة في التنبؤ. يوضح هذا المثال كيفية تصور مدى جودة معايرة الاحتمالات المتوقعة باستخدام منحنيات المعايرة، والمعروفة أيضًا باسم مخططات الموثوقية. سيتم أيضًا توضيح معايرة مصنف غير معاير."><img alt="" src="../_images/sphx_glr_plot_calibration_curve_thumb.png" />
<p><a class="reference internal" href="calibration/plot_calibration_curve.html#sphx-glr-auto-examples-calibration-plot-calibration-curve-py"><span class="std std-ref">منحنيات معايرة الاحتمالية</span></a></p>
  <div class="sphx-glr-thumbnail-title">منحنيات معايرة الاحتمالية</div>
</div></div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-footer sphx-glr-footer-gallery docutils container">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/07fcc19ba03226cd3d83d4e40ec44385/auto_examples_python.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">all</span> <span class="pre">examples</span> <span class="pre">in</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">auto_examples_python.zip</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/6f1e7a639e0699d6164445b55e6c116d/auto_examples_jupyter.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">all</span> <span class="pre">examples</span> <span class="pre">in</span> <span class="pre">Jupyter</span> <span class="pre">notebooks:</span> <span class="pre">auto_examples_jupyter.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


                </article>
              
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="prev-next-area">
    <a class="left-prev"
       href="../modules/generated/sklearn.utils.register_parallel_backend.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">السابق</p>
        <p class="prev-next-title">register_parallel_backend</p>
      </div>
    </a>
    <a class="right-next"
       href="release_highlights/index.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">التالي</p>
        <p class="prev-next-title">Release Highlights</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>
                </footer>
              
              
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2007 - 2024, scikit-learn developers (BSD License) ### Translate into Arabic Eng. Ahmed Almaghz - 2024.
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
</div>

  </footer>
  </body>
</html>