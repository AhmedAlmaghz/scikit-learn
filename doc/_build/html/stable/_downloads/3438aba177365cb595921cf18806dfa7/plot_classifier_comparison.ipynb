{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# \u0645\u0642\u0627\u0631\u0646\u0629 \u0627\u0644\u0645\u0635\u0646\u0641\u0627\u062a\n\n\u0645\u0642\u0627\u0631\u0646\u0629 \u0628\u064a\u0646 \u0639\u062f\u0629 \u0645\u0635\u0646\u0641\u0627\u062a \u0641\u064a scikit-learn \u0639\u0644\u0649 \u0645\u062c\u0645\u0648\u0639\u0627\u062a \u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0635\u0637\u0646\u0627\u0639\u064a\u0629.\n\u0627\u0644\u063a\u0631\u0636 \u0645\u0646 \u0647\u0630\u0627 \u0627\u0644\u0645\u062b\u0627\u0644 \u0647\u0648 \u062a\u0648\u0636\u064a\u062d \u0637\u0628\u064a\u0639\u0629 \u062d\u062f\u0648\u062f \u0627\u0644\u0642\u0631\u0627\u0631\n\u0644\u0645\u0635\u0646\u0641\u0627\u062a \u0645\u062e\u062a\u0644\u0641\u0629.\n\u064a\u062c\u0628 \u0623\u062e\u0630 \u0647\u0630\u0627 \u0628\u0639\u064a\u0646 \u0627\u0644\u0627\u0639\u062a\u0628\u0627\u0631\u060c \u062d\u064a\u062b \u0623\u0646 \u0627\u0644\u062d\u062f\u0633 \u0627\u0644\u0630\u064a \u062a\u0648\u0641\u0631\u0647\n\u0647\u0630\u0647 \u0627\u0644\u0623\u0645\u062b\u0644\u0629 \u0644\u0627 \u064a\u0646\u062a\u0642\u0644 \u0628\u0627\u0644\u0636\u0631\u0648\u0631\u0629 \u0625\u0644\u0649 \u0645\u062c\u0645\u0648\u0639\u0627\u062a \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u062d\u0642\u064a\u0642\u064a\u0629.\n\n\u0648\u0628\u0634\u0643\u0644 \u062e\u0627\u0635 \u0641\u064a \u0627\u0644\u0645\u0633\u0627\u062d\u0627\u062a \u0630\u0627\u062a \u0627\u0644\u0623\u0628\u0639\u0627\u062f \u0627\u0644\u0639\u0627\u0644\u064a\u0629\u060c \u064a\u0645\u0643\u0646 \u0641\u0635\u0644 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a \u0628\u0633\u0647\u0648\u0644\u0629 \u0623\u0643\u0628\u0631\n\u0628\u0634\u0643\u0644 \u062e\u0637\u064a \u0648\u0642\u062f \u062a\u0624\u062f\u064a \u0628\u0633\u0627\u0637\u0629 \u0627\u0644\u0645\u0635\u0646\u0641\u0627\u062a \u0645\u062b\u0644 \u0628\u0627\u064a\u0632 \u0627\u0644\u0633\u0627\u0630\u062c \u0648SVMs \u0627\u0644\u062e\u0637\u064a\u0629\n\u0625\u0644\u0649 \u062a\u0639\u0645\u064a\u0645 \u0623\u0641\u0636\u0644 \u0645\u0645\u0627 \u062a\u062d\u0642\u0642\u0647 \u0627\u0644\u0645\u0635\u0646\u0641\u0627\u062a \u0627\u0644\u0623\u062e\u0631\u0649.\n\n\u062a\u0648\u0636\u062d \u0627\u0644\u0631\u0633\u0648\u0645 \u0627\u0644\u0628\u064a\u0627\u0646\u064a\u0629 \u0646\u0642\u0627\u0637 \u0627\u0644\u062a\u062f\u0631\u064a\u0628 \u0628\u0623\u0644\u0648\u0627\u0646 \u0635\u0644\u0628\u0629 \u0648\u0646\u0642\u0627\u0637 \u0627\u0644\u0627\u062e\u062a\u0628\u0627\u0631\n\u0634\u0628\u0647 \u0634\u0641\u0627\u0641\u0629. \u064a\u0638\u0647\u0631 \u0627\u0644\u0631\u0628\u0639 \u0627\u0644\u0623\u064a\u0645\u0646 \u0627\u0644\u0633\u0641\u0644\u064a \u062f\u0642\u0629 \u0627\u0644\u062a\u0635\u0646\u064a\u0641 \u0639\u0644\u0649 \u0645\u062c\u0645\u0648\u0639\u0629 \u0627\u0644\u0627\u062e\u062a\u0628\u0627\u0631.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \u0627\u0644\u0645\u0624\u0644\u0641\u0648\u0646: \u0645\u0637\u0648\u0631\u064a scikit-learn\n# \u0645\u0639\u0631\u0641 \u0627\u0644\u062a\u0631\u062e\u064a\u0635: BSD-3-Clause\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.colors import ListedColormap\n\nfrom sklearn.datasets import make_circles, make_classification, make_moons\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.inspection import DecisionBoundaryDisplay\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\n\nnames = [\n    \"Nearest Neighbors\",\n    \"Linear SVM\",\n    \"RBF SVM\",\n    \"Gaussian Process\",\n    \"Decision Tree\",\n    \"Random Forest\",\n    \"Neural Net\",\n    \"AdaBoost\",\n    \"Naive Bayes\",\n    \"QDA\",\n]\n\nclassifiers = [\n    KNeighborsClassifier(3),\n    SVC(kernel=\"linear\", C=0.025, random_state=42),\n    SVC(gamma=2, C=1, random_state=42),\n    GaussianProcessClassifier(1.0 * RBF(1.0), random_state=42),\n    DecisionTreeClassifier(max_depth=5, random_state=42),\n    RandomForestClassifier(\n        max_depth=5, n_estimators=10, max_features=1, random_state=42\n    ),\n    MLPClassifier(alpha=1, max_iter=1000, random_state=42),\n    AdaBoostClassifier(random_state=42),\n    GaussianNB(),\n    QuadraticDiscriminantAnalysis(),\n]\n\nX, y = make_classification(\n    n_features=2, n_redundant=0, n_informative=2, random_state=1, n_clusters_per_class=1\n)\nrng = np.random.RandomState(2)\nX += 2 * rng.uniform(size=X.shape)\nlinearly_separable = (X, y)\n\ndatasets = [\n    make_moons(noise=0.3, random_state=0),\n    make_circles(noise=0.2, factor=0.5, random_state=1),\n    linearly_separable,\n]\n\nfigure = plt.figure(figsize=(27, 9))\ni = 1\n# iterate over datasets\nfor ds_cnt, ds in enumerate(datasets):\n    # preprocess dataset, split into training and test part\n    X, y = ds\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.4, random_state=42\n    )\n\n    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n\n    # just plot the dataset first\n    cm = plt.cm.RdBu\n    cm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"])\n    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n    if ds_cnt == 0:\n        ax.set_title(\"Input data\")\n    # Plot the training points\n    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=\"k\")\n    # Plot the testing points\n    ax.scatter(\n        X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6, edgecolors=\"k\"\n    )\n    ax.set_xlim(x_min, x_max)\n    ax.set_ylim(y_min, y_max)\n    ax.set_xticks(())\n    ax.set_yticks(())\n    i += 1\n\n    # iterate over classifiers\n    for name, clf in zip(names, classifiers):\n        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n# iterate over classifiers\n    for name, clf in zip(names, classifiers):\n        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n\n        clf = make_pipeline(StandardScaler(), clf)\n        clf.fit(X_train, y_train)\n        score = clf.score(X_test, y_test)\n        DecisionBoundaryDisplay.from_estimator(\n            clf, X, cmap=cm, alpha=0.8, ax=ax, eps=0.5\n        )\n\n        # Plot the training points\n        ax.scatter(\n            X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=\"k\"\n        )\n        # Plot the testing points\n        ax.scatter(\n            X_test[:, 0],\n            X_test[:, 1],\n            c=y_test,\n            cmap=cm_bright,\n            edgecolors=\"k\",\n            alpha=0.6,\n        )\n\n        ax.set_xlim(x_min, x_max)\n        ax.set_ylim(y_min, y_max)\n        ax.set_xticks(())\n        ax.set_yticks(())\n        if ds_cnt == 0:\n            ax.set_title(name)\n        ax.text(\n            x_max - 0.3,\n            y_min + 0.3,\n            (\"%.2f\" % score).lstrip(\"0\"),\n            size=15,\n            horizontalalignment=\"right\",\n        )\n        i += 1\n\nplt.tight_layout()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}