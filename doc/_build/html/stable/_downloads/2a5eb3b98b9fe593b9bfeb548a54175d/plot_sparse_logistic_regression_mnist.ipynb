{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# \u062a\u0635\u0646\u064a\u0641 MNIST \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u0627\u0644\u0644\u0648\u063a\u0627\u0631\u064a\u062a\u0645 \u0645\u062a\u0639\u062f\u062f \u0627\u0644\u062d\u062f\u0648\u062f + L1\n\n\u0647\u0646\u0627 \u0646\u0642\u0648\u0645 \u0628\u0636\u0628\u0637 \u0627\u0644\u0627\u0646\u062d\u062f\u0627\u0631 \u0627\u0644\u0644\u0648\u063a\u0627\u0631\u064a\u062a\u0645\u064a \u0645\u062a\u0639\u062f\u062f \u0627\u0644\u062d\u062f\u0648\u062f \u0645\u0639 \u0639\u0642\u0648\u0628\u0629 L1 \u0639\u0644\u0649 \u0645\u062c\u0645\u0648\u0639\u0629 \u0641\u0631\u0639\u064a\u0629\n\u0645\u0646 \u0645\u0647\u0645\u0629 \u062a\u0635\u0646\u064a\u0641 \u0623\u0631\u0642\u0627\u0645 MNIST. \u0646\u0633\u062a\u062e\u062f\u0645 \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 SAGA \u0644\u0647\u0630\u0627\n\u0627\u0644\u063a\u0631\u0636: \u0647\u0630\u0647 \u0623\u062f\u0627\u0629 \u062d\u0644 \u0633\u0631\u064a\u0639\u0629 \u0639\u0646\u062f\u0645\u0627 \u064a\u0643\u0648\u0646 \u0639\u062f\u062f \u0627\u0644\u0639\u064a\u0646\u0627\u062a \u0623\u0643\u0628\u0631 \u0628\u0634\u0643\u0644 \u0645\u0644\u062d\u0648\u0638\n\u0645\u0646 \u0639\u062f\u062f \u0627\u0644\u0645\u064a\u0632\u0627\u062a \u0648\u0642\u0627\u062f\u0631\u0629 \u0639\u0644\u0649 \u062a\u062d\u0633\u064a\u0646 \u062f\u0642\u064a\u0642\n\u0648\u0638\u0627\u0626\u0641 \u0627\u0644\u0647\u062f\u0641 \u063a\u064a\u0631 \u0627\u0644\u0645\u0644\u0633\u0627\u0621 \u0648\u0627\u0644\u062a\u064a \u0647\u064a \u0627\u0644\u062d\u0627\u0644\u0629 \u0645\u0639 \u0639\u0642\u0648\u0628\u0629 l1. \u062a\u0635\u0644 \u062f\u0642\u0629 \u0627\u0644\u0627\u062e\u062a\u0628\u0627\u0631\n> 0.8\u060c \u0628\u064a\u0646\u0645\u0627 \u062a\u0628\u0642\u0649 \u0645\u062a\u062c\u0647\u0627\u062a \u0627\u0644\u0648\u0632\u0646 *\u0645\u062a\u0641\u0631\u0642\u0629* \u0648\u0628\u0627\u0644\u062a\u0627\u0644\u064a \u0623\u0643\u062b\u0631 \u0633\u0647\u0648\u0644\u0629\n*\u0642\u0627\u0628\u0644 \u0644\u0644\u062a\u0641\u0633\u064a\u0631*.\n\n\u0645\u0644\u0627\u062d\u0638\u0629: \u0623\u0646 \u062f\u0642\u0629 \u0647\u0630\u0627 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0627\u0644\u062e\u0637\u064a \u0627\u0644\u0645\u0639\u0627\u0642\u0628 \u0639\u0644\u064a\u0647 l1 \u0623\u0642\u0644 \u0628\u0643\u062b\u064a\u0631\n\u0645\u0627 \u064a\u0645\u0643\u0646 \u0627\u0644\u0648\u0635\u0648\u0644 \u0625\u0644\u064a\u0647 \u0628\u0648\u0627\u0633\u0637\u0629 \u0646\u0645\u0648\u0630\u062c \u062e\u0637\u064a \u0645\u0639\u0627\u0642\u0628 \u0639\u0644\u064a\u0647 l2 \u0623\u0648 \u0646\u0645\u0648\u0630\u062c \u0645\u062a\u0639\u062f\u062f \u0627\u0644\u0637\u0628\u0642\u0627\u062a\n\u0634\u0628\u0643\u0629 \u0627\u0644\u0625\u062f\u0631\u0627\u0643 \u063a\u064a\u0631 \u0627\u0644\u062e\u0637\u064a\u0629 \u0639\u0644\u0649 \u0647\u0630\u0647 \u0627\u0644\u0645\u062c\u0645\u0648\u0639\u0629 \u0645\u0646 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \u0627\u0644\u0645\u0624\u0644\u0641\u0648\u0646: \u0645\u0637\u0648\u0631\u064a scikit-learn\n# \u0645\u0639\u0631\u0641 \u0627\u0644\u062a\u0631\u062e\u064a\u0635: BSD-3-Clause\n\nimport time\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import check_random_state\n\n# \u062e\u0641\u0636 \u0644\u0644\u062a\u0642\u0627\u0631\u0628 \u0627\u0644\u0623\u0633\u0631\u0639\nt0 = time.time()\ntrain_samples = 5000\n\n# \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a \u0645\u0646 https://www.openml.org/d/554\nX, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n\nrandom_state = check_random_state(0)\npermutation = random_state.permutation(X.shape[0])\nX = X[permutation]\ny = y[permutation]\nX = X.reshape((X.shape[0], -1))\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, train_size=train_samples, test_size=10000\n)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# \u0632\u064a\u0627\u062f\u0629 \u0627\u0644\u062a\u0633\u0627\u0645\u062d \u0644\u0644\u062a\u0642\u0627\u0631\u0628 \u0627\u0644\u0623\u0633\u0631\u0639\nclf = LogisticRegression(C=50.0 / train_samples, penalty=\"l1\", solver=\"saga\", tol=0.1)\nclf.fit(X_train, y_train)\nsparsity = np.mean(clf.coef_ == 0) * 100\nscore = clf.score(X_test, y_test)\n# print('Best C % .4f' % clf.C_)\nprint(\"Sparsity with L1 penalty: %.2f%%\" % sparsity)\nprint(\"Test score with L1 penalty: %.4f\" % score)\n\ncoef = clf.coef_.copy()\nplt.figure(figsize=(10, 5))\nscale = np.abs(coef).max()\nfor i in range(10):\n    l1_plot = plt.subplot(2, 5, i + 1)\n    l1_plot.imshow(\n        coef[i].reshape(28, 28),\n        interpolation=\"nearest\",\n        cmap=plt.cm.RdBu,\n        vmin=-scale,\n        vmax=scale,\n    )\n    l1_plot.set_xticks(())\n    l1_plot.set_yticks(())\n    l1_plot.set_xlabel(\"Class %i\" % i)\nplt.suptitle(\"Classification vector for...\")\n\nrun_time = time.time() - t0\nprint(\"Example run in %.3f s\" % run_time)\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}