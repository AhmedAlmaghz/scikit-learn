{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# \u0627\u0644\u062a\u062c\u0645\u064a\u0639 \u0627\u0644\u062b\u0646\u0627\u0626\u064a \u0644\u0644\u0645\u0633\u062a\u0646\u062f\u0627\u062a \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 \u0627\u0644\u062a\u062c\u0645\u064a\u0639 \u0627\u0644\u0637\u064a\u0641\u064a \u0627\u0644\u0645\u0634\u062a\u0631\u0643\n\n\u0647\u0630\u0627 \u0627\u0644\u0645\u062b\u0627\u0644 \u064a\u0648\u0636\u062d \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 \u0627\u0644\u062a\u062c\u0645\u064a\u0639 \u0627\u0644\u0637\u064a\u0641\u064a \u0627\u0644\u0645\u0634\u062a\u0631\u0643 \u0639\u0644\u0649\n\u0645\u062c\u0645\u0648\u0639\u0629 \u0628\u064a\u0627\u0646\u0627\u062a \u0645\u062c\u0645\u0648\u0639\u0627\u062a \u0627\u0644\u0623\u062e\u0628\u0627\u0631 \u0627\u0644\u0639\u0634\u0631\u064a\u0646. \u062a\u0645 \u0627\u0633\u062a\u0628\u0639\u0627\u062f \u0627\u0644\u0641\u0626\u0629 'comp.os.ms-windows.misc'\n\u0644\u0623\u0646\u0647\u0627 \u062a\u062d\u062a\u0648\u064a \u0639\u0644\u0649 \u0627\u0644\u0639\u062f\u064a\u062f \u0645\u0646 \u0627\u0644\u0645\u0646\u0634\u0648\u0631\u0627\u062a \u0627\u0644\u062a\u064a \u0644\u0627 \u062a\u062d\u062a\u0648\u064a \u0625\u0644\u0627 \u0639\u0644\u0649 \u0628\u064a\u0627\u0646\u0627\u062a.\n\n\u0627\u0644\u0645\u0646\u0634\u0648\u0631\u0627\u062a \u0627\u0644\u0645\u062a\u062c\u0647\u0629 TF-IDF \u062a\u0634\u0643\u0644 \u0645\u0635\u0641\u0648\u0641\u0629 \u062a\u0643\u0631\u0627\u0631 \u0627\u0644\u0643\u0644\u0645\u0627\u062a\u060c \u0648\u0627\u0644\u062a\u064a \u064a\u062a\u0645 \u0628\u0639\u062f \u0630\u0644\u0643\n\u062a\u062c\u0645\u0639\u0647\u0627 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u062e\u0648\u0627\u0631\u0632\u0645\u064a\u0629 Dhillon's Spectral Co-Clustering. \u062a\u0634\u064a\u0631 \u0645\u062c\u0645\u0648\u0639\u0627\u062a \u0627\u0644\u062a\u062c\u0645\u064a\u0639 \u0627\u0644\u0641\u0631\u0639\u064a\u0629 \u0644\u0644\u0648\u062b\u0627\u0626\u0642-\u0627\u0644\u0643\u0644\u0645\u0627\u062a \u0627\u0644\u0646\u0627\u062a\u062c\u0629\n\u0625\u0644\u0649 \u0645\u062c\u0645\u0648\u0639\u0627\u062a \u0641\u0631\u0639\u064a\u0629 \u0645\u0646 \u0627\u0644\u0643\u0644\u0645\u0627\u062a \u0627\u0644\u0645\u0633\u062a\u062e\u062f\u0645\u0629 \u0628\u0634\u0643\u0644 \u0645\u062a\u0643\u0631\u0631 \u0623\u0643\u062b\u0631 \u0641\u064a \u062a\u0644\u0643 \u0627\u0644\u0645\u0633\u062a\u0646\u062f\u0627\u062a \u0627\u0644\u0641\u0631\u0639\u064a\u0629.\n\n\u0628\u0627\u0644\u0646\u0633\u0628\u0629 \u0644\u0628\u0639\u0636 \u0623\u0641\u0636\u0644 \u0645\u062c\u0645\u0648\u0639\u0627\u062a \u0627\u0644\u062a\u062c\u0645\u064a\u0639 \u0627\u0644\u0641\u0631\u0639\u064a\u0629\u060c \u064a\u062a\u0645 \u0637\u0628\u0627\u0639\u0629 \u0641\u0626\u0627\u062a \u0627\u0644\u0645\u0633\u062a\u0646\u062f\u0627\u062a \u0627\u0644\u0623\u0643\u062b\u0631 \u0634\u064a\u0648\u0639\u064b\u0627\n\u0648\u0623\u0647\u0645 \u0639\u0634\u0631 \u0643\u0644\u0645\u0627\u062a \u0644\u0647\u0627. \u064a\u062a\u0645 \u062a\u062d\u062f\u064a\u062f \u0623\u0641\u0636\u0644 \u0645\u062c\u0645\u0648\u0639\u0627\u062a \u0627\u0644\u062a\u062c\u0645\u064a\u0639 \u0627\u0644\u0641\u0631\u0639\u064a\u0629 \u0645\u0646 \u062e\u0644\u0627\u0644 \u0642\u0637\u0639\u0647\u0627 \u0627\u0644\u0645\u0639\u064a\u0627\u0631\u064a\u0629. \u064a\u062a\u0645 \u062a\u062d\u062f\u064a\u062f \u0623\u0641\u0636\u0644 \u0627\u0644\u0643\u0644\u0645\u0627\u062a\n\u0645\u0646 \u062e\u0644\u0627\u0644 \u0645\u0642\u0627\u0631\u0646\u0629 \u0645\u062c\u0645\u0648\u0639\u0647\u0627 \u062f\u0627\u062e\u0644 \u0648\u062e\u0627\u0631\u062c \u0645\u062c\u0645\u0648\u0639\u0629 \u0627\u0644\u062a\u062c\u0645\u064a\u0639 \u0627\u0644\u0641\u0631\u0639\u064a\u0629.\n\n\u0644\u0645\u0642\u0627\u0631\u0646\u0629\u060c \u064a\u062a\u0645 \u0623\u064a\u0636\u064b\u0627 \u062a\u062c\u0645\u064a\u0639 \u0627\u0644\u0645\u0633\u062a\u0646\u062f\u0627\u062a \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 MiniBatchKMeans. \u062a\u062d\u0642\u0642 \u0645\u062c\u0645\u0648\u0639\u0627\u062a \u0627\u0644\u0645\u0633\u062a\u0646\u062f\u0627\u062a \u0627\u0644\u0645\u0634\u062a\u0642\u0629 \u0645\u0646 \u0645\u062c\u0645\u0648\u0639\u0627\u062a \u0627\u0644\u062a\u062c\u0645\u064a\u0639 \u0627\u0644\u0641\u0631\u0639\u064a\u0629\n\u0642\u064a\u0627\u0633 V \u0623\u0641\u0636\u0644 \u0645\u0646 \u0627\u0644\u0645\u062c\u0645\u0648\u0639\u0627\u062a \u0627\u0644\u062a\u064a \u0648\u062c\u062f\u0647\u0627 MiniBatchKMeans.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \u0627\u0644\u0645\u0624\u0644\u0641\u0648\u0646: \u0645\u0637\u0648\u0631\u064a \u0633\u0643\u0627\u064a\u0644\u0631\u0646\n# \u0645\u0639\u0631\u0641 \u0627\u0644\u062a\u0631\u062e\u064a\u0635: BSD-3-Clause\nfrom collections import Counter\nfrom time import time\n\nimport numpy as np\n\nfrom sklearn.cluster import MiniBatchKMeans, SpectralCoclustering\nfrom sklearn.datasets import fetch_20newsgroups\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.cluster import v_measure_score\n\n\ndef number_normalizer(tokens):\n    \"\"\"Map all numeric tokens to a placeholder.\n\n    For many applications, tokens that begin with a number are not directly\n    useful, but the fact that such a token exists can be relevant.  By applying\n    this form of dimensionality reduction, some methods may perform better.\n    \"\"\"\n    return (\"#NUMBER\" if token[0].isdigit() else token for token in tokens)\n\n\nclass NumberNormalizingVectorizer(TfidfVectorizer):\n    def build_tokenizer(self):\n        tokenize = super().build_tokenizer()\n        return lambda doc: list(number_normalizer(tokenize(doc)))\n\n\n# \u0627\u0633\u062a\u0628\u0639\u0627\u062f 'comp.os.ms-windows.misc'\ncategories = [\n    \"alt.atheism\",\n    \"comp.graphics\",\n    \"comp.sys.ibm.pc.hardware\",\n    \"comp.sys.mac.hardware\",\n    \"comp.windows.x\",\n    \"misc.forsale\",\n    \"rec.autos\",\n    \"rec.motorcycles\",\n    \"rec.sport.baseball\",\n    \"rec.sport.hockey\",\n    \"sci.crypt\",\n    \"sci.electronics\",\n    \"sci.med\",\n    \"sci.space\",\n    \"soc.religion.christian\",\n    \"talk.politics.guns\",\n    \"talk.politics.mideast\",\n    \"talk.religion.misc\",\n]\nnewsgroups = fetch_20newsgroups(categories=categories)\ny_true = newsgroups.target\n\nvectorizer = NumberNormalizingVectorizer(stop_words=\"english\", min_df=5)\ncocluster = SpectralCoclustering(\n    n_clusters=len(categories), svd_method=\"arpack\", random_state=0\n)\nkmeans = MiniBatchKMeans(\n    n_clusters=len(categories), batch_size=20000, random_state=0, n_init=3\n)\n\nprint(\"Vectorizing...\")\nX = vectorizer.fit_transform(newsgroups.data)\n\nprint(\"Coclustering...\")\nstart_time = time()\ncocluster.fit(X)\ny_cocluster = cocluster.row_labels_\nprint(\n    f\"Done in {time() - start_time:.2f}s. V-measure: \\\n{v_measure_score(y_cocluster, y_true):.4f}\"\n)\n\n\nprint(\"MiniBatchKMeans...\")\nstart_time = time()\ny_kmeans = kmeans.fit_predict(X)\nprint(\n    f\"Done in {time() - start_time:.2f}s. V-measure: \\\n{v_measure_score(y_kmeans, y_true):.4f}\"\n)\n\n\nfeature_names = vectorizer.get_feature_names_out()\ndocument_names = list(newsgroups.target_names[i] for i in newsgroups.target)\n\n\ndef bicluster_ncut(i):\n    rows, cols = cocluster.get_indices(i)\n    if not (np.any(rows) and np.any(cols)):\n        import sys\n\n        return sys.float_info.max\n    row_complement = np.nonzero(np.logical_not(cocluster.rows_[i]))[0]\n    col_complement = np.nonzero(np.logical_not(cocluster.columns_[i]))[0]\n    # Note: the following is identical to X[rows[:, np.newaxis],\n    # cols].sum() but much faster in scipy <= 0.16\n    weight = X[rows][:, cols].sum()\n    cut = X[row_complement][:, cols].sum() + X[rows][:, col_complement].sum()\n    return cut / weight\n\n\nbicluster_ncuts = list(bicluster_ncut(i)\n                       for i in range(len(newsgroups.target_names)))\nbest_idx = np.argsort(bicluster_ncuts)[:5]\n\nprint()\nprint(\"Best biclusters:\")\nprint(\"----------------\")\nfor idx, cluster in enumerate(best_idx):\n    n_rows, n_cols = cocluster.get_shape(cluster)\n    cluster_docs, cluster_words = cocluster.get_indices(cluster)\n    if not len(cluster_docs) or not len(cluster_words):\n        continue\n\n    # categories\n    counter = Counter(document_names[doc] for doc in cluster_docs)\n\n    cat_string = \", \".join(\n        f\"{(c / n_rows * 100):.0f}% {name}\" for name, c in counter.most_common(3)\n    )\n\n    # words\n    out_of_cluster_docs = cocluster.row_labels_ != cluster\n    out_of_cluster_docs = np.where(out_of_cluster_docs)[0]\n    word_col = X[:, cluster_words]\n    word_scores = np.array(\n        word_col[cluster_docs, :].sum(axis=0)\n        - word_col[out_of_cluster_docs, :].sum(axis=0)\n    )\n    word_scores = word_scores.ravel()\n    important_words = list(\n        feature_names[cluster_words[i]] for i in word_scores.argsort()[:-11:-1]\n    )\n\n    print(f\"bicluster {idx} : {n_rows} documents, {n_cols} words\")\n    print(f\"categories   : {cat_string}\")\n    print(f\"words        : {', '.join(important_words)}\\n\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}